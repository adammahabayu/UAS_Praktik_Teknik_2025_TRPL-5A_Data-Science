[{"DOI":"10.1155/2021/1071145","Abstract":"Forward-looking forecasting of the inflation rate could help the central bank and other government departments to better use monetary policy to stabilize prices and prevent the impact of inflation on market entities, especially for low- and middle-income groups. It can also help financial institutions and investors better make investment decisions. In this sense, the forecast of inflation rate is of great significance. The existing literature mainly uses linear models such as autoregressive (AR) and vector autoregressive (VAR) models to predict the inflation rate. The nonlinear relationship between variables and the mining of historical data information are relatively lacking. Therefore, the prediction strategies and accuracy of the existing literature need to be improved. The predictive model designed in deep learning can fully mine the nonlinear relationship between variables and process complex long-term time series dynamic information, thereby making up for the deficiencies of existing research. Therefore, this paper employs the recurrent neural networks with gated recurrent unit (GRU-RNN) model to train and analyze the Consumer Price Index (CPI) indicators to obtain inflation-related prediction results. The experimental results on historical data show that the GRU-RNN model has good performance in predicting China's inflation rate. In comparison, the performance of the proposed method is significantly better than some traditional models, showing its superior effectiveness.","Label":"1"},{"DOI":"10.1007/s43546-022-00384-2","Abstract":"Our study examined the disaggregation of inflation components in Nigeria using the stacked ensemble approach, a machine learning algorithm capable of compensating the weakness of an ensemble and a base learner with the strength of another. This approach gives flexibility of a synergistic performance of stacking each base learner and produces a formidable model that yields a high level of accuracy and predictive ability. We analyzed the test data, out-of-sample, and our analyses reveals a robust inflation prediction results. In particular, we show that food CPI is the most important driver for headline urban, and rural inflation while bread and cereals is the most important driver for food inflation in Nigeria. Also, biscuits, agric rice, garri white were found to be among the top main drivers of bread and cereal inflation. Our study further shows that some components of the CPI baskets that majorly drive inflation were assigned lower weights. Hence, attention to CPI weights only, without recourse to understanding the tipping source, may undermined a successful control of inflation in Nigeria. Tracing and tracking the source of inflation to the least sub-component will help resolve inflation problem.","Label":"1"},{"DOI":"10.1002/for.2667","Abstract":"This paper develops a dynamic factor model that uses euro area country-specific information on output and inflation to estimate an area-wide measure of the output gap. Our model assumes that output and inflation can be decomposed into country-specific stochastic trends and a common cyclical component. Comovement in the trends is introduced by imposing a factor structure on the shocks to the latent states. We moreover introduce flexible stochastic volatility specifications to control for heteroscedasticity in the measurement errors and innovations to the latent states. Carefully specified shrinkage priors allow for pushing the model towards a homoscedastic specification, if supported by the data. Our measure of the output gap closely tracks other commonly adopted measures, with small differences in magnitudes and timing. To assess whether the model-based output gap helps in forecasting inflation, we perform an out-of-sample forecasting exercise. The findings indicate that our approach yields superior inflation forecasts, both in terms of point and density predictions.","Label":"0"},{"DOI":"10.1007/s42973-021-00091-x","Abstract":"In this paper, I use a simple SIR Macro model to examine Japan’s soft lockdown policies in 2021 under the COVID-19 crisis. As real-time research, this paper consists of two parts written during two different research periods. The first part, which was originally reported in February 2021, studies the Japan’s second soft lockdown policy (state of emergency declaration) from January to March 2021. After the model is calibrated using 2020 data, the results show that a long enough lockdown can avoid future lockdowns, improving both the infection and the economy. In addition, I propose the ICU targeting policy, which keeps the number of severe patients at a constant level, mimicking the monetary policy’s inflation targeting. The model’s prediction is evaluated from an ex-post perspective in the second part, written in July 2021. I find that the model broadly captures the realized consequences of the second soft lockdown and the subsequent paths. Furthermore, the simulation is projected to the end of the pandemic under a revised scenario, incorporating the proliferation of COVID-19 variants. Finally, I discuss the effectiveness of the inverse lockdown (economic stimulus) policy in the fall of 2021 under the dynamic infection externality.","Label":"0"},{"DOI":"10.1007/s40258-012-0003-z","Abstract":"BackgroundGame theory is useful for identifying conditions under which individual stakeholders in a collective action problem interact in ways that are more cooperative and in the best interest of the collective. The literature applying game theory to healthcare markets predicts that when providers set prices for services autonomously and in a noncooperative fashion, the market will be susceptible to ongoing price inflation.ObjectivesWe compare the traditional fee-for-service pricing framework with an alternative framework involving modified doctor, hospital and insurer pricing and incentive strategies. While the fee-for-service framework generally allows providers to set prices autonomously, the alternative framework constrains providers to interact more cooperatively.MethodsWe use community-level provider and insurer data to compare provider and insurer costs and patient wellness under the traditional and modified pricing frameworks. The alternative pricing framework assumes (i) providers agree to manage all outpatient claims; (ii) the insurer agrees to manage all inpatient clams; and (iii) insurance premiums are tied to patients’ healthy behaviours.Results and ConclusionsConsistent with game theory predictions, the more cooperative alternative pricing framework benefits all parties by producing substantially lower administrative costs along with higher profit margins for the providers and the insurer. With insurance premiums tied to consumers’ risk-reducing behaviours, the cost of insurance likewise decreases for both the consumer and the insurer.","Label":"0"},{"DOI":"10.1136/tc-2021-057232","Abstract":"BACKGROUND: Between 2010 and 2020, the New Zealand (NZ) Government increased tobacco excise tax by inflation plus 10% each year. We reviewed market structure changes and examined whether NZ tobacco companies shifted excise tax increases to maintain the affordability of lower priced cigarette brands. METHODS: We cluster-analysed market data that tobacco companies supply to the NZ Ministry of Health, created four price partitions and examined the size and share of these over time. For each partition, we analysed cigarette brand numbers and market share, calculated the volume-weighted real stick price for each year and compared this price across different price partitions. We calculated the net real retail price (price before tax) for each price partition and compared these prices before and after plain packaging took effect. RESULTS: The number and market share of Super Value and Budget brands increased, while those of Everyday and Premium brands decreased. Differences between the price of Premium and Super Value brands increased, as did the net retail price difference for these partitions. Following plain packaging's implementation, Super Value brand numbers more than doubled; contrary to industry predictions, the price difference between these and higher priced brands did not narrow. CONCLUSIONS: Between 2010 and 2020, NZ tobacco companies introduced more Super Value cigarette brands and shifted excise tax increases to reduce the impact these had on low-priced brands. Setting a minimum retail price for cigarettes could curtail tobacco companies' ability to undermine tobacco taxation policies designed to reduce smoking.","Label":"1"},{"DOI":"10.1016/j.ssresearch.2019.102351","Abstract":"For decades, Western societies have experienced educational expansion accompanied by an upgrading of skills. The literature provides competing hypotheses on the consequences for educational wage returns - among them are the positional value theory, routine-biased technological change, and the social closure theory. We test these theoretical perspectives empirically on young, male full-time workers in West Germany between 1976 and 2010 in two ideal-type occupational segments using 2.34 million administrative earnings records (Sample of Integrated Labor Market Biographies, SIAB). Our findings show no credential inflation across all levels of education. Instead, the picture in both segments - negative effects of educational expansion on the returns to medium- but not high-level skills - confirms the predictions of routine-biased technological change. Wage premiums for medium-skilled workers differ between segments: the premiums worsen over time in the general segment whereas social-closure mechanisms seem to weaken this negative trend for vocational graduates in the specific segment.","Label":"0"},{"DOI":"10.1080/02664763.2020.1732885","Abstract":"When prediction intervals are constructed using unobserved component models (UCM), problems can arise due to the possible existence of components that may or may not be conditionally heteroscedastic. Accurate coverage depends on correctly identifying the source of the heteroscedasticity. Different proposals for testing heteroscedasticity have been applied to UCM; however, in most cases, these procedures are unable to identify the heteroscedastic component correctly. The main issue is that test statistics are affected by the presence of serial correlation, causing the distribution of the statistic under conditional homoscedasticity to remain unknown. We propose a nonparametric statistic for testing heteroscedasticity based on the well-known Wilcoxon's rank statistic. We study the asymptotic validation of the statistic and examine bootstrap procedures for approximating its finite sample distribution. Simulation results show an improvement in the size of the homoscedasticity tests and a power that is clearly comparable with the best alternative in the literature. We also apply the test on real inflation data. Looking for the presence of a conditionally heteroscedastic effect on the error terms, we arrive at conclusions that almost all cases are different than those given by the alternative test statistics presented in the literature.","Label":"0"},{"DOI":"10.1097/01.mlr.0000118873.10396.fc","Abstract":"OBJECTIVE: The objective of this study was to estimate the cost of eliminating the 24-month waiting period for Medicare entitlement for Social Security disabled-worker beneficiaries. There is concern that the waiting period could currently result in reduced access to health care. DATA: : The study linked Social Security and Medicare administrative records. METHODS: Social Security records were used to identify a 20% sample of disabled workers aged 61 or less and newly entitled to Social Security Disability Insurance (SSDI) in 1995 (n = 105,328). These records were linked to Medicare enrollment and claims data for 1997-2000. Cost prediction models were developed from the linked data to predict monthly Medicare costs. The prediction models were then used to estimate what Medicare costs would have been in the first 24 months of SSDI entitlement if the waiting period had been eliminated. RESULTS: Among the sample of new SSDI entitlees in 1995, 11.8% died during the waiting period, 2.1% recovered, and 86.1% became entitled to Medicare. For the first 24 months of SSDI entitlement, Medicare costs were predicted to be 10,055 US dollars per disabled worker in year 2000 dollars. Costs varied substantially by diagnostic group and whether the person died or recovered during the waiting period. CONCLUSIONS: Extrapolating from the study sample, predicted Medicare costs for the 24-month waiting period were 5.3 billion US dollars (inflation-adjusted to year 2000 dollars) for all disabled workers aged 61 or less and newly entitled to SSDI in 1995.","Label":"0"},{"DOI":"10.1016/j.mex.2021.101226","Abstract":"Money demand is one of the most important economic variables which are a critical component in appointing and choosing appropriate monetary policy, because it determines the transmission of policy-driven change in monetary aggregates to the real sector. In this paper, the data of economic indicators in Iran are presented for estimating the money demand using biogeography-based optimization (BBO) algorithm, particle swarm optimization (PSO) algorithm, and a new hybrid metaheuristic method based on biogeography-based optimization and particle swarm optimization algorithm (BBPSO). The data are used in two forms (i.e. linear and exponential) to estimate money demand values based on true liquidity, Consumer price index, GDP, lending interest rate, Inflation, and official exchange rate. The available data are partly used for finding optimal or near-optimal values of weighting parameters (1974-2013) and partly for testing the models (2014-2018). The performance of methods is evaluated using mean squared error (MSE), root mean squared error (RMSE), and mean absolute error (MAE). According to the simulation results, the proposed method (i.e. BBPSO) outperformed the other models. The findings proved that the recommended method was an appropriate tool for effective money demand prediction in Iran. These data were the result of a comprehensive look at the most influential factors for money market demand. With this method, the demand side of this market was clearly defined. Along with other markets, the consequences of economic policy could be analyzed and predicted. • The article provides a method for observing the effect of economic scenarios on the money market and the analysis obtained by this proposed method allows experts, public sector economics, and monetary economist to see a clearer explanation of the country's liquidity plan. • The method presented in this article can be beneficial for the policy makers and monetary authorities during their decision-making process.","Label":"1"},{"DOI":"10.1038/s41598-020-64506-2","Abstract":"In this paper, the annually average Defense Meteorological Satellite Program-Operational Linescan System (DMSP/OLS) night-time light data is first proposed as a surrogate indicator to mine and forecast the average housing prices in the inland capital cities of China. First, based on the time-series analysis of individual cities, five regression models with gross error elimination are established between average night-time light intensity (ANLI) and average commercial residential housing price (ACRHP) adjusted by annual inflation rate or not from 2002 to 2013. Next, an optimal model is selected for predicting the ACRHPs in 2014 of these capital cities, and then verified by the interval estimation and corresponding official statistics. Finally, experimental results show that the quadratic polynomial regression is the optimal mining model for estimating the ACRHP without adjustments in most provincial capitals and the predicted ACRHP of these cities are almost in their interval estimations except for the overrated Chengdu and the underestimated Wuhan, while the adjusted ACRHP is all in prediction interval. Overall, this paper not only provides a novel insight into time-series ACRHP data mining based on time-series ANLI for capital city scale but also reveals the potentiality and mechanism of the comprehensive ANLI to characterize the complicated ACRHP. Besides, other factors influencing housing prices, such as the time-series lags of government policy, are tested and analysed in this paper.","Label":"0"},{"DOI":"10.1371/journal.pone.0237672","Abstract":"Climate change has become intertwined with the global economy. Here, we describe the contribution of inertia to future trends. Drawing from thermodynamic principles, and using 38 years of available statistics between 1980 to 2017, we find a constant scaling between current rates of world primary energy consumption [Formula: see text] and the historical time integral W of past world inflation-adjusted economic production Y, or [Formula: see text]. In each year, over a period during which both [Formula: see text] and W more than doubled, the ratio of the two remained nearly unchanged, that is [Formula: see text] Gigawatts per trillion 2010 US dollars. What this near constant implies is that current growth trends in energy consumption, population, and standard of living, perhaps counterintuitively, are determined by past innovations that have improved the economic production efficiency, or enabled use of less energy to transform raw materials into the makeup of civilization. Current observed growth rates agree well with predictions derived from available historical data. Future efforts to stabilize carbon dioxide emissions are likely also to be constrained by the contributions of past innovation to growth. Assuming no further efficiency gains, options look limited to rapid decarbonization of energy consumption through sustained implementation of at least one Gigawatt of renewable or nuclear power capacity per day. Alternatively, with continued reliance on fossil fuels, civilization could shift to a steady-state economy, one that devotes economic production exclusively to maintining ongoing metabolic needs rather than to material expansion. Even if such actions could be achieved immediately, energy consumption would continue at its current level, and atmospheric carbon dioxide concentrations would only begin to balance natural sinks at concentrations exceeding 500 ppmv.","Label":"0"},{"DOI":"10.2139/ssrn.3042952","Abstract":"This paper studies the joint dynamics of real time U.S. inflation and the mean inflation predictions of the Survey of Professional Forecasters (SPF) on a 1968Q4 to 2017Q2 sample. The joint data generating process (DGP) is an unobserved components (UC) model of inflation and a sticky information (SI) prediction mechanism for SPF inflation predictions. We add drifting gap inflation persistence to a UC model that already has stochastic volatility (SV) afflicting trend and gap inflation. Another innovation puts a time-varying frequency of inflation forecast updating into the SI-prediction mechanism. The joint DGP is a nonlinear state space model (SSM). We estimate the SSM using Bayesian tools grounded in a Rao-Blackwellized auxiliary particle filter, particle learning, and a particle smoother. The estimates show (i) longer horizon average SPF inflation predictions inform estimates of trend inflation, (ii) gap inflation persistence is pro-cyclical, and SI inflation updating is frequent before the Volcker disinflation, and (iii) subsequently, trend inflation and its SV fall, gap inflation persistence turns counter-cyclical, and SI inflation updating becomes infrequent.","Label":"0"},{"DOI":"https://ssrn.com/abstract=1557280","Abstract":"EBRI'S BIANNUAL POLICY FORUM: This Issue Brief summarizes presentations at EBRI's 65th biannual policy forum, held in Washington, DC, on Dec. 10, 2009, on the topic, \"Employers, Workers, and the Future of Employment-Based Health Benefits.\" The forum brought together a wide range of economic, benefits, management, and labor experts to share their expertise at a time when major health reform legislation was being debated in Congress. The focus: How might this affect the way that the vast majority of Americans currently get their health insurance coverage? THE EMPLOYMENT-BASED HEALTH INSURANCE SYSTEM: Most people who have health insurance coverage in the United States get it through their job: In 2008, about 61 percent of the nonelderly population had employment-based health benefits, 19 percent were covered by public programs, 6 percent had individual coverage, and 17 percent were uninsured. DIFFERENCES, AGREEMENTS: Not surprisingly, given the deep conflicts that exist over President Obama's health reform plan and the different bills that have passed the House and Senate, benefits experts also do not agree on what \"health reform\" will mean for either workers or employers. Views ranged from \"Will anyone notice?\" to predictions of great upheaval for workers and their employers, patients and health care providers, and the entire U.S. health care system. One point of consensus among both labor and management representatives: Imposing a tax on health benefits is likely to cause major cuts in health benefits and might result in structural changes in the employment-based benefits system. A common disappointment voiced at the forum was that the initial effort to reform the delivery and cost of health care in America gradually became focused on just financing and coverage of health insurance. RECENT TRENDS: The ever-rising cost of health insurance affects different employers and workers in different ways--with small employers and low-wage workers being the most disadvantaged. With health premiums having risen almost five times as much as the overall rate of inflation since 2000, employers face unsustainable cost increases in health benefits. For a minimum-wage worker, the cost of family coverage (averaging about $13,700 a year in a small firm) exceeds their total annual income (about $11,500 a year). Small employers, if they offer health benefits at all, pay proportionately more than large employers for the same health coverage. PUBLIC OPINION: As reflected by the debate in Congress, the American public has conflicted opinions on both the U.S. health care system and on reform: Surveys find that people tend to be satisfied with the quality of their own care but not with costs and access, and a majority rates the system as fair or poor. Opinions divide sharply along partisan lines. PERSPECTIVES: While large employers tend to express continued commitment to health benefits, small employers see themselves strongly disadvantaged by the current system. Consultants report many employers privately want to drop benefits to control costs, but realize there are risks to doing so and none wants to be first. Employers express strong interest in wellness and disease management programs as a way to control costs, even though some experts say there is no evidence these work. Consumer-driven health plans are expected to continue their slow rate of growth.","Label":"0"},{"DOI":"10.1016/j.cbrev.2017.01.001","Abstract":"Expectations of inflation play a critical role in the process of price setting in the market. Central banks closely follow developments in inflation expectations to implement a successful monetary policy. The Central Bank of the Republic of Turkey (CBRT) conducts a survey of experts and decision makers in the financial and real sectors to reveal market expectations and predictions of current and future inflation. The survey is conducted every month. This paper examines the accuracy of these survey predictions using forecast evaluation techniques. We focus on both point and sign accuracy of the predictions. Although point predictions from CBRT surveys are compared with those of autoregressive models, sign predictions are evaluated on their value to a user. We also test the predictions for bias. Unlike the empirical evidence from other economies, our results show that autoregressive models outperform most of inflation expectations in forecasting inflation. This indicates that inflation expectations have poor point forecast accuracies. However, we show that sign predictions for all inflation expectations have value to a user.","Label":"0"},{"DOI":"10.23917/jep.v5i1.4030","Abstract":"The purpose of the research is to know whether inflation influences economic growth or economic growth influence inflation and to know the final prediction error of long - term equilibrium relationship between inflation and economic growth. The hypothesis presented in this research is that inflation has negative influence on economic growth and economic growth has negative influence on inflation. It is assumed that the final prediction error of long - term equilibrium relationship between inflation and economic growth has negative influence, and the final prediction error of equilibrium relationship between economic growth and inflation has negative influence. The method used in this research is causality analysis of Final Prediction Error (FPE) by using time series data of 1973 through 2002 taken from the Body of Statistic Center (BPS). It is conducted stationerity and causality test of FPE in this research. This research shows that there is one direction causality in which economic growth influences inflation.","Label":"0"},{"DOI":"10.1109/cec.2007.4424790","Abstract":"Reserve Bank of New Zealand (RBNZ) is one of many inflation-targeting central banks. The effective conduct of monetary policy requires the capacity to make accurate short and medium term predictions about price inflation. The RBNZ's prediction system is very complex, requiring many iterations and significant input from human experts. This paper investigates the capability of Genetic Programming (GP) to predict price inflation over short and medium terms. By using un-preprocessed economic time series over small intervals, the experimental results demonstrate that GP can produce predictions of price inflation with accuracy comparable to the RBNZ's official prediction system, over both short and medium terms.","Label":"1"},{"DOI":"10.1007/s12197-016-9354-x","Abstract":"The Fisher effect maintains that movements in short-term interest rates largely reflect changes in expected inflation. Since expected inflation is subject to error, we ask whether interest rates move in response to over- and under-predictions of inflation. In answering, we measure expected inflation by the consumers’ forecast of inflation derived from the Michigan Surveys of Consumers (MSC). Our findings for 1978–2013 indicate that the MSC inflation forecasts were unbiased, efficient, and directionally accurate. For 1978–2007, (i) interest rates moved downward (upward) in response to MSC over-predictions (under-predictions) of inflation, and (ii) MSC inflation forecast errors had directional predictability for interest rates. However, no link between interest rate movements and MSC inflation forecast errors is detected for 2008–2013 when monetary policy kept short-term interest rates unusually low.","Label":"0"},{"DOI":"10.1080/1331677x.2017.1314826","Abstract":"The main aim of this study is to evaluate and improve the Survey of Professional Forecasters (S.P.F.) quarterly inflation rate forecasts. According to the Diebold–Mariano test, on the horizon 1991:Q1–2015:Q1, there were no significant differences in accuracy between the four types of predictions provided by SPF (mean forecasts, median predictions, predictions of financial service providers [f1] and predictions of non-financial service providers [f2]). The main contribution is given by the use of the algorithm for stochastic search variable selection in order to construct Bayesian combined predictions. Considering the horizon 2013:Q1–2015:Q1, the proposed Bayesian combined predictions for rate of change in the quarterly average headline consumer price index (C.P.I.) level outperformed the initial experts’ expectations. The combined predictions based on the Bayesian approach and principal component analysis for core inflation and personal consumption expenditures inflation improved the accuracy of S.P.F. predictions and naïve forecasts on the horizon 2015:Q1–2016:Q1.","Label":"0"},{"DOI":"10.1111/j.1467-985x.2012.01061.x","Abstract":"Summary We use univariate and multivariate singular spectrum analyses to predict the rate of inflation as well as changes in the direction of inflation time series for the USA. We use consumer price indices and realtime chain-weighted gross domestic product price index series in these prediction exercises. Moreover, we compare our out-of-sample, h-step-ahead moving prediction results with other prediction results based on methods such as the activity-based non-accelerating inflation rate of unemployment Phillips curve, auto-regressive AR(p) model, the dynamic factors model and random-walk models with the last as a naive forecasting method. We use short-run (quarterly) and long-run (1–6 years) time windows for predictions and find that multivariate singular spectrum analysis outperforms all other competing prediction methods. Also, we confirm the results of earlier studies that prediction of the rate of inflation in the USA during the period of the ‘Great Moderation’ is less challenging compared with the more volatile inflationary period of 1970–1985.","Label":"0"},{"DOI":"10.1109/inocon57975.2023.10101073","Abstract":"Inflation is one of the main issues affecting the world economy right now, necessitating the accurate inflation prediction for the development of tools and policies by the monetary authorities to prevent extreme price volatility. Expectations of inflation influence many financial and economic actions, and this dependence motivates economists to develop techniques for precise inflation forecasting. Nearly everyone in the economy is impacted by inflation, including lending institutions, stock brokers, and corporate financial officials. In many cases, inflation determines whether a firm will accept a particular project or if banks will make a particular loan. These different economic actors can modify their financial portfolios, strategic goals, and upcoming investments if they are able to forecast changes in inflation rates. The multiple interaction economic components that depend on inflation will be better understood by economic agents operating in a business context if inflation forecasting accuracy is improved. There are numerous techniques to forecast inflation ranging from basic statistical methods to complex neural network methods. Therefore, this paper employs LSTM model to train and analyze the Consumer Price Index (CPI) indicators to obtain inflation-related prediction results. The experimental results on historical data show that the statistical model has good performance in predicting India’s inflation rate compared to deep learning methods in case of smaller dataset.","Label":"1"},{"DOI":"10.1109/isitia.2017.8124101","Abstract":"Severe inflation can cause a country's economic downturn. Therefore, inflation needs to be controlled. One of inflation control conducted by the government is predicting and calculating inflation using CPI indicators on a monthly. Prediction with monthly frequency, could be too late, because inflation has been a few days and it is not known quickly. With the development of internet technology today, various data sources related to inflation easily obtained in real-time. This data can be used for daily CPI prediction. Daily predictions allow policy makers to make better policies. CPI prediction using daily data will face challenges. The growing variants and data volumes need good computing systems. Cloud computing can be used to solve the problem. This is a preliminary research in developing daily CPI prediction model using big data and cloud computing. Here we focus on developing a daily CPI prediction model using the Support Vector Regression (SVR) method in a cloud computing. For better accuracy, we compared the kernel functions of SVR and tuning SVR parameters using the grid search and Random Search method. In addition, we compared SVR with the Random Forest method. These daily CPI predictions are simulated into cloud computing environments. From this simulation we show computation time and accuration comparisons needed if run on personal computers with cloud computing. The results showed that SVR using RBF kernel has less mse value 0.3454 in monthly prediction and 0.0095 in daily predictions. And Random Forest result is slightly different than SVR - RBF, mse value 0.0171 in daily prediction. Experiment show that running CPI prediction have less time, for 1644 data need takes 522s than PC takes 837s.","Label":"1"},{"DOI":"10.1002/jae.2784","Abstract":"Much research studies US inflation history with a trend‐cycle model with unobserved components, where the trend may be viewed as the Fed's evolving inflation target or long‐horizon expected inflation. We provide a novel way to measure the slowly evolving trend and the cycle (or inflation gap), by combining inflation predictions from the Survey of Professional Forecasters (SPF) with realized inflation. The SPF forecasts may be treated either as rational expectations (RE) or updating according to a sticky information (SI) law of motion. We estimate RE and SI state‐space models with stochastic volatility on samples of consumer price index and gross national product/gross domestic product deflator inflation and the associated SPF inflation predictions using a particle Metropolis–Markov chain Monte Carlo sampler. The trend converges to 2% and its volatility declines over time—two tendencies largely complete by the late 1990s.","Label":"0"},{"DOI":"10.1080/13504850701578835","Abstract":"This article tests the asymmetric information hypothesis using the CPI inflation forecasts of the Federal Reserve and consumers for the volatile inflationary period of 1979–1983. The Fed generally over-predicted inflation, but consumers produced unbiased forecasts with superior predictive content. In fighting inflation, the Fed was, perhaps, cautious by assigning much cost to under-predictions, but little or no cost to over-predictions. Under such an asymmetric loss function, the bias in the Federal Reserve forecast of inflation appears to be rational. However, this explanation, while plausible, cannot be substantiated from the Federal Open Market Committee (FOMC) transcripts.","Label":"0"},{"DOI":"10.18356/df5e9f55-en","Abstract":"We examine the problem of combining Mexican inflation predictions or projections provided by a biweekly survey of professional forecasters. Consumer price inflation in Mexico is measured twice a month. We consider several combining methods and advocate the use of dimension reduction techniques whose performance is compared with different benchmark methods, including the simplest average prediction. Missing values in the database are imputed by two different databased methods. The results obtained are basically robust to the choice of the imputation method. A preliminary analysis of the data was based on its panel data structure and showed the potential usefulness of using dimension reduction techniques to combine the experts’ predictions. The main findings are: the first monthly predictions are best combined by way of the first principal component of the predictions available; the best second monthly prediction is obtained by calculating the median prediction and is more accurate than the first one.","Label":"1"},{"DOI":"10.1162/003465303772815952","Abstract":"Did inflation targets reduce the level of expected inflation in Australia, Canada, New Zealand, Sweden, and the United Kingdom? In this note, predictions of forecasts by professional forecasters are constructed for five consecutive 12-month periods after the announcement of targets. These predictions use a variety of information variables known to forecasters at the time they make their forecasts. The results show that, after the announcement of targets, predicted forecasts are less than actual forecasts in Australia, Canada, New Zealand, and Sweden. This is evidence that targets reduced the level of expected inflation. No evidence of such effects is found in the United Kingdom.","Label":"0"},{"DOI":"10.2139/ssrn.1016574","Abstract":"Potential links between inflation and unemployment in Canada have been examined. No consistent Phillips curve has been found likely due to strong changes in monetary policy of the Bank of Canada. However, there were two distinct periods where linear links between inflation and unemployment could exist - before 1983 and after 1983. A linear and lagged relationship between inflation, unemployment and labor force has been obtained for Canada. Similar relationships were reported previously for the USA, Japan, France and Austria. Changes in labor force level are simultaneously reflected in unemployment and lead inflation by two years. Therefore this generalized relationship provides a two-year ahead natural prediction of inflation based on current estimates of labor force level and unemployment rate. The goodness-of-fit for the relationship is of 0.7 for the period since 1965, i.e. including the periods of high inflation and disinflation.","Label":"0"},{"DOI":"10.17016/ifdp.2003.780","Abstract":"Recent empirical work has considered the prediction of inflation by combining the information in a large number of time series. One such method that has been found to give consistently good results consists of simple equal weighted averaging of the forecasts over a large number of different models, each of which is a linear regression model that relates inflation to a single predictor and a lagged dependent variable. In this paper, I consider using Bayesian Model Averaging for pseudo out-of-sample prediction of US inflation, and find that it gives more accurate forecasts than simple equal weighted averaging. This superior performance is consistent across subsamples and inflation measures. Meanwhile, both methods substantially outperform a naive time series benchmark of predicting inflation by an autoregression.","Label":"0"},{"DOI":"10.2139/ssrn.235310","Abstract":"We examine the relationship between inflation and inflation uncertainty using a GARCH model that allows for simultaneous feedback between the conditional mean and variance of inflation. We also derive a number of theoretical econometric results and illustrate the relevance of these results with an empirical example of the US monthly inflation process. Our results show that there is strong evidence in favour of a positive bi-directional relationship between inflation and inflation uncertainty in agreement with the predictions of economic theory.","Label":"0"},{"DOI":"10.2991/assehr.k.201010.013","Abstract":"Inflation is one of macroeconomics indicator can describe the economic development of the country. Inflation is one of the important factors, the high inflation can disturb the economy a country so it has been concerned by the government. Inflation can be caused by various factors, one of them come from the money supply. Inflation in Indonesia has a...","Label":"0"},{"DOI":"10.1007/978-3-642-38279-6_21","Abstract":"The neuronal network, veritable instruments of optimal solution generating and diagnosis utilized in the field of artificial intelligence, tends to increase its spectrum of applicability reaching financial-banking predictions. This paper aims to achieve a study regarding the efficiency of applying neuronal networks, with different architectures, in the process of predicting inflation rates in Romania. Also, we will compare results estimated by applying neuronal networks with results obtained through predictions gained by applying classic econometric methods.","Label":"1"},{"DOI":"10.18267/j.pep.80","Abstract":"In 1998 the Czech National Bank (CNB) changed its monetary policy framework and started to target inflation. The article discusses main theoretical aspects of inflation targeting and some practical problems with implementation of inflation targeting. The main characteristics of the inflation and monetary targeting are described in the first and second part. The third part deals with practical issues connected with inflation targeting (number of countries using inflation targeting, quality of inflation predictions, inflation and interest rate volatility). In the final part the CNB monetary policy function is estimated and the results are compared with the theoretical assumptions of the inflation targeting.","Label":"0"},{"DOI":"10.2139/ssrn.884954","Abstract":"A two-country theoretical model is presented, showing the effects of monetary, fiscal, and supply-side disturbances on prices of primary commodities and manufactured goods, and on exchange rates. If monetary shocks dominate, then commodity prices should lead general price movements, and the level of commodity prices should be correlated with the general inflation rate. Country-specific commodity price indexes are developed for the major industrial countries. Several empirical tests broadly support the conclusions of the model. Commodity price levels tend to be cointegrated with consumer-price inflation rates. Commodity price movements contribute weakly to predictions of inflation rates but more strongly to predictions of turning points in inflation.","Label":"0"},{"DOI":"10.1002/for.1088","Abstract":"Recent empirical work has considered the prediction of inflation by combining the information in a large number of time series. One such method that has been found to give consistently good results consists of simple equal‐weighted averaging of the forecasts from a large number of different models, each of which is a linear regression relating inflation to a single predictor and a lagged dependent variable. In this paper, I consider using Bayesian model averaging for pseudo out‐of‐sample prediction of US inflation, and find that it generally gives more accurate forecasts than simple equal‐weighted averaging. This superior performance is consistent across subsamples and a number of inflation measures. Copyright © 2008 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.2139/ssrn.1018168","Abstract":"Potential links between inflation, (t), and unemployment, UE(t), in Germany have been examined. There exists a consistent (conventional) Phillips curve despite some changes in monetary policy. This Phillips curve is characterized by a negative relation between inflation and unemployment with the latter leading the former by one year: UE(t-1) = 1.50(t) + 0.116. Effectively, growing unemployment has resulted in decreasing inflation since 1971, i.e. for the period where GDP deflator observations are available. The relation between inflation and unemployment is statistically reliable with R2=0.86, where unemployment spans the range from 0.01 to 0.12 and inflation, as represented by GDP deflator, varies from -0.01 to 0.07. A linear and lagged relationship between inflation, unemployment and labor force has been also obtained for Germany. Changes in labor force level are leading unemployment and inflation by five and six year, respectively. Therefore this generalized relationship provides a natural prediction of inflation at a six-year horizon, as based upon current estimates of labor force level. The goodness-of-fit for the relationship is 0.87 for the period between 1971 and 2006, i.e. including the periods of high inflation and disinflation.","Label":"0"},{"DOI":"10.3982/qe980","Abstract":"This paper studies the joint dynamics of U.S. inflation and a term structure of average inflation predictions taken from the Survey of Professional Forecasters (SPF). We estimate these joint dynamics by combining an unobserved components (UC) model of inflation and a sticky‐information forecast mechanism. The UC model decomposes inflation into trend and gap components, and innovations to trend and gap inflation are affected by stochastic volatility. A novelty of our model is to allow for time‐variation in inflation‐gap persistence as well as in the frequency of forecast updating under sticky information. The model is estimated with sequential Monte Carlo methods that include a particle learning filter and a Rao–Blackwellized particle smoother. Based on data from 1968                     Q                     4 to 2018                     Q                     3, estimates show that (i) longer horizon average SPF inflation predictions inform estimates of trend inflation; (ii) inflation gap persistence is countercyclical before the Volcker disinflation and acyclical afterwards; (iii) by 1990 sticky‐information inflation forecast updating is less frequent than it was earlier in the sample; and (iv) the drop in the frequency of the sticky‐information forecast updating occurs at the same time persistent shocks become less important for explaining movements in inflation. Our findings support the view that stickiness in survey forecasts is not invariant to the inflation process.","Label":"0"},{"DOI":"10.26509/frbc-ec-201503","Abstract":"Looking across a range of statistical models, we consider the likely path of future inflation and the uncertainty surrounding the models' predictions. The models suggest that inflation is on a rising path, and while inflation forecast uncertainty is somewhat elevated relative to the norms of the last 20 years, core inflation uncertainty is relatively low. For both inflation rates, forecast uncertainty is much lower as of the first quarter of 2015 than it was around the Great Recession.","Label":"0"},{"DOI":"10.26509/frbc-ec-202119","Abstract":"We examine the predictive relationship between various measures of inflation expectations and future inflation. We find that the expectations of professional economists and of businesses have tended to provide more accurate predictions of future inflation than the expectations of households and of financial market participants. However, the forecasts coming from a relatively simple and popular benchmark inflation forecasting model have historically been roughly as accurate as the expectations of businesses and professional economists.","Label":"0"},{"DOI":"10.48550/arxiv.hep-ph/0111365","Abstract":"We review the prediction of inflation and the constraints on inflationary models coming from recent observations.","Label":"1"},{"DOI":"10.2139/ssrn.494384","Abstract":"This paper investigates core inflation defined as the best predictor of US inflation. I compare forecasts obtained using the weighted median consumer price index inflation rate, a trimmed mean consumer price index inflation rate, the consumer price index inflation rate and the consumer price index less food and energy inflation rate. The latter two often have been considered informative about future inflation movements. The unconditional predictions using the weighted median are more accurate than those made with the other measures. Moreover, the weighted median is a better predictor even when conditioning on real variables. These results support that the weighted median is a good measure of core inflation.","Label":"0"},{"DOI":"10.1016/0165-1765(88)90163-2","Abstract":"This paper tests the implication of the theory of optimal seigniorage that over time higher tax rates are associated with higher inflation rates and higher nominal interest rates. In particular, the study investigates whether knowledge of past tax rates improves the prediction of future nominal interest rates (or inflation) beyond predictions that are based on past nominal interest rates (or inflation) alone. This is the empirical definition of Granger causality.","Label":"0"},{"DOI":"10.2139/ssrn.596702","Abstract":"The empirical \"gravity\" equation is extremely successful in explaining bilateral trade. This paper shows how a multi-country model of specialization and costly trade (i.e. a microfounded gravity model) can be applied to explain empirical exchange rate puzzles. One such puzzle is the fact that nominal exchange rates are enormously volatile, but that this volatility does not appear to affect inflation. The gravity model is very successful in explaining this puzzle. In a sample of 25 OECD countries in the post-Bretton Woods period, the gravity prediction of inflation substantially outperforms the purchasing power parity prediction. The gravity prediction matches the volatility of actual inflation, and tracks its path closely. The superior performance of the gravity prediction is explained primarily by the fact that it takes account of the interaction of specialization with home bias. The stability of inflation in very open economies is explained in addition by the fact that the size of bilateral trade is negatively correlated with bilateral exchange rate volatility.","Label":"0"},{"DOI":"10.2139/ssrn.1024941","Abstract":"Past and future evolution of inflation, (t), and unemployment, UE(t), in Japan is modeled. Both variables are represented as linear functions of the change rate of labor force level. These models provide an accurate description for disinflation in the 1990s and deflationary period in the 2000s. In Japan, there exists a statistically reliable (R2=0.68) Phillips curve. This Phillips curve is characterized by a negative relation between inflation and unemployment and their synchronous evolution: UE(t) = -0.94(t) + 0.045. Effectively, growing unemployment has resulted in decreasing inflation since 1982. A linear and lagged generalized relationship between inflation, unemployment and labor force has been also obtained for Japan: (t) = 2.8*dLF(t)/LF(t) + 0.9*UE(t) - 0.0392. Labor force projections allow a reliable prediction of inflation and unemployment in Japan: CPI inflation will be negative (between -0.5% and -1% per year) during the next 40 years. Unemployment will increase from 4.0% in 2010 to 5.3% in 2050.","Label":"0"},{"DOI":"10.2139/ssrn.1020964","Abstract":"A crucial but often ignored element of inflation expectations is the amount of perceived inflation risk. This paper estimates the degree of uncertainty and asymmetry in the probability forecasts of the Survey of Professional Forecasters (SPF) using a new methodology. The main conclusion from our analysis is that, when monitoring inflation expectations, limiting attention to a point prediction is not sufficient. The analysis of inflation expectations should take into account inflation risks. As an example, we show that our measures of inflation risks can better explain why inflation scares happened in the bond market during the Volcker disinflation.","Label":"0"},{"DOI":"10.2139/ssrn.2676273","Abstract":"This paper constructs regime-switching models for estimating the probability of inflation returning to its relatively high levels of variability and persistence in the 1970s and 1980s. Forecasts and probabilities of extreme events from the models are evaluated against comparable estimates from other statistical models, from surveys, and from financial markets. The paper then uses the models to construct prediction intervals around Federal Reserve Board staff forecasts of PCE price inflation, combining the recent non-parametric forecast error distribution with parametric information from the model. The outer tails of the prediction intervals depend importantly on the probability inflation is in its high-variance, high-persistence regime.","Label":"0"},{"DOI":"10.48550/arxiv.2011.07920","Abstract":"We present a hierarchical architecture based on Recurrent Neural Networks (RNNs) for predicting disaggregated inflation components of the Consumer Price Index (CPI). While the majority of existing research is focused mainly on predicting the inflation headline, many economic and financial entities are more interested in its partial disaggregated components. To this end, we developed the novel Hierarchical Recurrent Neural Network (HRNN) model that utilizes information from higher levels in the CPI hierarchy to improve predictions at the more volatile lower levels. Our evaluations, based on a large data-set from the US CPI-U index, indicate that the HRNN model significantly outperforms a vast array of well-known inflation prediction baselines.","Label":"1"},{"DOI":"10.1080/00036846.2010.508729","Abstract":"The impact of inflation on Relative Price Variability (RPV) generates an important channel for real effects of inflation. This article provides first evidence on the empirical relation between inflation and RPV in the euro area. Stirred by the widespread use of inflation caps or target bands in monetary policy practice, we are particularly interested in threshold effects of inflation. In line with the predictions of monetary search models, our results indicate that expected inflation significantly increases RPV only if inflation is either very low (below 0.95% per annum (p.a.)) or very high (above 4.96% p.a.).","Label":"0"},{"DOI":"10.1080/00036840701857978","Abstract":"Many studies have undertaken separate analyses of the Fed's forecasts of real Gross Domestic Product (GDP) growth and inflation. This article presents a method for jointly evaluating the direction of change predictions of these variables. We conclude that some of the inflation forecasts, examined separately, were not valuable. However, the joint pattern of GDP and inflation projections was generally in accord with the economy's movements. ‘… directional forecasting … is now an increasingly popular metric for forecasting performance….’ (Pesaran and Timmermann, 2004, 414) ‘… directional forecasting … is now an increasingly popular metric for forecasting performance….’ (Pesaran and Timmermann, 2004, 414)","Label":"0"},{"DOI":"10.1016/j.red.2017.07.005","Abstract":"The standard search model of unemployment predicts, under realistic assumptions about household preferences, that disembodied technological progress leads to higher steady-state unemployment. This prediction is at odds with the 1970s experience of slow productivity growth and high unemployment in industrial countries. We show that introducing nominal price rigidity helps in reconciling the model's prediction with experience. Faster growth is shown to lead to lower unemployment when inflation is relatively high, as was the case in the 1970s. In general, the sign of the effect of growth on unemployment is shown to depend on the level of steady-state inflation. There is a threshold level of inflation below (above) which faster growth leads to higher (lower) unemployment. The prediction of the model is supported by an empirical analysis based on US and European data.","Label":"0"},{"DOI":"10.17016/feds.2002.01","Abstract":"It is commonly supposed in public and academic discourse that inflation and big government are related. We show that economic theory delivers such a prediction only in special cases. As an empirical matter, inflation is significantly positively related to the size of government mainly when periods of war and peace are compared. We find a weak positive peacetime time series correlation between inflation and the size of government and a negative cross-country correlation of inflation with non-defense spending.","Label":"0"},{"DOI":"10.1016/j.econlet.2017.04.018","Abstract":"Rudd and Whelan (2006) document evidence that the first-difference of inflation negatively depends on its own lag, and highlight that sticky price models emphasizing the role of firms’ forward-looking pricing behavior cannot be reconciled with the stylized fact. We show that the puzzling negative dependence of the first-difference of inflation on its own lag is consistent with the prediction of the hybrid New Keynesian Phillips Curve (NKPC) with lags of inflation, whereas, as it is argued, it is inconsistent with the prediction of both the purely forward-looking NKPC and its hybrid variant with a lag of inflation. Our theoretical results show that the negative dependence appears only when firms’ forward-looking pricing behavior is relatively more important than backward-looking behavior in determining inflation dynamics.","Label":"0"},{"DOI":"10.1145/3343485.3343496","Abstract":"A country's inflation rate and exchange rate forms a two-way relationship, whereby the former can affect the latter and vice versa. However, past researches have proven that the exchange rate affects inflation to a lesser extent. Thus, we choose to study the behaviour of exchange rate in response to inflation. While Malaysia has a relatively constant inflation rate for the past 35 years, without exceeding 10 percent, Vietnam's inflation rate is significantly higher with great fluctuations in the same duration. With this large difference in inflation rates, it would be interesting to study the affect onto the movement of the VND/MYR exchange rate. Besides observing the relationship, we are predicting the 2015 exchange rate based on historical data. This is done by fitting the data to two prediction models, the Purchasing Power Parity model and the Autoregressive model, and evaluating the most appropriate and accurate model. We found that the best prediction model is the Autoregressive model and proceeded to generate the forecasted exchange rate.","Label":"0"},{"DOI":"10.1016/j.ejpoleco.2005.09.001","Abstract":"This paper develops a model of an open economy containing both sectors in which wages are market-determined and sectors with wage-setting arrangements. A portion of the latter group of sectors coordinate their wages, taking into account that their collective actions influence the equilibrium inflation outcome in an environment in which the central bank engages in discretionary monetary policymaking. Key predictions forthcoming from this model are (1) increased centralization of wage setting initially causes inflation to increase at low degrees of wage centralization but then, as wage centralization increases, results in an inflation drop-off; (2) a greater degree of centralized wage setting reduces the inflation-restraining effect of greater central bank independence; and (3) increased openness is more likely to reduce inflation in nations with less centralized wage bargaining. Analysis of data for seventeen nations for the period 1970–1999 provides generally robust empirical support for all three of these predictions.","Label":"0"},{"DOI":"10.1111/jmcb.12105","Abstract":"We show that with a unit root in inflation, the new Keynesian Phillips curve (NKPC) implies an unobserved components model with a stochastic trend component and an inflation gap. Our empirical results suggest that with an increase in trend inflation during the Great Inflation, the response of inflation to real economic activity decreases and the persistence of the inflation gap increases due to an increase in the persistence of the unobserved stationary component. These results are in line with the predictions of Cogley and Sbordone (2008), who show that the coefficients of the NKPC are functions of time‐varying trend inflation.","Label":"0"},{"DOI":"10.1016/j.ememar.2015.05.003","Abstract":"This study investigates the asymmetric and time-varying causalities between inflation and inflation uncertainty in South Africa within a conditional Gaussian Markov switching vector autoregressive (MS-VAR) model framework. The MS-VAR model is capable of determining both the sign and direction of causality. We account for the nonlinear, long memory and seasonal features of the inflation series simultaneously by measuring inflation uncertainty as the conditional variance of inflation generated by recursive estimation of a Seasonal Fractionally Integrated Smooth Transition Autoregressive Asymmetric Power GARCH (SEA-FISTAR-APGARCH) model using monthly data for the period 1921:01 to 2012:12. The recursive, rather than full-sample, estimation allows us to obtain a time-varying measure of uncertainty and better mimics the real-time scenario faced by economic agents and/or policy makers. The inferred probabilities from the four-state MS-VAR model show evidence of a time-varying relationship. The conditional (i.e. lead–lag) and regime-prediction Granger causality provide evidence in favor of Friedman's hypothesis. This implies that past information on inflation can help improve the one-step-ahead prediction of inflation uncertainty but not vice versa. Our results have some important policy implications.","Label":"0"},{"DOI":"10.2478/jcbtp-2020-0004","Abstract":"Abstract Inflation expectations are very important when it comes to monetary policy and its decisions. In countries which are applying inflation targeting, inflation expectations reflect prediction of economic agents of movement of inflation rate in mid and long term. Anchored inflation expectations and their movements within target tolerance band are pointing to effectiveness of the inflation targeting strategy. Consistent with the best international practice, after introducing the inflation targeting regime in January 2009, the National Bank of Serbia began monitoring and analysing inflation expectations of economic agents (financial sector, corporate sector, trade unions, and households). The aim of this paper is to analyse inflation expectations in Serbia, but also to give a comparative analysis of inflation expectation of other countries which are using inflation targeting and floating exchange rate, as is the case of the National Bank of Serbia.","Label":"0"},{"DOI":"10.1016/j.econlet.2018.05.001","Abstract":"In this article a novel methodology for building core inflation measures is proposed based on the k-means clustering machine learning algorithm. This new methodology is explored using Mexican CPI data in the spirit of getting a clear signal and having good predictions of the inflationary process based on selecting items with low volatility and assigning them to clusters. The results show that the core inflation built captures better the inflation signal and also outperforms the short-term inflation forecasts obtained by the trimmed means method and the core inflation excluding food and energy.","Label":"1"},{"DOI":"10.1016/j.ribaf.2017.07.171","Abstract":"The fact that predictions of inflation can create a self-fulfilling expectations trap creates a powerful incentive to balance output and inflation. Media reports, as a source of public information, contribute to formation of inflation expectations. We investigate how media coverage and possible media bias may affect inflation expectations using the sticky information paradigm and Bayesian learning theory. The findings suggest that the quantity of media reports may or may not affect inflation expectations, depending on media bias and the economic climate. However, media bias explicitly expands the deviation between expected and actual inflation, making media content more important to manage than volume of coverage for controlling inflation expectations.","Label":"1"},{"DOI":"10.1016/j.jmoneco.2008.01.007","Abstract":"If countries specialize in imperfectly substitutable goods, trade costs increase the share of expenditure devoted to domestic output, reducing the exposure of consumer price inflation to exchange rate changes. I present a multi-country flexible-price model where expenditure shares are inversely related to trade costs through a gravity equation. In this setting, consumer price inflation can be approximated as an expenditure-share-weighted average of the contributions to inflation from all countries. I use data from 24 OECD countries, 1970–2003, to estimate a structural gravity model. I combine the fitted expenditure shares from the estimation with actual data on exchange rates to construct predictions of inflation. The behavior of these predictions indicates that trade costs can explain both qualitatively and quantitatively the failure of exchange rate volatility to feed into inflation.","Label":"0"},{"DOI":"10.1016/j.euroecorev.2020.103506","Abstract":"We present a simple model with financial frictions where inflation increases the cost faced by firms holding liquid assets to hedge risky production against expenditure shocks. Inflation tilts firms’ technology choice away from innovative activities and toward safer but return-dominated ones, and therefore reduces long-run growth. Our theory makes specific predictions about how the severity of this adverse effect depends on industry characteristics. We test these industry-specific predictions in a generalized difference-in-differences framework with novel harmonized firm-level data from 139 developing countries and a long panel of U.S. firms, overcoming small sample problems constraining previous work. We find that inflation affects the composition but not the overall quantity of investment. Moreover, consistent with our theoretical mechanism, we find that innovating firms display a stronger dependence on liquid assets, which, in turn, are negatively related to inflation.","Label":"0"},{"DOI":"10.1109/isise.2012.37","Abstract":"Inflation forecasting plays an important role in monetary policy and daily life. This study focuses on developing an inflation support vector regression (SVR) model to forecast CPI. Money gap and CPI historical data are utilized to perform forecasts. Furthermore, grid search method is applied to select the parameters of SVR. In addition, this study examines the feasibility of applying SVR in inflation forecasting by comparing it with back-propagation neural network and linear regression. The result shows SVR provides a promising alternative to inflation prediction.","Label":"1"},{"DOI":"10.1111/j.0008-4085.2004.00257.x","Abstract":"Abstract. Sticky price models based on menu costs predict that countries with high trend inflation should have (i) smaller impact effects of demand shocks on output and (ii) less persistent output fluctuations, relative to low‐trend inflation countries. These predictions are tested, controlling for changes in trend inflation, using a country‐specific approach. The results do not support the second prediction. That prediction is also not robust to a modified measure of trend inflation that excludes episodes of hyperinflation. These findings suggest that while price stickiness is important for understanding short‐run impact effects, real propagation mechanisms may drive persistence in output fluctuations. Viscosité des prix, inflation tendancielle, et dynamique de production: une analyse transversale. Les modèles de prix visqueux fondés sur des menus de coûts prédisent que les pays qui ont une tendance à une forte inflation devraient (i) avoir de plus petits impacts des chocs en provenance de la demande sur la production et (ii) engendrer des fluctuations de production moins persistantes, en comparaison avec ce qui se produit dans les pays à faible inflation. Des études antérieures (utilisant une approche en deux étapes) ont supporté ces résultats. Cet article utilise une approche qui est spécifique au pays et permet que le comportement des prix s’ajuste en réponse à des chocs dans la demande et à des changements dans l’inflation tendancielle, et donc prend mieux en compte la nature des données. Les résultats ne supportent pas la seconde hypothèse. De plus, cette prédiction n’est pas assez robuste face à une mesure modifiée de l’inflation moyenne pour exclure les épisodes d’hyperinflation quand on utilise l’approche en deux étapes. Ces résultats suggèrent que si la viscosité des prix est importante pour comprendre les effets à court terme, les mécanismes de propagation des impacts réels sont déterminants dans la persistance des fluctuations du niveau du produit.","Label":"0"},{"DOI":"10.1002/for.1235","Abstract":"This paper first shows that survey‐based expectations (SBE) outperform standard time series models in US quarterly inflation out‐of‐sample prediction and that the term structure of survey‐based inflation forecasts has predictive power over the path of future inflation changes. It then proposes some empirical explanations for the forecasting success of survey‐based inflation expectations. We show that SBE pool a large amount of heterogeneous information on inflation expectations and react more flexibly and accurately to macro conditions both contemporaneously and dynamically. We illustrate the flexibility of SBE forecasts in the context of the 2008 financial crisis. Copyright © 2011 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.21111/fij.v3i2.2286","Abstract":"The use of data that has long stored in the information system can be utilized to know information that supports decision-making activities. One of them is sales transaction data. During this time, the case of sales transaction data is rarely analyzed to be taken into consideration when taking a decision, such as analyzing the transaction data. The prediction analysis of the transaction should analyze the inflation factors that affect earnings. It is predicted that inflation will lead to an increase in the price of basic necessities which can also lead to employers tend to raise the price of products to be sold. Therefore, this research focuses to analyze sales transaction data at a restaurant. Where the data used is data that has been stored for 3 years within the period 2015-2017. The purpose of this study is to determine the quality comparison of sales predictions of sales between years with regard to inflation based on changes in selling prices. The result of the study is known that the prediction of goods sold with actual data in the following year is quite significant and the prediction of income is not affected by the inflation based on price comparison.","Label":"1"},{"DOI":"10.1016/j.econmod.2017.12.014","Abstract":"Inflation in Europe fell sharply after the Great Recession in 2008 due to the severity of the financial crisis. However, the post-recession sharp decline in inflation in 2012 was not anticipated by most observers. This paper seeks to explain this behavior of eurozone core inflation, which we do by estimating a Phillips curve with professional forecasters' inflation expectations. Doing so produces inflation predictions that closely match the observed behavior of core inflation, whereas lagged expectations fail to predict the 2012 disinflation. Furthermore, we find that short-term inflation expectations are most relevant for the euro area, rather than longer-term ones. Indeed the evidence suggests that the ECB's inflation anchor of 2% has weakened since the Great Recession, and is something that should cause policymakers a lot of concern.","Label":"0"},{"DOI":"10.1016/j.econmod.2012.03.016","Abstract":"This paper provides new evidence on inflation persistence before and after the European Monetary Union (EMU). Taking into account fractional integration of inflation, we confirm that inflation dynamics differed considerably across Euro area countries before the start of EMU. Since 1999, however, results obtained from panel estimation indicate that the degree of long run inflation persistence has converged. In line with theoretical predictions, we find that the persistence of inflation has significantly decreased in the Euro area, probably as a result of the more effective monetary policy of the ECB.","Label":"0"},{"DOI":"10.1057/978-1-349-95189-5_2087","Abstract":"Abstract             There have been a number of changes in monetary policy rules in the United States and UK since the early 1960s. The Lucas critique says that this should induce changes in the equilibrium law of motion. This article summarizes reduced-form evidence on the evolving law of motion for inflation in the USA and the UK. Since the 1970s, inflation has become lower on average, less volatile and less persistent. There is also less uncertainty about the central bank’s long-run target for inflation.","Label":"0"},{"DOI":"10.1016/s0304-3932(01)00049-6","Abstract":"A growing theoretical literature describes mechanisms whereby even predictable increases in the rate of inflation interfere with the ability of the financial sector to allocate resources effectively. This paper empirically assesses these predictions. The evidence indicates that there is a significant, and economically important, negative relationship between inflation and both banking sector development and equity market activity. Further, the relationship is nonlinear. As inflation rises, the marginal impact of inflation on banking lending activity and stock market development diminishes rapidly. Moreover, we find evidence of thresholds. For economies with inflation rates exceeding 15 percent, there is a discrete drop in financial sector performance. Finally, while the data indicate that more inflation is not matched by greater nominal equity returns in low-inflation countries, nominal stock returns move essentially one-for-one with marginal increases in inflation in high-inflation economies.","Label":"0"},{"DOI":"10.48550/arxiv.1102.5405","Abstract":"An empirical model is presented linking inflation and unemployment rate to the change in the level of labour force in Switzerland. The involved variables are found to be cointegrated and we estimate lagged linear deterministic relationships using the method of cumulative curves, a simplified version of the 1D Boundary Elements Method. The model yields very accurate predictions of the inflation rate on a three year horizon. The results are coherent with the models estimated previously for the US, Japan, France and other developed countries and provide additional validation of our quantitative framework based solely on labour force. Finally, given the importance of inflation forecasts for the Swiss monetary policy, we present a prediction extended into 2050 based on official projections of the labour force level.","Label":"0"},{"DOI":"10.1002/jid.3380020305","Abstract":"In this paper we argue that the relationship between inflation and the accuracy of inflation predictions in high‐inflation countries, such as those in Latin America, is ambiguous. Several empirical studies have measured a positive link between the level of inflation and its variability, suggesting that inflation uncertainty rises with the level of inflation. Others have noted, however, that variability measures may not capture uncertainty and that the evidence on a positive relationship between inflation and its uncertainty is weak. In fact, the relationship could, in principle, be negative and we present here some evidence from Latin America that supports partially this latter view. The reason for the potentially negative effect of inflation on inflation uncertainty is that in a high‐inflation environment economic agents invest more resources in generating accurate inflation forecasts and in developing instruments capable of reducing the uncertainty costs of high inflation. In general, however, there is no clear relationship between inflation and its predictability.","Label":"0"},{"DOI":"10.24042/djm.v5i3.14093","Abstract":"This paper discusses the prediction of the inflation rate in Indonesia. The data used in this research is assumed to have both linear and non-linear components. The ARIMA model is selected to accommodate the linear component, while the ANFIS method accounts for the non-linear component in the inflation data. Thus, the model is known as the hybrid ARIMA-ANFIS model. The clustering method is performed in the ANFIS model using Fuzzy C-Mean (FMS) with a Gaussian membership function. Consider 2 to 6 clusters. The optimal number of clusters is assessed according to the minimum value of the error prediction. To evaluate the performance of the fitted hybrid ARIMA-ANFIS model, it can be compared to the classical ARIMA model and with the ordinary ANFIS model. The result reveals that the best ARIMA model for inflation prediction in Indonesia is ARIMA(2,1,0). In the hybrid ARIMA(2,1,0)-ANFIS model, two clusters are optimal. Meanwhile, the optimum number of clusters in the ordinary ANFIS model is six. The comparison of prediction accuracy confirms that the hybrid model is superior to the individual model alone of either ARIMA or ANFIS model.","Label":"1"},{"DOI":"10.1002/j.2325-8012.2005.tb00665.x","Abstract":"A testable implication of the modern quantity theory of money, when viewed as a theory of inflation, is the joint hypothesis that (i) there is a one‐to‐one positive relationship between inflation and the money stock growth rate, (ii) there is a one‐to‐one negative relationship between inflation and the aggregate output growth rate, and (iii) there are no other determinants of inflation besides the money stock and aggregate output expansion rates. This implication is the theory's linchpin prediction. A recent prior study published in this journal examines cross‐country data and reports that this hypothesis cannot be rejected. The present study reexamines the prior study's data and finds that the joint hypothesis is decisively rejected, an unpleasant finding from a monetarist perspective. The article then goes on to propose an alternative to the prior study's model of the inflation process and reports findings that are, from the perspective of a monetarist, at least mildly pleasant.","Label":"0"},{"DOI":"10.17016/feds.2019.042","Abstract":"We explore the consequences of losing confidence in the price-stability objective of central banks by quantifying the inflation and deflationary biases in inflation expectations. In a model with an occasionally binding zero-lower-bound constraint, we show that an inflation bias as well as a deflationary bias exist as a steady-state outcome. We assess the predictions of this model using unique individual-level inflation expectations data across nine countries that allow for a direct identification of these biases. Both inflation and deflationary biases are present (and sizable) in inflation expectations of these individuals. Among the euro-area countries in our sample, we can document significant differences in perceptions of the European Central Bank's objectives, despite having a common monetary policy.","Label":"0"},{"DOI":"10.2139/ssrn.2321281","Abstract":"We propose a new framework for understanding the effectiveness of central bank announcements when firms have heterogeneous inflation expectations. Expectations are updated through social dynamics and, with heterogeneity, not all firms choose to operate, putting downward pressure on realized inflation. Our model rationalizes why countries stuck at the zero lower bound have had a hard time increasing inflation with- out being aggressive. The same model also predicts that announcing an abrupt target to disinflate will cause inflation to undershoot the target whereas announcing gradual targets will not. We present new empirical evidence that corroborates this prediction.","Label":"0"},{"DOI":"10.1080/00036840600771247","Abstract":"Several recent studies have focused on the predictive power of the yield spread for future economic activity. The current paper reformulates the work of Estrella and Mishkin (1998) by focusing on the usefulness of monetary variables for generating probability predictions of rising or falling real GDP growth and inflation. Besides redefining the dependent variables, the independent monetary variables are allowed to include lagged information. Also, the current paper considers the usefulness of the Divisia monetary aggregates in the context of probit models for predicting the probability that real GDP growth or inflation will be increasing","Label":"0"},{"DOI":"10.1057/9780230599338_3","Abstract":"An important question that has been asked extensively in the financial economics literature is whether nominal returns contain market assessments of expected and unexpected inflation rates, and whether common stocks are an effective hedge against inflation. However, theoretical attempts to examine the relation between stock returns and inflation diverge. While some studies found a significant negative relationship between unexpected inflation and stock returns (Bodie 1976, Jaffe and Mandelker 1976, Nelson 1976, Fama and Schwert 1977, Fama 1981, Schwert 1981), others found no significant relationship (Pearce and Roley 1985, Hardouvelis 1987, McQueen and Roley 1993). In theses studies, unexpected inflation was created from time series estimation of expected inflation, from the difference between nominal interest rats and inflation, or from experts’ predictions.","Label":"0"},{"DOI":"10.1257/aer.20171066","Abstract":"Sticky price models featuring heterogeneous firms and systematic firm-level productivity trends deliver radically different predictions for the optimal inflation rate than their popular homogenous-firm counterparts: (i) the optimal steady-state inflation rate generically differs from zero and (ii) inflation optimally responds to productivity disturbances. We show this by aggregating a heterogeneous-firm model with sticky prices in closed form. Using firm-level data from the US Census Bureau, we estimate the historically optimal inflation path for the US economy: the optimal inflation rate ranges between 1 percent and 3 percent per year and displays a downward trend over the period 1977–2015. (JEL C51, D24, D25, E31, E52)","Label":"0"},{"DOI":"10.2139/ssrn.1761545","Abstract":"An empirical model is presented linking inflation and unemployment rate to the change in the level of labour force in Switzerland. The involved variables are found to be cointegrated and we estimate lagged linear deterministic relationships using the method of cumulative curves, a simplified version of the 1D Boundary Elements Method. The model yields very accurate predictions of the inflation rate on a three year horizon. The results are coherent with the models estimated previously for the US, Japan, France and other developed countries and provide additional validation of our quantitative framework based solely on labour force. Finally, given the importance of inflation forecasts for the Swiss monetary policy, we present a prediction extended into 2050 based on official projections of the labour force level.","Label":"0"},{"DOI":"10.2139/ssrn.1362580","Abstract":"This paper uses the European Monetary Union (EMU) as a natural experiment to investigate whether more effective monetary policy reduces the persistence of inflation. Taking into account the fractional integration of inflation, we confirm that inflation dynamics differed considerably across Euro area countries before the start of EMU. Since 1999, however, results obtained from panel estimation indicate that the degree of long run inflation persistence has converged. In line with theoretical predictions, we find that the persistence of inflation has significantly decreased in the Euro area probably as a result of the more effective monetary policy of the ECB.","Label":"0"},{"DOI":"10.1353/jda.2011.0005","Abstract":"In this study, we argue that institutional rigidities contribute to the inflation rates in Bangladesh. Using annual data covering the period 1982-2005 and incorporating three new measures of institutional rigidities, we estimate an inflation model by ARDL and OLS techniques. The results do confirm our prediction that higher degree of institutional rigidities leads to higher inflation rate in Bangladesh. Evidence also suggests that inflation is unlikely to be \"monetary phenomenon\" in Bangladesh. The results are reliable and robust to the inclusion of alternative measures of institution, money supply, real economic activities, and estimation techniques.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2022.04.009","Abstract":"We present a hierarchical architecture based on recurrent neural networks for predicting disaggregated inflation components of the Consumer Price Index (CPI). While the majority of existing research is focused on predicting headline inflation, many economic and financial institutions are interested in its partial disaggregated components. To this end, we developed the novel Hierarchical Recurrent Neural Network (HRNN) model, which utilizes information from higher levels in the CPI hierarchy to improve predictions at the more volatile lower levels. Based on a large dataset from the US CPI-U index, our evaluations indicate that the HRNN model significantly outperforms a vast array of well-known inflation prediction baselines. Our methodology and results provide additional forecasting measures and possibilities to policy and market makers on sectoral and component-specific price changes.","Label":"1"},{"DOI":"10.2139/ssrn.965444","Abstract":"We develop a method of quantifying the uncertainty surrounding the estimates of the fundamental inflation implied by the New Keynesian Phillips Curve (NKPC). The uncertainty is represented as a band around the fundamental inflation, and encompasses the sampling uncertainty of both the estimates of the structural parameters and the estimates of the VAR used to form a projection of real marginal costs. An empirical application on UK and US data confirms that fundamental inflation tracks actual inflation reasonably well in both countries. For the United Kingdom the confidence band is sufficiently narrow, relative to the sample variance of inflation, to identify a number of periods where the predictions of the NKPC do not fully capture movements in actual inflation. In contrast, considerable uncertainty surrounds the estimates of fundamental inflation for the United States.","Label":"0"},{"DOI":"10.1016/j.jmacro.2008.10.003","Abstract":"This paper considers a model of an open economy in which the degree of income-tax progressivity influences the interaction among openness, central bank independence, and the inflation rate. Our model suggests that an increase in the progressivity of the tax system induces a smaller response in real output to a change in the price level. This implies that increased income-tax progressivity reduces the equilibrium inflation rate and that the effect of increased income-tax progressivity on inflation is smaller when the central bank places a higher weight on inflation or when there is greater openness. Examination of cross-country inflation data provides empirical support for these key predictions.","Label":"0"},{"DOI":"10.1080/09603107.2011.587771","Abstract":"Campbell and Vuolteenaho (CV, 2004) empirically decompose the S&P 500's dividend yield from 1927 to 2002 to derive a measure of residual mispricing attributed to inflation illusion. They argue that the strong positive correlation between the mispricing component and inflation is strong evidence for the inflation illusion hypothesis. We find evidence for structural instability in their prediction equation for the excess return. We apply the same decomposition approach to the data before and after 1952, and find that the correlation between inflation and the mispricing component is close to zero in the post-war period, when inflation and the dividend yield are strongly positively correlated. The post-war data do not support the inflation illusion hypothesis as the explanation for the positive correlation between inflation and dividend yields.","Label":"0"},{"DOI":"10.1051/shsconf/202112903034","Abstract":"Research background: Unemployment and inflation are among the basic macroeconomic indicators of the national economy. Both these phenomena are inextricably linked to market economy and have undisputable social and economic impacts on the population of the countries where these processes take place. The relationship between the inflation and unemployment can be expressed by means of Philips curve.   Purpose: The objective of the research is to compile Philips’s curve for the years 2000-2021 and compare the resulting curve with the initial short-run Philips curve.   Methods: The validity of the mutual relationship between unemployment and inflation is examined using the method of neural networks. The data on inflation and unemployment rate are available from the period of 31 January 2020 and 28 February 2021. The data on inflation were obtained from the database of the Czech Statistical Office; the data on unemployment, from the official websites of the Czech National Bank.   Findings & Value added: During the period under review, unemployment rate and inflation fluctuated constantly. Currently, both variables have stabilized at around 3%. Compared the long-term trend, in the years 2008-2009, the inflation rate was higher than unemployment rate. The analysis performed shows that the actual Philips curve for the Czech Republic in the period under review does not copy the initial short-run Philips curve, which indicates that the prediction of inflation rate development cannot be based on the development of unemployment rate, and the development of inflation rate cannot be a basis for exact prediction of unemployment rate development.","Label":"1"},{"DOI":"10.1007/978-981-16-2380-6_50","Abstract":"Inflation is one of the critical parameters that indicate a country’s economic position. Therefore, maintaining it at a stable level is one of the objectives of any country’s financial regulator. In Sri Lanka, the Central Bank of Sri Lanka (CBSL) is mandated to formulate policies to achieve desired inflation targets that reflect in price indices, mainly the Colombo Consumer Price Index (CCPI). The effectiveness of these policies depends on the accuracy of projections obtained by such CCPI models. Hence, regulators continuously attempt to develop models that are more accurate, flexible, and stable in their predictions. At present, economic data modeling has taken a new turn around the globe with the introduction of Machine Learning (ML) algorithms. ML approach, although is promising, is not yet extensively explored in the context of the Sri Lankan economy. The study attempts to address this gap by constructing six different types of tuned ML models to compare and arrive at the best model for CCPI-based inflation prediction in Sri Lanka. It also presents a rationally selected combination of predictor variables, specialized for the Sri Lankan economic environment. The results of the study indicate that support vector regression is the best model in terms of prediction power to achieve the said objective. This study also recommends it as a model that is highly flexible and resistant to any future modifications.","Label":"1"},{"DOI":"10.48550/arxiv.2209.14737","Abstract":"We implement traditional machine learning and deep learning methods for global tweets from 2017-2022 to build a high-frequency measure of the public's sentiment index on inflation and analyze its correlation with other online data sources such as google trend and market-oriented inflation index. We use manually labeled trigrams to test the prediction performance of several machine learning models(logistic regression,random forest etc.) and choose Bert model for final demonstration. Later, we sum daily tweets' sentiment scores gained from Bert model to obtain the predicted inflation sentiment index, and we further analyze the regional and pre/post covid patterns of these inflation indexes. Lastly, we take other empirical inflation-related data as references and prove that twitter-based inflation sentiment analysis method has an outstanding capability to predict inflation. The results suggest that Twitter combined with deep learning methods can be a novel and timely method to utilize existing abundant data sources on inflation expectations and provide daily indicators of consumers' perception on inflation.","Label":"1"},{"DOI":"10.54691/bcpbm.v44i.4811","Abstract":"Since January 2020, UK faced a serious epidemic and this COVID had a significant impact on the UK' s economy. In order to make the UK's economy recovered, Bank of England set the monetary and fiscal policy and injected many liquidity into the market to stimulate public's buying demand. After around one and a half years, the inflation grew alongside with the UK economy growth and finally the inflation has reached a historical high level over the past few decade. This essay mainly gather the information from different UK's data website, some news website and bank of England’s official website to introduce the recent inflation and interest rate in UK, analyze the reasons of nowadays high inflation, presented the central bank's recent policy and discussed the prediction of the future inflation and central bank’s policy towards the high inflation. The main findings are that the previous' bank of England’s policy during the COVID-19 period and Russia and Ukraine were the mainly causes and reasons for the nowadays' high and continuous inflation. For the prediction, the inflation in UK is forecast to continue increasing in the short period of time (the end of 2022 and the early of 2023) and it will decrease since the start of late 2023 and be back to the normal stage. Bank of England will continue increasing the bank rate to battle the inflation in the short period of time and then stop add bps and gradually make the bank rate back to the normal value.","Label":"0"},{"DOI":"10.1111/j.1538-4616.2009.00259.x","Abstract":"Survey data on household expectations of inflation are routinely used in economic analysis, yet it is not clear how accurately households are able to articulate their expectations in survey interviews. We propose an alternative approach to recovering households' expectations of inflation from their consumption expenditures. We show that these expectations measures have predictive power for consumer price index (CPI) inflation. They are better predictors of CPI inflation than household survey responses and more highly correlated with professional inflation forecasts, except for highly educated consumers, consistent with the view that more educated consumers are better able to articulate their expectations. We also document that households' inflation expectations respond to inflation news, as measured by the unpredictable component of inflation predictions in the Survey of Professional Forecasters. The response to inflation news tends to increase with households' level of education, consistent with the existence of constraints on household's ability to process this information.","Label":"0"},{"DOI":"10.1080/758518039","Abstract":"A technique developed for evaluating the market timing of financial managers was previously applied to GNP forecasts. This paper demonstrates that a similar procedure may be used to determine whether inflation forecasts are valuable.","Label":"0"},{"DOI":"10.2139/ssrn.2854067","Abstract":"This paper studies the forecasting ability of various Phillips curve specifications in a pseudo out-of-sample exercise for Swedish inflation over the period 1980-2014. Three measures of inflation are considered –– headline inflation, underlying inflation, GDP deflator inflation, in addition to different activity variables, various econometric specifications and different sample periods. Although the results indicate heterogeneity in individual model performance and evidence of model instability, in general, the Phillips curve models improve inflation forecasts against the random walk benchmark for both headline inflation and underlying inflation, and fail to beat the random walk benchmark for GDP deflator inflation. Phillips curve forecasts beat the random walk benchmark especially for 2004-2013. The monetary regime change in 1993 from exchange rate targeting to inflation targeting is also taken into account. The results suggest that for all Phillips curve models and all three inflation measures, the performance of the Phillips curve depends on whether the data used for making the predictions was under the inflation targeting regime or not. Univariate forecasting models perform well for the fixed exchange rate regime period, but the Phillips curve models are useful under the inflation targeting regime.","Label":"0"},{"DOI":"10.2139/ssrn.3292395","Abstract":"We develop an asset-pricing model with endogenous corporate policies that explains how inflation jointly impacts real asset prices and corporate default risk. Our model includes two empirically grounded nominal frictions: fixed nominal coupons and sticky profitability. Taken together, these two frictions result in higher real equity prices and credit spreads when inflation falls. An increase in inflation has opposite effects, but with smaller magnitudes. In the cross section, the model predicts the negative impact of inflation on real equity values is stronger for low leverage firms. We find empirical support for the model predictions.","Label":"0"},{"DOI":"10.11114/aef.v10i1.5821","Abstract":"We implement traditional machine learning and deep learning methods for global tweets from 2017-2022 to build a high-frequency measure of the public’s sentiment index on inflation and analyze its correlation with other online data sources such as google trend and market-oriented inflation index. We use manually labeled trigrams to test the prediction performance of several machine learning models (logistic regression, random forest etc.) and choose Bert model for final demonstration. Then, we sum daily tweets’ sentiment scores gained from Bert model to obtain the predicted inflation sentiment index, and we further analyze the regional and pre/post covid patterns of these inflation indexes. Lastly, we take other empirical inflation-related data as references and prove that twitter-based inflation sentiment analysis method has an outstanding capability to predict inflation. The results suggest that Twitter combined with deep learning methods can be a novel and timely method to utilize existing abundant data sources on inflation expectations and provide daily indicators of consumers’ perception on inflation.","Label":"1"},{"DOI":"10.26509/frbc-ec-202306","Abstract":"Using a model based on staff research, the Cleveland Fed's website provides daily nowcasts—or near-term predictions—of multiple US inflation measures for public use. In this Commentary, we compare the historical predictive accuracy of the model behind those inflation nowcasts with the accuracy of inflation nowcasts coming from competing sources: surveys of professional forecasters and alternative statistical models. We find that our inflation nowcasts have performed relatively well in these comparisons, both over a long sample and a short sample that focuses on the period since the start of the COVID-19 pandemic.","Label":"1"},{"DOI":"10.2139/ssrn.3290745","Abstract":"We develop an asset-pricing model with endogenous corporate policies that explains how inflation jointly impacts real asset prices and corporate default risk. Our model includes two empirically grounded nominal frictions: fixed nominal coupons and sticky profitability. Taken together, these two frictions result in higher real equity prices and credit spreads when inflation falls. An increase in inflation has opposite effects, but with smaller magnitudes. In the cross section, the model predicts the negative impact of inflation on real equity values is stronger for low leverage firms. We find empirical support for the model predictions.","Label":"0"},{"DOI":"10.1007/s43546-022-00376-2","Abstract":"This study estimates the threshold level of inflation for Kenya using 49 years of annual time series data for the period 1971 to 2019. First, the estimated threshold level of inflation was obtained using the threshold regression method and, second, by use of an augmented regression model with inflation at structural breaks. Lastly, an econometric analysis of the restricted parametric model was used to verify the validity of each of the estimated threshold levels of inflation obtained from the two techniques. The threshold regression method estimated a statistically significant threshold inflation rate of 5.83%. An augmented regression model with inflation at structural breaks predicted a statistically insignificant threshold inflation rate of 5.7%. The restricted parametric model established a statistically significant positive effect and negative effect for the threshold inflation of 5.8% and 5.7%, respectively. At threshold inflation of 5.8% and 5.7%, a unit increase in inflation improved GDP growth by 2.89% and decreased GDP growth by 3.29%, respectively. Therefore, the estimated threshold inflation of 5.8% obtained by the threshold regression method gives a better prediction than the estimated threshold inflation of 5.7%. The study recommends that the central bank of Kenya pursues inflation below 5.83% to boost economic growth.","Label":"0"},{"DOI":"10.4038/sjae.v19i2.4649","Abstract":"The relationship between inflation rate and inflation volatility has attracted more attention by theoretical and empirical macroeconomists. Empirical studies on the relationship between food inflation and food inflation variability is scarce in the literature. This study examines the intertemporal dynamic linkages between food price inflation and its volatility in the context of Sri Lanka. The empirical evidence derived from the monthly data for the period from 2003M1 to 2017M12 for Sri Lanka. Food price inflation is defined as log difference of food price series. The volatility of a food price inflation is measured by conditional variance generated by the FIGARCH model. Granger causality tests show that food inflation seems to exert positive impact on inflation variability. Hence, the findings of the study supports the Friedman hypothesis in both cases of consumer food price inflation and wholesale food price inflation. This implies that past information on food inflation can help improve the one-step-ahead prediction of food inflation variability but not vice versa. Our results have some important policy implications for the design of monetary policy, thereby promoting macroeconomic stability.","Label":"0"},{"DOI":"10.1016/s0014-2921(02)00237-4","Abstract":"This paper studies the proposition that an inflation bias can arise in a setup where a central banker with asymmetric preferences targets the natural unemployment rate. Preferences are asymmetric in the sense that positive unemployment deviations from the natural rate are weighted more (or less) severely than negative deviations in the central banker's loss function. The bias is proportional to the conditional variance of unemployment. The time-series predictions of the model are evaluated using data from G7 countries. Econometric estimates support the prediction that the conditional variance of unemployment and the rate of inflation are positively related.","Label":"0"},{"DOI":"10.25126/jitecs.202051173","Abstract":"Inflation is a indicator which illustrated the economics condition of a country. This moneter phenomenom is signed with the increase of price in entire case. It can cause an effect for political sector which impact to economic stability in a nation. The importance of inflation control is very important due to the high and unstable of inflation will cause negative impact  to economic and social in society.  One of the solutions to control the inflation rate is predicting the inflation rate. This research using SVR as machine learning that is being optimized by GA as evolutionary agorithm as predicting method. SVR can solve nonlinear regression problems to linear regression using Kernel function that easy to implement. But, in SVR there is no general rule to set the parameters of SVR. Therefore, this research proposed to use GA to optimize the parameters of SVR. GA can solve the optimization problems in various research of economics prediction problem. Based on the testing that has been conducted, GA-SVR generate the MSE value is 0.03767, lower than SVR basic method is 0.053158. It proves that GA-SVR method can be utilized for predicting.","Label":"1"},{"DOI":"10.1111/infi.12087","Abstract":"In this paper we analyse the utility of international measures of inflation in predicting local ones. To that end, we consider a set of 31 OECD economies for which monthly inflation data are available. Three main conclusions emerge. First, there is an important share of countries for which relatively robust evidence of predictability is found for both core and headline inflation. Second, the share of countries for which there is evidence of robust predictability is about the same for core and headline inflation, although gains in root‐mean‐squared prediction error are higher for headline inflation. Third, while the evidence indicates that an international inflation factor may be a useful predictor for several countries, it also indicates that, for many countries as well, predictability is either questionable, undetectable, non‐robust or simply non‐existent.","Label":"0"},{"DOI":"10.1016/j.econmod.2010.02.011","Abstract":"In this paper we examine the dynamics of the link between inequality and inflation from a political economy perspective. We consider a simple dynamic general equilibrium model in which agents vote over the desired inflation rate in each period, and inequality is persistent. Inflation in our model is a mechanism of redistribution, and we find that the link between inequality and inflation within any period or over time depends on institutional and preference related parameters. Furthermore, we find that differences in the initial distributions of wealth can yield a diverse set of patterns for the evolution of the inflation and inequality link. Relative to existing literature, our model leads to more precise predictions about the inflation–inequality correlation. To that end, results in the extant empirical literature on the inflation and inequality link need to be interpreted with caution.","Label":"0"},{"DOI":"10.2139/ssrn.3065179","Abstract":"Time-variation in disagreement about inflation expectations is a stylized fact in surveys, but little is known on how disagreement interacts with the efficacy of monetary policy. This paper fills this gap in providing theoretical predictions of monetary policy shocks for different levels of disagreement and testing these empirically. When disagreement is high, a dispersed information New Keynesian model predicts that a contractionary monetary policy shock leads to a short-run rise in inflation and inflation expectations, whereas both decline when disagreement is low. Estimating a smooth-transition model on U.S. data shows significantly different responses in inflation and inflation expectations consistent with theory.","Label":"0"},{"DOI":"10.4284/sej.2009.76.1.146","Abstract":"This article provides new evidence on the empirical relationship between inflation and relative prices in the United States. In line with the predictions of recent monetary search models, we find that the impact of expected inflation on relative price variability (RPV) has disappeared during the recent period when inflation expectations have been stabilized on a low level. Endogenous break‐point tests are applied to identify the timing and to confirm the significance of the changing role of inflation for RPV. The empirical findings are robust with respect to different price indices, disaggregation levels, and measurement concepts.","Label":"0"},{"DOI":"10.1093/ei/cbg016","Abstract":"Inflation has been low when productivity growth has been high. This occurs because the Federal Reserve has not adjusted nominal income growth in response to changes in productivity growth, implying that an acceleration in trend productivity growth leads to a deceleration in inflation. The model's predictions are confirmed: (1) Inflation should fall when trend productivity growth rises, and (2) nominal income and wage growth should not change with trend productivity. The model also implies that productivity growth enters a Phillips curve relationship as a proxy for inflation expectations. Thus, estimates of the NAIRU should fall when productivity growth accelerates.","Label":"0"},{"DOI":"10.2139/ssrn.3980337","Abstract":"Predictions of oil prices reaching $100 per barrel during the winter of 2021/22 have raised fears of persistently high inflation and rising inflation expectations for years to come. We show that these concerns have been overstated. A $100 oil scenario of the type discussed by many observers, would only briefly raise monthly headline inflation, before fading rather quickly. However, the short-run effects on headline inflation would be sizable. For example, on a year-over-year basis, headline PCE inflation would increase by 1.8 percentage points at the end of 2021 under this scenario, and by 0.4 percentage points at the end of 2022. In contrast, the impact on measures of core inflation such as trimmed mean PCE inflation is only 0.4 and 0.3 percentage points in 2021 and 2022, respectively. These estimates already account for any increases in inflation expectations under the scenario. The peak response of the 1-year household inflation expectation would be 1.2 percentage points, while that of the 5-year expectation would be 0.2 percentage points.","Label":"0"},{"DOI":"10.1111/j.1468-2362.2010.01268.x","Abstract":"This paper evaluates the hypothesis that globalization has increased the role of international factors and decreased the role of domestic factors in the inflation process in industrial economies. Towards that end, we estimate standard Phillips curve inflation equations for 11 industrial countries and use these estimates to test several predictions of the globalization and inflation hypothesis. Our results provide little support for this hypothesis. First, the estimated effect of foreign output gaps on domestic consumer price inflation is generally insignificant and often of the wrong sign. Second, we find no evidence that the trend decline in the sensitivity of inflation to the domestic output gap observed in many countries owes to globalization. Finally, and most surprisingly, our econometric results indicate no increase over time in the responsiveness of inflation to import prices for most countries.","Label":"0"},{"DOI":"10.2139/ssrn.73079","Abstract":"The menu-cost models of price adjustment developed by Ball and Mankiw (1994; 1995) predict that short-run movements in inflation should be positively related to the skewness and the variance of the distribution of disaggregated relative-price shocks in each period. We test these predictions on Canadian data using the distribution of changes in disaggregated producer prices to measure the skewness and standard deviation of relative-price shocks. We find the Canadian data, both in the context of partial correlations and standard price Phillips curve equations, are highly supportive of the predictions that arise from the menu-cost models. Indeed, we find that the positive relationship between inflation and the skewness of the distribution of relative-price shocks is one of the most robust features of the Canadian Phillips curve and significantly improves our ability to explain inflation dynamics.","Label":"0"},{"DOI":"10.1017/s1365100517000372","Abstract":"I use a two-country dynamic stochastic general equilibrium (DSGE) model with a nonzero steady-state inflation to study monetary policy in transition economies. In particular, my analysis focuses on whether inflation targeting is based on a consumer price index (CPI) or its producer counterpart, producer price index (PPI). This issue is specifically relevant for transition economies as they might be subject to Balassa–Samuelson effects arising from trading in international markets. Under these circumstances, domestic inflation is possibly higher than imported inflation, hence targeting PPI inflation may prove more effective in influencing domestic macroeconomic variables than targeting CPI inflation. Using a Bayesian methodology, I find that the central banks of three Eastern European countries (namely, the Czech Republic, Hungary, and Poland) are likely to target PPI inflation rather than CPI inflation. This result is in line with the theoretical predictions in the literature, and is robust across several Taylor-type rules.","Label":"0"},{"DOI":"10.54097/hbem.v11i.8104","Abstract":"What people anticipate inflation to be in the future is known as inflation expectations. These future inflation expectations are significant because they have an impact on people's actions now, which in turn has an impact on inflation in the future. It is crucial to get the inflation expectation as close to the central bank's target as possible because doing so makes it easier for the bank to achieve its goal of inflation. This study tries to explore the inflation expectations in the European region and how they change during the pandemic and post-pandemic periods. The paper also offers a future prediction regarding the inflation expectation. In order to forecast the level of expected future inflation, the study conducts a comparative analysis including the GDP, unemployment rate, and consumer price index. In the end, it was discovered that future inflation expectations are typically less firmly anchored and higher than the central bank's target. The study's conclusion also suggests a possible way to make the expectation more certain.","Label":"0"},{"DOI":"10.1108/eb008050","Abstract":"The purpose of this paper is to show that three factors, the location, the direction and magnitude of variations in the unemployment rate, will affect the actual rate of inflation. A specific prediction of the expectations‐augmented trade‐off relation between unemployment and inflation may then be derived by considering how the rate of inflation ought to change in the course of a hypothetical unemployment cycle","Label":"0"},{"DOI":"10.1016/b978-0-12-680050-0.50017-9","Abstract":"A simple regression between the rate of inflation as the independent variable and the rate of growth of GNP as the dependent will be meaningless in the case of total GNP, because the long-term rate of growth of the Argentine economy has been fairly constant, and will show a positive association in the case of per capita GNP. But because this kind of naive econometrics is not very illuminating, the issue of the influence of inflation on growth is presented from the predictions offered by economic analysis based on the behavior of the government observed in the Argentine case, given the existence of inflation and the corresponding behavior of the private sector. The chapter discusses the costs of inflation and explains one of the costs of inflation, that is, repressed inflation; it discusses the relationship between inflation and growth. The movement from repressed to open inflation lies along the road to sustained price stability.","Label":"0"},{"DOI":"10.1007/s00181-015-1041-9","Abstract":"In this paper we build forecasts for Chilean year-on-year inflation using both multivariate and univariate time series models augmented with different measures of international inflation. We consider two versions of international inflation factors. The first version is built using year-on-year inflation of 18 Latin American countries (excluding Chile). The second version is built using year-on-year inflation of 30 OECD countries (excluding Chile). We show sound in-sample and pseudo out-of-sample evidence indicating that these international factors do help forecast Chilean inflation at several horizons by reducing the root-mean squared prediction error of our benchmarks models. Our results are robust to a number of sensitivity analyses. Several transmission channels from international to domestic inflation are also discussed. Finally, we provide some comments about the implications of our findings for the conduction of domestic monetary policy.","Label":"0"},{"DOI":"10.1002/jae.2836","Abstract":"Using a novel, nationally representative dataset containing the expectations of over 300,000 Australians, individuals are shown to form expectations in a manner inadequately explained by popular expectation mechanisms. Approximately one in five individuals form inflation expectations that are negatively related to their own‐income changes, even after accounting for their level of optimism regarding future economic conditions and their observation of economic news. These individuals are more likely to be engaged in manual labour and to be on lower income brackets. The inflation expectations of such individuals rise, even as Phillips curve predictions of inflation fall. The findings are particularly important for inflation dynamics during economic downturns when large numbers of consumers are likely to heavily increase their inflation expectations, potentially resulting in large inflation surprises.","Label":"0"},{"DOI":"10.2139/ssrn.2580491","Abstract":"The purpose of this paper is to answer the three questions in the title. Using a large monthly survey of businesses, we investigate the inflation expectations and uncertainties of firms. We document that, in the aggregate, firm inflation expectations are very similar to the predictions of professional forecasters for national inflation statistics, despite a somewhat greater heterogeneity of expectations that we attribute to the idiosyncratic cost structure firms face. We also show that firm inflation expectations bear little in common with the \"prices in general\" expectations reported by households. Next we show that, during our three-year sample, firm inflation expectations appear to be unbiased predictors of their year-ahead observed (perceived) inflation. We also show that firms know what they don’t know — that the accuracy of firm inflation expectations is significantly and negatively related to their uncertainty about future inflation. And lastly, we demonstrate, by way of a cross-sectional Phillips curve, that firm inflation expectations are a useful addition to a policymaker’s information set. We show that firms’ inflation perceptions depend (importantly) on their expectations for inflation and their perception of firm-level slack.","Label":"0"},{"DOI":"10.48550/arxiv.2202.13793","Abstract":"The relationship between inflation and predictors such as unemployment is potentially nonlinear with a strength that varies over time, and prediction errors error may be subject to large, asymmetric shocks. Inspired by these concerns, we develop a model for inflation forecasting that is nonparametric both in the conditional mean and in the error using Gaussian and Dirichlet processes, respectively. We discuss how both these features may be important in producing accurate forecasts of inflation. In a forecasting exercise involving CPI inflation, we find that our approach has substantial benefits, both overall and in the left tail, with nonparametric modeling of the conditional mean being of particular importance.","Label":"1"},{"DOI":"10.1080/000368496327606","Abstract":"An inaccurate forecast of inflation is costlier to economic agents when the inflation rate is high and volatile. In this situation, the use of more sophisticated and information-oriented forecasting models become economically efficient. We test this hypothesis by analysing the forecasting accuracy of vector auto-regressive (VAR), auto-regressive integrated moving average (ARIMA) and static expectation models. We use Canadian data and divide the post-sample forecasting period into four sub-periods, based on high/low and volatile/stable inflation. Prediction errors are compared for both short-term and long-term forecasts. Finally, the paper proposes a portfolio approach for obtaining a more accurate forecast of inflation.","Label":"0"},{"DOI":"10.1016/0164-0704(90)90053-d","Abstract":"The effects on aggregate demand of redistributions of wealth due to unanticipated inflation are typically ignored by macroeconomists. This paper uses the overlapping generations model extended to three periods to show, under plausible assumptions, that an unanticipated increase in inflation results in a decline in aggregate demand. Further this implies that the ex ante real interest rate will decline in response to past unanticipated inflation. This prediction of the model provides an explanation of the results of empirical studies which find that nominal interest rates rise less than one-for-one with anticipated inflation.","Label":"0"},{"DOI":"10.4028/www.scientific.net/amr.805-806.1434","Abstract":"Among the supply shocks on inflation, energy is one of the most important. In order to reflect energy condition’s impact on inflation comprehensively, referring the financial condition index, we construct China’s energy condition index by bring in 3 variables: China’s energy price, consumption and production. The empirical analysis’s result shows that the index has an ideal prediction to China’s inflation.","Label":"0"},{"DOI":"10.2139/ssrn.3562060","Abstract":"Previous studies have stressed that inflation dynamics exhibit a substantial dispersion across sectors. Using US producer price data, we present evidence that sectoral inflation persistence is negatively correlated with market concentration, which is difficult to reconcile with the prediction of the standard model of monopolistic competition. To explain the data, we incorporate imperfect common knowledge into the monopolistic competition model introduced by Melitz and Ottaviano (2008). In the model, strategic complementarity among firms increases as market concentration decreases. Because higher strategic complementarity generates greater inflation persistence, our model successfully replicates the observed negative correlation between inflation persistence and market concentration across sectors.","Label":"0"},{"DOI":"10.2139/ssrn.2210310","Abstract":"We examine the predictive ability, the consistency properties and the possible driving forces of inflation expectations, using a survey conducted in Spain by PwC among a panel of experts and entrepreneurs. When analysing the headline inflation rate, our results suggest that the PwC panel has some forecasting ability for time horizons from 3 to 9, improving when it comes to predict the core inflation rate. Nevertheless, the results indicate that predictions made by survey participants are neither unbiased nor efficient predictors of future inflation rates, regardless of the measures of inflation used. As for the consistency properties of the inflation expectations formation process, we find that panel members form stabilising expectations in the case of the headline inflation rate, both in the short and in the long-run, although in the case of the core inflation rate, consistency remains indeterminate. Finally, we find that inflation expectations are very persistent and that they appear to incorporate the information content of some macroeconomic variables (current core inflation and growth rate, the USD/EUR exchange rate, the ECB inflation target and changes in the ECB official short-term interest rate).","Label":"0"},{"DOI":"10.2139/ssrn.1931020","Abstract":"This paper takes up the issue of the flexibility of inflation targeting regimes, with the specific goal of determining whether the monetary policy of the Bank of England, which has a formal inflation target, has been any less flexible than that of the Federal Reserve, which does not have such a target. The empirical analysis uses the speed of inflation forecast convergence, estimated from professional forecasters' predictions at successive forecast horizons, to gauge the perceived flexibility of the central bank's response to macroeconomic shocks. Based on this criterion, there is no evidence to suggest that the Bank of England's inflation target has compelled it to be more aggressive in pursuit of low inflation than the Federal Reserve.","Label":"0"},{"DOI":"10.1111/jmcb.12896","Abstract":"Price inflation in the U.S. has been slow to pick up in the last two decades. We show that this missing inflation can be traced to a growing disconnect between unemployment and core goods inflation. We exploit rich industry‐level data to show that weakening pass‐through from wages to prices in the goods‐producing sector is an important source of the slow inflation pickup. We develop a theory where markups and pass‐through depend on firms' market shares and show that increased import competition and rising market concentration reduce pass‐through from wages to prices. We find strong empirical support for these predictions.","Label":"0"},{"DOI":"10.1016/j.jebo.2021.10.026","Abstract":"Previous studies have stressed that inflation dynamics exhibit substantial dispersion across sectors. Using US producer price data, we present evidence that sectoral inflation persistence is negatively correlated with market concentration, which is difficult to reconcile with the prediction of the standard model of monopolistic competition. To better explain the data, we incorporate imperfect common knowledge into the monopolistic competition model introduced by Melitz and Ottaviano (2008). In the model, pricing complementarity among firms increases as market concentration decreases. Because higher pricing complementarity generates greater inflation persistence, our model successfully replicates the observed negative correlation between inflation persistence and market concentration across sectors.","Label":"0"},{"DOI":"10.1016/j.jmacro.2003.10.003","Abstract":"Theoretical models of the relationship between inflation and markup focus on the markup of price on marginal costs in contrast with empirical models that typically concentrate on the markup on unit costs. Using nearly 50 years of quarterly United States data we identify a strong negative long-run relationship between inflation and both measures of the markup. We derive the theoretical link between the two measures and empirically verify our prediction that the two inflation cost coefficients should not differ from each other significantly. We conclude that the long-run trade-off between inflation and markup does not depend on the particular measure of the markup used.","Label":"0"},{"DOI":"10.1016/j.euroecorev.2012.01.004","Abstract":"Monetary search theory implies that the real effects of inflation via its impact on price dispersion depend on the level of search costs and, thus, on the level of market integration. For less integrated markets, the inflation–price dispersion nexus is predicted to be asymmetrically V-shaped which results in an optimal inflation rate above zero. For highly integrated markets with low search costs, however, the impact of inflation on price dispersion should only be small. Using price data of the European Union member states, this paper tests and confirms these predictions of monetary search theory.","Label":"0"},{"DOI":"10.2139/ssrn.2722440","Abstract":"The paper uses dynamic quantile regressions to estimate and forecast the conditional distribution of euro-area inflation. As in a Phillips curve relationship we assume that inflation quantiles depend on past inflation, the output gap, and other determinants, namely oil prices and the exchange rate. We find significant time variation in the shape of the distribution. Overall, the quantile regression approach describes the distribution of inflation better than a benchmark univariate trend-cycle model with stochastic volatility, which is known to perform very well in forecasting inflation. In an out-of-sample prediction exercise, the quantile regression approach provides forecasts of the conditional distribution of inflation that are superior, overall, to those produced by the benchmark model. Averaging the distribution forecasts of the different models improves robustness and in some cases results in the greatest accuracy of distributional forecasts.","Label":"1"},{"DOI":"10.2139/ssrn.1548062","Abstract":"This paper reports graphical and statistical evidence that the inflation targeting regimes in Canada and the UK - but not in Australia, New Zealand, or Sweden - actually resemble price-level targeting. In particular, the price level closely tracks the path implied by the inflation target, and the time-series predictions of the \"bygones-are-bygones\" version of inflation targeting are rejected by the data in favor of those implied by price-level targeting. These results indicate heterogeneity in the actual application of inflation targeting across countries and, for Canada and the UK, imply that the characterization of inflation targeting as a policy where shocks are accommodated is at odds with the data. Moreover, up to extent that their current policies already resemble price-level targeting, the welfare gains of replacing inflation with (explicit) price-level targeting are likely to be small.","Label":"0"},{"DOI":"10.1111/coep.12156","Abstract":"Using U.S. data from 1950 to 2010, we analyze to what extent inflation raises the incidence of property crime. To match our theoretical predictions, we consider different types of property crime (larceny, burglary, motor vehicle theft, and robbery) and broad and narrow definitions of inflation separately. We control for the state of the business cycle and demographic changes over time explicitly. Unobserved or difficult‐to‐measure determinants of property crime are captured through a stochastic‐trend specification within a state‐space framework. We find a robust statistical link between inflation and each of the four property crime rates. Our findings are robust to alternative definitions of inflation and the inclusion or exclusion of different control variables. In terms of policy, our findings suggest that monetary policy that creates inflation has costly spillover effects. (JEL J10, J11)","Label":"0"},{"DOI":"10.1111/jmcb.12142","Abstract":"We explore empirically the theoretical prediction that public information acts as a focal point in the context of the U.S. monetary policy. We aim at establishing whether the publication of Federal Open Market Committee (FOMC) inflation forecasts affects the cross‐sectional dispersion of private inflation expectations. Our main finding is that publishing FOMC inflation forecasts has a negative effect on the cross‐sectional dispersion of private current‐year inflation forecasts. This effect is found to be robust to another survey data set and to various macroeconomic controls. Moreover, we find that the dispersion of private inflation forecasts is not affected by the dispersion of views among FOMC members.","Label":"0"},{"DOI":"10.1093/qje/qjv037","Abstract":"Abstract                   How do individuals form expectations about future inflation? We propose that individuals overweight inflation experienced during their lifetimes. This approach modifies existing adaptive learning models to allow for age-dependent updating of expectations in response to inflation surprises. Young individuals update their expectations more strongly than older individuals since recent experiences account for a greater share of their accumulated lifetime history. We find support for these predictions using 57 years of microdata on inflation expectations from the Reuters/Michigan Survey of Consumers. Differences in experiences strongly predict differences in expectations, including the substantial disagreement between young and old individuals in periods of highly volatile inflation, such as the 1970s. It also explains household borrowing and lending behavior, including the choice of mortgages.","Label":"1"},{"DOI":"10.1111/jori.12434","Abstract":"Ignoring the effects of inflation in retirement planning can have severe consequences for an individual's future financial well‐being. Yet, many pension funds do not communicate inflation‐related information, presumably for the fear of reduced contributions once the members understand how low the “real” return on saving for retirement is. As an alternative prediction, the provision of inflation information could increase pension contributions, because it reveals possible pension shortfalls. In cooperation with a major German pension fund, we conduct a field experiment, in which we vary the inflation information provided to the fund members, to explore this important issue. Among all participants, we find mostly positive but insignificant effects of the inflation information on pension contributions. Among those participants who voluntarily changed their pension contributions after the experimental intervention, the provision of inflation information significantly raises the likelihood of increasing pension contributions.","Label":"0"},{"DOI":"10.2139/ssrn.3037397","Abstract":"Which level of inflation should Central Banks be targeting? We investigate this issue in the context of a simplified Agent Based Model of the economy. Depending on the value of the parameters that describe the behaviour of agents (in particular inflation anticipations), we find a rich variety of behaviour at the macro-level. Without any active monetary policy, our ABM economy can be in a high inflation/high output state, or in a low inflation/low output state. Hyper-inflation, deflation and \"business cycles\" between coexisting states are also found. We then introduce a Central Bank with a Taylor rule-based inflation target, and study the resulting aggregate variables. Our main result is that too-low inflation targets are in general detrimental to a CB-monitored economy. One symptom is a persistent under-realisation of inflation, perhaps similar to the current macroeconomic situation. Higher inflation targets are found to improve both unemployment and negative interest rate episodes. Our results are compared with the predictions of the standard DSGE model.","Label":"0"},{"DOI":"10.2139/ssrn.4017367","Abstract":"Can monetary policy stimulate consumption through inflation expectations? We study how US consumers revise inflation expectations and planned consumption in response to monetary policy shocks using VAR models, where we identify exogenous policy shocks with interest rate surprises around FOMC announcements. Based on survey data, we construct measures of changes in planned consumption conditional on how consumers update their inflation expectations. Expansionary policy shocks tend to increase planned consumption conditional on higher expected inflation outside the zero lower bound (ZLB), but the effect is small. At the ZLB, consumers increasingly plan to reduce consumption if they expect higher inflation. The responses to contractionary shocks are generally less systematic. Overall, we find only limited evidence suggesting that policy-induced variations in inflation expectations are associated with adjustments of consumption plans that are in line with the predictions of standard macroeconomic models.","Label":"0"},{"DOI":"10.5018/economics-ejournal.ja.2018-15","Abstract":"Abstract Which level of inflation should Central Banks be targeting? The authors investigate this issue in the context of a simplified Agent Based Model of the economy. Depending on the value of the parameters that describe the behaviour of agents (in particular inflation anticipations), they find a rich variety of behaviour at the macro-level. Without any active monetary policy, our ABM economy can be in a high inflation/high output state, or in a low inflation/low output state. Hyper-inflation, deflation and “business cycles” between coexisting states are also found. The authors then introduce a Central Bank with a Taylor rule-based inflation target, and study the resulting aggregate variables. The main result is that too-low inflation targets are in general detrimental to a CB-monitored economy. One symptom is a persistent under-realization of inflation, perhaps similar to the current macroeconomic situation. Higher inflation targets are found to improve both unemployment and negative interest rate episodes. The results are compared with the predictions of the standard DSGE model.","Label":"0"},{"DOI":"10.1017/s1365100523000020","Abstract":"Abstract Can monetary policy stimulate consumption through inflation expectations? We study how US consumers revise inflation expectations and readiness to spend in response to monetary policy shocks using a structural vector-autoregressive model, where we identify exogenous policy shocks with interest rate surprises around FOMC announcements. Based on survey data, we construct measures of changes in consumers’ readiness to spend conditional on how consumers update their inflation expectations. Expansionary policy shocks tend to increase readiness to spend conditional on higher expected inflation outside the zero lower bound (ZLB), but the effect is small. At the ZLB, consumers increasingly reduce their readiness to spend if they expect higher inflation. Overall, we find only limited evidence suggesting that policy-induced variations in inflation expectations are associated with adjustments that are in line with the predictions of standard macroeconomic models.","Label":"0"},{"DOI":"10.1080/03796205.1986.12128930","Abstract":"This paper predicts the impact of changes in the administered retail price of petrol on the rate of inflation in South Africa. It relies upon the recorded effects of the increase in the price of petrol in 1979 on the rate of inflation as the basis for estimation. A model of inflation is derived for the period before the petrol price increase of 1979, which is used to infer what the rate of inflation would have been without the petrol price increase. The difference between the predictions of this model and the actual rate of inflation after the petrol price increase of 1979 is then regarded as the petrol price effect and used as the basis for predicting the rate of inflation after a petrol price increase.","Label":"0"},{"DOI":"10.2139/ssrn.3397935","Abstract":"In this paper, I derive a Behavioral-Attention Phillips Curve (BAPC) based on the theory of behavioral inattention. This Phillips Curve features both an output gap slope and an inflation expectation slope that vary with attention and inflation uncertainty. During periods of high inflation uncertainty, firms in the economy endogenously pay higher attention to prices and demand, making the Phillips Curve steeper (with respect to the output gap) and more forward-looking. The BAPC rationalizes why inflation stays low in advanced economies in recent years.Using novel measures of inflation uncertainty constructed from surveys of inflation expectation, I show that the new Phillips Curve performs better both in-sample and out-of-sample than the traditional Phillips Curve with constant slope. Particularly, the BAPC does not generate the counterfactual prediction of large disinflation after the 2008-2009 Financial Crisis as do traditional Phillips Curves.","Label":"0"},{"DOI":"10.1515/1558-3708.1944","Abstract":"A plethora of models of learning has been developed and studied in macro-economic models in recent years. In this paper we will try to discriminate between these learning models by running laboratory experiments with incentivized human subjects. Participants predict inflation rates for 50 successive periods in a standard overlapping generations model and are rewarded on the basis of their forecasting accuracy. The information set for each participant contains the past inflation rates and the participant's own past predictions which, in turn, determine the actual inflation rate. We consider two treatments, with a low and a high level of monetary growth, respectively. We find that the level of convergence to the monetary steady state is significantly lower and volatility of inflation rates higher in the second treatment. Constant gain learning algorithms, such as adaptive expectations with a low adjustment parameter, seem to provide a better description of the experimental data than decreasing gain algorithms, such as (ordinary) least squares learning. Moreover, many participants switch between prediction strategies during the experiment on the basis of poor performance of their initial prediction strategy.","Label":"1"},{"DOI":"10.4995/carma2020.2020.11322","Abstract":"In this paper we use high frequency multidimensional textual news data and propose an index of inflation news. We utilize the power of text mining and its ability to convert large collections of text from unstructured to structured form for in-depth quantitative analysis of online news data. The significant relationship between the household’s inflation expectations and news topics is documented and the forecasting performance of news-based indices is evaluated for different horizons and model variations. Results suggest that with optimal number of topics a machine learning model is able to forecast the inflation expectations with greater accuracy than the simple autoregressive models. Additional results from forecasting headline inflation indicate that the overall forecasting accuracy is at a good level. Findings in this paper support the view in the literature that the news are good indicators of inflation and are able to capture inflation expecta-tions well.","Label":"1"},{"DOI":"10.1016/j.rie.2007.12.001","Abstract":"The menu-costs model developed by Ball and Mankiw (BM) [Ball, L., Mankiw, N.G., 1994. Asymmetric price adjustment and economic fluctuations. Economic Journal 104 (423), 247–261; Ball, L., Mankiw, N.G., 1995. Relative-Price Changes as Aggregate supply shocks. Quarterly Journal of Economics 110 (1), 161–193] predicts that inflation is positively related to the skewness of price changes distribution. We test this prediction in different inflationary contexts: Spain (1975–2002) and Argentina (1960–1989). We find a positive inflation–skewness relationship in both countries at low inflation, even though the mean annual inflation rates were very different: 2.2% for Spain and 23% for Argentina. Therefore, the threshold of low inflation under which the menu-costs model is suitable is determined endogenously, and it depends on the inflationary experience of each economy. In the higher inflation periods skewness is not significant. Finally, our results suggest that the menu-costs model is not suitable beyond certain threshold of inflation.","Label":"0"},{"DOI":"10.1002/for.2277","Abstract":"Recent literature has suggested that macroeconomic forecasters may have asymmetric loss functions, and that there may be heterogeneity across forecasters in the degree to which they weigh under‐ and over‐predictions. Using an individual‐level analysis that exploits the Survey of Professional Forecasters respondents’ histogram forecasts, we find little evidence of asymmetric loss for the inflation forecasters. Copyright © 2013 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.1007/978-981-16-3153-5_17","Abstract":"Variations of inflation rate possess a diverse influence on the economic growth of any country. Inflation rate control can be accommodated to stabilize the financial aspect’s condition, including the political area. The way to restrain the inflation rate is the prediction of the inflation rate. This paper proposes forecasting the inflation rate by applying machine learning algorithms: support vector regression (SVR), random forest regressor (RFR), decision tree, AdaBoosting, gradient boosting, and XGBoost. These algorithms are employed since the predicting value is nonlinear and complex. Moreover, the regression and boosting algorithms confer good accuracy, as inflation is a frequent dynamic variable that depends on several factors. The models show decent accuracy using the elements consumer price index (CPI), food, non-food, clothing-footwear, and transportation. Among the models, AdaBoost retrospectives the most desirable outcome with the lowest MSE value of 0.041.","Label":"1"},{"DOI":"10.1016/j.jmacro.2020.103259","Abstract":"In a fully micro-founded New Keynesian framework, we characterize an analytical relationship between average inflation and oil price volatility by solving the rational expectations equilibrium of the model up to second order of accuracy. The model shows that higher oil price volatility induces higher levels of average inflation. We also show that when oil has low substitutability in the production function, the higher the weight the central bank assigns to inflation in the policy rule, the lower the level of average inflation is. The analytical solution further indicates that, for a given level of oil price volatility, average inflation is higher when marginal costs are convex in oil prices, the Phillips Curve is convex, and the degree of relative price dispersion is higher. The evolution of inflation during the 70s and 80s is consistent with the prediction of the model.","Label":"0"},{"DOI":"10.2139/ssrn.2371727","Abstract":"In this paper we build forecasts for Chilean year-on-year inflation using simple time-series models augmented with different measures of international inflation. Broadly speaking, we construct two families of international inflation factors. The first family is built using year-on-year inflation of 18 Latin American (LA) countries (excluding Chile). The second family is built using year-on-year inflation of 30 OECD countries (excluding Chile). We show sound in-sample and pseudo out-of-sample evidence indicating that these international factors do help forecast Chilean inflation at several horizons. Incorporating the international factors reduce the Root Mean Squared Prediction Error of pure univariate SARIMA models statistically speaking. We also show that the predictive pass-through from international to local inflation has increased in the recent years. As a robustness check we construct another international inflation factor as an average of the inflation of fifteen countries from which Chile gets a high percentage of its imports. With the aid of this factor the models outperform our univariate benchmarks but also underperform the results obtained with the broader factors built with LA or OECD countries, suggesting that imported inflation is not the only channel explaining our findings.","Label":"0"},{"DOI":"10.24148/wp2019-27","Abstract":"We estimate a New Keynesian Phillips curve that allows for changes in the degree of anchoring of agents' subjective inflation forecasts. The estimated slope coefficient in U.S. data is stable over the period 1960 to 2019. Out-of-sample forecasts with the model resolve both the \"missing disinflation puzzle\" during the Great Recession and the \"missing inflation puzzle\" during the subsequent recovery. Using a simple New Keynesian model, we show that if agents solve a signal extraction problem to disentangle transitory versus permanent shocks to inflation, then an increase in the policy rule coefficient on inflation serves to endogenously anchor agents' inflation forecasts. Improved anchoring reduces the correlation between changes in inflation and the output gap, making the backward-looking Phillips curve appear flatter. But at the same time, improved anchoring increases the correlation between the level of inflation and the output gap, leading to a resurrection of the \"original\" Phillips curve. Both model predictions are consistent with U.S. data since the late 1990s.","Label":"0"},{"DOI":"10.1016/s0304-3932(98)00060-9","Abstract":"Empirical evidence suggests that real activity, the volume of bank lending activity, and the volume of trading in equity markets are strongly positively correlated. At the same time, inflation and financial market activity are strongly negatively correlated (in the long run), as are inflation and the real rate of return on equity. Inflation and real activity are also negatively correlated in the long run, particularly for economies with relatively high rates of inflation. We present a monetary growth model in which banks and secondary capital markets play a crucial allocative function. We show that – at least under certain configurations of parameters – the predictions of the model are consistent with these and several other observations about inflation, finance and long-run real activity.","Label":"0"},{"DOI":"10.1007/s40888-019-00171-7","Abstract":"We propose an expectations formation mechanism (EFM) aimed to explain the median—hence lay—forecaster’s year-ahead inflation predictions. The EFM is a time-varying combination of long-run expectations, current inflation and uncertainty with weights naively calibrated according to inflation dynamics. Earning fixed income, in fact, the median forecaster has an aversion toward underestimation that increases with inflation. To allow for occasional—albeit unintentional—cost-minimizing calibrations, the EFM nests various forecasting rules. Data from the Michigan Survey of Consumers sustains the argued behavior and contributes to interpret some puzzling price dynamics such as the missing disinflation and reflation.","Label":"0"},{"DOI":"10.2139/ssrn.1802433","Abstract":"This paper explains the negative correlation between realized inflation and real stock prices under a rare-event framework. Agents make use of realized inflation rates to update their beliefs on the time-varying probability of a rare-event (stagflation or hyperinflation). A higher stagflation probability implies a higher correlation between inflation and real stock prices (dividend yield). I show that for a Bayesian belief-updating agent, the expectation on the Fed commitment to low inflation is key in order to explain the magnitude of the correlation. To test the model predictions, I perform a Markov Regime switching estimation and identify two statistically different regimes: one regime in which agents expect a strong commitment to low inflation by the Fed; and another regime in which they expect a low commitment to low inflation. Inflation correlates higher with stock prices in the second regime than in the first one. Finally, I show that the rare-event approach is more robust than the money illusion approach a-là Modigliani and Cohn (1979).","Label":"0"},{"DOI":"10.1111/j.1467-9957.2011.02241.x","Abstract":"This paper investigates the relationship between firm mark‐ups and inflation. In sectors of the economy with industries characterized by flexible prices and sticky wages, mark‐ups should respond positively to inflation. Industry mark‐ups in sectors with both flexible prices and flexible wages theoretically may rise or fall in response to an increase in the price level. Mark‐ups of industries in sectors of the economy in which prices are sticky should respond negatively to inflation, with an absolutely larger negative response occurring in sticky‐price industries with flexible wages. Empirical analysis of US industries provides support for nearly all of these theoretical predictions.","Label":"0"},{"DOI":"10.2139/ssrn.885122","Abstract":"This paper reviews the evidence on stabilization plans in high inflation countries within a unified theoretical framework. The evidence suggests that hyperinflations have been stopped almost instantaneously with no major output costs, while stabilization programs in chronic-inflation countries have resulted in an initial expansion followed by a later recession, in addition to a sustained real exchange rate appreciation and current account deficits. These outcomes turn out to be consistent with the predictions of the analytical model.","Label":"0"},{"DOI":"10.1016/j.econlet.2016.10.023","Abstract":"This paper focuses on the role of the quantity theory in improving inflation forecasts. We find that the cointegration-based quantity theory does not hold for the period after 1995 for the U.S. data. However, that period is well explained by an adaptive quantity theory based on a functional-coefficient cointegration that adapts to the unemployment rate. The forecasting exercises show that the adaptive quantity theory has superior predictive power for targeting future inflation.","Label":"0"},{"DOI":"10.48550/arxiv.2208.14653","Abstract":"This paper examines the drivers of CPI inflation through the lens of a simple, but computationally intensive machine learning technique. More specifically, it predicts inflation across 20 advanced countries between 2000 and 2021, relying on 1,000 regression trees that are constructed based on six key macroeconomic variables. This agnostic, purely data driven method delivers (relatively) good outcome prediction performance. Out of sample root mean square errors (RMSE) systematically beat even the in-sample benchmark econometric models. Partial effects of inflation expectations on CPI outcomes are also elicited in the paper. Overall, the results highlight the role of expectations for inflation outcomes in advanced economies, even though their importance appears to have declined somewhat during the last 10 years.","Label":"1"},{"DOI":"10.1016/s0210-0266(13)70045-1","Abstract":"We examine the predictive ability, the consistency properties, and the possible driving forces of inflation expectations, using a survey conduct ed in Spain by PwC, among a panel of experts and entrepreneurs. When analysing the headline inflation rate, our results suggest that the PwC panel has some forecasting ability for time horizons from 3 to 9 months, improving when it comes to predicting the core inflation rate. Nevertheless, the results indicate that predictions made by survey participants are neither unbiased nor efficient predictors of future inflation rates, regardless of the measures of inflation used. As for the consistency properties of the inflation expectations formation process, we find that panel members form stabilising expectations in the case of the headline inflation rate, both in the short and in the long-run, although in the case of the core inflation rate, consistency remains indeterminate. Finally, we find that inflation expectations are very persistent and that they appear to incorporate the information content of some macroeconomic variables (current core inflation and growth rate, the USD/EUR exchange rate, the European Central Bank (ECB) inflation target, and changes in the ECB official short-term interest rate).","Label":"0"},{"DOI":"10.48550/arxiv.1606.05879","Abstract":"We study the power spectra of f(R) inflation using a new technique in which the norm-squared of the mode functions is evolved. Our technique results in excellent analytic approximations for how the spectra depend upon the function $f(R)$. Although the spectra are numerically the same in the Jordan and Einstein frames for the same wave number $k$, they depend upon the geometries of these frames in quite different ways. For example, the power spectra in the two frames are different functions of the number of e-foldings until end of inflation. We discuss how future data on reheating can be used to distinguish f(R) inflation from scalar-driven inflation.","Label":"1"},{"DOI":"10.1080/00036840701704493","Abstract":"This document presents the estimation of a recent version of the P-Star model by Gerlach and Svensson (2003) and its predictions for Colombia (January 1980 to April 2005). The model is designed to explain the inflation gap (observed rate minus the target) based on the monetary gap and the output gap. According to the results, the output gap lacks significant effects while the monetary gap has significant positive effects on inflation.","Label":"0"},{"DOI":"10.1016/j.eswa.2008.08.073","Abstract":"In the present paper we apply multiresolution decomposition in order to test if the Brazilian yield spread has informational content in the prediction of inflation. Additionally, we investigate the effect of the implementation of inflation targeting regime over this relation. The results suggest that the predictive power of the spread varies across time patterns. Inasmuch, the results indicate that the implementation of the inflation target regime was a sine qua non condition for a substantial increase in the predictive power of inflation. Overall, results suggest that wavelets transformations may be very useful in the building of forecasts of important financial variables.","Label":"0"},{"DOI":"10.1016/j.fiae.2016.03.005","Abstract":"Inflation can be attributed to both microeconomic and macroeconomic factors which influence the stability of the economy of any nation. With the raising of recession at the end of the year 2008, world communities started paying much contemplation on inflation and put enormous hard work to predict it accurately. Prediction of inflation is not a simple task. Moreover, the behavior of inflation is so complex and uncertain that both economists and statisticians have been striving to model and forecast inflation in an accurate way. As a result, many researchers have proposed inflation forecasting models based on different methods; however the accuracy is always being a major constraint. In this paper, we have analyzed the historical monthly economic data of India between January 2000 and December 2012 and constructed an inflation forecasting model based on feed forward back propagation neural network. Initially some critical factors that can considerably influence the inflation of India have been identified, then an efficient artificial neural network (ANN) model has been proposed to forecast the inflation. Accuracy of the model is proved to be satisfactory when compared with the forecasting of some well-known agencies.","Label":"1"},{"DOI":"10.2139/ssrn.910686","Abstract":"This paper provides comprehensive empirical evidence that supports the predictions of Sargent and Wallace's (1981) 'unpleasant monetarist arithmetic' that an increase in public debt is typically inflationary in countries with large public debt. Drawing on an extensive panel dataset, we find that the relationship holds strongly in indebted developing countries, weakly in other developing countries, but generally not in developed economies. These results are robust to the inclusion of other variables, corrections for endogeneity biases, and relaxation of common-slope restrictions and are invariant over sub-sample periods. We estimate a VAR to trace out the transmission channel and find the impulse responses consistent with the predictions of a forward-looking model of inflation. Wealth effects of public debt could also affect inflation, as posited by the fiscal theory of the price level, but we do not find supportive evidence. The results suggest that the risk of a debt-inflation trap is significant in highly indebted countries, and pure money-based stabilization is unlikely to be effective over the medium term. Our findings stress the importance of institutional and structural factors in the link between fiscal policy and inflation.","Label":"0"},{"DOI":"10.1016/j.qref.2019.04.004","Abstract":"The recent housing price inflation forecasting literature has focused on the use of domestic variables for prediction of housing price inflation. However, around 7% of all US housing sales are attributed to international buyers; a potentially important market force. Further, international finance theory finds a role for foreign savings shocks in causing the housing price bubble of the last decade. Under floating exchange rate regimes, the Dornbusch model predicts shocks to domestic or foreign economies will be reflected in exchange rates. When exchange rates are fixed, shocks are likely to affect the net foreign asset holdings. In this study, I examine the role of exchange rates returns and the net change in foreign asset holdings in improving US real estate inflation forecasts. I conduct in-sample and out-of-sample comparison of forecasting models relative to an autoregressive baseline model. I find that the inclusion of foreign sector variables can improve the US real estate inflation forecasts by up to 40%. This improvement is mostly driven by changes in the net foreign asset holdings at longer horizons. The results are robust to samples at the metropolitan level although with different gains.","Label":"0"},{"DOI":"10.1515/1558-3708.1900","Abstract":"In this paper, we integrate heterogeneous inflation expectations into a simple monetary model. Guided by empirical evidence, we assume that boundedly rational agents, selecting between extrapolative and regressive forecasting rules to predict the future inflation rate, prefer rules that have produced low prediction errors in the past. We show that integrating this behavioral expectation formation process into the monetary model leads to the possibility of endogenous macroeconomic dynamics. For instance, our model replicates certain empirical regularities such as irregular growth cycles or inflation persistence. Moreover, we observe multi-stability via a Chenciner bifurcation.","Label":"0"},{"DOI":"10.1057/imfsp.2008.26","Abstract":"This paper provides comprehensive empirical evidence that supports the predictions of Sargent and Wallace's “unpleasant monetarist arithmetic” that an increase in public debt is typically inflationary in countries with large public debt. Drawing on an extensive panel data set, we find that the relationship holds strongly in indebted developing countries, weakly in other developing countries, and generally does not hold in developed economies. These results are robust to the inclusion of other variables, corrections for endogeneity biases, relaxation of common-slope restrictions, and are invariant over subsample periods. We estimate a vector autoregression to trace out the transmission channel and find the impulse responses consistent with the predictions of a forward-looking model of inflation. Wealth effects of public debt could also affect inflation, as posited by the fiscal theory of the price level, but we do not find supportive evidence. The results suggest that the risk of a debt-inflation trap is significant in highly indebted countries and pure money-based stabilization is unlikely to be effective over the medium term. Our findings stress the importance of institutional and structural factors in the link between fiscal policy and inflation.","Label":"0"},{"DOI":"10.2139/ssrn.4188536","Abstract":"This study investigates how inflation expectations affect precautionary wealth by using Japanese household survey data.A key contribution of this study is that it confirms the prediction of the buffer stock (Carroll, 1997) that, given the nominal interest rate, higher inflation expectations raise the target ratio of precautionary wealth to permanent income when households forecast that higher inflation does not fully translate into their nominal income. This study also confirms that actual liquid wealth gradually converges to the target level of precautionary wealth over the years, which is consistent with the implications of the buffer stock model.","Label":"0"},{"DOI":"10.1111/coep.12440","Abstract":"We study how unconventional monetary policy announcements affected professional forecasters' predictions of bond rates, gross domestic product growth and inflation using data from the monthly survey by the Wall Street Journal. We find that unconventional monetary policy (UMP) announcements moved predicted bond rates in the direction the Fed intended. UMP announcements had differential impacts on forecasters' predictions; they also tended to move growth and inflation predictions in directions opposite those the Fed intended due to Fed information effects. A policy implication of our study is that the Fed should communicate economic projections to the public separately from monetary policy announcements to mitigate Fed information effects. (JEL E52, E58)","Label":"0"},{"DOI":"10.30812/matrik.v19i1.511","Abstract":"Inflation reflects an increase in the prices of these items as well as those used by the Indonesian government, especially Bank Indonesia, in determining monetary policy. An indicator that can be obtained by Bank Indonesia in measuring inflation is the Consumer Price Index. This study discusses inflation prediction using the SVR method. Inflation test data issued by Bank Indonesia. As a comparison material for the kernel used in the SVR method using two kernels, namely Linear and Radial Base Function. The error rate evaluation results show that linear kernels produce better values, with a MAPE rate of 8.70% and MSE of 0.0037","Label":"1"},{"DOI":"10.1109/qir.2017.8168445","Abstract":"Inflation rate could describe economic growth and it is usually used by policy-maker to determine a monetary policy. The Consumer Price Index (CPI) is one of indicator used to measure inflation rate. Until now, the inflation calculations and CPI prediction are conducted on monthly even though it is now likely to predict them on daily basis by utilizing online commodity price movement. Daily predictions could become a tool to analyze the real value of the market and will allow policy-makers to make better policy. This is a preliminary research to develop daily CPI prediction model by using Big Data. This paper discussed daily prediction model by using real-time data (daily commodity price and exchange rate) and SVR method. Build a model focused on accuracy and execution time. Grid Search and Random Search method were applied to select the best parameter for SVR model. In addition, we compared SVR method with linear regression and Kernel Ridge Regression method. The results show that the prediction model using SVR-kernel RBF has MSE value, 0.3454, less than other methods. Execute time for process data show that Kernel Ridge method has training time 0.0698s, little faster than SVR method 0.134s.","Label":"1"},{"DOI":"10.54691/bcpbm.v13i.45","Abstract":"In the past decade, America's inflation rate has always been mysteriously low, varying around 1%~3% (“United States,” 2021). However, to everyone's surprise, the inflation rate has reached 5% (“United States,” 2021) in June 2021, far higher than the Federal Reserve's 3.4% (Smart, 2021) prediction made in this year.","Label":"0"},{"DOI":"10.2139/ssrn.3491863","Abstract":"Low and unresponsive inflation has been termed a “puzzle.” The paper describes a formula for which these conditions have been a prediction since early 2016.The Money Value Formula analyzes the unit value of a currency solely as a function of long lags of monetary aggregates. The Formula produces a significant statistical explanation for virtually all variability of forward long-term inflation. Its U.S. inflation forecasts are comparable to recognized leaders in accuracy with potential applicability to international economies as well.Inflation Elasticity, the responsiveness of inflation to monetary stimulus, is derived from the Formula and becomes increasingly inelastic at a geometric rate, explaining central banks’ difficulty attaining targets. The onset of financial crises in four major advanced economies is linked to unanticipated real monetary expansion as economies transition from elastic to inelastic inflation with disinflation spurring unsustainable credit growth for central banks, banking systems, and entire economies.","Label":"0"},{"DOI":"10.48550/arxiv.1002.0277","Abstract":"The evolution of inflation, p(t), and unemployment, UE(t), in Japan has been modeled. Both variables were represented as linear functions of the change rate of labor force, dLF/LF. These models provide an accurate description of disinflation in the 1990s and a deflationary period in the 2000s. In Japan, there exists a statistically reliable (R2=0.68) Phillips curve, which is characterized by a negative relation between inflation and unemployment and their synchronous evolution: UE(t) = -0.94p(t) + 0.045. Effectively, growing unemployment has resulted in decreasing inflation since 1982. A linear and lagged generalized relationship between inflation, unemployment and labor force has been also obtained for Japan: p(t) = 2.8*dLF(t)/LF(t) + 0.9*UE(t) - 0.0392. Labor force projections allow a prediction of inflation and unemployment in Japan: CPI inflation will be negative (between -0.5% and -1% per year) during the next 40 years. Unemployment will increase from ~4.0% in 2010 to 5.3% in 2050.","Label":"0"},{"DOI":"10.3390/jrfm13120329","Abstract":"The paper uses a Walrasian two-period financial market model with informed and uninformed constant absolute risk averse (CARA) rational investors and noise traders. The investors allocate their initial wealth between risky assets and risk-free fiat money. The analysis concentrates on the effects of decreasing value of money, or inflation, on the rational investors’ behavior and the asset market. The main findings are the following: Inflation does not affect the informed investors’ prediction coefficient but makes that of the uninformed investors diminish. Inflation does not affect rational investors’ risk but makes the asset price more sensitive to fundament-based and sentiment-based shocks. Inflation changes the market price of the risky asset rise; while it has no effects on the informed investors’ demand of the risky asset, it does affect the uninformed investors’ demand. Finally, inflation makes the asset market more volatile.","Label":"1"},{"DOI":"10.1016/s0164-0704(98)00058-5","Abstract":"Traditional theories of inflation have often relied on the Phillips curve to tie inflation to other macroeconomic variables. The optimal seigniorage hypothesis, however, offers an alternative view of inflation behavior. This hypothesis posits that a government will attempt to minimize the sum of social costs arising from inflation and direct taxation resulting in the testable prediction that inflation and tax rates will be positively related. This paper provides empirical evidence on the validity of the optimal seigniorage hypothesis for Canada and the United States over the 1953 to 1993 sample period. The results provide evidence consistent with the hypothesis, but we argue and find evidence to support the idea that there may be important non-neutralities in the tax system that may account for some part of the positive relationship between inflation and tax rates.","Label":"0"},{"Abstract":"Inflation is a major determinant for allocation decisions and its forecast is a fundamental aim of governments and central banks. However, forecasting inflation is not a trivial task, as its prediction relies on low frequency, highly fluctuating data with unclear explanatory variables. While classical models show some possibility of predicting inflation, reliably beating the random walk benchmark remains difficult. Recently, (deep) neural networks have shown impressive results in a multitude of applications, increasingly setting the new state-of-the-art. This paper investigates the potential of the transformer deep neural network architecture to forecast different inflation rates. The results are compared to a study on classical time series and machine learning models. We show that our adapted transformer, on average, outperforms the baseline in 6 out of 16 experiments, showing best scores in two out of four investigated inflation rates. Our results demonstrate that a transformer based neural network can outperform classical regression and machine learning models in certain inflation rates and forecasting horizons.","Label":"1"},{"Abstract":"This paper proposes a parsimoniously time varying parameter vector autoregressive model (with exogenous variables, VARX) and studies the properties of the Lasso and adaptive Lasso as estimators of this model. The parameters of the model are assumed to follow parsimonious random walks, where parsimony stems from the assumption that increments to the parameters have a non-zero probability of being exactly equal to zero. By varying the degree of parsimony our model can accommodate constant parameters, an unknown number of structural breaks, or parameters with a high degree of variation.   We characterize the finite sample properties of the Lasso by deriving upper bounds on the estimation and prediction errors that are valid with high probability; and asymptotically we show that these bounds tend to zero with probability tending to one if the number of non zero increments grows slower than $\\sqrt{T}$.   By simulation experiments we investigate the properties of the Lasso and the adaptive Lasso in settings where the parameters are stable, experience structural breaks, or follow a parsimonious random walk. We use our model to investigate the monetary policy response to inflation and business cycle fluctuations in the US by estimating a parsimoniously time varying parameter Taylor rule. We document substantial changes in the policy response of the Fed in the 1980s and since 2008.","Label":"1"},{"DOI":"10.33830/jmst.v22i2.1346.2021","Abstract":"The economic growth of a nation is strongly influenced by inflation. Inflation is the continuous soaring price of goods or services. This study aims to predict the movement of inflation that will occur in East Java from January 2021 to December 2021. This study uses 48 data from the East Java Province inflation rate data from January 2017 to December 2020 sourced from the official website of BPS East Java. Predictions using the triple exponential smoothing method with forecasting evaluation using MAPE. Based on the analysis results, the parameters used are ⍺ = 0,01, β = 0,09 dan γ = 0,30 which produces a MAPE value of 1.619%, which is classified as very good. The results show that the inflation forecasting from January 2021 to December 2021 is estimated at -0.13 to 0.48, with an average of 0.087. Thus, the movement of inflation in East Java from January 2021 to December 2021 is classified as low inflation, so it shows that prices and services are still stable.","Label":"0"},{"DOI":"10.2139/ssrn.2407256","Abstract":"Inflation rates are highly persistent and extremely difficult to predict. Most statistical predictions based on predictive regressions fail to outperform the simple assumption of random walk in out-of-sample testing. The poor out-of-sample performance is a common feature of predictive regressions on highly persistent time series. This paper proposes a new approach for inflation forecasting that does not specify or estimate any predictive regressions, but rather starts by estimating a contemporaneous relation between inflation rate and a short-term interest rate, and then relies on the forward interest rate curve to predict future interest rates and accordingly inflation rates over both short and long horizons. Historical analysis with the US inflation series shows that this approach can outperform random walk, out-of-sample, by 30-50% over horizons as far as three to five years.","Label":"0"},{"DOI":"10.2139/ssrn.614763","Abstract":"We shed new light on the negative relationship between real stock returns or real interest rates and (i) post inflation, (ii) expected inflation, (iii) unexpected inflation, and (iv) changes in expected inflation. Using the structural vector autoregression methodology, we propose a decomposition of those series into economically interpretable components driven by aggregate supply, real demand and money market shocks. Our empirical results support Fama's 'proxy hypothesis' and the predictions of several general eqilibrium models. Concerning the negative relation between the real rate of interest and inflation, we find that the Mundell-Tobin model and the explanation of Fama and Gibbons (1982) are not competitors: both add insight in their own way about the reasons for the negative correlation between those variables. However, the importance of the latter explanation decreased since the 1980's.","Label":"0"},{"DOI":"10.2139/ssrn.2316880","Abstract":"Under the Globalization Hypothesis for inflation, as globalization increases, global economic slack should progressively replace the domestic gap in driving inflation. In order to assess the empirical support for this theoretical prediction, we use impulse response functions of inflation to domestic and foreign output gap shocks from a TV-VAR model estimated for eighteen countries. The main results of the analysis are twofold: First, the structural results show that global slack affects the dynamics of inflation in many countries, yet these effects do not get stronger over time. Second, a panel analysis that exploits the cross-section characteristics of the response functions shows that globalization, measured in terms of openness and business cycles integration, is positively related to the effects of global slack on inflation. The degree of openness of a country and its economic integration into the global economy are complementary rather than overlaid forces.","Label":"0"},{"DOI":"10.1016/j.jinteco.2005.05.014","Abstract":"This paper tests the empirical validity of the forward-looking pricing hypothesis using data from four exchange rate based stabilization (ERBS) episodes. It finds that backward-looking components of inflation play an important role in inflation dynamics, in some cases exceeding the importance of forward-looking components. The paper then shows that the presence of empirically relevant degrees of inflation stickiness increases the size of the real exchange rate appreciation predicted by an imperfect credibility model of ERBS. The 12% real appreciation predicted by the sticky inflation model is a 70% improvement over the predictions of the fully forward looking pricing setup, but as in other ERBS models, still falls short of matching the real appreciations observed in practice.","Label":"0"},{"DOI":"10.2139/ssrn.3261892","Abstract":"In order to tackle the non-availability of inflation futures data, we introduce the futures on the CPI proxy (FCP). Compared to over-the-counter inflation-linked derivatives, the FCP is a more accessible tool for inflation forecasting. The time series of the FCP chain is analysed by a two-factor valuation model. Our model captures the downward trend of U.S. CPI inflation in 2014. Furthermore, the model-filtered spot CPI alleviates the publication lag of U.S. CPI. The uncertainty of FCP price level prediction is estimated by analysing the fan charts derived from a synthetic option implied volatility surface. Among all fan charts, the one derived from the out-of-the-money option chain yields the most certain price level forecast, although the uncertainty of the corresponding inflation forecast is higher than that of the Bank of England inflation forecast. Additionally, the negative inflation risk premium estimated from the time series of the FCP chain is consistent with post-Lehman estimates in the literature.","Label":"0"},{"DOI":"10.25105/mrbm.v11i1.1095","Abstract":"The objective of this paper is to predict Indonesia's inflation rate in 2009 by employing BOX-JENKINS (ARIMA) model. The prediction of inflation rate is very important since the inflation affects us in economy aspect. Moreover, by knowing the approximate inflation in the future will help companies to plan the operational cost better. It also will help the government to anticipate the predicted inflation by making good policies, thus the prosperity of Indonesia people will be achieved. AR (2) is the best ARIMA model that we obtain. By employing AR (2), we predict the inflation rate in 2009 is 10.48%. This number is not surprising since inflation rate in Indonesia is mainly affected by exchange rate. As we know that the global crisis will start recovering in early 2010 (Yearly Bank Indonesia Report, 2008). The impact is that exchange rate pressure will be still high in 2009, it is due to non-optimal export and limited foreign fund's inflow.","Label":"0"},{"DOI":"10.2139/ssrn.1009161","Abstract":"Why is inflation so much lower and at the same time more stable in developed economies in the 1990s, compared with the 1970s? This paper suggests that the United Kingdom, United States and other countries may have escaped from a volatile inflation equilibrium. Our argument builds on the story proposed by Tom Sargent in \"The Conquest of American Inflation,\" where the fall in inflation in the 1980s was attributed to the changing beliefs informing monetary policy. To explain the escape in inflation volatility, we unwind one of Sargent's simplifications and allow the monetary authority to react to some of the shocks in the economy. In this new model, a revised account of recent history is that when the evidence turned against the existence of a long-run inflation-output trade-off in the 1980s there was an escape from high inflation, but the authorities were also persuaded to stop using changes in inflation to offset shocks. Inflation and inflation volatility therefore escaped in tandem. Our analysis also sheds some light on why the escape in inflation occurred at the time it did. Our model, like the Sargent model it derives from, omits the revolution in institutional design and understanding that underpins monetary policy. So the gloomy predictions for the future derived from a literal reading of it are likely to be unfounded.","Label":"0"},{"DOI":"10.17016/ifdp.2007.891","Abstract":"This paper evaluates the hypothesis that globalization has increased the role of international factors and decreased the role of domestic factors in the inflation process in industrial economies. Toward that end, we estimate standard Phillips curve inflation equations for 11 industrial countries and use these estimates to test several predictions of the globalization and inflation hypothesis. Our results provide little support for that hypothesis. First, the estimated effect of foreign output gaps on domestic consumer price inflation is generally insignificant and often of the wrong sign. Second, we find no evidence that the trend decline in the sensitivity of inflation to the domestic output gap observed in many countries owes to globalization. Finally, and most surprisingly, our econometric results indicate no increase over time in the responsiveness of inflation to import prices for most countries. However, even though we find no evidence that globalization is affecting the parameters of the inflation process, globalization may be helping to stabilize real GDP and hence inflation. Over time, the volatility of real GDP growth has declined by more than the volatility of domestic demand, suggesting that net exports increasingly are acting to buffer output from fluctuations in domestic demand.","Label":"0"},{"DOI":"10.1108/fs-09-2013-0045","Abstract":"Purpose                     – The paper aims to evaluate different artificial neural network models and to suggest a suitable model for forecasting inflation in G-7 countries.                                                           Design/methodology/approach                     – The study applies different combinations of neural networks with hyperbolic tangent function using backpropagation learning with the steepest gradient descent technique to monthly data on Consumer Price Index (a measure of inflation) of the USA, the UK, France, Germany, Italy, Japan and Canada.                                                           Findings                     – Predictions of inflation based on the Consumer Price Index for all the seven countries divulged that it is expected that the rate of inflation will decline marginally in the near future.                                                           Practical implications                     – The results proposed in this study will be a benchmark for policy-makers, economists and practitioners to forecast inflation and design policies accordingly.                                                           Originality/value                     – The paper’s findings provide strong evidence for policy-makers that while constructing models for forecasting inflation, the suggested models can be used to track the future rates of inflation and, further, they can apply that model in framing policies.","Label":"1"},{"DOI":"10.2139/ssrn.1926475","Abstract":"We examine the relationship between inflation and unemployment in the long run, using quarterly US data from 1952 to 2010. Using a band-pass filter approach, we find strong evidence that a positive relationship exists, where inflation leads unemployment by some 3 to 3 1/2 years, in cycles that last from 8 to 25 or 50 years. Our statistical approach is a theoretical in nature, but provides evidence in accordance with the predictions of Friedman (1977) and the recent New Monetarist model of Berentsen, Menzio, and Wright (2011): the relationship between inflation and unemployment is positive in the long run.","Label":"0"},{"DOI":"10.2307/3867576","Abstract":"Data for the G-7 countries strongly support the view that economic activity has a nonlinear effect on inflation, with high levels of activity raising inflation by more than low levels decrease it. In the face of such asymmetries, the average level of output in an economy subject to demand shocks will be below the level of output at which there is no tendency for inflation to rise or fall, contrary to linear model predictions. One implication is that policymakers can raise the average level of output over time by responding promptly to demand shocks, reducing the variance of output around trend.","Label":"0"},{"DOI":"10.1016/j.rie.2018.07.001","Abstract":"The inflation rate is a key economic indicator for which forecasters are constantly seeking to improve the accuracy of predictions, so as to enable better macroeconomic decision making. Presented in this paper is a novel approach which seeks to exploit auxiliary information contained within inflation forecasts for developing a new and improved forecast for inflation by modeling with Multivariate Singular Spectrum Analysis (MSSA). Unlike other forecast combination techniques, the key feature of the proposed approach is its use of forecasts, i.e. data into the future, within the modeling process and extracting auxiliary information for generating a new and improved forecast. We consider real data on consumer price inflation in UK, obtained via the Office for National Statistics. A variety of parametric and nonparametric models are then used to generate univariate forecasts of inflation. Thereafter, the best univariate forecast is considered as auxiliary information within the MSSA model alongside historical data for UK consumer price inflation, and a new multivariate forecast is generated. We find compelling evidence which shows the benefits of the proposed approach at generating more accurate medium to long term inflation forecasts for UK in relation to the competing models. Finally, through the discussion, we also consider Google Trends forecasts for inflation within the proposed framework.","Label":"1"},{"DOI":"10.2139/ssrn.1337046","Abstract":"Much of the US inflation forecasting literature deals with examining the ability of macroeconomic indicators to predict the mean of future inflation, and the overwhelming evidence suggests that the macroeconomic indicators provide little or no predictability. In this paper, we expand the scope of inflation predictability and explore whether macroeconomic indicators are useful in predicting the distribution of future inflation. To incorporate macroeconomic indicators into the prediction of the conditional distribution of future inflation, we introduce a semi-parametric approach using conditional quantiles. The approach offers more flexibility in capturing the possible role of macroeconomic indicators in predicting the different parts of the future inflation distribution. Using monthly data on US inflation, we find that unemployment rate, housing starts, and the term spread provide significant out-of-sample predictability for the distribution of core inflation. Importantly, this result is obtained for a forecast evaluation period that we intentionally chose to be after 1984, when current research shows that macroeconomic indicators do not add much to the predictability of the future mean inflation. This paper discusses various findings using forecast intervals and forecast densities, and highlights the unique insights that the distribution approach offers, which otherwise would be ignored if we relied only on mean forecasts.","Label":"0"},{"DOI":"10.1016/j.jedc.2021.104279","Abstract":"Can inflation anchoring foster growth? To answer this question, we use panel data on sectoral growth for 22 manufacturing industries from 39 advanced and emerging market economies over 1990–2014 and employ a difference-in-differences strategy based on the theoretical prediction that higher inflation uncertainty particularly depresses investment in industries that are more credit constrained. Industries characterized by high external financial dependence, liquidity needs, and R&D intensity, and low asset tangibility, tend to grow faster in countries with well-anchored inflation expectations. The results, based on an IV approach—using indicators of monetary policy transparency and central bank independence as instruments—confirm our findings.","Label":"0"},{"DOI":"10.1080/09603100010001090","Abstract":"This paper examines the same-day reaction of a variety of UK asset prices to monthly RPI inflation announcements over a sample period extending from the early 1980s until April 1997, the month before the Bank of England was given operational independence for setting interest rates. These announcements are decomposed into their expected and unexpected, or ‘news’, components using survey data on financial analysts' inflation expectations and, as a cross-check, prediction errors from a time-series model of inflation. It is found that markets are efficient, in that asset prices do not respond to the expected component of RPI announcements. Generally, only government bond prices are sensitive to inflation news, and this sensitivity appears particularly marked after late 1992, when the UK adopted an explicit inflation target. The responsiveness of implied medium and long-term forward inflation rates (calculated from conventional and index-linked bonds) during the post-1992 period is consistent with the expected inflation hypothesis, a result that suggests that the pre-independence inflation-targeting framework was not seen as fully credible by the financial markets. Nevertheless, the declining responsiveness of bond yields and implied forward inflation rates to inflation news over the period of operation of the framework suggests that its credibility improved over time.","Label":"0"},{"DOI":"10.1080/1540496x.2016.1212704","Abstract":"The Minsky (1992) model links inflation during economic expansion to the potential for subsequent reversal. This model was tested in the European economic region using logistic regression, which indicated inflation had the greatest contribution toward potential for crisis. Three equations included inflation with other selected macroeconomic indicators tracked by the World Bank. GDP growth, GDP/GNI ratio, and adoption of the Euro demonstrated positive effects. Predictions based on the chosen indicators suggest that the newer members of the European Union may be vulnerable to crisis following periods of high inflation; recent slowing of economic activity in Europe has actually improved the predicted outcomes.","Label":"0"},{"DOI":"10.1017/cbo9781139173735.019","Abstract":"Correct prediction of the inflation rate and its turning points is an important problem for businesses and households alike. An early signal for a major turn in the inflation rate will allow economic agents to redo their economic calculations for the forthcoming environment. Because inflation rates are highly cyclical, Moore (1983a, 1983b) adapted the leading indicator approach, long associated with the National Bureau of Economic Research (NBER) studies of business cycles, to specifically forecast the inflation rate. Klein (1986) successfully extended this methodology of inflation forecasting to a number of major market-oriented economies. Moore (1986) reported that the composite inflation indicator has a better ex post record in forecasting next year's inflation rate than the consensus of economists has achieved. In Chapter 16, Roth evaluated five different leading indicators of inflation and found that composite indicators have a very impressive track record. The main purpose of this chapter is to propose another predictor of inflation obtained by extracting information about future inflation from nominal interest rates of various maturities. For the sake of comparison, we will analyze these forecasts in the context of the existing leading indicator literature. Since the nominal interest rate, which is known at the beginning of a period, can be written as expected real interest rate plus expected rate of inflation, a reasonable estimate of the ex ante real rate will yield an equally reasonable estimate of the inflation component.","Label":"0"},{"DOI":"10.2139/ssrn.179695","Abstract":"UK asset price reactions to RPI announcements are examined from the early 1980s up to April 1997. Announcements are decomposed into their expected and unexpected components using survey data on inflation expectations. Asset prices do not appear to respond to the expected component of announcements, consistent with the predictions of the efficient markets hypothesis. The main sensitivity to inflation news appears in government bond prices, and the results are consistent with the 1992-97 inflation targeting regime being not fully credible, though its credibility increased over time.","Label":"0"},{"DOI":"10.1016/j.econlet.2019.108823","Abstract":"We estimate vector autoregressions with time-varying parameters to demonstrate that the impulse response of inflation to government spending shocks underwent significant changes over time. Fiscal spending increases lowered inflation in the first half of the postwar period, but have been inflationary from about 1980 onwards. In contrast to estimates based on models with constant parameters, the evidence for more recent decades is in line with the prediction of basic New Keynesian models.","Label":"0"},{"DOI":"10.1257/pandp.20221094","Abstract":"In a basic New Keynesian DSGE model with involuntary unemployment and inflation target shocks, we study the role of labor markets in the transmission of persistent monetary policy shocks that increase households' inflation expectations. The model predicts that labor market conditions can play an important role in the transmission channel of the persistent inflation target shock: quantitatively realistic labor market frictions increase the expansionary effect of inflation target shock on output by around a half compared to that under the model without labor market frictions. Using VAR analysis, we further provide empirical evidence consistent with the predictions of our theoretical model.","Label":"0"},{"DOI":"10.1016/0304-3932(90)90045-6","Abstract":"The one-year expected inflation rate and the expected real return on one-year bonds move opposite one another. The result is that the term structure shows little power to forecast near-term changes in the one-year interest rate, even though it shows power to forecast its components. When the forecast horizon is extended, interest-rate predictions improve because they primarily reflect changes in expected inflation that are less strongly offset by changes in the expected real return. The information is the term structure about interest rates, inflation and real returns is related to the business cycle.","Label":"0"},{"DOI":"10.1016/s0304-3878(00)00132-2","Abstract":"Identifying determinants of the output–inflation tradeoff has been a key issue in business cycle research. We provide evidence that in countries with greater restrictions on capital mobility, a given reduction in the inflation rate is associated with a smaller loss in output. This result is shown to be consistent with the predictions of a version of the Mundell–Fleming model. Restrictions on capital mobility are measured using the IMF's Annual Report on Exchange Rate Arrangements and Exchange Restrictions. Estimates of the output–inflation tradeoff are taken from previous studies (viz., Lucas [Am. Econ. Rev. 63 (1973)] and Ball, Mankies and Romer 19 (1988)).","Label":"0"},{"DOI":"10.1177/002795019916700111","Abstract":"This article examines the statistical issues surrounding the Bank of England's density forecast of inflation and its presentation as a ‘fan chart’. The Bank's preferred central projection is the mode of the density but this underestimates ‘average inflation over a number of years’ in terms of which monetary stability is defined. An alternative fan chart based on central prediction intervals is presented, better reflecting the extent to which the overall balance of risks is on the upside of the inflation target. An ‘all-or-nothing’ loss function is seen to be implicit in the Bank's choices of statistical measures, but is unrealistic.","Label":"1"},{"DOI":"10.26710/sbsee.v4i1.2147","Abstract":"Purpose: The purpose of this study is to specify an efficient forecast model for the accurate prediction of macroeconomic variables in the context of Pakistan. Design/Methodology/Approach: We particularly investigate the comparative accuracy of Artificial Neural Network (ANN) and Autoregressive Integrated Moving Average (ARIMA) models-based predictions using monthly data of inflation, exchange rate, and GDP from 1990 to 2014. Findings: According to our findings, the ANN-based forecasted inflation series is more precise as compared to ARIMA-based estimates. On the contrary, the ARIMA model outperforms the ANN model for exchange rate forecasts with the forecasted values being very close to the actual values. Further, ARIMA performs comparatively better in forecasting GDP with relatively smaller forecast error. On the whole, our findings suggest the ARIMA model provides appropriate results for forecasting exchange rates and GDP, while the ANN model offers precise estimates of inflation. Implications/Originality/Value: Our findings have important implications for the analysts and policymakers highlighting the need to use appropriate forecasting models that are well aligned with the structure of an economy.","Label":"1"},{"DOI":"10.1088/1757-899x/1115/1/012058","Abstract":"Abstract  One of the macroeconomic indicators to see the stability of a country’s economy is inflation. This study aims to model the value of monthly inflation in Indonesia from January 2003 to December 2019 using the ARIMA-NN hybrid. The data plot shows a non-linear pattern and trends, so that the differencing process is carried out and the model is built using ARIMA model. The best ARIMA model obtained is SARIMA (1,1,0)(0,1,1) 12 with a Root Mean Square Error (RMSE) of 0.01134. Furthermore, ARIMA residuals that do not satisfy white noise and normality are modeled using NN. The best structure obtained of NN model is (3×2×1) with an RMSE of 0.023984. From the ARIMA and residual NN prediction results, the ARIMA-NN hybrid model is obtained to predict the value of monthly inflation in Indonesia for the next 12 months with the Mean Absolut Percentage Error (MAPE) value is 11.40873%. It means that the model result has high prediction accuracy.","Label":"1"},{"DOI":"10.1142/s2010495213500097","Abstract":"This paper explores whether a financial conditions index (FCI) can serve as a good predictor of inflation and hence, a useful guide to monetary policy in the context of Singapore by constructing an index that comprises interest rates, exchange rates, credit expansions, stock prices and house prices. The choice of these variables is motivated by the role they play in the monetary transmission mechanism and how they contribute to inflationary pressures in an economy. A weighted-sum approach is adopted for index construction whereby the weight assigned to each component is derived from the generalized impulse responses of a monetary VAR model estimated using quarterly data. Cross-correlations and Granger causality tests confirm the proposed index possesses good in-sample leading qualities over consumer price inflation. Using this index to generate predictions recursively from a direct multistep forecasting methodology yields substantial gains in out-of-sample prediction performance when compared with forecasts of a benchmark autoregressive model for inflation within the one-year forecast horizon.","Label":"0"},{"DOI":"10.33005/ijdasea.v1i2.8","Abstract":"This research aims to compare the performance of Holt Winters and Seasonal Autoregressive Integrate Moving Average (SARIMA) models in predicting inflation in Balikpapan and Samarinda, two biggest cities in East Kalimantan province. The importance of East Kalimantan province cannot be overstated since it has been declared as the venue for the capital of Indonesia. Hence, inflation prediction of the two cities will give valuable insights about the economic nature of the province for the country’s new capital. The data used in this study extended from January 2015 to September 2021. The data were divided into training and test data. The training data were used to model the time series equation using Holt winters and SARIMA models. Later, the models derived from training data were employed to produce forecasts. The forecasts were compared to the actual inflation data to determine the appropriate model for forecasting. Test data were from January 2015 to December 2020 and test data extended from January 2021 to September 2021. The result showed that Holt-Winters performed better than SARIMA in prediction inflation. The Root Mean Squared Error (RMSE) values are lower for Holt-Winters Exponential Smoothing for both cities. It also predicts better timing of cyclicality than SARIMA model.","Label":"0"},{"DOI":"10.1017/cbo9781107045149.016","Abstract":"14.1 Introduction It is hard to overestimate the importance of inflation forecasting. Since most prices are sticky and a number of contracts imply long-term commitments in nominal terms, forward-looking economic agents tend to have implicitly in their decision-making process some form of forecasting of the general price level in the economy. For example, the prediction of inflation guides firms and employees during the negotiation of labour contracts, and influences investors in the evaluation of asset prices. This central role of inflation expectations in the economy also creates a man-date for central banks to achieve predictable (and low) inflation rates. Therefore, inflation forecasting is also important from a central banking perspective; inflation projections typically serve as an important element in the monetary policy decision process. Notwithstanding the importance of inflation forecasting, it has been difficult to develop satisfactory forecasting models that generate both accurate and timely inflation forecasts. The significant publication lags of crucial information variables limit the use of various model-based or survey-based approaches and have introduced market-based alternatives. The latter circumvent the issue of publication lags by limiting the information set to observable financial variables and hence have the potential to provide timely inflation forecasts. Examples of this approach include the well-known breakeven inflation rate or, more recently, the use of inflation swaps. However, the success of the latter approach crucially hinges on the dominance of the expectations component in the time variation of the derived measures.","Label":"0"},{"DOI":"10.1002/for.2941","Abstract":"This paper evaluates the forecasting ability when inflation is viewed as an inherently global phenomenon through the lens of the workhorse New Open Economy Macro (NOEM) model. The NOEM model emphasizes the importance of cross‐country spillovers arising through trade, and its reduced form solution can be represented by a finite‐order VAR that provides a tractable model of inflation forecasting. We use Bayesian techniques to estimate this VAR specification—we name it NOEM‐BVAR—and pseudo‐out‐of‐sample forecasts to assess its forecasting performance at different horizons in a diverse set of 18 countries. On average, the NOEM‐BVAR specification produces a similar or even lower root mean square prediction error (RMSPE) than its standard competitors, which include both purely statistical models and theoretically‐based forecasting models (e.g., Phillips‐curve‐type alternatives and others with global inflation measures). In a number of cases, the gains in smaller RMSPEs are statistically significant, especially at short horizons. The NOEM‐BVAR model is also accurate in predicting the direction of change for inflation and is often better than its competitors along this dimension as well. Even though purely statistical models can be useful as prediction tools, the NOEM‐BVAR is an attractive tool among those forecasting models motivated by economic theory.","Label":"0"},{"DOI":"10.1093/rfs/hhac021","Abstract":"Abstract We develop an asset pricing model with endogenous corporate policies that explains how inflation jointly affects real asset prices and corporate default risk. Our model includes two empirically founded nominal rigidities: fixed nominal debt coupons (sticky leverage) and sticky cash flows. These two frictions result in lower real equity prices and credit spreads when expected inflation rises. A decrease in expected inflation has opposite effects, with even larger magnitudes. In the cross-section, the model predicts that the negative impact of higher expected inflation on real equity values is stronger for low leverage firms. We find empirical support for the model’s predictions. Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online.","Label":"0"},{"DOI":"10.2139/ssrn.3938628","Abstract":"This paper develops a Bayesian quantile regression model with time-varying parameters (TVPs) for forecasting inflation risks. The proposed parametric methodology bridges the empirically established benefits of TVP regressions for forecasting inflation with the ability of quantile regression to model flexibly the whole distribution of inflation. In order to make our approach accessible and empirically relevant for forecasting, we derive an efficient Gibbs sampler by transforming the state-space form of the TVP quantile regression into an equivalent high-dimensional regression form. An application of this methodology points to a good forecasting performance of quantile regressions with TVPs augmented with specific credit and money-based indicators for the prediction of the conditional distribution of inflation in the euro area, both in the short and longer run, and specifically for tail risks.","Label":"1"},{"DOI":"10.4028/www.scientific.net/kem.474-476.114","Abstract":"Along with the economy development and the living standards enhancement unceasingly, the inflation also accompanies naturally lives. Generally speaking the temperate inflation has not the enormous influence to people's life and the national economy, but the serious inflation's occurrence can affect a country exchange rate level, disrupt the import and export order and financial order, simultaneously, will affect the people revenues and the living standard, will cause the national competitive power to drop. In view of this problem, it is necessary to construct the model to forecast the year in the future that will occur the serious inflation. This paper construct the predict model base on the grey fuzzy theory, the experimental simulation is shown that the results is accuracy and reliable.","Label":"1"},{"DOI":"10.1016/j.red.2014.07.004","Abstract":"According to the Globalization Hypothesis, global economic slack should progressively replace the domestic output gap in driving inflation as globalization increases. We investigate the empirical evidence in favor of this prediction by using a time-varying VAR. Two main results emerge from the analysis: First, global slack is found to affect the dynamics of inflation in many countries, yet its influence did not become stronger over time. Second, a panel analysis that exploits the cross-sections characteristics of our dataset shows that globalization, measured in terms of trade and financial openness, is positively related to the effects of global slack on inflation. We conclude that integration in the global economy is in fact important, but globalization has not yet induced changes in openness large enough to justify significant brakes in inflation dynamics.","Label":"0"},{"DOI":"10.2139/ssrn.2589712","Abstract":"This paper provides both theoretical insight as well as empirical evidence in support of the view that inflation is largely a global phenomenon. First, we show that inflation across countries incorporates a significant common factor captured by global inflation. Second, we show that in theory a role for global inflation in local inflation dynamics emerges over the business cycle even without common shocks, and under flexible exchange rates and complete international asset markets. Third, we identify a strong \"error correction mechanism\" that brings local inflation rates back in line with global inflation which explains the relative success of inflation forecasting models based on global inflation (e.g., Ciccarelli and Mojon (2010)). Fourth, we argue that the workhorse New Open Economy Macro (NOEM) model of Martínez-García and Wynne (2010) can be approximated by a finite-order VAR and estimated using Bayesian techniques to forecast domestic inflation incorporating all relevant linkages with the rest of the world. This NOEM-BVAR provides a tractable model of inflation determination that can be tested empirically in forecasting. Finally, we use pseudo-out-of-sample forecasts to assess the NOEM-BVAR at different horizons (1 to 8 quarters ahead) across 17 OECD countries using quarterly data over the period 1980Q1-2014Q4. In general, we find that the NOEM-BVAR model produces a lower root mean squared prediction error (RMSPE) than its competitors --- which include most conventional forecasting models based on domestic factors and also the recent models based on global inflation. In a number of cases, the gains in smaller RMSPEs are statistically significant. The NOEM-BVAR model is also accurate in predicting the direction of change for inflation, and often better than its competitors along this dimension too.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2013.07.010","Abstract":"We consider whether survey respondents’ probability distributions, reported as histograms, provide reliable and coherent point predictions, when viewed through the lens of a Bayesian learning model. We argue that a role remains for eliciting directly-reported point predictions in surveys of professional forecasters.","Label":"1"},{"DOI":"10.34312/jjps.v1i1.5408","Abstract":"The vector autoregressive (VAR) model is a simultaneous equation modeling used to construct forecasting systems from interrelated time-series data. This study intends to predict factors that significantly influence inflation in the province of Gorontalo. Moreover, the data used in this study involved inflation data and factors that influence inflation every month in the province in the period of January 2009 - December 2018. The results of inflation forecasting in Gorontalo in 2019 show that at the beginning of 2019, the inflation was considered to be very low at around -0.48% to -0.40%. However, the inflation surged in March with -0.25% (the highest inflation rate). The percentage decreased to -0.30% and -0.33% in April and May. After the decline in April and May, in the middle of the year (June) inflation returned to -0.31% and did not experience a significant change until the end of the year, which was still in the range of -0.32%. The accuracy of the prediction results seen in the MAPE value from out sample data of variables Y1 to Y8 is on the average below 10%, indicating that VAR is a significant forecasting model.","Label":"0"},{"DOI":"10.1002/pa.2779","Abstract":"This study examines the time‐frequency causal link between economic policy uncertainty and inflation in Japan while answering the following questions: (i) is there any causal link between economic policy uncertainty and inflation in Japan? (ii) if yes, in which direction(s)? To the best of our knowledge, this is the first study that conducts this nexus. To do so, this study employs the wavelet coherence causality test and focuses on the wide range period from 2003:03 to 2021:03, in which Japan was experienced the specific Quantitative and Qualitative Monetary Easing Policies. Overall, the findings mirror that economic policy uncertainty is an essential predictor of inflation in Japan, and economic policy uncertainty leads to inflation at different periods and frequencies. The results of this study are crucial for policy decision‐making, monetary authorities, and central banks, and Japan should reduce uncertainty about economic policies to curb the possible risk of inflation rises. The policymakers in Japan can control the inflation rate fluctuation if they can ensure a more reliable prediction of economic policies.","Label":"0"},{"DOI":"10.2139/ssrn.2801414","Abstract":"We consider the fundamental issue of what makes a “good” probability forecast for a central bank operating within an inflation targeting framework. We provide two examples in which the candidate forecasts comfortably outperform those from benchmark specifications by conventional statistical metrics such as root mean squared prediction errors and average logarithmic scores. Our assessment of economic significance uses an explicit loss function that relates economic value to a forecast communication problem for an inflation targeting central bank. We analyse the Bank of England’s forecasts for inflation during the period in which the central bank operated within a strict inflation targeting framework in our first example. In our second example, we consider forecasts for inflation in New Zealand generated from vector autoregressions, when the central bank operated within a flexible inflation targeting framework. In both cases, the economic significance of the performance differential exhibits sensitivity to the parameters of the loss function and, for some values, the differentials are economically negligible.","Label":"0"},{"DOI":"10.2139/ssrn.4350855","Abstract":"The link between money creation and inflation has been theoretically demonstrated, but different inflation responses to Federal Reserve activity after the Great Recession and COVID recession showed the incomplete nature of the theory. We model a ``fiscal transmission mechanism'' whereby Federal Reserve purchases of Treasury securities lead to inflation as new dollars flow through fiscal deficits into the economy. In our model, other Federal Reserve activity generally lacks inflationary effects. Using a nonstructural vector autoregression approach, we test for the presence of this mechanism and offer near perfect predictions of the 2022 inflation rate using a time series extending back half a century. We explain the fiscal transmission mechanism and the reasons why other Federal Reserve activity lacks the same effects, and we propose an emphasis on controlling the money supply by limiting Federal Reserve purchases of Treasury securities as a better way to control inflation than setting an interest rate target.","Label":"0"},{"DOI":"10.1016/j.econmod.2019.08.011","Abstract":"Does theory aid inflation forecasting? To address this question, we develop a novel forecasting procedure based upon a New Keynesian Phillips Curve that incorporates time-varying trend inflation, to capture shifts in central bank preferences and monetary policy frameworks. We generate theory-implied predictions for both the trend and cyclical components of inflation, and recombine them to obtain an overall inflation forecast. Using quarterly data for the Euro Area and the United States that cover almost half a century, we compare our inflation forecasting procedure against the most popular time series models. We find that our theory-based forecasts outperform these benchmarks that previous studies found difficult to beat. Our results are shown to be robust to structural breaks, geographic areas, and variants of the econometric specification. Our findings suggest that the scepticism concerning the use of theory in forecasting is unwarranted, and theory should continue to play an important role in policymaking.","Label":"0"},{"DOI":"10.1016/j.techfore.2022.121867","Abstract":"Considering the necessity to have accurate inflation forecasts in a pandemic period with hyperinflation in many countries, the aim of this study is to improve the quarterly inflation forecasts provided by the National Bank of Romania using sentiment analysis. The sentiment forecasts based on narratives in the official reports of the central banks outperformed the numerical predictions of the central bank and various combined forecasts on the horizon 2008:Q1–2021:Q4. In addition, more forecasting models based on machine learning, sentiment indices and various forecasts provided by the National Bank of Romania were proposed. The forecasting model that used signals based on Fourier transform as inputs in artificial neural network and support vector machine performed better than all the other models in terms of forecast accuracy.","Label":"1"},{"DOI":"10.1109/csii54342.2021.00015","Abstract":"The research of this paper applied data mining technologies to examine one of the potential causes of income inequality: inflation. In order to better understand the link between inflation rates and the growth of income inequality, we obtained and analyzed historical data sets of inflation records such as the Consumer Price Index, Gini Coefficient, Producer Price Indices, Unemployment Rate, Minimum Wage, Gross Domestic Product, Federal Tax Rate, etc. to draw empirical conclusions. This study utilized data mining technologies, to develop a data model that analyzes substantial amount of data which contain information on the income, expenses and the financial footprints of families in the United States. The deep learning intelligent system learned from the detailed historical data of the trends of the income inequality, found the major elements that govern inflation, and predicted inflation rates in the future. The public and the economic research society can use the information for their decision making.","Label":"1"},{"DOI":"10.2139/ssrn.1413654","Abstract":"We examine whether standard theoretical models of inflation forecast targeting are consistent with the observed behaviour of the central banks of Australia, Canada, and the United States. The target criteria from these models restrict the conditionally expected paths of variables targeted by the central bank, in particular inflation and the output gap. We estimate various moment conditions, providing a description of monetary policy for each central bank under different maintained hypotheses. We then test whether these estimated conditions satisfy the predictions of models of optimal monetary policy. The overall objective is to examine the extent to which and the manner in which these central banks successfully balance inflation and output objectives over the near term. For all three countries, we obtain reasonable estimates for both the strict and flexible inflation forecast targeting models, though with some qualifications. Most notably, for Australia and the United States there are predictable deviations from forecasted targets, which is not consistent with models of inflation targeting. In contrast, the results for Canada lend considerable support to simple models of flexible inflation forecast targeting.","Label":"0"},{"DOI":"10.1016/j.jedc.2014.04.002","Abstract":"This paper examines optimal monetary policy in a New Keynesian model where supply and demand shocks affect the price of oil. Optimal policy fully stabilizes core inflation when wages are flexible. The nominal rate rises (falls) in response to the demand (supply) shock. With sticky wages core inflation falls (rises) in response to the demand (supply) shock. Impulse response functions from a VAR estimated with post-1986 U.S. data show minimal movement in core inflation in response to both shocks. The federal funds rate rises (falls) in response to the demand (supply) shock, consistent with the predictions from the theoretical model for policy that stabilizes core inflation.","Label":"0"},{"DOI":"10.1016/j.jedc.2004.07.005","Abstract":"The money-in-utility model is re-considered with habits and endogenous growth. An increase in the inflation rate requires a fall in the steady state habits relative to capital, if initially the nominal interest rate is positive. If habits exhibit adjacent complementarity, immediately after the increase in the inflation rate savings and investment fall, reducing the growth rate. However, the long-run growth rate is not affected by the policy change. The long-run level of capital would be lower than it would have been had there been no increase in the inflation rate. These predictions are supported by our empirical evidence, and also reconcile some recent empirical evidence on inflation and growth.","Label":"0"},{"DOI":"10.2139/ssrn.604361","Abstract":"The aim of this paper is to propose a new method for forecasting Italian inflation. We expand on a standard factor model framework (see Stock and Watson (1998)) along several dimensions. To start with we pay special attention to the modeling of the autoregressive component of the inflation. Second, we apply forecast combination (Granger (2000) and Pesaran and Timmermann (2001)) and generate our forecast by averaging the predictions of a large number of models. Third, we allow for time variation in parameters by applying rolling regression techniques, with a window of three-years of monthly data. Backtesting shows that our strategy outperforms both the benchmark model (i.e. a factor model with does not allow for model uncertainty) and additional univariate (ARMA) and multivariate (VAR) models. Our strategy proves to improve on alternative models also when applied to turning point prediction.","Label":"0"},{"DOI":"10.1007/978-981-19-2211-4_38","Abstract":"Crude oil forecasting plays an important role in every country’s economic progress. Inflation is likely to rise as oil prices rise, delaying economic progress. In terms of inflation, oil prices directly affect the expense of commodities produced using petroleum products. Not only crude, this paper provides the idea of best prediction models that could be used for easy prediction in stocks. It provides an overview of the data and methodology. As a result, we have compiled a list of articles that discuss the impact of crude oil on various stock markets and how it affects different countries. And in general, we were looking for the optimal price prediction model between gated recurrent units (GRUs) and long short-term memory (LSTM).","Label":"1"},{"DOI":"10.34312/euler.v9i2.11173","Abstract":"Using the regression model, a method that accommodates variables related to each other is called the simultaneous equation method. The study aims to determine the factors affecting inflation and rupiah exchange rate and model simultaneous equations towards the factors affecting inflation and rupiah exchange rate in Indonesia using Two-Stage Least Square. Data used in this study are secondary data obtained from the website of Statistics of Indonesia. Findings on the simultaneous equation model with two-stage least squares reveal that variables that significantly affect inflation are the Indonesia rupiah exchange rate and money supply. At the same time, variables that significantly affect the Indonesian rupiah exchange rate are inflation and money supply. The predictive value using the inflation and rupiah exchange rate equation indicates that the obtained MAPE (Mean Absolute Percentage Error) value does not exceed 50%. In conclusion, the prediction result using the inflation and Indonesia rupiah exchange rate equation is accurate.","Label":"0"},{"DOI":"10.32535/jicp.v5i2.1700","Abstract":"Inflation is one of the most widely tested economic variables both theoretically and empirically. Stable inflation is a sign that sustainable economic growth provides benefits for improving people's welfare. This study aims to analyze the impact of Covid-19 on volatility inflation in Indonesian. The method used in this study is the ARIMA model. The results of this study are the ARMA (1.1.0) model suitable for testing inflation volatility in Indonesia. Forecasting results show that inflation over the next 5 months or until December 2022 tends to decrease. From the prediction results, the policy that can be applied to business sector actors is to carry out operational (marketing) activities carried out with an online system. The next policy that can be applied to companies is tax relaxation and easy access to credit to banks. Finally, the policies that can be applied due to the decline in commodity prices in the food and beverage and tobacco sectors are capital assistance and production equipment assistance for business actors.","Label":"0"},{"DOI":"10.2202/1558-3708.1280","Abstract":"In this paper we study 2-state Markov switching VAR models of monthly unemployment and inflation for three countries: Sweden, United Kingdom, and the United States. The primary purpose is to examine if periods of low inflation are associated with high or low unemployment volatility. To interpret the regimes the empirical results are compared with the predictions from a version of Rogoff's (1985) model of monetary policy. Our version is consistent with equilibrium unemployment and has the realistic feature of allowing both variables to be persistent. We find that both the theoretical and the empirical results suggest that an increase in central bank \"conservativeness\" can be associated with either a higher or a lower variance in unemployment. In the U.S. case we find that the variance of unemployment is lower in the low inflation regime than in the high inflation regime, while the Swedish and the U.K. cases suggest that unemployment variability is higher in the low inflation regime.","Label":"0"},{"DOI":"10.1111/j.1465-7295.1986.tb01813.x","Abstract":"How much will a 1% increase in expected inflation increase nominal interest rates? Irving Fisher's famous equation implies that nominal interest rates will rise in proportion to an increase in expected inflation. Darby and Feldstein, correcting the Fisher equation for taxation, predict a nominal interest rate increase of [1/(1 ‐ T)]% where T is the marginal tax rate: i.e., if T =3, then a 1 % increase in expected inflation should cause a 1.4 % rise in interest rates. Empirical evidence, however, suggests that the rise in interest rates is much smaller than the Darby/Feldstein prediction. Estimates are around 9, varying mostly between 5 and 1.15, which is much closer to Fisher's original prediction. It is important to know the size of the interest rate response to inflation expectations in a world in which inflation and interest rates are volatile and in which tax laws are designed to influence savings and investment through interest rates. In this paper we attempt to close the gap between theorized and estimated effects of inflation by incorporating into the Fisher equation two important aspects of the U.S. tax code: historic cost depreciation and the lower tax rate on capital gains. Our model shows that the effect of expected inflation on interest rates is dampened by the lower benefits from depreciation deductions arid the capital gains tax. Our corrected Fisher equation predicts a 1.12 % nominal interest rate increase, rather than the 1.4 % increase implied by the Darby/Feldstein model. The, our model closes about 56 % of the gap between theory and empirical evidence. The remainder could be closed by additional refinements in the model or better empirical modeling.","Label":"0"},{"DOI":"10.2139/ssrn.3401446","Abstract":"Central bankers often assert that anchoring of inflation expectations and reducing inflation uncertainty are good for economic outcomes. We test this claim and search for a relevant channel using panel data on sectoral growth for 22 manufacturing industries from 36 advanced and emerging market economies over the period 1990-2014. Our difference-in-difference strategy is based on the theoretical prediction that inflation uncertainty has larger effects in industries that are more credit constrained by increasing effective real borrowing costs. The results show that industries characterized by high external financial dependence, low asset tangibility, and high R&D intensity tend to grow faster in countries with well-anchored inflation expectations. The results are robust to controlling for the interaction between these characteristics and a broad set of macroeconomic variables over the sample period, including the level of inflation and output volatility. The results are also robust to IV techniques, using indicators of monetary policy transparency and independence as instruments.","Label":"0"},{"DOI":"10.2139/ssrn.2636234","Abstract":"Expectations play a crucial role in modern macroeconomic models. We consider a New Keynesian framework under a behavioral model of expectation formation and under rational expectations. Contrary to the rational model, the behavioral model predicts that inflation volatility can be lowered if the central bank reacts to the output gap in addition to inflation. We test the opposing theoretical predictions in a learning-to-forecast experiment. In line with the behavioral model, the results support the claim that output stabilization can lead to less volatile inflation.","Label":"0"},{"DOI":"10.1016/j.euroecorev.2019.05.009","Abstract":"Expectations play a crucial role in modern macroeconomic models. We consider a New Keynesian framework under a behavioral model of expectation formation and under rational expectations. Contrary to the rational model, the behavioral model predicts that inflation volatility can be lowered if the central bank reacts to the output gap in addition to inflation. We test the opposing theoretical predictions in a learning-to-forecast experiment. In line with the behavioral model, the results support the claim that output stabilization can lead to less volatile inflation.","Label":"0"},{"DOI":"10.1108/fs-07-2018-0070","Abstract":"Purpose                     This study aims to address the issue of prediction of inflation differences for an economy that considers either fixing its exchange rate or joining a currency union. In this setting, individual countries have limited control over their inflation, and anticipating the possible course of domestic inflation relative to inflation abroad becomes an important input in policy-making. In this context, the author compares simple forecast heuristics and econometric modeling.                                                           Design/methodology/approach                     The study compares two basically different approaches. The first approach of forecasting consists of simple heuristics. Various heuristics are considered that differ with respect to the economic reasoning that goes into quantifying the forecast rules. The simplest such forecasting heuristic suggests that the average over all available observations of inflation differentials should be taken as a predictor for the future. Bringing more economic insight to bear suggests a further heuristic according to which historical inflation differentials should be adjusted for changes in the nominal exchange rate. A further variant of this approach suggests that a forecast should exclusively rely on data from earlier times under a pegged exchange rate. A fundamentally different approach to prediction builds on dynamic econometric models estimated by using all available historical data independent of the currency regime.                                                           Findings                     The author studies three small member countries of the Eurozone, i.e. Finland, Luxembourg and Portugal. For the evaluation of the various forecasting strategies, he performs out-of-sample predictions over a horizon of five years. The comparison of the four different forecasting strategies documents that the variant of the forecast heuristic that draws on data from earlier experiences under fixed exchange rates performs better than the forecast based on the estimated econometric model.                                                           Practical implications                     The findings of this study provide helpful guidelines for countries considering either joining a currency union or fixing their exchange rate. The author shows that a simple forecasting heuristic gives sound advice for assessing the likely course of inflation.                                                           Originality/value                     This study describes how economic theory can guide the selection of historical data for assessing likely future developments. The analysis shows that using a simple heuristic based on historical analogy can lead to better forecasts than the analytically more sophisticated approach of econometric modeling.","Label":"0"},{"DOI":"10.2139/ssrn.4091992","Abstract":"We examine whether the quality of firms’ internal information systems influences the relation between inflation shocks and corporate investment, as posited by imperfect information models. Inconsistent with RBC models’ prediction that nominal variables (e.g., inflation) do not affect real variables (e.g., corporate investment) but consistent with the presence of information frictions, we first document a positive relation between inflation shocks and firm-level investment. Next, we show that higher internal information system quality, measured through responses to the World Management Survey, mitigates the positive relation between inflation shocks and firm-level investment. This result suggests that internal information quality serves as a channel through which aggregate-level nominal variables affect firm-level real variables. We then document relatively more efficient investment decisions following inflation shocks for firms with higher internal information system quality. Our inferences are robust to using the 8th EU Company Law Directive as a shock to internal information system quality and to several additional tests.","Label":"0"},{"DOI":"10.17016/feds.2003.43","Abstract":"This paper presents a re-formulated version of a canonical sticky-price model that has been extended to account for variations over time in the central bank's inflation target. We derive a closed-form solution for the model, and analyze its properties under various parameter values. The model is used to explore topics relating to the effects of disinflationary monetary policies and inflation persistence. In particular, we employ the model to illustrate and assess the critique that standard sticky-price models generate counterfactual predictions for the effects of monetary policy.","Label":"0"},{"DOI":"10.2139/ssrn.897702","Abstract":"Qualitative data on inflation perceptions and expectations, as obtained from surveys, can be quantified into numerical indicators of the perceived and expected rates of price change. This paper presents the results of different versions of probability and regression methods, implemented in order to estimate Polish consumer inflation perceptions and predictions, based on monthly consumer surveys. The paper also discusses the limited usefulness of quantitative questions, which occur to be excessively difficult for a significant part of respondents, whose numerical declarations are inconsistent with opinions expressed in a qualitative manner.","Label":"0"},{"DOI":"10.2202/1935-1690.1759","Abstract":"The Great Moderation refers to the fall in US output growth volatility in the mid-1980s. At the same time, the US experienced a moderation in inflation and lower average inflation. Asset pricing theory predicts that moderations -- real or nominal -- influence interest rates. Using annual data since 1890, we find that an earlier 1946 moderation in output and consumption growth was comparable to that of 1984. To assess the impact of these moderations, we also isolate the 1969-1983 Great Inflation using quarterly data since 1947. We examine the quantitative predictions of a consumption-based asset pricing model for shifts in the unconditional average of US interest rates across these time periods. A central finding is that such shifts probably were related to changes in average inflation rather than to moderations in inflation and consumption growth.","Label":"0"},{"DOI":"10.48550/arxiv.1010.2318","Abstract":"We compare forecasts of United States inflation from the Survey of Professional Forecasters (SPF) to predictions made by simple statistical techniques. In nowcasting, economic expertise is persuasive. When projecting beyond the current quarter, novel yet simplistic probabilistic no-change forecasts are equally competitive. We further interpret surveys as ensembles of forecasts, and show that they can be used similarly to the ways in which ensemble prediction systems have transformed weather forecasting. Then we borrow another idea from weather forecasting, in that we apply statistical techniques to postprocess the SPF forecast, based on experience from the recent past. The foregoing conclusions remain unchanged after survey postprocessing.","Label":"1"},{"DOI":"10.1007/bf02707690","Abstract":"A Nonnormative Theory of Inflation and Central Bank Independence. — The authors study monetary policy under different central bank constitutions when the labor-market insiders set the minimal wage so that the outsiders are involuntarily unemployed. If the insiders are in the majority, the representative insider will be the median voter. The authors show that an independent central bank, if controlled by the median voter, does not produce a systematic inflation bias, albeit equilibrium employment is too low from a social welfare point of view. A dependent central bank, in contrast, is forced by the government to collect seigniorage and to take the government’s re-election prospects into account. The predictions of their theory are consistent with the evidence that central bank independence decreases average inflation and inflation variability, but does not affect employment variability.","Label":"0"},{"DOI":"10.1007/bf00182190","Abstract":"This paper examines a voter model for the US which is interconnected with the partisan theory. In our model, voters are rational and forward-looking. They are perfectly informed about the preferences of political parties and about the state of the economy. The predictions of our voter model differ from the predictions of conventional voter models, according to which the incumbent benefits from low unemployment and low inflation, irrespective of its political colour. In a partisan setting, the democratic party benefits from high unemployment and the republican party benefits from high inflation. Regressions of presidential approval rates indicate that the predictions of both the partisan voter model and the conventional model are consistent with the data.","Label":"0"},{"DOI":"10.2139/ssrn.2799750","Abstract":"Purpose: This study addresses the issue of prediction of inflation differences for an economy that considers either fixing its exchange rate or joining a currency union. In this setting individual countries have limited control over their inflation and anticipating the possible course of domestic inflation relative to inflation abroad becomes an important input in policy making. In this context, we compare simple forecast heuristics and econometric modeling. Design/methodology/approach: We compare two basically different approaches. The first approach of forecasting consists of simple heuristics. Various heuristics are considered that differ with respect to the economic reasoning that goes into quantifying the forecast rules. The simplest such forecasting heuristic suggests that the average over all available observations of inflation differentials should be taken as a predictor for the future. Bringing more economic insight to bear suggests a further heuristic according to which historical inflation differentials should be adjusted for changes in the nominal exchange rate. A further variant of this approach suggests that a forecast should exclusively rely on data from earlier times under a pegged exchange rate. A fundamentally different approach to prediction builds on dynamic econometric models estimated by using all available historical data independent of the currency regime. Findings: We study three small member countries of the Eurozone, i.e., Finland, Luxembourg, and Portugal. For the evaluation of the various forecasting strategies we perform out-of-sample predictions over a horizon of five years. The comparison of the four different forecasting strategies documents that the variant of the forecast heuristic that draws on data from earlier experiences under fixed exchange rates performs better than the forecast based on the estimated econometric model. Practical Implications: The findings of this study provide helpful guidelines for countries considering either joining a currency union or fixing their exchange rate. We show that a simple forecasting heuristic gives sound advice for assessing the likely course of inflation. Originality: This study describes how economic theory can guide the selection of historical data for assessing likely future developments. The analysis shows that using a simple heuristic based on the historical analogy can lead to better forecasts than the analytically more sophisticated approach of econometric modeling.","Label":"0"},{"DOI":"10.2139/ssrn.885062","Abstract":"This paper empirically tests the benefits of Treasury inflation protected securities (TIPS) for investors. This study examines whether TIPS enhance the risk return characteristics of an investor's portfolio. The results of conditional spanning tests show that adding TIPS to any combined portfolio of stocks, Treasury bonds, Treasury bills, corporate bonds, and real estate provides investors with diversification benefits. This paper also shows that United Kingdom (UK) inflation-linked gilts (ILGs) enhance the risk return characteristics of an investor's portfolio. These findings hold in different economic and inflationary environments, and they confirm the prediction of economic theory that indexed bonds are important for investors who are vulnerable to inflation.","Label":"0"},{"DOI":"10.2139/ssrn.4098307","Abstract":"Using responses obtained through the Nielsen Homescan panel survey, we explore the differences between managers’ and non-managers’ expectations and perceptions of inflation and unemployment. By and large, managers and non-managers exhibit similar average inflation and unemployment expectations as well as similar levels of disagreement and sensitivity to information provided in a randomized control trial. Finally, the inflation expectations of managers deviate systematically from the predictions of “anchored” expectations.Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at www.nber.org.","Label":"0"},{"DOI":"10.1016/j.iref.2004.11.006","Abstract":"I study the value to society of information about central bankers' preferences for inflation relative to output stabilization. I find that the value to society of information is only positive if bankers are “very” conservative. The reason is the following. More information has two effects. On the one hand it allows the public to make more accurate predictions, reducing surprise inflation and consequently the expected variance of output; on the other hand, information increases the expected variability of inflation. The latter effect dominates the former when bankers are not “sufficiently” conservative.","Label":"0"},{"DOI":"10.1080/0003684022000015919","Abstract":"The optimal seigniorage hypothesis argues that the government will attempt to minimize the sum of social costs arising from the rate of inflation and taxation, which results in the testable prediction that inflation and rate of tax revenue will be positively correlated. This article empirically examines the regime-switching properties of this theory. Using quarterly data from Taiwan over 1961–2000 sampling periods, it finds that the optimal seigniorage hypothesis is weakly supported, and its explanatory power for the long-run inflation behaviour is weak.","Label":"0"},{"DOI":"10.1016/j.euroecorev.2022.104351","Abstract":"We develop an experimental framework to investigate the quantity theory of money and the real effects of inflation in an economy where money serves as a medium of exchange. We test the classical view that inflation reduces output and welfare by taxing monetary exchange. Inflation is engineered by constant money growth where newly-issued money is injected in one of three ways: to finance government spending, lump-sum transfers, or proportional transfers. Experimental results largely support theoretical predictions. Higher money growth leads to higher inflation. Output and welfare are significantly lower with government spending, output is significantly lower with lump-sum transfers, while there are no significant real effects with proportional transfers. A deviation from theory is that the detrimental effect of money growth depends on the implementation scheme and is stronger with government spending relative to lump-sum transfers.","Label":"0"},{"DOI":"10.1016/j.jmacro.2016.04.005","Abstract":"We use a threshold methodology to investigate the importance of non-linear effects in the analysis of the inflation globalization hypothesis. Accounting for potential non-linearities in the Phillips Curve, we show that trade openness is not rejected as a threshold variable for the effects of domestic and foreign slack on inflation in many advanced economies, and we find a switch of the output gap slopes from one regime to the other that is consistent with the key predictions of the inflation globalization hypothesis. For some countries the threshold Phillips Curve model also leads to improvements in out-of-sample forecast over the linear Phillips models, especially at longer horizons. Contrary to most of the previous literature which ignores such non-linearities, our new approach provides some interesting empirical evidence supportive of the effect globalization has on a country’s inflation dynamics.","Label":"0"},{"DOI":"10.14254/jems.2016.1-1.1","Abstract":"In this study, we proposed some inflation rate predictions based on econometric models that performed better than the targets of the National Bank of Romania. Few econometric models (multiple regressions model and a vector-autoregression) were used to predict the quarterly inflation rate in Romania during 2000:Q1-2016:Q4. The GDP growth has a negative impact on inflation rate in Romania, an increase in logarithm of GDP with one percentage point determining a decrease in inflation logarithm with less than 0.1 units according to both proposed models. However, an increase in inflation rate in the previous period determined an increase in this variable in the current period. The inverse of unemployment rate is positively correlated with the index of prices. The causal relationship between inflation rate and unemployment rate is reciprocal. In the first period the index of prices evolution is explained only by changes in this variable. The inflation rate volatility is due mainly to the evolution of this indicator, the influence decreasing insignificantly in time, not descending under 88%. More than 99% of the variation in unemployment rate is explained by the own volatility for all lags. The annual forecasts based on these models performed better than the targets on the horizon 2015-2016.","Label":"0"},{"DOI":"10.1002/jae.2411","Abstract":"Changing time series properties of US inflation and economic activity, measured as marginal costs, are modeled within a set of extended New Keynesian Phillips curve (NKPC) models. It is shown that mechanical removal or modeling of simple low‐frequency movements in the data may yield poor predictive results which depend on the model specification used. Basic NKPC models are extended to include structural time series models that describe typical time‐varying patterns in levels and volatilities. Forward‐ and backward‐looking expectation components for inflation are incorporated and their relative importance is evaluated. Survey data on expected inflation are introduced to strengthen the information in the likelihood. Use is made of simulation‐based Bayesian techniques for the empirical analysis. No credible evidence is found on endogeneity and long‐run stability between inflation and marginal costs. Backward‐looking inflation appears stronger than forward‐looking inflation. Levels and volatilities of inflation are estimated more precisely using rich NKPC models. The extended NKPC structures compare favorably with existing basic Bayesian vector autoregressive and stochastic volatility models in terms of fit and prediction. Tails of the complete predictive distributions indicate an increase in the probability of deflation in recent years. Copyright © 2014 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.2139/ssrn.4243161","Abstract":"We provide a comprehensive assessment of leading monetary policy frameworks away from and at the ELB. Inflation targeting, dual mandate, average inflation targeting under 4- and 10-period horizons, price level targeting, and nominal GDP level targeting are evaluated in a laboratory setting. Contrary to theoretical prediction with full information rational expectations, participants exhibit backward-looking expectations and, consequently, rate-targeting mandates outperform level targeting. More history dependence worsens macroeconomic stability. Inflation expectations are managed better when mandates are framed in terms of inflation rates than price levels. Central bank communication significantly improves the performance of price level targeting.Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at www.nber.org.","Label":"0"},{"DOI":"10.4028/www.scientific.net/amr.989-994.5536","Abstract":"This paper analyzes inflation forecast based on BP neural network model. Firstly, it reviews some references about BP neural network and finds that it is a nonlinear adaptive data-driven model with induction ability and a wide range of function approximation ability so that BP neural network could be applied into forecast research. Secondly, it builds up the BP neural network model to predict CPI, selecting the four indicators, which are excess liquidity, exchange rates, inflation expectation and macro-economic leading index. Then it carries out empirical experiment and takes advantage of the monthly data of the above four indicators from March 2005 to December 2012 to forecast CPI. The results show that when prediction period is 3 months, the maximum absolute error between forecast value and real value is 0.0139, and the minimum absolute error is 0.0005. When prediction period is 6 months, the maximum absolute error is not more than 0.02. It proves that BP neural network model can predict coming CPI trend at least 6 months according to the existing data and it means it is suitable for the study of inflation forecast.","Label":"1"},{"DOI":"10.2139/ssrn.119908","Abstract":"Financial innovation challenges the foundations of monetary theory, and standard monetary theory has not been very successful at describing the history of U.S. inflation. Motivated by these observations, I ask: Can we understand the history of U.S. inflation using a framework that ignores monetary frictions? The fiscal theory of the price level allows us to think about price level determination with no monetary frictions. The price level adjusts to equilibrate the real value of nominal government debt with the present value of surpluses. I describe the theory, and I argue that it is a return to pre-quantity theoretic ideas in which money is valued via a commodity standard or because the government accepts it to pay taxes. Both sources of value are immune to financial innovation and the presence or absence of monetary frictions. I then interpret the history of U.S. inflation with a fiscal-theory, frictionless view. I show how the fiscal theory can accommodate the stylized fact that deficits and inflation seem to be negatively, not positively correlated. I verify its prediction that open market operations do not affect inflation. I show how debt policy has already smoothed inflation a great deal.","Label":"0"},{"DOI":"10.1177/000271628145600104","Abstract":"To know who loses from inflation we must understand the social forces that cause it and be able to predict what will happen if we stop it. We do not know enough to make such a prediction, so my answer to the question is partial. Inflation should not be blamed for the fall in private consumption caused by the Organization of Petroleum Exporting Countries (OPEC), food shortages, or government spending. Rather it is the way we have resolved the conflicts created by the need to cut consumption. The main cost identified by economists is distortion of economic activity as people change their behavior to avoid holding cash; such effects are not severe enough to explain the intensity of public opposition to inflation. This could mean simply that people are deluded, blaming inflation for shortages, rather than the reverse. But here is another possible explanation: the most serious costs of persistent inflation may be that it destroys our confidence that society can solve its problems and creates fear that our social contract is falling apart. Coupled with the fear is resentment, based on suspicion by many that inflation treats them unfairly. Those who lose are all of us who share those fears and frustrations.","Label":"0"},{"DOI":"10.48550/arxiv.2108.10767","Abstract":"Plateau inflation is an experimentally consistent framework in which the scale of inflation can be kept relatively low. Close to the edge of the plateau, scalar perturbations are subject to a strong tachyonic instability. Tachyonic preheating is realized when, after inflation, the oscillating inflaton repeatedly re-enters the plateau. We develop the analytic theory of this process and expand the linear approach by including backreaction between the coherent background and growing perturbations. For a family of plateau models, the analytic predictions are confronted with numerical estimates. Our analysis shows that the inflaton fragments in a fraction of an $e$-fold in all examples supporting tachyonic preheating, generalizing the results of previous similar studies. In these scenarios, the scalar-to-tensor ratio is tiny, $r<10^{-7}$.","Label":"1"},{"DOI":"10.47065/ekuitas.v4i2.2395","Abstract":"Inflation is a condition where there is an increase in the price of goods and services continuously within a certain period of time. The impact of inflation is often in a negative direction due to increasing prices for products, causing a decrease in people's purchasing power, especially for people who have lower middle income levels. Assumptions or predictions of news related to inflation have already had an impact on the community. One of them is a decrease in consumer buying interest in goods. In this study, a research process will be carried out on the effect of inflation on consumer buying interest in a product, where the measurement is based on the positive or negative effect of inflation on consumer buying interest in the present. The research was conducted using quantitative methods by testing hypotheses. The results of the test show that the value of the inflation variable is 0.645 while the ttable value is 2.060, so it can be said that the hypothesis is rejected. In the sense that the effect of inflation does not have a negative impact on consumer buying interest in the product.","Label":"0"},{"DOI":"10.2139/ssrn.2294496","Abstract":"Changing time series properties of US inflation and economic activity, measured as marginal costs, are modeled within a set of extended Phillips Curve (PC) models. It is shown that mechanical removal or modeling of simple low frequency movements in the data may yield poor predictive results which depend on the model specification used. Basic PC models are extended to include structural time series models that describe typical time varying patterns in levels and volatilities. Forward as well as backward looking expectation mechanisms for inflation are incorporated and their relative importance evaluated. Survey data on expected inflation are introduced to strengthen the information in the likelihood. Use is made of simulation based Bayesian techniques for the empirical analysis. No credible evidence is found on endogeneity and long run stability between inflation and marginal costs. Backward-looking inflation appears stronger that forward-looking one. Levels and volatilities of inflation are estimated more precisely using rich PC models. Estimated inflation expectations track nicely the observed long run inflation from the survey data. The extended PC structures compare favorably with existing basic Bayesian Vector Autoregressive and Stochastic Volatility models in terms of fit and prediction. Tails of the complete predictive distributions indicate an increase in the probability of disinflation in recent years.","Label":"0"},{"DOI":"10.48550/arxiv.1401.2926","Abstract":"Inflation can be parameterized by means of truncated flow equations. In this \"horizon-flow\" setup, generic results have been obtained, such as typical values for $r/(1-n_\\mathrm{S})$. They are sometimes referred to as intrinsic features of inflation itself. In this paper we first show that the phenomenological class of inflationary potentials sampled by horizon-flow is directly responsible for such predictions. They are therefore anything but generic. Furthermore, the horizon-flow setup is shown to rely on trajectories in phase space that differ from the slow-roll. For a given potential, we demonstrate that this renders horizon-flow blind to entire relevant inflationary regimes, for which the horizon-flow trajectory is shown to be unstable. This makes horizon-flow a biased parameterization of inflation.","Label":"1"},{"DOI":"10.1007/s10368-005-0027-z","Abstract":"This paper uses an open economy DSGE model to analyse the short and long run quantitative impact of a permanent oil price increase for output and inflation in the euro area and compares the results to the predictions of other models currently in use. Special emphasis is devoted to the issue of stagflation. It is found that with standard monetary feedback rules as currently estimated for the euro area, there is no severe inflation risk. The paper also addresses the issue to what extent there is a short run trade off between inflation and output with an adverse supply shock.","Label":"0"},{"DOI":"10.1016/j.jmacro.2006.11.002","Abstract":"This paper shows an avenue through which a numerical long-run inflation target ensures low inflation and high credibility; one that is independent of the usual Walsh incentive contract. Our novel game theoretic framework – a generalization of alternating move games – formalizes the fact that since the target is explicit (legislated), it cannot be frequently reconsidered. This ‘explicitness’ therefore serves as a commitment device. There are two key results. First, it is shown that if the inflation target is sufficiently rigid/explicit relative to the public’s wages, low inflation is time consistent and hence credible even if the policymaker’s output target is above potential. Second, it is found that the central banker’s optimal explicitness level is decreasing in the degree of his patience/independence (due to their substitutability in achieving credibility). Our analysis therefore offers an explanation for the ‘inflation and credibility convergence’ over the past two decades as well as the fact that inflation targets were legislated primarily by countries that had lacked central bank independence like New Zealand, Canada, and the UK rather than the US, Germany, or Switzerland. We show that there exists fair empirical support for all the predictions of our analysis.","Label":"0"},{"DOI":"10.1007/s00181-005-0031-8","Abstract":"In this paper, by using a combination of long-run and short-run restrictions, we identify a small structural VECM which includes inflation, unemployment and the federal funds rate and study the dynamic interactions at different frequencies among these variables. Our results show that: (a) in accordance with the traditional view of economic fluctuations, aggregate demand shocks and monetary policy shocks push inflation and unemployment in opposite directions in the short run; (b) the permanent supply shock explains the long-run movement of inflation and unemployment. These conclusions are at odds with the prediction of “natural-rate” models but are consistent with the idea of a propagation mechanism which links productivity shocks to inflation and unemployment at medium and low frequencies. Thus, with respect to some recent studies (e.g. Beyer and Farmer, ECB Working Paper 121, 2002, and Ireland, J Monet Econ 44:279–291, 1999), we offer a different interpretation of the low-frequency comovements between inflation and unemployment characterizing the US economy in the last decades.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2015.01.004","Abstract":"This study utilizes Chilean data for analyzing the factors that affect the expectations of private forecasters (PFs), and, in particular, for determining whether they are influenced by the Central Bank of Chile’s (CBC’s) forecasts. Robust evidence suggests that short-term inflation expectations are influenced directly by the CBC’s forecasts, while the evidence is weaker for medium-term predictions. This is the case even though the CBC’s short-term inflation forecasts do not seem to contain any additional information that is of use for PFs when making their predictions. PFs’ short-term growth expectations seem to incorporate the CBC’s forecasts only when they are published in the second half of the year, when the CBC may have private information, e.g., about future data revisions.","Label":"0"},{"DOI":"10.1109/i-society16502.2010.6018807","Abstract":"In present context, Information Technology (IT) is used in every field whether it is Business, Social Service or Entertainment. However, application of IT in economic field is very limited. Stability and healthiness of a country's economy directly connects with the accuracy of forecasted Inflation rate. With the recession raised at end of year 2008, world communities pay much attention on inflation and put huge efforts to predict it accurately. Neural networking and data mining are two IT techniques that are commonly used in forecasting and hidden pattern recognition. We have applied both of these techniques to the theoretically sound data set with the intention of identifying most appropriate IT forecasting technique for forecasting the inflation rate. Since forecasted inflation rate directly link with country's monetary policy, accuracy of predictions is very significant. Further continuity of government as well as the economy depends on these decisions. Through this study we were able to identify appropriate characteristics of neural networks and Data mining techniques in case of forecasting inflation rate with high accuracy.","Label":"1"},{"DOI":"10.12775/dem.2010.010","Abstract":"This paper aims to use the local level models with GARCH and SV errors to predict Polish inflation. The series to be forecast, measured monthly, is consumer price index (CPI) in Poland during 1992-2008. We selected three forecasting models i.e. LL-GARCH(1,1) with Normal or Student errors and LL-SV. A simple AR(2)-SV model is used as a benchmark to assess the accuracy of prediction. The presented results indicate, that there is no clear advantage of LL models in forecasting Polish inflation over standard AR(2)-SV model, although all the models give satisfactory results.","Label":"0"},{"DOI":"10.2139/ssrn.4396266","Abstract":"This study explores the relationship between inflation and income inequality in an open-economy Schumpeterian growth model with heterogeneous households, firm-level innovation, and cash-in-advance constraints on R&D investment. We find that income inequality may monotonically increase with domestic inflation or display a U-shaped pattern, depending on the influence of a country’s technology growth on the global real interest rate. These predictions are supported by our quantitative model calibrated to the US and eurozone economies and empirical results using cross-country data.","Label":"0"},{"DOI":"10.2202/1534-6005.1068","Abstract":"Fair (2002) argues that New Keynesian models are wrong in predicting that an inflation shock has contractionary effects only if it raises the real interest rate, and that a coefficient on inflation higher than one in the Taylor rule is a necessary condition for stability. While Fair uses his macroeconometric model as a benchmark to evaluate the predictions of the standard New Keynesian framework, we adopt a VAR supported by models in that framework, and the model of Rudebusch and Svensson (1999). The findings are broadly in line with Fair's.","Label":"0"},{"DOI":"10.1016/s0304-3878(02)00002-0","Abstract":"The median developing country has had significantly higher inflation than the median advanced country since the early 1980s. We present a model in which a developing country may reduce inflationary expectations by pegging its exchange rate to the currency of an advanced country, at the expense of forgoing its ability to compensate for real exchange rate shocks. Different types of pegged exchange rate offer varying degrees of anti-inflation credibility and of exposure to shocks. Tests on a sample of 80 developing countries support the empirical predictions of the model.","Label":"0"},{"DOI":"10.1080/10800379.2006.12106398","Abstract":"This study analyses the reaction of daily stock prices on the JSE Securities Exchange to new information about inflation, contained in the announcement of the Consumer Price Index (CPI). Three different prediction models for inflation are compared. It is shown that a model based on the time-series of past inflation announcements performs as well, if not better, than a model based on the time-series of real rates of return. However, both these models are shown to be far more accurate predictors of inflation than a simple interest rate model. The results of a multiple regression model for stock returns based on unexpected inflation reveal that there is no significant reaction of stock prices to the information contained in CPI announcements. This suggests that such announcements do not really convey new information to the market, and that the announcement figure is already impounded into stock prices well before the actual announcement date. This evidence suggests that the JSE Securities Exchange may show stronger evidence of efficiency than previously believed.","Label":"0"},{"DOI":"10.1016/0047-2727(80)90029-8","Abstract":"Traditional theory implies that the relative price of consumer goods and of such real assets as land and gold should not be permanently affected by the rate of inflation. A change in the general rate of inflation should, in equilibrium, cause an equal change in the rate of inflation for each asset price. The experience of the past decade has been very different from the predictions of this theory: the prices of land, gold, and other such stores of value have increased by substantially more than the general price level. The present paper presents a simple theoretical model that explains the positive relation between the rate of inflation and the relative price of such real assets. More specifically, in an economy with an income tax, an increase in the expected rate of inflation causes an immediate increase in the relative price of such ‘store of value’ real assets. The behavior of real asset prices discussed in this paper is thus a further example of the non-neutral response of capital markets to inflation in an economy with income taxes.","Label":"0"},{"DOI":"10.1016/j.econmod.2015.04.007","Abstract":"In this paper we investigate the trade-off between the output gap and inflation using a nonlinear quantile regression approach. This approach combines the classical quantile regression with a nonlinear analysis technique and presents the advantages of discovering the heterogeneous nonlinearity of the Phillips curve across quantiles of the inflation distribution. For the empirical illustration, we compare three types of the Phillips curve models in the quantile regression framework. Empirical results for the United States show that the hybrid Phillips curve model outperforms the other two in terms of goodness of fit and prediction ability. We find that the shape of the Phillips curve for the United States is nonlinear and asymmetric, and varies considerably across quantiles. We also provide a novel look at the inflation changes by estimating the conditional density of inflation given different output gap levels, with the numerical results indicating that an increase of the output gap boosts the level of inflation as well as raises the uncertainty of inflation. Our findings imply that the effectiveness of monetary policy mainly depends on the phase of the economic cycle and the inflation uncertainty.","Label":"1"},{"DOI":"10.2139/ssrn.421880","Abstract":"In this paper we assess the empirical relevance of an expectations version of purchasing power parity in forecasting the Dollar/Euro exchange rate. This version is based on the differential of inflation expectations derived from inflation-indexed bonds for the Euro area and the USA. Using the longest daily data a for both the Dollar/Euro exchange rate and for the inflation expectations, our results suggest that, with few exceptions, our predictors behave significantly better than a random walk in forecasts up to five days, both in terms of prediction errors and in directional forecast.","Label":"0"},{"DOI":"10.2139/ssrn.880594","Abstract":"According to theory, inflation persistence should have less variance across countries under pegged than floating exchange rates, but not necessarily a lower mean. The paper tests this prediction on postwar data for OECD countries. After allowing for the upward bias to persistence estimates created by shifts in mean inflation, the paper finds persistence has a greater spread (but not a higher mean) in the floating-rate period, as predicted by theory. Monetary growth has been much less accommodative of inflation under floating rates, most probably because of the shifts in monetary policy rather than those in exchange rate regime.","Label":"0"},{"DOI":"10.1177/056943451005500111","Abstract":"This study extends previous work on the asymmetric information hypothesis by comparing the Federal Reserve and private inflation forecasts in terms of directional accuracy for 1983–2002. In support of this hypothesis, the Federal Reserve forecasts show superiority in terms of both predictive content and directional accuracy. However, both sets of forecasts are far more accurate in predicting upward moves than they are in predicting downward moves. In an environment where maintaining price stability is a top priority, we interpret such evidence as preference for over-prediction under asymmetric loss and argue that the bias in the inflation forecasts is rational.","Label":"0"},{"DOI":"10.1198/016214507000000473","Abstract":"This article focuses on the widely studied question of whether the inclusion of indicators of real economic activity lowers the prediction mean squared error of forecasting models of U.S. consumer price inflation. We propose three variants of the bagging algorithm specifically designed for this type of forecasting problem and evaluate their empirical performance. Although bagging predictors in our application are clearly more accurate than equally weighted forecasts, median forecasts, ARM forecasts, AFTER forecasts, or Bayesian forecast averages based on one extra predictor at a time, they are generally about as accurate as the Bayesian shrinkage predictor, the ridge regression predictor, the iterated LASSO predictor, or the Bayesian model average predictor based on random subsets of extra predictors. Our results show that bagging can achieve large reductions in prediction mean-squared errors even in such challenging applications as inflation forecasting; however, bagging is not the only method capable of achieving such gains.","Label":"1"},{"DOI":"10.1016/j.econmod.2009.09.010","Abstract":"We examine the informational content of New Zealand data releases using a parametric dynamic factor model estimated with unbalanced real-time panels of quarterly data. The data are categorised into 21 different release blocks, allowing us to make 21 different factor model forecasts each quarter. We compare three of these factor model forecasts for real GDP growth, CPI inflation, non-tradable CPI inflation, and tradable CPI inflation with three different real-time forecasts made by the Reserve Bank of New Zealand each quarter. We find that, at some horizons, the factor model produces forecasts of similar accuracy to the Reserve Bank's forecasts. Analysing the marginal value of each of the data releases reveals the importance of the business opinion survey data—the Quarterly Survey of Business Opinion and the National Bank's Business Outlook survey—in determining how factor model predictions, and the uncertainty around those predictions, evolve through each quarter.","Label":"0"},{"DOI":"10.1080/10168730802497551","Abstract":"This paper investigates the relationship between capital account openness and inflation since the 1980s. It argues that widespread capital account liberalization during the last two decades appears to have contributed to the worldwide disinflation observed during the same period. The paper builds a theoretical model to motivate the presence of a negative link between financial integration and inflation. It tests the prediction of the theoretical model by employing static and dynamic panel data procedures. Financial integration appears to discipline monetary authorities, or to help them convince the private sector that they will be more disciplined in the future.","Label":"0"},{"DOI":"10.1016/j.ecosys.2022.101005","Abstract":"We develop an overlapping generations (OLG) monetary endogenous growth model characterized by socio-political instability, with the latter being specified as a fraction of output lost due to strikes, riots and protests. We show that growth dynamics arise in this model when socio-political instability is a function of inflation. In particular, two distinct growth dynamics emerge, one convergent and the other divergent contingent on the strength of the response of socio-political instability to inflation. Since our theoretical results hinge on socio-political instability being a function of inflation, we test the prediction that inflation affects socio-political instability positively by using a panel of 156 countries for the 1980–2012 period, and allowing for country and time fixed effects. The results indicate that inflation relates positively with socio-political instability. Policy makers should be cognisant that it is crucial to maintain long-run price stability, as failure to do so may result in high inflation emanating from excessive money supply growth, leading to high (er) socio-political instability, and ultimately, the economy being on a divergent balanced growth path.","Label":"0"},{"DOI":"10.2139/ssrn.2152083","Abstract":"We evaluate the ability of several univariate models to predict inflation in a number of countries and at several forecasting horizons. We focus on forecasts coming from a family of ten seasonal models that we call the Driftless Extended Seasonal ARIMA (DESARIMA) family. Using out-of-sample Root Mean Squared Prediction Errors (RMSPE) we compare the forecasting accuracy of the DESARIMA models with that of traditional univariate time-series benchmarks available in the literature. Our results show that DESARIMA-based forecasts display lower RMSPE at short horizons for every single country, except one case. We obtain mixed results at longer horizons. In particular, when the median forecast is considered, in more than half of the countries our DESARIMA-based forecasts outperform the benchmarks at long horizons. Remarkably, the forecasting accuracy of our DESARIMA models is high in stable inflation countries, for which the RMSPE is around 100 basis points when prediction is made 24- and even 36-months ahead.","Label":"0"},{"DOI":"10.31227/osf.io/3cb29","Abstract":"This study examines whether economic stability in Indonesia capable predicted by the model Mundell-Fleming. Prediction proxy stability of the interaction of fiscal and monetary policy. During Indonesia's economic stability is largely determined by the strength of economic fundamentals, while economic fundamentals are strongly influenced by fiscal and monetary policies. Therefore flemming Mundell predicts how strong the economic stability in Indonesia ?, the statement in the analysis by using a long-term predictions are Vector Autoregression. Research findings indicate patterns of interaction predictions variety of fiscal and monetary policy, both short term, medium term and long term. It turned out that fiscal policies are derived from taxes are more effective than government spending to control economic growth, investment and inflation, but government spending is more effective to control the exchange rate. The monetary policy of interest rates more effectively control the exchange rate and inflation, while the money supply is more effective in controlling the growth of economy and investment.","Label":"0"},{"DOI":"10.1016/j.jmacro.2014.04.003","Abstract":"Conventional wisdom holds that, in the long run, the Phillips curve is vertical. We re-examine the relationship between inflation and unemployment in the long run, using quarterly US data from 1952 to 2010, and state-of-the art econometric methods. Using a band-pass filter approach, we find strong evidence that a positive relationship exists, where inflation leads unemployment by some 3–312years, in cycles that last from 8 to 25 or 50years. Tests for multiple structural changes at unknown dates show that this relationship is stable. Our statistical approach is atheoretical in nature, but provides evidence in accordance with the predictions of Friedman (1977) and the recent New Monetarist model of Berentsen et al. (2011): the relationship between inflation and unemployment is positive in the long run.","Label":"0"},{"DOI":"10.31227/osf.io/7hsp2","Abstract":"In this study will be used back propagation neural network method to predict themonthly inflation rate in Indonesia. In the results of the data analysis is concludedthat the  performance of  back  propagation  neural network   that  formed by thetraining data and validated by  testing data generates prediction accuracy rate  isvery good with a mean square error (MSE) is 0.0171. By using a moving averageto forecast the independent variables obtained the rate of inflation in the month ofJuly  2014  is  0.514,  by using  exponential  smoothing  to  forecast  the independentvariables obtained by  the rate of inflation  in  the month of July 2014 is 0.45, andby using  seasonal method  to  forecast  the independent variables obtained by  therate of inflation in the month of July 2014 is 0.93.","Label":"1"},{"DOI":"10.5935/0034-7140.20150021","Abstract":"This paper proposes a generalized Phillips curve in order to forecast Brazilian inflation over the 2003:M1–2013:M10 period. To this end, we employ the Dynamic Model Averaging (DMA) method, which allows for both model evolution and time-varying parameters. The procedure mainly consists in state-space representation and by Kalman filter estimation. Overall, the dynamic specifications deliver good inflation predictions for all the forecast horizons considered, underscoring the importance of time-varying features for forecasting exercises. As to the usefulness of the predictors on explaining the Brazilian inflation, there are evidences that the short- and long-term Phillips curve relationship may be rejected for Brazil while short- and medium-term exchange rate pass-through apparently has been decreasing in the last years.","Label":"0"},{"DOI":"10.1111/0008-4085.00089","Abstract":"In this paper we evaluate the dynamic inconsistency argument put forth by Kydland and Prescott (1977) and Barro and Gordon (1983) as an explanation for differences in the average inflation experience across OECD countries. The focus is on the empirical evidence relating the overall degree of competition among firms, as measured by the markup of price over marginal cost, and inflation over the 1973–88 period. The prediction is that higher markups raise the monetary authority's incentive to increase output, leading to higher equilibrium rates of inflation. We find that the markup does well in explaining cross‐country differences in average inflation. JEL Classification: E31, E58, D43 L'écart du prix par rapport au coût marginal et l'inflation: résultats pour les pays de l'OCDE. Ce mémoire examine l'argument mis de l'avant par Kydland et Prescott (1977) et Barro et Gordon (1983) pour expliquer les différences dans le taux moyen d'inflation entre les pays de l'OCDE. On porte une attention spéciale aux résultats empiriques qui relient le degré général de concurrence entre les entreprises, mesuré par l'écart du prix par rapport au coût marginal, et le niveau d'inflation entre 1973 et 1988. La prédiction est que des écarts prix/coût marginal plus élevés augmentent l'incitation des autorités monétaires à accroître le niveau de production, ce qui entraîne des taux d'inflation d'équilibre plus élevés. Il s'avère que l'écart du prix par rapport au coût marginal tend à expliquer bien les différences dans le niveau moyen d'inflation entre pays.","Label":"0"},{"DOI":"10.1109/icsssm.2015.7170251","Abstract":"Analyzing inflation forecast problem, this paper proposes a SVM-based approach. Firstly, the paper reviews some former studies about inflation forecasting and predicting methodology, finding that SVM is a nonlinear adaptive data-driven model with strong approximation and generalization ability, which can be applied to complex forecasting tasks. Secondly, the paper establishes a SVM model and discusses the selection of kernel functions. Thirdly, the Particle Swarm Optimization (PSO) and the Genetic Algorithm (GA) are introduced to optimize the models. Then the SVM-based models (Fixed-SVM, PSO-SVM, GA-SVM) together with a BP neural network are employed to forecast Chinese inflation rate. The results show that the PSO-SVM performs better than BP and any other SVM-based model since its MSE of testing group is 0.006 and its absolute errors between predictions and real values are all below 0.02. It reveals that the final PSO-SVM model is promising in short-term inflation forecast.","Label":"1"},{"DOI":"10.1016/j.ijforecast.2020.08.003","Abstract":"If ‘learning by doing’ is important for macro-forecasting, newcomers might be different from regular, established participants. Stayers may also differ from the soon-to-leave. We test these conjectures for macro-forecasters’ point predictions of output growth and inflation, and for their histogram forecasts. Histogram forecasts of inflation by both joiners and leavers are found to be less accurate, especially if we suppose that joiners take time to learn. For GDP growth, there is no evidence of differences between the groups in terms of histogram forecast accuracy, although GDP point forecasts by leavers are less accurate. These findings are predicated on forecasters being homogeneous within groups. Allowing for individual fixed effects suggests fewer differences, including leavers’ inflation histogram forecasts being no less accurate.","Label":"1"},{"DOI":"10.1016/j.jdeveco.2004.02.006","Abstract":"This paper further tests Romer's [Romer, D., 1993. Openness and inflation: theory and evidence. Quarterly Journal of Economics 58, 869–903] extension of Kydland and Prescott's [Kydland, F., Prescott, E., 1977. Rules rather than discretion: the inconsistency of optimal plans. Journal of Political Economy 85, 473–491] predictions for dynamic inconsistency problems in open economies. In a panel data set of developed and developing countries from 1973 to 1998, I find that openness does not play a role in restricting inflation in the short run. On the other hand, a fixed exchange-rate regime plays a significant role. The results are robust to controlling for other variables that determine inflation, performing sensitivity analysis, and using a de facto exchange-rate regime classification.","Label":"0"},{"DOI":"10.1080/758518501","Abstract":"Combining and processing the information in ten previously published studies, we analyse the Lucas variability hypotheses. When adequate account is taken of structural differences between developing and developed countries, the prediction of the Lucas model that higher nominal demand variability leads to a lower inflation-output trade-off must be rejected for the group of developed countries. This does not imply that developed countries can use active demand policies without deteriorating their short-run inflation-output trade-off. More realistically, the result suggests that nominal demand variability is an inadequate indicator of demand shocks for the group of developed countries. This may be due to relatively low inflation levels and variability in the developed countries. For the developing countries where nominal (inflationary) shocks dominate, this may be less of a problem.","Label":"0"},{"DOI":"10.2139/ssrn.1456384","Abstract":"This paper examines optimal monetary policy in a New Keynesian model where the relative price of oil is affected by exogenous supply shocks and a productivity driven demand shock. When wages are flexible, stabilizing core inflation is optimal and the nominal rate rises (falls) in response to a demand (supply) shock. When both prices and wages are sticky, core inflation falls (rises) in response to the demand (supply) shock. Stabilizing CPI inflation generates small welfare losses only if the demand shock is the main driver of oil prices. Based on a VAR estimated using post-1986 data for the U.S., both shocks have had minimal impacts on core inflation. The federal funds rate rises in response to the demand shock but falls in response to the supply shock, consistent with the predictions of the theoretical model for a policy that stabilizes core inflation.","Label":"0"},{"DOI":"10.2139/ssrn.190852","Abstract":"The simultaneous occurrence in the second half of the 1990s of low and falling price inflation and low unemployment appears to be at odds with the properties of a standard Phillips curve. We find this result in a model in which inflation depends on the unemployment rate, past inflation, and conventional measures of price supply shocks. We show that, in such a model, long lags of past inflation are preferred to short lags, and that with long lags, the NAIRU is estimated precisely but is unstable in the 1990s. Two alternative modifications to the standard Phillips curve restore stability. One replaces the unemployment rate with capacity utilization. Although this change leads to more accurate inflation predictions in the recent period, the predictive ability of the utilization rate is not superior to that of the unemployment rate for the 1955 to 1998 sample as a whole. The second, and preferred, modification augments the standard Phillips curve to include an \"error-correction\" mechanism involving the markup of prices over trend unit labor costs. With the markup relatively high through much of the 1990s, this channel is estimated to have held down inflation over this period, and thus provides an explanation of the recent low inflation.","Label":"0"},{"DOI":"10.2139/ssrn.670202","Abstract":"Recent research and policy discussions have noted that the potentially increased competition among firms since the 1990s may affect inflation and economic activity. This paper considers the implications of this structural change on short-run inflation dynamics, and for assessing shocks to inflation and output. The importance of firms' price-setting behaviour is highlighted in this context using a standard New Keynesian model with microfoundations. It is well known that both Rotemberg and Calvo price-setting assumptions imply the same reduced-form New Keynesian Phillips Curve (NKPC). Increased competition among firms, however, increases price flexibility in the former, and has either no effect or decreases price flexibility in the latter. The effects of mark-up shocks on inflation and output are small when firms' price-setting behaviour incorporates concerns about potential loss of market share. These effects are further dampened in an environment of more intense competition. Under the assumption of increased competition, both models lead to unambiguous predictions about the direction of change in the slope of the Phillips curve. Rolling estimates of the NKPC indicate that the slope has declined or flattened for several countries since the 1990s. This evidence is consistent with the prediction of the Calvo model.","Label":"0"},{"DOI":"10.1016/j.eswa.2022.117982","Abstract":"Forecasting inflation accurately in a data-rich environment is a challenging task and an active research field which still contains various unanswered methodological questions. One of them is how to find and extract the information with the most predictive power for a variable of interest when there are many highly correlated predictors, as in the inflation forecasting problem. Traditionally, factor models have been used to tackle this problem. However, a few recent studies have revealed that machine learning (ML) models such as random forests may offer some valuable solutions to the problem. This study encourages greater use of ML models with or without factor models by replacing the functional form of the forecast equation in a factor model with ML models or directly employing them with several feature selection techniques. This study adds new tree-based models to the analysis in the light of the recent findings in the literature. Moreover, it proposes the integration of feature selection techniques with Shapley values to find out concise explanations of the inflation predictions. The results obtained by a comprehensive set of experiments in an emerging country, Turkey, facing a high degree of volatility and uncertainty, indicate that tree-based ensemble models can be advantageous by providing better accuracy together with explainable predictions.","Label":"1"},{"DOI":"10.1080/17520843.2021.1901347","Abstract":"This paper examines the behaviour of inflation, output, and unemployment in Sub-Saharan Africa (SSA) countries and shows that the predictions of the Phillips curve and Okun’s law are valid in the short run. In the long run however, the Okun’s law coefficient declines greatly and turns positive while the Phillips curve phenomenon gravitates towards the New Keynesian Phillips Curve (NKPC) but with a negative relationship. The evidence echoes Friedman’s proposition of a temporary trade-off between inflation and unemployment but no permanent trade-off. The output-unemployment relationship suggests that the long-term growth revival in SSA was neither inclusive nor pro-poor.","Label":"0"},{"DOI":"10.1002/for.955","Abstract":"In this paper we assess the empirical relevance of an expectations version of purchasing power parity in forecasting the dollar/euro exchange rate. This version is based on the differential of inflation expectations derived from inflation‐indexed bonds for the euro area and the USA. Using the longest daily data for both the dollar/euro exchange rate and for the inflation expectations, our results suggest that, with few exceptions, our predictors behave significantly better than a random walk in forecasts up to five days, both in terms of prediction errors and in directional forecasts. Copyright © 2005 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.2139/ssrn.2362420","Abstract":"Do managerial incentive horizons have capital market consequences? We find that they do when short-sale constraints are more binding. Firms experience significant stock price inflation when their CEOs have short horizon incentives. The short-horizon CEOs sell more shares at inflated prices and generate greater abnormal trading profits. The stock price inflation is partly explained by greater earnings surprises and more positive investor reaction to the surprises. To inflate stock prices, short-horizon firms are more likely to employ income-increasing discretionary accruals. Consistent with theoretical predictions, all these effects are attenuated or statistically insignificant when short-sale constraints are less binding.","Label":"0"},{"DOI":"10.1080/758532829","Abstract":"In this paper, Fama's joint hypothesis that the ex ante real interest rate is constant and that the US Treasury bill market is efficient, is tested. The signal extraction technique, a methodology from engineering literature, is used to identify and measure the ex ante real interest rate. The maximum-likelihood estimate of the variance of the ex ante real interest rate is significantly different from zero. Regression results based on the filtered estimate of the expected inflation also show a large and significant effect on the composite predictions of the rate of inflation. Thus, Fama's joint hypothesis is rejected.","Label":"0"},{"DOI":"10.1111/j.1468-0297.2008.02162.x","Abstract":"This article introduces a new source of survey data, namely the Bank of England Survey of External Forecasters. The survey collects point and density forecasts of inflation and GDP growth and, hence, offers the opportunity of constructing direct measures of uncertainty. We present a simple statistical framework in which to define and interrelate measures of uncertainty and disagreement. The resulting measures are compared with other direct measures of uncertainty, nationally and internationally. A significant, sustained reduction in inflation uncertainty followed the 1997 granting of operational independence to the Bank of England to pursue a monetary policy of inflation targeting.","Label":"0"},{"DOI":"10.2139/ssrn.3575169","Abstract":"This paper investigates how the difference between firms' inflation expectations, measured by the loan amounts they demand, and actual inflation affects their employment. In addition, it examines the relationship between firms' inflation expectations and wages in an individualistic bargaining model. Theoretically, the model shows that a firm's actual labor demand meets its expected labor demand if the firm has a rational expectation regarding inflation. On the other hand, the firm's actual labor demand deviates from its expected labor demand if the firm cannot forecast inflation correctly. Empirically, using firm-level data from a province in Iran between 2004 and 2011, the model's predictions have been tested. The empirical results confirm that there is a specific loan amount for which firms' expected employments meet their actual ones. In contrast, there is a gap between firms' expected employments and their actual ones for any other loan amount. Furthermore, the result indicates that there is a positive and significant relationship between the loan amounts demanded by firms and wages. These results can be explained by firms' inflation expectations that show they are not consistent with full-information rational expectations models, though they are not far away from them.","Label":"0"},{"DOI":"10.1016/s2212-5671(15)00701-7","Abstract":"This article measures and analyzes how the monetary policy's credibility is dynamically related to macroeconomic performance in Brazil. Performing a Bayesian VAR with Litterman/Minnesota priors, we obtain results highlighting that monetary policy's credibility gains (and losses) are affected by inflation rate shocks, while the higher such credibility the easier the control of inflationary expectations and thereby taming effective inflation rates becomes a natural result over time. Furthermore, we verified other important new-keynesian predictions for Brazil, such as the pass-through effect, the output-inflation relation (Phillips curve), the interest rate-output one (IS curve), as well as the reaction of such a rate to inflation shocks (Taylor rule). At last, the monetary policy's credibility is negatively affected by an undervaluated domestic currency.","Label":"0"},{"DOI":"10.1016/s0304-3932(03)00079-5","Abstract":"This paper uses a large data set, consisting of 447 monthly macroeconomic time series concerning the main countries of the Euro area to simulate out-of-sample predictions of the Euro-area industrial production and the harmonized inflation index and to evaluate the role of financial variables in forecasting. We considered two models which allow forecasting based on large panels of time series: Forni et al. (Rev. Econom. Statist. 82 (2000) 540; Mimeo (2001b)) and Stock and Watson (Mimeo (1999)). Performance of both models were compared to that of a simple univariate AR model. Results show that multivariate methods outperform univariate methods for forecasting inflation at one, three, six, and twelve months and industrial production at one and three months. We find that financial variables do help forecasting inflation, but do not help forecasting industrial production.","Label":"0"},{"DOI":"10.1002/for.1056","Abstract":"This paper uses a meta‐analysis to survey existing factor forecast applications for output and inflation and assesses what causes large factor models to perform better or more poorly at forecasting than other models. Our results suggest that factor models tend to outperform small models, whereas factor forecasts are slightly worse than pooled forecasts. Factor models deliver better predictions for US variables than for UK variables, for US output than for euro‐area output and for euro‐area inflation than for US inflation. The size of the dataset from which factors are extracted positively affects the relative factor forecast performance, whereas pre‐selecting the variables included in the dataset did not improve factor forecasts in the past. Finally, the factor estimation technique may matter as well. Copyright © 2008 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.2139/ssrn.281128","Abstract":"This paper reconsiders the link between tight money policies and inflation in the spirit of Sargent and Wallace's (1981) influential paper \"Some Unpleasant Monetarist Arithmetic\". A standard neoclassical model with production, capital, bonds, and return-dominated currency is used to study the long-run effects on inflation of a tightening of monetary policy engineered via a open market sale of bonds. The potential for tight money policies to be inflationary (unpleasant arithmetic) is shown to exist even when the real interest rate is below the growth rate of the economy. Equilibria exhibiting unpleasant arithmetic can be stable. In contrast, when monetary policy is conducted via an inflation target rule, the only stable equilibrium is the one that exhibits pleasant arithmetic. The two monetary policy rules therefore produce sharply different predictions about the likely observability of unpleasant arithmetic in real-world economies.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2019.08.013","Abstract":"We analyze the narratives that accompany the numerical forecasts in the Bank of England’s Quarterly Inflation Reports, 1997–2018. We focus on whether the narratives contain useful information about the future course of key macro variables over and above the point predictions, in terms of whether the narratives can be used to enhance the accuracy of the numerical forecasts. We also consider whether the narratives are able to predict future changes in the numerical forecasts. We find that a measure of sentiment derived from the narratives can predict the errors in the numerical forecasts of output growth, but not of inflation. We find no evidence that past changes in sentiment predict subsequent changes in the point forecasts of output growth or of inflation, but do find that the adjustments to the numerical output growth forecasts have a systematic element.","Label":"1"},{"DOI":"10.1016/0261-5606(91)90045-l","Abstract":"In this paper we investigate empirically the determinants of inflation, seigniorage and fiscal deficits in developing countries. We first test the optimal taxation theory of inflation for a group of 21 LCDs. We find that the implications of this theory are rejected for all these countries. We then proceed to implement a number of tests based on the new political economy approach to macroeconomic policies: we deal with some of the implications of a credibility and reputation model, and of a strategic government behavior model. We find that the data support the most important predictions of the political economy view of fiscal policy. Our measures of political instability and political polarization play an important role in explaining cross country differences in seigniorage, inflation, government borrowing and fiscal deficits. We end by discussing directions for future research.","Label":"0"},{"DOI":"10.1007/bf02298856","Abstract":"The paper examines how the presence of capital adjustment costs and time-to-build constraints weaken the Fisher effect and inflation neutrality, and hence attenuate the arbitrage opportunities implicit in intertemporal substitution and the investment decision. It is demonstrated that large and permanent changes in inflation affect nominal interest rates, intertemporal substitution, and investment choices differently than small or temporary changes. Small, transitory inflationary innovations will lower real interest rates, yet create no arbitrage opportunities since the benefits from these low rates will be insufficient relative to the adjustment costs implicit in altering investment. Large, permanent inflationary innovations will possess no real effects. The paper then presents empirical work to support the prediction that the expected inflation effect on nominal interest rates depends on the perceived size and permanence of the innovation.","Label":"0"},{"DOI":"10.1088/1757-899x/352/1/012056","Abstract":"A country has some important parameters to achieve the welfare of the economy, such as tax revenues and inflation. One of the largest revenues of the state budget in Indonesia comes from the tax sector. Besides, the rate of inflation occurring in a country can be used as one measure, to measure economic problems that the country facing. Given the importance of tax revenue and inflation rate control in achieving economic prosperity, it is necessary to analyze the relationship and forecasting tax revenue and inflation rate. VECM (Vector Error Correction Model) was chosen as the method used in this research, because of the data used in the form of multivariate time series data. This study aims to produce a VECM model with optimal lag and to predict the tax revenue and inflation rate of the VECM model. The results show that the best model for data of tax revenue and the inflation rate in Banda Aceh City is VECM with 3rd optimal lag or VECM (3). Of the seven models formed, there is a significant model that is the acceptance model of income tax. The predicted results of tax revenue and the inflation rate in Kota Banda Aceh for the next 6, 12 and 24 periods (months) obtained using VECM (3) are considered valid, since they have a minimum error value compared to other models.","Label":"0"},{"DOI":"10.47473/2020rmm0099","Abstract":"An Inflation-Indexed Swap (IIS) is a derivative in which, at every payment date, the counterparties swap an inflation rate with a fixed rate. For the calculation of the Inflation Leg cash flows it is necessary to build a mathematical model suitable for the Consumer Price Index (CPI) projection. For this purpose, quants typically start by using market quotes for the Zero-Coupon swaps in order to derive the future trend of the inflation index, together with a seasonality model for capturing the typical periodical effects. In this study, we propose a forecasting model for inflation seasonality based on a Long Short Term Memory (LSTM) network: a deep learning methodology particularly useful for forecasting purposes. The CPI predictions are conducted using a FinTech paradigm, but in respect of the traditional quantitative finance theory developed in this research field. The paper is structured according to the following sections: the first two parts illustrate the pricing methodologies for the most popular IIS: the Zero Coupon Inflation-Indexed Swap (ZCIIS) and the Year-on-Year Inflation-Indexed Swap (YYIIS); section 3 deals with the traditional standard method for the forecast of CPI values (trend + seasonality), while section 4 describes the LSTM architecture, and section 5 focuses on CPI projections, also called inflation bootstrap. Then section 6 describes a robust check, implementing a traditional SARIMA model in order to improve the interpretation of the LSTM outputs; finally, section 7 concludes with a real market case, where the two methodologies are used for computing the fair-value for a YYIIS and the model risk is quantified.","Label":"1"},{"DOI":"10.14710/medstat.6.2.91-101","Abstract":"The inflation data is one of the financial time series data that has a high volatility, so if the data is modeled with parametric models (AR, MA and ARIMA), sometimes occur problems because there was an assumption that cannot be satisfied. Then a nonparametric method that does not require strict assumptions as parametric methods is developed. This study aims to analyze inflation in Indonesia after the goverment raised the price of electricity basic and fuel price in 2013 using kernel regression models. This method was good for data modeling inflation in Indonesia before. The goodness of a kernel regression model is determined by the chosen kernel function and wide bandwidth used. However, the most dominant is the selection of the wide bandwidth. In this study, determination of the optimal bandwidth by minimizing the Generalized Cross Validation (GCV). By model the annual inflation data (Indonesia) December 2006 - December 2011, the inflation target in 2012 is (4,5 + 1 )% can be achieved both exactly and predictly, while the inflation target in 2013 is (4,5 + 1 )% cannot be achieved neither exactly nor predictly. The inflation target in 2013 can’t be achieve because since the beginning of 2013, there was a government policy to raise the price of electricity and the middle of 2013, there was an increase in fuel prices. The prediction of Indonesia inflation in 2014 by Gauss kernel is 6,18%. Keywords : Inflation, Kernel Regression Models, Generalized Cross Validation","Label":"1"},{"DOI":"10.22487/2540766x.2019.v16.i2.14986","Abstract":"ABSTRACTEconomic growth in the region is the regional economy conditions change continuously towards a better State fora certain period. The slow economic growth became the latest leading indicator an area to develop. Indicators thatcan be used for example, GDP and inflation. On the research of these indicators will be used to predict the growthrate of the economy of Central Sulawesi province using the Backpropagation Neural Network Methods. Simulationof the program in the form of input data is represented 𝑥1 and 𝑥2 and biased 𝑏1 dan 𝑏2 symbolized. With hiddenlayers comprising 𝑧1, 𝑧2, 𝑧3, 𝑧4, … , 𝑧17 . and y as output. Based on the results and discussion has been done, can bedrawn the conclusion of process Neural Network prediction of Backpropagation with 1 hidden layer neurons andthe number 17 against 26 data represents data inflation and GDP of the year 2010 up to 2016 with sigmoid activationfunction binner was able to predict the rate of economic growth with a prediction error of 16.66%.Keywords : ANN, Backpropagation Method, Inflation, PDRB.","Label":"1"},{"DOI":"10.1007/s10645-006-0002-2","Abstract":"In this study, we build two forecasting models to predict inflation Harmonised Index of Consumer Prices (HICP) for the Netherlands and for the euro area. The models provide point forecasts and prediction intervals for both the components of the HICP and the aggregated HICP -index itself. Both models are small-scale linear time series models allowing for long-run equilibrium relationships between HICP components and other variables, notably the hourly wage rate and the import or producer prices. The model for the Netherlands is used to generate the Dutch inflation projections for the eurosystem’s Narrow Inflation Projection Exercise (NIPE). The recursive forecast errors for several forecast horizons are evaluated for all models, and are found to outperform a naive forecast and optimal AR models. Moreover, the same result holds for the Dutch NIPE projections, which have been provided quarterly since 1999. The aggregation method to predict total HICP inflation generally outperforms the direct method, except for long horizons in the case of the Netherlands.","Label":"0"},{"DOI":"10.1016/j.iref.2016.01.003","Abstract":"This paper presents a comprehensive review of the newly emerging literature on the New Keynesian Phillips Curve (NKPC). The theoretical predictions, econometric estimation techniques as well as the corresponding empirical evidence are discussed focusing on both the closed economy and the open economy versions of the NKPC. A number of important findings are reported about the ability of NKPC to explain the process of inflation dynamics. First, there is weak support for the open economy version of the NKPC to be able to track inflation dynamics if imported inputs are used in the production process. Second, the NKPC describes inflation dynamics across sectors if microeconomic and sectoral level data are used. Further, the survey data employed as a proxy for inflation measure in the newer studies provide enhanced support to the closed economy NKPC with the sign, size and statistical significance of coefficients in line with the theoretical predictions. We provide fresh empirical evidence to check the first finding from the review. The deep structural parameters for four different versions of the NKPC, the pure forward looking NKPC, the Gali and Monacelli's (2005) NKPC, the open economy NKPC and the open economy hybrid NKPC, are estimated for Australia, Canada, New Zealand and the United Kingdom. These estimated coefficients show some support that the specifications of open economy NKPC, which incorporate prices of imported goods as opposed to the terms of trade and real exchange rate, seems to be a better, however, weak indicator of the inflation dynamics. These findings may have important policy implications.","Label":"0"},{"DOI":"10.17016/feds.2010.57","Abstract":"We consider what, if any, relationship there is between monetary aggregates and inflation, and whether there is any substantial reason for modifying the current mainstream mode of policy analysis, which frequently does not consider monetary aggregates at all. We begin by considering the body of thought known as the 'quantity theory of money.' The quantity theory centers on the prediction that there will be a long-run proportionate reaction of the price level to an exogenous increase in the nominal money stock. The nominal homogeneity conditions that deliver the quantity-theory result are the same as those that deliver monetary neutrality, an important principle behind policy formulation. The quantity theory implies a ceteris paribus unitary relationship between inflation and money growth. Simulations of a New Keynesian model suggest that we should expect this relationship to be apparent in time series data, with no heavy averaging or filtering required, but with allowance needed for the phase shift in the relationship between monetary growth rates and inflation. While financial innovation can obscure the relationship between monetary growth and inflation, evidence of a money growth/inflation relationship does emerge from U.S. time series and G7 panel data. Various considerations suggest that studies of inflation and monetary policy behavior can benefit from including both interest rates and money in the empirical analysis.","Label":"0"},{"DOI":"10.2139/ssrn.320820","Abstract":"This paper provides evidence that the relationship between inflation and money growth has changed as the inflation-targeting regime has progressed. During the disinflation period (mid 1980s to mid or late 1991) the correlation between inflation and money aggregates was fairly consistent with the prediction of theory. Both inflation and money growth fell sharply. In 1992, inflation was stabilised around an average of little less than 2 per cent. Since then, the correlation between money growth and inflation has been fairly weak at the permanent (trend) and the business cycle frequencies. By contrast, there is a significant correlation between money and real GDP over the business cycle. As far as base velocity is concerned, it was stable up until December 1997, but broke down in late 1998. As money growth took off in the late 1990s, velocity declined rather sharply, but these downward trends are consistent with the decline of interest rates as predicted by the quantity theory of money. The demand for real-monetary base is well behaved and interest inelastic, but this relationship also broke down in late 1998. However, both velocity-interest rate and money demand function breakdown is probably only temporary. Finally, at least until March 1999, the rate of growth of the monetary base has, on average, been consistent with a nominal GDP targeting policy of 4 per cent.","Label":"0"},{"DOI":"10.2139/ssrn.270936","Abstract":"This paper develops and estimates an equilibrium model which investigates the relationship between the term structure of interest rates, inflation and GDP growth. The model accounts for non-neutral effects of inflation, so that real and monetary variables are interrelated and jointly influence the term structure of interest rates, while bond yields convey information about expectations of output growth and inflation. Estimation is based on quarterly data for the United States over the period 1960-1999 and is carried out using a maximum likelihood - Kalman filter approach. The model fits the nominal term structure well and provides estimates for the implicit real term structure and for other unobservable variables, such as the instantaneous real interest rate and expected inflation rate and their time-varying central tendencies. The latter variables are shown to be strictly related to market expectations of medium-long term interest rate targets of the monetary authority. The estimates show that the covariance between output growth and inflation significantly affects long-term nominal bond prices, whereas the cross-sectional restrictions which link the yield curve to the macroeconomic variables give rise to relatively accurate in-sample and out-of-sample forecasts of inflation and GDP growth. The model also produces satisfactory predictions for future movements of the slope of the yield curve.","Label":"0"},{"DOI":"10.1016/j.jedc.2018.01.013","Abstract":"The forward fiscal guidance puzzle pertains to New Keynesian models when monetary policy is temporarily caught in a liquidity trap: (1) expected future fiscal shocks have an unbelievably large effect on current inflation, and (2) the effect on current inflation is larger the further out is the shock expected to occur. We illustrate the problem analytically. Then, we use Blue Chip inflation forecasts to argue that the effects on inflation expectations should be small. And finally, we analyze two potential resolutions to the puzzle. The first is the Fiscal Theory of the Price Level. In a calibrated model with price inertia, investment, and long term debt, we show that the Fiscal Theory resolves the second aspect of the puzzle, but certainly not the first. In our preferred resolution we return to a Ricardian fiscal policy. And we assume that the probability of a return to the Taylor Rule depends on the rate of inflation. The model’s predictions are in line with the evidence from the Blue Chip forecasts. This article is part of a Special Issue entitled “Fiscal and Monetary Policies”.","Label":"0"},{"DOI":"10.1198/jbes.2009.0003","Abstract":"We use data from the Survey of Professional Forecasters (SPF) to compare point predictions of gross domestic product (GDP) growth and inflation with the subjective probability distributions held by forecasters. We find that most SPF point predictions are quite close to the central tendencies of forecasters subjective distributions tend to be asymmetric, with SPF forecasters tending to report point predictions that give a more favorable view of the economy than do their subjective means/medians/modes.","Label":"0"},{"DOI":"10.1109/la-cci48322.2021.9769835","Abstract":"Forecasting price indexes of the economy has received an attention from scholars and policy makers due to its significant effect on various sectors and markets. The stability of economy is at risk if inflation is not properly checked through models and macroeconomic studies, therefore, forecasting inflation is an important task for the formulation of policies in governments and companies. In this sense, this research work attempts to model inflation rate to Brazil, United State of America and Japan. The literature, in the field of time series, indicates the combination of linear and non-linear models to model inflation. In this paper, a hybrid ARIMA-MLP system has been proposed to map linear and nonlinear patterns. This is explored using a hybrid evolutionary system consisting of a simple exponential filter, linear ARIMA and autoregressive (AR) models and a Multilayer Perceptron model. In addition, it was also implemented exponential smoothing models (ETS), Qunatile Regression (QR) and Support Vector Machines. The experimental results show that the hybrid evolutionary system presented promising results in the prediction domain.","Label":"1"},{"DOI":"10.1002/(sici)1099-131x(199907)18:4<225::aid-for722>3.0.co","Abstract":"This paper presents short‐ and long‐term composite leading indicators (CLIs) of underlying inflation for seven EU countries, namely Belgium, Germany, France, Italy, the Netherlands, Sweden and the UK. CLI and CPI reference series are calculated in terms of both growth rates and in deviations from its trend. The composite leading indicators are based on leading basic series, such as sources of inflation, series containing information on inflation expectations and prices of intermediate goods and services. Neftci's decision rule approach has been applied to transfer movements in the CLIs into a measure of the probability of a cyclical turning point, which enables the screening out of false turning point predictions. Finally, CLIs have been used to analyse the international coherence of price cycles. The forecast performance of CLIs of inflation over the past raises hope that this forecast instrument can be useful in predicting future price movements. Copyright © 1999 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.1080/16081625.2017.1378114","Abstract":"This study develops a model arguing that corruption and weak corporate governance institutions magnify economic fluctuations. Corruption increases the difficulty of corporate governance and decreases the costs to controlling families of misusing firm assets as collateral for bank loans and creating credits for their own high-risk business, thus increasing cyclical fluctuations in inflation and production. Consistent with the predictions of the model, our longitudinal analyses covering 155 countries from 1995 to 2015 suggest that corruption increases the Hodrick-Prescott cyclical volatility of inflation and production in the following 10 years. We also find that inflation volatility mediates the relationship between corruption and production volatility. However, corruption does not show significant effects on unemployment fluctuations.","Label":"0"},{"DOI":"10.1093/jeea/jvad029","Abstract":"Abstract When financial contracts are not fully enforceable and firms observe their own nominal sales before the observation of the aggregate nominal price, the optimal financial contract is not fully indexed to inflation. Because of the limited nominal indexation, which is endogenous in the model, unanticipated inflation affects aggregate investment and future economic activity. The macroeconomic volatility induced by price uncertainty, however, is not monotone: it first increases and then decreases with nominal price uncertainty. We also show that the degree of nominal indexation declines with real idiosyncratic volatility and the impact of an inflation shock decreases with nominal indexation. Using firm-level data from Canada, we find that both predictions are supported by the data.","Label":"0"},{"DOI":"10.1002/jae.1257","Abstract":"The aim of this paper is to assess whether modeling structural change can help improving the accuracy of macroeconomic forecasts. We conduct a simulated real‐time out‐of‐sample exercise using a time‐varying coefficients vector autoregression (VAR) with stochastic volatility to predict the inflation rate, unemployment rate and interest rate in the USA. The model generates accurate predictions for the three variables. In particular, the forecasts of inflation are much more accurate than those obtained with any other competing model, including fixed coefficients VARs, time‐varying autoregressions and the naïve random walk model. The results hold true also after the mid 1980s, a period in which forecasting inflation was particularly hard. Copyright © 2011 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.1016/b978-0-444-53238-1.00003-x","Abstract":"We consider what, if any, relationship there is between monetary aggregates and inflation, and whether there is any substantial reason for modifying the current mainstream mode of policy analysis, which frequently does not consider monetary aggregates at all. We begin by considering the body of thought known as the “quantity theory of money.” The quantity theory centers on the prediction that there will be a long-run proportionate reaction of the price level to an exogenous increase in the nominal money stock. The nominal homogeneity conditions that deliver the quantity-theory result are the same as those that deliver monetary neutrality, an important principle behind policy formulation. The quantity theory implies a ceteris paribus unitary relationship between inflation and money growth. Simulations of a New Keynesian model suggest that we should expect this relationship to be apparent in time series data, with no heavy averaging or filtering required, but with allowance needed for the phase shift in the relationship between monetary growth rates and inflation. While financial innovation can obscure the relationship between monetary growth and inflation, evidence of a money growth/inflation relationship does emerge from the United States time series and G7 panel data. Various considerations suggest that studies of inflation and monetary policy behavior can benefit from including both interest rates and money in the empirical analysis.","Label":"0"},{"DOI":"10.1016/j.jedc.2012.01.009","Abstract":"This paper deals with the analysis of price-setting in U.S. manufacturing industries. Recent studies have heavily criticized the ability of the New Keynesian Phillips curve (NKPC) to fit aggregate inflation (see, e.g., Rudd and Whelan, 2006). We challenge this evidence, showing that forward-looking behavior as implied by the New Keynesian model of price-setting is widely supported at the sectoral level. In fact, current and expected future values of the income share of intermediate goods emerge as an effective driver of inflation dynamics. Unlike alternative proxies for the forcing variable, the cost of intermediate goods presents dynamic properties in line with the predictions of the New Keynesian theory.","Label":"0"},{"DOI":"10.2139/ssrn.3594103","Abstract":"Recent work by Medeiros et al. (2019, Journal of Business & Economic Statistics) shows that point forecasts of the random forest machine learning algorithm systematically outperform well-established benchmarks at predicting U.S. inflation. This article extends their work from point to density forecasts derived from large-scale datasets by means of the novel distributional forest algorithm of Schlosser et al. (2019, The Annals of Applied Statistics), which allows us to simultaneously account for locally evolving means, time-varying volatilities, nonlinearities as well as heavy-tailed densities – all of which constitute stylized characteristics highlighted in the recent literature. We show that distributional forests typically achieve superior point and density predictions over random walk, auto-regressive and stochastic volatility benchmarks.","Label":"1"},{"DOI":"10.1016/j.ijforecast.2009.12.010","Abstract":"This paper develops and illustrates a simple method of generating a DSGE model-based forecast for variables that do not explicitly appear in the model (non-core variables). We use auxiliary regressions that resemble measurement equations in a dynamic factor model to link the non-core variables to the state variables of the DSGE model. Predictions for the non-core variables are obtained by applying their measurement equations to DSGE model-generated forecasts of the state variables. Using a medium-scale New Keynesian DSGE model, we apply our approach to generate and evaluate recursive forecasts for PCE inflation, core PCE inflation, the unemployment rate, and housing starts, along with predictions for the seven variables that have been used to estimate the DSGE model.","Label":"0"},{"DOI":"10.1007/978-3-642-48356-1_4","Abstract":"Eight subjects had to predict values in a time series generated by a stochastic process. These predictions were analysed for the following questions: (1) Is there a learning process towards better predictions? (2) Can the last predictions be explained by a weak form of the Rational Expectations Hypothesis? (3) Can we observe short-term adaptations of the prediction rule and, if so, how do they work? (4) Are there better descriptions of prediction behaviour than Rational Expectations?","Label":"0"},{"DOI":"10.1109/gsis.2015.7301873","Abstract":"In order to solve the inflation forecasting problem with small samples and inherent uncertainty, this paper employs the Grey Markov model for inflation prediction by using the annual data from the year of 2005 to 2013. In contrast, the traditional econometric regression models are invalid for the small sample because the estimator of coefficients lose the BLUE properties under the small sample circumstances. Based on the model, the forecasted values are given for the years of 2014 to 2017. The result indicates that the expected price of the economy will experience slow growth for the next three years, then change to high inflation for the year of 2017. Further, the result implies the increase of the price level and the decrease of the natural level of output through the channel of aggregate supply and aggregate demand. From the view of policy, the government should employ the mix expansion of fiscal policy and monetary policy in order to eliminate the fluctuation in output. Specifically for the year of 2017, the government should pay more attention to the increase of the price level besides improving the output. As a result the policy would change to be more prudent.","Label":"0"},{"DOI":"10.2139/ssrn.1268319","Abstract":"This paper develops and illustrates a simple method to generate a DSGE model-based forecast for variables that do not explicitly appear in the model (non-core variables). We use auxiliary regressions that resemble measurement equations in a dynamic factor model to link the non-core variables to the state variables of the DSGE model. Predictions for the non-core variables are obtained by applying their measurement equations to DSGE model-generated forecasts of the state variables. Using a medium-scale New Keynesian DSGE model, we apply our approach to generate and evaluate recursive forecasts for PCE inflation, core PCE inflation, and the unemployment rate along with predictions for the seven variables that have been used to estimate the DSGE model.","Label":"0"},{"DOI":"10.2139/ssrn.1019580","Abstract":"This paper exploits a unique natural experiment - Cornell University's 1996 decision to publish course median grades online - to examine the effect of grade information on course selection and grade inflation. We model students' course selection as dependent on their tastes, abilities, and expected grades. The model yields three testable hypotheses: (1) students will tend to be drawn to leniently graded courses once exposed to grade information; (2) the most talented students will be less drawn to leniently graded courses than their peers; (3) the change in students' behavior will contribute to grade inflation. Examining a large dataset that covers the period 1990-2004, our study provides evidence consistent with these predictions.","Label":"0"},{"DOI":"10.2139/ssrn.1525643","Abstract":"Survey measures of consumer inflation expectations have an important shortcoming in that, while providing useful summary measures of the distribution of point forecasts across individuals, they contain no direct information about an individual’s uncertainty about future inflation. The latter is important not only for forecasting inflation and other macroeconomic outcomes, but also for assessing a central bank’s credibility and effectiveness of communication. This paper explores the feasibility of eliciting individual consumers’ subjective probability distributions of future inflation outcomes. In November 2007, we began administering web-based surveys to participants in RAND’s American Life Panel. In addition to their point predictions, respondents were asked for their subjective assessments of the percentage chance that inflation will fall in each of several predetermined intervals. We find that our measures of individual forecast densities and uncertainty are internally consistent and reliable. Those who are more uncertain about year-ahead price inflation are also generally more uncertain about longer term price inflation and future wage changes. We find also that participants expressing higher uncertainty in their density forecasts make larger revisions to their point forecasts over time. Measures of central tendency derived from individual density forecasts are highly correlated with point forecasts, but they usually differ, often substantially, at the individual level. Finally, we relate our direct measure of aggregate consumer uncertainty to a more conventional approach that uses disagreement among individual forecasters, as seen in the dispersion of their point forecasts, as a proxy for forecast uncertainty. Although the two measures are positively correlated, our results suggest that disagreement and uncertainty are distinct concepts, both relevant to the analysis of inflation expectations.","Label":"0"},{"DOI":"10.1007/978-3-031-30474-3_18","Abstract":"International businesses are using foreign currencies as part of their activities. To optimize the cost of foreign exchange, the prediction of the exchange rate can be crucial. For time series forecasting, moving average techniques should be adopted. In this study, the exchange rate of EUR/USD is mainly focused on. The data under consideration are the Forex transaction rates which include open, high, low, and close. Furthermore, four financial factors are the dollar index, interest rate, inflation rate, and real growth of domestic products which are also included as inputs. Four models were employed: linear regression, multilayer perceptron, recurrent neural networks, and general regression neuron networks for predicting the Forex rate. Mean squared error is used for comparing forecasting performance. The results show that applying a sliding-window and moving average techniques improves the efficiency of the prediction.","Label":"1"},{"DOI":"10.1080/00036846.2016.1158915","Abstract":"Motivated by economic-theory concepts – the Fisher hypothesis and the theory of the term structure – we consider a small set of simple bivariate closed-loop time-series models for the prediction of price inflation and of long- and short-term interest rates. The set includes vector autoregressions (VAR) in levels and in differences, a cointegrated VAR and a non-linear VAR with threshold cointegration based on data from Germany, Japan, UK and the US. Following a traditional comparative evaluation of predictive accuracy, we subject all structures to a mutual validation using parametric bootstrapping. Ultimately, we utilize the recently developed technique of Mallows model averaging to explore the potential of improving upon the predictions through combinations. While the simulations confirm the traded wisdom that VARs in differences optimize one-step prediction and that error correction helps at larger horizons, the model-averaging experiments point at problems in allotting an adequate penalty for the complexity of candidate models.","Label":"0"},{"DOI":"10.2139/ssrn.1581346","Abstract":"This study approaches the Quantity Theory of Money at a conceptual level, asking how it can be most reasonably interpreted and quantitatively assessed. The resulting approach is straightforward. Unlike studies relying on other methods we find evidence of its linchpin prediction that is not limited to periods of high inflation.","Label":"0"},{"DOI":"10.29207/resti.v3i3.1086","Abstract":"Long Short Term Memory (LSTM) is known as optimized Recurrent Neural Network (RNN) architectures that overcome RNN’s lact about maintaining long period of memories. As part of machine learning networks, LSTM also notable as the right choice for time-series prediction. Currently, machine learning is a burning issue in economic world, abundant studies such predicting macroeconomic and microeconomics indicators are emerge. Inflation rate has been used for decision making for central banks also private sector. In Indonesia, CPI (Consumer Price Index) is one of best practice inflation indicators besides Wholesale Price Index and The Gross Domestic Product (GDP). Since CPI data could be used as a direction for next inflation move, we conducted CPI prediction model using LSTM method. The network model input consists of 28 variables of staple price in Surabaya and the output is CPI value, also the entire development of prediction model are done in Amazon Web Service (AWS) Cloud. In the interest of accuracy improvement, we used several optimization algorithm i.e. Stochastic Gradient Descent (sgd), Root Mean Square Propagation (RMSProp), Adaptive Gradient(AdaGrad), Adaptive moment (Adam), Adadelta, Nesterov Adam (Nadam) and Adamax. The results indicate that Nadam has 4,008 RMSE’s value, less than other algorithm which indicate the most accurate optimization algorithm to predict CPI value.","Label":"1"},{"DOI":"10.1016/s0261-5606(98)00037-0","Abstract":"Economic theory suggests that an economy's openness reduces the ability of monetary policy to affect output, while increasing its effects on inflation. Using annual data from the 1953–1990 period for a panel of 38 countries, the paper's empirical results support the theoretical predictions: the more open the economy, the smaller (larger) the output (inflation) effects of a given change in the money supply. This finding is robust across all the different specifications and estimation methods examined.","Label":"0"},{"DOI":"10.1016/s0022-1996(96)01442-0","Abstract":"This paper relates the time-consistent inflation rate to the degree of trade openness of an economy. The mechanism linking the welfare effects of monetary surprises (and hence the incentives to inflate) to openness does not rely on a large-country terms of trade effect but rather is due to imperfect competition and nominal price rigidity in the non-traded sector. The empirical evidence supports the main predictions of the model. © 1997 Elsevier Science B.V.","Label":"0"},{"DOI":"10.1017/s136510050705033x","Abstract":"This paper compares the forecasting performance of some leading models of inflation for G-7 countries. We show that bivariate and trivariate models suggested by economic theory or statistical analysis are not much better than univariate ones. Phillips curve specifications fit well into this class. Improvements in both the MSE of the forecasts and turning point prediction are obtained with time-varying coefficients models, which exploit international interdependencies. The performance of the latter class of models is stable throughout the 1990s.","Label":"0"},{"DOI":"10.3390/su10061691","Abstract":"Forecasting inflation rate is one of the most important topics in finance and economics. In recent years, China has stepped into a “New Normal” stage of economic development, with a different state from the fast growth period during the past few decades. Hence, forecasting the inflation rate of China with a time-varying model may give high accuracy. In this paper, we investigate the problem of forecasting the inflation rate with a functional coefficient autoregressive (FAR) model, which allows the coefficient to change over time. We compare the FAR model based on the B-splines estimation method with the autoregressive moving average (ARMA) model by extensive simulation studies. In addition, with the monthly CPI data of China, we conduct both in-sample analysis and out-of-sample forecasting. The forecasting result shows that the FAR model based on the B-splines estimation method has a better performance than the ARMA model.","Label":"0"},{"DOI":"10.1063/1.4936429","Abstract":"Inflation, at a healthy rate, is a sign of growing economy. Nonetheless, when inflation rate grows uncontrollably, it will negatively influence economic growth. Many tackle this problem by increasing interest rate to help protecting the value of money which is detained by inflation. There are few, however, who study the effects of interest rate in economic growth. The main purposes of this paper are to find how the change of interest rate affects economic growth and to use the relationship in prognostication of economic growth. By using expenditure model, a linear relationship between economic growth and interest rate is developed. The result is then used for prediction by normal copula and Vine Archimedean copula. It is shown that increasing interest rate to tackle inflation is a poor solution. Whereas implementation of copula in predicting economic growth yields an accurate result, with not more than 0.5% difference.","Label":"0"},{"DOI":"10.48550/arxiv.2205.00924","Abstract":"This paper uses predictive densities obtained via mixed causal-noncausal autoregressive models to evaluate the statistical sustainability of Brazilian inflation targeting system with the tolerance bounds. The probabilities give an indication of the short-term credibility of the targeting system without requiring modelling people's beliefs. We employ receiver operating characteristic curves to determine the optimal probability threshold from which the bank is predicted to be credible. We also investigate the added value of including experts predictions of key macroeconomic variables.","Label":"0"},{"DOI":"10.1111/1467-8454.12143","Abstract":"Inflation, defined as a sustained increase in the price level, is considered a monetary phenomenon, as it can be explained within the framework of money‐demand and money‐supply relationships. In the extant literature, money growth is shown to remain causally related to inflation across countries and over time, irrespective of the exchange rate regime and stability of the money‐demand function. Nevertheless, emerging literature suggests a diminishing role of money in the conduct of monetary policy for price stability, especially under inflation targeting. Monetary policy in Australia under inflation targeting since 1993 is an example of policy that denies a relationship between money growth and inflation. The proposition that money does not matter insofar as inflation is concerned seems odd in both theory and the best‐practice monetary policy for price stability. This paper uses annual data for the period 1970–2017 and quarterly data for the period 1970Q1–2015Q1. It deploys both the Johansen cointegration approach and the autoregressive distributed lag (ARDL) cointegration approach to investigate for Australia whether money, real output, prices and the exchange rate (non‐stationary variables) maintain the long‐run price‐level relationship that the classical monetary theory suggests in the presence of such stationary variables as the domestic and foreign interest rates. As expected, the empirical findings for Australia are consistent with the classical long‐run price‐level relationship between money, real output, prices and the exchange rate. The error‐correction model of inflation confirms the presence of a cointegral relationship among these variables; it also provides strong evidence of a short‐run causal relationship between money supply growth and inflation. On the basis of a priori theoretical predictions and empirical findings, the paper draws the conclusion that the monetary aggregate and its growth rate matter insofar as inflation is concerned, irrespective of the strategy of monetary policy for price stability.","Label":"0"},{"DOI":"10.2139/ssrn.2324110","Abstract":"We model the rate of inflation and unemployment in Austria since the early 1960s within the Phillips/Fisher framework. The change in labour force is the driving force representing economic activity in the Phillips curve. For Austria, this macroeconomic variable was first tested as a predictor of inflation and unemployment in 2005 with the involved time series ended in 2003. Here we extend all series by nine new readings available since 2003 and re-estimate the previously estimated relationships between inflation, unemployment, and labour force. As before, a structural break is allowed in these relationships, which is related to numerous changes in definitions in the 1980s. The break year is estimated together with other model parameters by the Boundary Element Method with the LSQ fitting between observed and predicted integral curves. The precision of inflation prediction, as described by the root-mean-square (forecasting) error is by 20% to 70% better than that estimated by AR(1) model. The estimates of model forecasting error are available for those time series where the change in labour force leads by one (the GDP deflator) or two (CPI) years. For the whole period between 1965 and 2012 as well as for the intervals before and after the structural break (1986 for all inflation models) separately, our model is superior to the naïve forecasting, which in turn, is not worse than any other forecasting model. The level of statistical reliability and the predictive power of the link between inflation and labour force imply that the National Bank of Austria does not control inflation and unemployment beyond revisions to definitions. The labour force projection provided by Statistic Austria allows foreseeing inflation at a forty-year horizon: the rate of CPI inflation will hover around 1.3% and the GDP deflator will likely sink below zero between 2018 and 2034.","Label":"0"},{"DOI":"10.2139/ssrn.3049503","Abstract":"We estimate the ECB’s monetary policy reaction function by using real time Eurosystem/ECB staff macroeconomic projection data, which are presented to the ECB’s Governing Council when it assesses the monetary policy stance in the euro area. Alternative specifications of the reaction function account for a possible credibility loss due to persistent deviations of past inflation from the ECB’s inflation target. The results provide support for two alternative interpretations of the definition of price stability. First, the ECB dislikes inflation rates above two percent more than rates below two percent. Second, the ECB policy responses to past inflation gaps are symmetric with respect to a target of 1.6 - 1.7 percent. The out-of-sample predictions of the reaction function based on the second interpretation of the definition of price stability track well an estimated shadow interest rate during the zero lower bound period.","Label":"0"},{"DOI":"10.1016/j.jmacro.2021.103353","Abstract":"Is inflation ‘always and everywhere a monetary phenomenon’ or is it fundamentally a fiscal phenomenon? The answer hinges crucially on the underlying monetary–fiscal policy regime. Scant attention has been directed to the role of credit market frictions in discerning the policy regime, despite its growing importance in empirical macroeconomics. We augment a standard monetary model to incorporate fiscal details and credit market imperfections. These ingredients allow for both interpretations of the inflation process in a financially constrained environment. We find that introducing financial frictions to the model and adding financial variables to the dataset generate important identifying restrictions on the observed pattern between inflation and measures of financial and fiscal stress, to the extent that it overturns existing findings about which monetary–fiscal policy regime produced the U.S. data. To confront policy regime uncertainty, we propose the use of dynamic prediction pools and find strong cyclical patterns in the estimated historical regime weights.","Label":"0"},{"DOI":"10.2139/ssrn.1488722","Abstract":"In this paper, we propose a Bayesian estimation and prediction procedure for noncausal autoregressive (AR) models. Specifically, we derive the joint posterior density of the past and future errors and the parameters, which gives posterior predictive densities as a byproduct. We show that the posterior model probability provides a convenient model selection criterion and yields information on the probabilities of the alternative causal and noncausal specifications. This is particularly useful in assessing economic theories that imply either causal or purely noncausal dynamics. As an empirical application, we consider U.S. inflation dynamics. A purely noncausal AR model gets the strongest support, but there is also substantial evidence in favor of other noncausal AR models allowing for dependence on past inflation. Thus, although U.S. inflation dynamics seem to be dominated by expectations, the backward-looking component is not completely missing. Finally, the noncausal specifications seem to yield inflation forecasts which are superior to those from alternative models especially at longer forecast horizons.","Label":"0"},{"DOI":"10.2139/ssrn.1009011","Abstract":"The paper analyzes how globalization forces induce monetary authorities, guided in their policies by the welfare criterion of a representative household, to put a greater emphasis on reducing the inflation rate than on narrowing the output gaps. We demonstrate that with capital account liberalization the representative household is able to smooth fluctuations in consumption, and thus becomes relatively insensitive to fluctuations in the output gap. With trade liberalization the economy tends to specialize in the production of relatively few varieties of goods. The specialization in production as a result of trade openness increases the distortion originating from fluctuations in the inflation rate. Therefore, policymakers (guided by efficiency considerations) become more aggressive on inflation and less responsive to the output gap when trade and financial openness increases. We provide evidence on the effect on preferences towards fluctuations in the output gap and in inflation of trade and capital openness, which supports the theory predictions.","Label":"0"},{"DOI":"10.33429/cjas.09218.5/6","Abstract":"The study estimates a dynamic model using quarterly data spanning 1995 to 2016. Four dynamic models: level lagged variables, differenced lagged variables, log-transformed lagged variables and differenced log-transformed lagged variables were considered. The best predictive model was selected based on the Schwarz Information Criterion (SIC) value. From the empirical results, the level form models performed better than the differenced form models. On the basis of model parsimony, the level lagged model was the preferred model among the set of selected models. Predictions obtained from the model indicate that the model is stable as actual interest rate (IR) values, fall well within the computed 95% prediction interval. The study concludes that previous values of IR and money supply (MS) are significant in predicting future inflation rates in Nigeria.","Label":"0"},{"DOI":"10.1111/ecin.12176","Abstract":"Standard theoretical models predict that higher inflation expectations generate greater current consumer spending at the zero lower bound of interest rates. However, recent empirical studies using U.S. micro data find negative results for this relationship. We use micro data for Japan, which has experienced low interest rates for a prolonged period, to estimate ordered probit models with a variety of controls. We find robust evidence supporting the prediction of standard models: survey respondents with higher expected inflation tend to indicate that their household has increased real spending compared with 1 year ago but will decrease it in the future. This relationship appears to be stronger for asset holders and older people. (JEL E20, E21, E30, E31, E50, E52)","Label":"1"},{"DOI":"10.48550/arxiv.1310.1786","Abstract":"We model the rate of inflation and unemployment in Austria since the early 1960s within the Phillips/Fisher framework. The change in labour force is the driving force representing economic activity in the Phillips curve. For Austria, this macroeconomic variable was first tested as a predictor of inflation and unemployment in 2005 with the involved time series ended in 2003. Here we extend all series by nine new readings available since 2003 and re-estimate the previously estimated relationships between inflation, unemployment, and labour force. As before, a structural break is allowed in these relationships, which is related to numerous changes in definitions in the 1980s. The break year is estimated together with other model parameters by the Boundary Element Method with the LSQ fitting between observed and predicted integral curves. The precision of inflation prediction, as described by the root-mean-square (forecasting) error is by 20% to 70% better than that estimated by AR(1) model. The estimates of model forecasting error are available for those time series where the change in labour force leads by one (the GDP deflator) or two (CPI) years. For the whole period between 1965 and 2012 as well as for the intervals before and after the structural break (1986 for all inflation models) separately, our model is superior to the naïve forecasting, which in turn, is not worse than any other forecasting model. The level of statistical reliability and the predictive power of the link between inflation and labour force imply that the National Bank of Austria does not control inflation and unemployment beyond revisions to definitions. The labour force projection provided by Statistic Austria allows foreseeing inflation at a forty-year horizon: the rate of CPI inflation will hover around 1.3% and the GDP deflator will likely sink below zero between 2018 and 2034.","Label":"0"},{"DOI":"10.1016/b978-0-444-53683-9.00001-3","Abstract":"This chapter discusses recent developments in inflation forecasting. We perform a horse-race among a large set of traditional and recently developed forecasting methods, and discuss a number of principles that emerge from this exercise. We find that judgmental survey forecasts outperform model-based ones, often by a wide margin. A very simple forecast that is just a glide path between the survey assessment of inflation in the current-quarter and the long-run survey forecast value turns out to be competitive with the actual survey forecast and thereby does about as well or better than model-based forecasts. We explore the strengths and weaknesses of some specific prediction methods, including forecasts based on the Phillips curve and based on dynamic stochastic general equilibrium models, in greater detail. We also consider measures of inflation expectations taken from financial markets and the tradeoff between forecasting aggregates and disaggregates.","Label":"0"},{"DOI":"10.2139/ssrn.2137160","Abstract":"Contrary to recent evidence of rating inflation in structured finance products, studies that predate the recent credit crisis show tightening of credit rating standards in corporate ratings. This study revisits this rating standards issue with an updated sample and finds evidence consistent with Bolton, Freixas and Shapiro’s (2012) prediction that rating inflation is present even in corporate ratings especially during periods of economic growth. However, over the entire sample period examined here, 1986-2010, there is a general tightening in rating standards in ratings issued by three major rating agencies including S&P, Moody’s and Fitch Ratings. Additional tests using bond pricing data show that capital markets do not view the tightening rating standards as warranted.","Label":"0"},{"DOI":"10.2139/ssrn.420141","Abstract":"This paper tests a version of the rational expectations hypothesis using 'fixed-event' inflation forecasts for the UK. Fixed-event forecasts consist of a panel of forecasts for a set of outturns of a series at varying horizons prior to each outturn. The forecasts are the prediction of fund managers surveyed by Merrill Lynch. Fixed-event forecasts allow tests for whether expectations are unbiased in a similar fashion to the rest of the literature. But they also permit particular tests of forecast efficiency to be conducted - whether the forecasts make best use of available information- that are not possible with rolling event data. The results show evidence of a positive bias in inflation expectations. Evidence for inefficiency is much less clear cut.","Label":"0"},{"DOI":"10.51406/jnset.v16i2.1842","Abstract":"Inflation measure is an important indicator of the state of an economy and the desire to determine it ahead of “time” cannot be overemphasised. This paper presents a step-by-step algorithm to predict the would-be monthly inflation rate of the Nigerian economy, using Kalman Filtering Predictor (KFP). The ordinary structural model for a time series (structTS) is highlighted to “fairly” compete against our proposed KFP. The structTS is a powerful “competitor”, it is in recommended R package “stats” and used for fitting basic structural models to “univariate” time series. It is quite reliable and fast, and is used as a benchmark in some comparisons of filtering techniques, it is indeed the “predictor” to “beat”, yet our proposed KFP has more to “offer”. The pertinent statistics and pictorial representation of the results obtained, through both techniques, is highlighted for any “incorruptible” judge’s perusal. All of these are contained in the couple of illustrative examples that exhibit the steps involved in the proposed algorithm, using a hypothetical monthly inflation rate and the monthly inflation rates data (January, 2011 to June, 2014) of the Nigerian economy.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2019.04.008","Abstract":"Part of a prediction is the judgment applied by the forecaster. This judgmental input may be affected by the forecaster’s mood swings, which have been shown to affect, for example, stock market returns. The present paper analyzes the extent to which mood (approximated by the development in sentiment indicators) affects macroeconomic prediction errors; i.e., whether it explains part of the prediction bias. The evidence suggests that mood can explain part of the error in inflation and output growth predictions, and hence, that anomalies should be taken into account when trying to understand expectation formation and assess the uncertainty related to private forecasters’ point predictions.","Label":"1"},{"DOI":"10.48550/arxiv.2007.07353","Abstract":"The objective of this work is twofold: to expand the depression models proposed by Tobin and analyse a supply shock, such as the Covid-19 pandemic, in this Keynesian conceptual environment. The expansion allows us to propose the evolution of all endogenous macroeconomic variables. The result obtained is relevant due to its theoretical and practical implications. A quantity or Keynesian adjustment to the shock produces a depression through the effect on aggregate demand. This depression worsens in the medium/long-term. It is accompanied by increases in inflation, inflation expectations and the real interest rate. A stimulus tax policy is also recommended, as well as an active monetary policy to reduce real interest rates. On the other hand, the pricing or Marshallian adjustment foresees a more severe and rapid depression in the short-term. There would be a reduction in inflation and inflation expectations, and an increase in the real interest rates. The tax or monetary stimulus measures would only impact inflation. This result makes it possible to clarify and assess the resulting depression, as well as propose policies. Finally, it offers conflicting predictions that allow one of the two models to be falsified.","Label":"0"},{"DOI":"10.2139/ssrn.2022965","Abstract":"We study how differences in beliefs about expected inflation affect the nominal term structure when investors have \"catching up with the Joneses'' preferences. In the model, \"catching up with the Joneses'' preferences help to match the level and slope of yields as well as the level of yield volatilities. Disagreement about expected inflation helps to match the dynamics of yields and yield volatilities. Expected inflation disagreement induces a spillover effect to the real side of the economy with a strong impact on the real yield curve. When investors share common preferences over consumption relative to the habit with a coefficient of relative risk aversion greater than one, real average yields across all maturities rise as disagreement increases. Real yield volatilities also rise with disagreement. To develop intuition concerning the role of different beliefs between investors, we consider a case where the real and nominal term structures can be computed as weighted-averages of quadratic Gaussian term structure models. We numerically find increased disagreement about expected inflation between the investors increases nominal yields and nominal yield volatilities at all maturities. We find empirical support for these predictions.","Label":"0"},{"DOI":"10.1016/j.csda.2011.07.010","Abstract":"In the context of linear state space models with known parameters, the Kalman filter (KF) generates best linear unbiased predictions of the underlying states together with their corresponding Prediction Mean Square Errors (PMSE). However, in practice, when the filter is run with the parameters substituted by consistent estimates, the corresponding PMSE do not take into account the parameter uncertainty. Consequently, they underestimate their true counterparts. In this paper, we propose two new bootstrap procedures to obtain PMSE of the unobserved states designed to incorporate this latter uncertainty. We show that the new bootstrap procedures have better finite sample properties than bootstrap alternatives and than procedures based on the asymptotic approximation of the parameter distribution. The proposed procedures are implemented for estimating the PMSE of several key unobservable US macroeconomic variables as the output gap, the Non-accelerating Inflation Rate of Unemployment (NAIRU), the long-run investment rate and the core inflation. We show that taking into account the parameter uncertainty may change their prediction intervals and, consequently, the conclusions about the utility of the NAIRU as a macroeconomic indicator for expansions and recessions.","Label":"0"},{"DOI":"10.2139/ssrn.2198827","Abstract":"Changing time series properties of US inflation and economic activity are analyzed within a class of extended Phillips Curve (PC) models. First, the misspecification effects of mechanical removal of low frequency movements of these series on posterior inference of a basic PC model are analyzed using a Bayesian simulation based approach. Next, structural time series models that describe changing patterns in low and high frequencies and backward as well as forward inflation expectation mechanisms are incorporated in the class of extended PC models. Empirical results indicate that the proposed models compare favorably with existing Bayesian Vector Autoregressive and Stochastic Volatility models in terms of fit and predictive performance. Weak identification and dynamic persistence appear less important when time varying dynamics of high and low frequencies are carefully modeled. Modeling inflation expectations using survey data and adding level shifts and stochastic volatility improves substantially in sample fit and out of sample predictions. No evidence is found of a long run stable cointegration relation between US inflation and marginal costs. Tails of the complete predictive distributions indicate an increase in the probability of disinflation in recent years.","Label":"0"},{"DOI":"10.2139/ssrn.4128509","Abstract":"Bitcoin has grown in popularity and has now attracted the attention of individual and institutional investors. Accurate Bitcoin price direction forecasts are important for determining the trend in Bitcoin prices and asset allocation. This paper addresses several unanswered questions. How important are business cycle variables like interest rates, inflation, and market volatility for forecasting Bitcoin prices? Does the importance of these variables change across time? Are the most important macroeconomic variables for forecasting Bitcoin prices the same as those for gold prices? To answer these questions, we utilize tree-based machine learning classifiers, along with traditional logit econometric models. The analysis reveals several important findings. First, random forests predict Bitcoin and gold price directions with a higher degree of accuracy than logit models. Prediction accuracy for bagging and random forests is between 75% and 80% for a five-day prediction. For 10-day to 20-day forecasts bagging and random forests record accuracies greater than 85%. Second, technical indicators are the most important features for predicting Bitcoin and gold price direction, suggesting some degree of market inefficiency. Third, oil price volatility is important for predicting Bitcoin and gold prices indicating that Bitcoin is a substitute for gold in diversifying this type of volatility. By comparison, gold prices are more influenced by inflation than Bitcoin prices, indicating that gold can be used as a hedge or diversification asset against inflation.","Label":"1"},{"DOI":"10.1504/ijie.2023.127236","Abstract":"Stock price prediction has drawn huge attention due to its impact on economic stability. Accurate stock price prediction is highly essential to reduce the risk associated with it so as to decide good investment strategies. There are various factors influencing the prediction of stock indices namely gross margin, exchange rate, inflation rate, relative index and so on. Feature selection plays a vital role in effective and accurate prediction of stock indices. This paper aims to provide a clear review of widely used features affecting the stock price fluctuations, feature selection techniques and prediction models from the recent literature. The study also highlights the future directions in this domain focusing the enhancement of the prediction performance.","Label":"1"},{"DOI":"10.1016/j.jeconbus.2011.11.002","Abstract":"While theoretical predictions establish a strong positive relationship between equity prices and inflation, finding substantiating empirical evidence has been a difficult endeavor. Generally, the data suggests a weak negative relationship between stock prices and inflation. Aided by two different structural VAR specifications that allow for time variation in the covariance and drift of the system, this paper finds evidence that the weakly negative correlation between stock prices and US inflation results from offsetting effects of shocks to monetary policy and disturbances to the demand for financial assets. Since the 1960s, the stock price-inflation correlation is estimated to be relatively more stable than the volatility of either series, both of which have experienced substantial change—albeit volatility in US economic activity is estimated to have taken place far more gradually than that of stock prices. The volatilities of US economic activity, inflation, and stock prices all rose as a result of the financial crisis and the ensuing 2008–2009 Great Recession—with the level of inflation volatility estimates during the Great Recession comparable to those of the Great Inflation period of the 1970s. While it is shown that a traditional VAR approach would also predict a positive stock price response to inflationary disturbances, our time-varying approach enables us to uncover that during the 2008–2009 Great Recession period a stock price increase is more pronounced following inflationary shocks that stem from money supply, rather than money demand, disturbances—in contrast to the 1980–1982 recession where the magnitude of the stock price response to both shocks is more similar. These conclusions are qualitatively robust to changes in variable choice and measurement frequencies.","Label":"0"},{"DOI":"10.2139/ssrn.1692704","Abstract":"This paper examines the distribution of Belgian consumer prices and its interaction with aggregate inflation over the period June 1976-September 2000. Given the fat-tailed nature of this distribution, both classical and robust measures of location, scale and skewness are presented. We found a positive short-run impact of the skewness of relative prices on aggregate inflation, irrespective of the average inflation rate. The dispersion of relative prices has also a positive impact on aggregate inflation in the short run and this impact is significantly lower in the sub-sample starting in 1988 than in the pre-1988 sub-sample, suggesting that the prevailing monetary policy regime has a substantial effect on this coefficient. The chronic right skewness of the distribution, revealed by the robust measures, is positively cointegrated with aggregate inflation, suggesting that it is largely dependent on the inflationary process itself and would disappear at zero inflation. These results have three important implications for monetary policy. First, as to the transmission of monetary policy, our results are in line with the predictions of menu cost models and therefore suggest that this type of friction can be an important factor behind the short run non-neutrality of monetary policy. Second, as to the design of robust estimators of core inflation, economic arguments based on menu cost models tend to highlight the importance of the absence of bias. We have proposed an unbiased estimator by taking the time-varying degree of chronic right skewness explicitly into account. Third, as to the optimal rate of inflation, the chronic right skewness found in the data provides no argument against price stability, as it appears as an endogenous response of optimising price setters and would disappear when targeting a zero inflation rate. This conclusion contrasts sharply with the implications of the exogenously assumed downward rigidity of Tobin (1972), which would justify targeting a sufficiently positive inflation rate in order to facilitate the adjustment of relative prices. Our empirical findings contradict the latter type of downward rigidity which implies a negative correlation between skewness and inflation. Therefore, the cross-sectional properties of Belgian inflation data do not provide strong arguments against a price stability-oriented monetary policy, such as the one pursued by the Eurosystem.","Label":"0"},{"DOI":"10.1590/s1413-80502012000100002","Abstract":"This work aims at testing the null hypothesis of no sticky information against the alternative of sticky information using Brazilian data. The rejection of the null hypothesis allows us to derive the expected time between information updates. The median of market participants' predictions collected by Gerin/Bacen is used as a proxy to firms' expectation contained in the sticky information version of the Phillips curve. Our estimates imply that inflation expectations in Brazil are updated about once each five quarters, which in part can be attributed to reduced uncertainty about Brazilian inflation in the period of analysis.","Label":"0"},{"DOI":"10.2139/ssrn.883453","Abstract":"This paper presents a theoretical and empirical analysis of policies aimed at setting a more depreciated level of the real exchange rate. An intertemporal optimizing model suggests that, in the absence of changes in fiscal policy, a more depreciated level of the real exchange can only be attained temporarily. This can be achieved by means of higher inflation and/or higher real interest rates, depending on the degree of capital mobility. Evidence for Brazil, Chile, and Colombia supports the model`s prediction that undervalued real exchange rates are associated with higher inflation.","Label":"0"},{"DOI":"10.1007/bf00134216","Abstract":"This paper+ derives the combined effect of depreciation schedules and regulatory lag on a firm's choice of input mix. It shows that a schedule called the real constant (RC) schedule induces efficient capital-labor proportions. More (less) accelerated schedules cause undercapitalization (overcapitalization). Since most typically used schedules are accelerated relative to the RC schedule, they lead to undercapitalization. Testable predictions are derived by showing that these distortions become more severe as the inflation rate increases and as the lag length decreases.","Label":"0"},{"DOI":"10.2139/ssrn.2193936","Abstract":"The use of different time-series models to generate forecasts is fairly usual in the forecasting literature in general, and in the inflation forecast literature in particular. When the predicted variable is stationary, the use of processes with unit roots may seem counterintuitive. Nevertheless, in this paper we demonstrate that forecasting a stationary variable with driftless unit-root-based forecasts generates bounded Mean Squared Prediction Errors errors at every single horizon. We also show via simulations that persistent stationary processes may be better predicted by unit-root-based forecasts than by forecasts coming from a model that is correctly specified but that is subject to a higher degree of parameter uncertainty. Finally, we provide an empirical illustration in the context of CPI inflation forecasts for three industrialized countries.","Label":"0"},{"DOI":"10.2139/ssrn.2580290","Abstract":"This paper reinvestigates the performance of trimmed-mean inflation measures some 20 years since their inception, asking whether there is a particular trimmed-mean measure that dominates the median consumer price index (CPI). Unlike previous research, we evaluate the performance of symmetric and asymmetric trimmed means using a well known equality of prediction test. We find that there is a large swath of trimmed means that have statistically indistinguishable performance. Also, although the swath of statistically similar trims changes slightly over different sample periods, it always includes the median CPI — an extreme trim that holds conceptual and computational advantages. We conclude with a simple forecasting exercise that highlights the advantage of the median CPI (and trimmed-mean estimators in general) relative to other standard measures in forecasting headline inflation.","Label":"0"},{"DOI":"10.2139/ssrn.3861829","Abstract":"Using data from the European Central Bank's Survey of Professional Forecasters, we analyze the role of ex-ante conditioning variables for macroeconomic forecasts. In particular, we test to which extent the heterogeneity, updating and ex-post performance of predictions for inflation, real GDP growth and the unemployment rate are related to assumptions about future oil prices, exchange rates, interest rates and wage growth. Our findings indicate that inflation forecasts are closely associated with oil price expectations, whereas expected interest rates are used primarily to predict output growth and unemployment. Expectations about exchange rates and wage growth also matter for macroeconomic forecasts, albeit less so than oil prices and interest rates. We show that survey participants can considerably improve forecast accuracy for macroeconomic outcomes by reducing prediction errors for external conditions. Our results contribute to a better understanding of the expectation formation process of experts.","Label":"0"},{"DOI":"10.54691/bcpbm.v25i.1854","Abstract":"This paper analyzes the key drivers for the change of the Singapore dollar and makes predictions for its future trend. First, the author focuses on trade by discussing the GDP and current account of Singapore, mainly in terms of services. Second, the author focuses on inflation by discussing the current situation of inflation and Monetary Authority of Singapore’s monetary policy. In the end, the author forecasts that the exchange rate of the SGD against the CNY is expected to fluctuate in the short-time and strengthen in the long-time.","Label":"0"},{"DOI":"10.1109/bigdata50022.2020.9378468","Abstract":"In the long run, gold price is positively related to inflation rates because gold is a perfect asset to hedge against inflation. In the short run, gold price fluctuates a lot. Many factors can cause gold price volatility, such as economic and political uncertainties, exchange rates, interest rates and so on. Here we try several models to predict monthly gold prices, including linear regression model and ARIMA model. We also try to predict monthly gold returns with hidden Markov model. It turns out that HMM is much better.","Label":"0"},{"DOI":"10.48550/arxiv.2107.07155","Abstract":"This study presents a novel approach to incorporating news topics and their associated sentiment into predictions of breakeven inflation rate (BEIR) movements for eight countries with mature bond markets. We calibrate five classes of machine learning models including narrative-based features for each country, and find that they generally outperform corresponding benchmarks that do not include such features. We find Logistic Regression and XGBoost classifiers to deliver the best performance across countries. We complement these results with a feature importance analysis, showing that economic and financial topics are the key performance drivers in our predictions, with additional contributions from topics related to health and government. We examine cross-country spillover effects of news narrative on BEIR via Graphical Granger Causality and confirm their existence for the US and Germany, while five other countries considered in our study are only influenced by local narrative.","Label":"1"},{"DOI":"10.1016/j.jmacro.2009.02.002","Abstract":"Risk-adjusted LQG optimal control with perfect and imperfect observation of the economy is used to obtain prudent Taylor rules for monetary policies and cautious Kalman filters. A prudent central bank adjusts the nominal interest rate more aggressively to changes in the inflation gap, especially if the volatility of cost-push shocks is large. If the interest rate impacts the output gap after a lag, the interest also responds to the output gap, especially with strong persistence in aggregate demand. Prudence pushes up this reaction coefficient as well. If data are poor and appear with a lag, a prudent central bank responds less strongly to new measurements of the output gap. However, prudence attenuates this policy reaction and biases the prediction of the output gap upwards, particularly if output targeting is important. Finally, prudence requires an extra upward (downward) bias in its estimate of the output gap before it feeds into the policy rule if inflation is above (below) target. This reinforces nominal interest rate reactions. A general lesson is that prudent predictions are neither efficient nor unbiased.","Label":"0"},{"DOI":"10.1007/s12197-012-9230-2","Abstract":"Utilizing recent techniques with comparable private forecasts as benchmarks, we test the rationality of the Federal Reserve forecasts of growth under flexible loss. Our findings for 1984–2006 indicate that these forecasts are rational (efficient) and directionally accurate under symmetric loss and are thus of value when similar cost is assigned to both incorrect upward and downward predictions. Over-predictions (under-predictions) are costly when the Fed responds by implementing an unnecessary contractionary (expansionary) monetary policy and thus causes lower growth (higher inflation). Symmetric loss thus indicates that the Fed is equally concerned about both low growth and high inflation. Further results reveal that the private sector closely replicates the Federal Reserve forecasts released to the public with a five-year lag, suggesting that one can utilize the readily available private data as proxies for the not-yet-released Federal Reserve forecasts.","Label":"0"},{"DOI":"10.1080/10800379.2015.12097277","Abstract":"In this study, we estimated to what extent monetary quantities such as M3 money overhang (excess money stock), M3 money stock growth, and M3 money stock available in the economy are useful in predicting future inflation in the East African Community (EAC) countries. To investigate this, we used Johansen cointegration analysis to estimate and analyse the stability of the M3 money demand model for each country member of the EAC. From this estimation, we derived a country-specific measure of money overhang. We compared its forecasting power of future inflation with that of money stock growth, and money stock available in the economy. Over the study period (from 2000 to 2012), except for Uganda, we identified a reasonable and stable country-specific M3 money demand model. Also, for predicting future inflation, the estimation results showed that M3 money stock growth is more reliable in Burundi and in Kenya, while M3 money overhang is preferable in Rwanda and M3 money stock in Tanzania.","Label":"0"},{"DOI":"10.4236/ojbm.2016.44059","Abstract":"The relatively recent (last few years) actions by the Federal Reserve and other economic factors have mitigated potential changes in unemployment rate. We examine the trends in economic inflation for the USA using the data and empirical models given in the recent paper by Yellen [1]. A new correlation for the inflation rate trend is developed based on Learning Theory. We may conclude that the Federal Reserve has learnt to control inflation rate via an implicit learning process, and has tempered the fluctuations in unemployment rate, which previously showed evidence of instability. The fluctuations and trends in unemployment do not show evidence of learning, and are fitted by a simple periodic dynamic expression with an underlying unemployment rate of 6.5%. Yellen [1] also discusses the role of “expectation” in forecasting and economic changes in policies and directions. This behavioral response to rule changes is clearly linked to the learning processes in society and by people, which are a fruitful topic for future research on economic predictions and for interpretive purposes.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2010.07.004","Abstract":"A probabilistic forecast is the estimated probability with which a future event will occur. One interesting feature of such forecasts is their calibration, or the match between the predicted probabilities and the actual outcome probabilities. Calibration has been evaluated in the past by grouping probability forecasts into discrete categories. We show here that we can do this without discrete groupings; the kernel estimators that we use produce efficiency gains and smooth estimated curves relating the predicted and actual probabilities. We use such estimates to evaluate the empirical evidence on the calibration error in a number of economic applications, including the prediction of recessions and inflation, using both forecasts made and stored in real time and pseudo-forecasts made using the data vintage available at the forecast date. The outcomes are evaluated using both first-release outcome measures and subsequent revised data. We find substantial evidence of incorrect calibration in professional forecasts of recessions and inflation from the SPF, as well as in real-time inflation forecasts from a variety of output gap models.","Label":"0"},{"DOI":"10.2139/ssrn.3288387","Abstract":"In this paper, we examine how professional forecasters’ expectations and expectation uncertainty have reacted to the ECB’s interest rate decisions and non-conventional monetary policy measures during the period 1999-2017. The analysis makes use of a conventional dif-in-dif type set up with different time series tools. The results indicate that expectations have been sensitive to policy actions, but all forecasters’ reactions do not seem to follow the basic predictions of a standard New Keynesian model. Also the relationship between inflation and output forecasts does not seem to follow a Phillips curve type relationship. Moreover, short- and long term reactions to policy are often weakly related and of different sign. Interestingly, subjective forecast uncertainty measures are very sensitive to policy measures. Thus, there seems to be much heterogeneity in forecasters’ reactions to most policy decisions. All uncertainty measures, including long-term inflation uncertainty, have increased over time. This has to be taken into account when considering the anchoring of inflation expectations to the inflation target.","Label":"0"},{"DOI":"10.48550/arxiv.2001.03935","Abstract":"This paper develops a dynamic factor model that uses euro area (EA) country-specific information on output and inflation to estimate an area-wide measure of the output gap. Our model assumes that output and inflation can be decomposed into country-specific stochastic trends and a common cyclical component. Comovement in the trends is introduced by imposing a factor structure on the shocks to the latent states. We moreover introduce flexible stochastic volatility specifications to control for heteroscedasticity in the measurement errors and innovations to the latent states. Carefully specified shrinkage priors allow for pushing the model towards a homoscedastic specification, if supported by the data. Our measure of the output gap closely tracks other commonly adopted measures, with small differences in magnitudes and timing. To assess whether the model-based output gap helps in forecasting inflation, we perform an out-of-sample forecasting exercise. The findings indicate that our approach yields superior inflation forecasts, both in terms of point and density predictions.","Label":"0"},{"DOI":"10.20525/ijfbs.v11i2.1790","Abstract":"In a two-period decision model, a central bank chooses a CBDC (central bank digital currency) interest rate and a representative household allocates resources into production, consumption, CBDC holding, and non-CBDC holding. The model’s analytical results and a plausible benchmark are compared with the empirics for the US, China and Russia. Interesting novelties of the article are that the model predicts that the US in 2021/2022 should choose  rather than 0.125% CBDC interest to combat its high October 2021 empirical inflation of 6.2%. That would induce households to hold more CBDC, hold less non-CBDC, and produce and consume less. In contrast, the model predicts that China should choose a low  rather than  CBDC interest rate. That would decrease each household’s CBDC holding and increase the low inflation. The model predicts that Russia should choose  rather than  CBDC interest rate. Russia’s strategy is remarkably consistent with the model’s predictions. The model predicts that the central bank should choose negative CBDC interest rate when the inflation and real interest rate are low, and the inflation target is high. The article shows how extremely high inflation, which increases the CBDC interest rate, makes production and consumption nearly impossible, unless the real interest rate is extremely negative.","Label":"0"},{"DOI":"10.18800/economia.201101.005","Abstract":"This paper analyzes and distinguishes the role and importance of the shocks related to the aggregate demand and aggregate supply on the behavior of the Peruvian inflation during the period 1997:1-2009:2. We use the methodology based on structural vector autoregressive (SVAR) models using a long-run identification based on Blanchard and Quah (1989) which allows to obtain the historical decomposition of the annual inflation. Unlike Salas (2009), this paper uses a more simple model of aggregate demand and aggregate supply, and a larger sample. The results show that the behavior of inflation was largely explained for shocks related to the aggregate demand side in comparison with aggregate supply shocks. Furthermore, the results of the variance decomposition of the prediction error show that in the short and long term, the shocks of the demand side explain around 70% and 60% of the movements of the inflation. The results are robust to the inclusion of different variables in the set of information.","Label":"0"},{"DOI":"10.2139/ssrn.787645","Abstract":"The paper investigates the relationship between relative price movements and changes in the aggregate price level using monthly data on Finland's Consumer Price Index and its components from the period covering the past eight and a half years. This was a period of very low inflation. The rate of growth in the aggregate price level was occasionally very close to zero. The paper shows that declining nominal prices were a rather common phenomenon during this period of low or no inflation. The declining prices cannot, however, be explained by lack of demand or any generalized deflationary tendencies. Hence, the downward rigidity of nominal prices has not prevented relative price adjustments under price stability. The paper develops a new method for looking at the composition of inflation and illustrating how relative price dynamics interact with changes in the aggregate price level. The correlation of relative price variability and aggregate inflation has been negligible, but the correlation between the skewness of price change distribution and aggregate inflation is high. This is in accordance with the predictions of the menu cost models. A significant proportion of the relative price changes appear to have been persistent, suggesting the dominance of productivity and other supply shocks.","Label":"0"},{"DOI":"10.1007/s00181-005-0262-8","Abstract":"This paper tests a version of the rational expectations hypothesis using ‘fixed-event’ inflation forecasts for the UK. Fixed-event forecasts consist of a panel of forecasts for a set of outturns of a series at varying horizons prior to each outturn. The forecasts are the prediction of fund managers surveyed by Merrill Lynch. Fixed-event forecasts allow tests for whether expectations are unbiased in a similar fashion to the rest of the literature. But they also permit the conduct of particular tests of forecast efficiency - whether the forecasts make best use of available information - that are not possible with rolling-event data. We find evidence of a positive bias in inflation expectations. Evidence for inefficiency is much less clear cut.","Label":"0"},{"DOI":"10.2139/ssrn.2969198","Abstract":"Spanish Abstract: El indicador de precios ajustado para expresar las presiones inflacionarias «excluyendo las variaciones de corto plazo», normalmente es construido eliminando los sub componentes del índice que son altamente volátiles, esta forma de calcular la denominada inflación subyacente puede incurrir en el error de dejar de lado la información que tienen algunos precios que son volátiles pero persistentes. El presente trabajo estima la persistencia de los 31 subgrupos componentes del Índice de precios al consumidor de Lima Metropolitana, entre el año 2001 y 2015 utilizando data mensual disponible, asimismo prueba si los indicadores ajustados propuestos mejoran la predicción de la inflación general. Se encuentra que los indicadores propuestos no logran mejorar la predicción de la inflación en el corto plazo, aunque el error cuadrático medio es menor. English Abstract: The price index adjusted to include inflation pressure “excluding short term variations”, most of times is calculated deleting the sub components that have high volatility, this way of compute the so called core inflation would be wrong ignoring the information that have some prices with high volatility but with high persistence. This work estimates the degree of persistence of the 31 components of the Consumer Price Index of Lima Metropolitana, between 2001 and 2015 using monthly data available, also tests if the adjusted index can improve the prediction of the headline inflation. We finds that index can’t enhance the short term prediction of inflation, however the mean of squared error is lower.","Label":"0"},{"DOI":"10.1177/097380101000400302","Abstract":"A growing literature in the field of econometrics is on the treatment of seasonal variables. However, so far, very few studies in India have applied advanced seasonal modelling techniques to important macroeconomic variables. This paper examines the seasonal properties of Indian monthly WPI inflation and their usefulness in modelling the series more efficiently. Monthly WPI inflation was found to be a periodic process with 18 lags and periodic integration of order two. A comparison between the performances of a PAR (18) and an AR (18) model showed that the former performed substantially better in terms of R 2 , AIC, in-sample predictive ability and residual properties. However, the out-of-sample forecasts from the PAR model were only reasonable. The best forecasts obtained for a horizon of 22 months, however, had good ‘direction of change’ predictions. The model could also produce interval forecasts of modest accuracy.","Label":"0"},{"DOI":"10.1111/j.1467-9485.2009.00473.x","Abstract":"In this paper, we analyze the money demand functions of the four largest EMU countries and of the four‐country (EMU‐4) aggregate. We identify reasonable and stable money demand relationships for Germany, France and Spain as well as the EMU‐4 aggregate. For the case of Italy, results are less clear. From the estimated money demand functions, we derive both EMU‐4 and country‐specific measures of money overhang. We find that the EMU‐4 overhang measure strongly correlates with the country‐specific measures, particularly since the start of EMU, and is useful to predict country‐specific inflation. However, it generally does not encompass country‐specific money overhang measures as predictors of inflation. Hence, aggregate money overhang is an important, but by far not an exhaustive, indicator for the disaggregate level.","Label":"0"},{"DOI":"10.2139/ssrn.3355356","Abstract":"We propose a method to measure people's subjective models of the macroeconomy. Using a sample of 2,200 households representative of the US population and a sample of more than 1,000 experts, we measure beliefs about how the unemployment rate and the inflation rate respond to four different hypothetical exogenous shocks: a monetary policy shock, a government spending shock, an income tax shock, and an oil price shock. While expert predictions are quantitatively close to benchmarks from standard DSGE models and VAR evidence and relatively homogeneous, there is strong heterogeneity among households. Households predict changes in unemployment that are largely in line with the experts' responses for all four shocks. However, their predictions of changes in inflation are at odds with those of experts both for the tax shock and the interest rate shock. We show that a substantial fraction of deviations of household predictions from expert predictions can be explained by the use of a simple heuristic according to which people expect a positive co-movement among variables they perceive as good and among variables they perceive as bad. Our findings inform the validity of central assumptions about the expectation formation process and have important implications for the optimal design of fiscal and monetary policy.","Label":"0"},{"DOI":"10.2346/1.2151003","Abstract":"Abstract Linear relations have been observed experimentally between tire equilibrium rolling resistance, tire load, and the reciprocal of tire inflation pressure. These variables are used to formulate a simple general expression for rolling resistance, and predictions made with this expression are compared with measured data.","Label":"0"},{"DOI":"10.2139/ssrn.1445192","Abstract":"By analyzing the history of traditional Phillips curves, this paper criticizes that the prior studies of Phillips curve have ignored the accumulative effect of economic growth and inflation on a particular economy. By doing an empirical analysis on Chinese economy during 1979-2008, this paper has got three results: Firstly, it defines a variable of ideal real GDP growth rate and a variable of ideal CPI. When considering the accumulative effects of the economic growth rate and inflation rate, it approves that the accumulative ideal real GDP growth rate can be used as the ideal potential accumulative real GDP growth rate, and the accumulative ideal CPI can be used as the ideal natural accumulative CPI. Secondly, it constructs an accumulative Phillips curve. When considering the cross accumulative effects, it approves that the accumulative Phillips curve is good fitted to the relation between the accumulative real GDP growth rate and accumulative inflation rate. Finally, it creates a prediction mechanism. When comparing the prediction results of four models, it approves that the Chinese real GDP growth rate will be about 7.15% in 2009 and 9.59% in 2010, and the Chinese CPI will be about -1.40% in 2009 and -8.55% in 2010.","Label":"0"},{"DOI":"10.2139/ssrn.303116","Abstract":"This paper employs the predictability of monthly excess returns on U.K. conventional and index-linked gilts to study the risk premiums of nominal and real bonds. The excess return predictions of nominal and real bonds are highly correlated and the restrictions of a single-latent-variable model for expected excess returns are accepted. The estimates of the conditional asset-pricing model reveal that indexed gilts of medium and long maturities require approximately half the risk compensation of conventional gilts. The government can significantly reduce its long run borrowing costs through issuing inflation index-linked debt. However, the inflation indexation of bonds with maturities of up to 3 years does not significantly reduce their risk compensation. The paper also shows that membership in the ERM did not significantly alter the ratio of risk compensation of conventional and indexed gilts.","Label":"0"},{"DOI":"10.1016/j.jeca.2016.07.005","Abstract":"This paper explores the ability of the Phillips curve to forecast inflation over the course of the recent Great Recession. We use quarterly data for the USA and Canada for the period 1960Q1 through 2013Q4. Estimating the slope of the Phillips curve over a rolling 10-year (40-quarter) window, we find evidence in favor of its empirical instability for both countries. More precisely, our results suggest that the slope coefficient becomes smaller for the USA from 1980 and onwards, while it increases for Canada since 2000. We then simulate inflation for the period 2008Q1 to 2013Q4 and compare the results with those obtained from a standard, constant coefficient Phillips curve model. We conclude that modeling time variation of the slope parameter helps improve the accuracy of predictions for the USA, but not for Canada.","Label":"0"},{"DOI":"10.1007/978-3-030-35740-5_14","Abstract":"Time series forecasting is an important topic widely addressed with traditional statistical models such as regression, and moving average. This work uses the state-of-the-art Long Short-Term Memory (LSTM) Networks to predict Ecuadorian imports of Home Appliances, and to compare the results against those obtained by traditional methods. First, an ARIMA model was used to forecast imports data. Then, the predictions were calculated by a Univariate LSTM network. The time series used in both experiments was the monthly average of imports from 1996 to April 2019. In addition, time series of GDP Growth, Population, and Inflation were included in the model to test prediction improvements. The performance of the models was assessed comparing the Mean Squared, Root Mean Square and Mean Absolute Error metrics. The results show that a LSTM network produces a better fit of the imports data and improved predictions compared against those produced by the ARIMA model. Furthermore, the use of multivariate time series (i.e., GDP Growth, Population, Inflation) data, for the LSTM model, did not produce significant improvements compared to the univariate imports time series.","Label":"1"},{"DOI":"10.32479/ijeep.13022","Abstract":"This study aims to explore the influence of electricity consumption, electricity price, inflation and interest rate on GDP and investments in Indonesia in the period 2001-2018. This paper is explanatory research. A Generalized Structured Component Analysis was a component-based approach to Structural Equation Modelling has used as a research model. The empirical analysis uses time-series data of GDP, Electricity Consumption, Electricity Price, Inflation Rate, Interest Rate, Investments and GDP in Indonesia in the period 2001-2018. The findings of this study are electricity consumption has a significant positive effect on GDP and electricity price. Electricity price has an insignificant positive effect on electricity consumption and investment. GDP has a significant positive effect on electricity consumption but insignificant on investment and inflation. Investment has an insignificant negative effect on electricity consumption and inflation. Inflation has a significant positive effect on the interest rate, vice versa, but is insignificant to electricity consumption. The interest rate has an insignificant positive effect on investment. The Originality of this study, namely previous studies focused more on the relationships and causality between Electricity Consumption, FDI, GDP, while in this study the emphasis is more on predictions between latent variables using the GSCA. In previous studies using total electricity consumption, in this study, the latent variable of electricity consumption is formed by industry electricity consumption and business electricity consumption which is productive consumption in increasing GDP. This study uses a multi-variate study consisting of Electricity Consumption of Industrial and Business, Electricity Price, Investment, GDP variables, and adding Inflation Rate and Interest Rate that represent macro-economic conditions in the research model.","Label":"0"},{"DOI":"10.2139/ssrn.3801271","Abstract":"Using sector-level survey data for the universe of Japanese firms, we establish the positive co-movement in the firm’s expectations about aggregate and sector-specific demand shocks. We show that a simple model with imperfect information on the current aggregate and sector-specific components of demand explains the positive co-movement of expectations in the data. The model predicts that an increase in the relative volatility of sector-specific demand shocks compared to aggregate demand shocks reduces the sensitivity of inflation to changes in aggregate demand. We test and corroborate the theoretical prediction on Japanese data and find that the observed decrease in the relative volatility of sector-specific demand has played a significant role for the decline in the sensitivity of inflation to movements in aggregate demand from mid-1980s to mid-2000s.","Label":"0"},{"DOI":"10.52903/wp2022296","Abstract":"This study evaluates oil price forecasts based on their economic significance for macroeconomic predictions. More specifically, we first use the current state-of-the-art frameworks to forecast monthly oil prices and subsequently we use these forecasts, as oil price assumptions, to predict eurozone and Greek inflation rates and industrial production indices. The macroeconomic predictions are generated by means of regression-based models. We show that when we assess oil price forecasts, based on statistical loss functions, the MIDAS models, as well as the futures-based forecasts outperform those generated by the VAR and BVAR models. By contrast, in terms of their economic significance we show that none of the oil price forecasts are capable of providing predictive gains for the eurozone core inflation rate and the Greek industrial production index, whereas some gains are evident for the eurozone industrial production index and the Greek core inflation rate. However, in all cases the oil price forecasting models, including the random-walk, generate equal macroeconomic predictive accuracy. Thus, overall, we show that it is important to assess oil price forecasting frameworks based on the purpose that they are designed to serve, rather than based on their ability to predict oil prices per se.","Label":"0"},{"DOI":"10.1109/iscit.2014.7011878","Abstract":"This paper presents the prediction Thai baht by using Hidden Markov Models (HMM) with which the prediction model uses four factors, dollar index, interest rate, inflation rate and economic growth. The main idea of this work is a technique of encoding four factors into one observation sequence to train HMM. One result of prediction data will present four factors after decoding. The experiment is done using the data-by-day from 2002 to 2013 and showed that the technique has the mean percentage error of 0.167% to predict Thai currency exchange.","Label":"0"},{"DOI":"10.1111/jmcb.12425","Abstract":"We consider a monetary authority that provides an explicit inflation target in order to align expectations with the policy objective. However, biased perceptions of the target may arise due to imperfect information flows. We allow agents to revise expectations over time and we model their recursive choice among prediction strategies as an optimization problem under rational inattention. We then investigate whether a simple policy rule can steer the economy toward the targeted equilibrium. Our findings suggest that determinacy under rational expectations may not be sufficient to reach the target. Instead, monetary policy should be fine‐tuned to correct agents' biased beliefs.","Label":"0"},{"DOI":"10.1108/01443589210027293","Abstract":"Some recent research has reported results more favourable to long‐run purchasing‐power parity (PPP) for exchange rates within the European Monetary System (EMS) than for those outside it. This is inconsistent with the predictions of theories that regard the EMS as a means of acquiring anti‐inflation credibility for the governments of relatively high‐inflation countries. Results of tests on a wide range of intra‐EMS exchange rates suggest a tendency to under‐adjust for cumulative price differentials, and that the DM‐FF rate is atypical in its adherence to long‐run PPP.","Label":"0"},{"DOI":"10.1016/0264-9993(86)90005-2","Abstract":"It is suggested that the public forecasts of various modelling organizations affect agents' views about the future and that the average of these predictions is a candidate for putting into practice the concept of economically rational expectations. A series of averages of five forecasts of inflation is examined and while it is found to be biased it is a better predictor of inflation than simply using past values of that variable. The average of the forecasts works satisfactorily as a proxy for price expectations in a wage equation.","Label":"0"},{"DOI":"10.1111/j.1475-4932.1995.tb01872.x","Abstract":"The menu costs model predicts that during times of rapid inflation firms are less likely to vary output in response to changes in nominal aggregate demand. This paper tests the proposition using a disaggregated sample of Australian three‐digit ASIC manufacturing industries. The results show that a significant number of Australian industries exhibit behaviour that is consistent with this prediction. In addition, the results show that the variability of inflation and changes to the import penetration ratio also influence the response of output to nominal demand changes.","Label":"0"},{"DOI":"10.2139/ssrn.883001","Abstract":"The paper presents a model of irreversible investment under uncertainty, where investment takes place whenever a threshold level of marginal returns is reached. The threshold depends positively on price volatility; a change from high to low inflation induces an upward capital stock adjustment. In economies that move in and out of temporary stabilizations, the observed effect is a negative inflation-investment correlation that replicates previous empirical findings, due to purely short-term dynamics. I study how this correlation is affected by the expected duration of each regime. Empirical evidence from ten inflationary economies confirms the predictions of the model.","Label":"0"},{"DOI":"10.1162/rest_a_00971","Abstract":"Abstract This paper develops and estimates a New Keynesian (NK) model with endogenous technology. It shows that introducing endogenous technology can solve three important puzzles that conventional NK models face: the inflation persistence, disinflationary news shock, and zero lower bound (ZLB) supply shock. First, the observed persistence in inflation is explained without relying on the conventional NK models' additional assumptions (e.g., backward price indexation). Second, it explains the observed disinflationary effect of a news shock. Third, the model avoids the conventional NK models' paradoxical, empirically inconsistent prediction that a negative supply shock is expansionary at the ZLB on interest rates.","Label":"0"},{"DOI":"10.2139/ssrn.3082428","Abstract":"We analyze credit ratings' effects on firms' investments in a rational debt-financing game that features a feedback loop. The credit rating agency (CRA) inflates the rating, providing a biased but informative signal to creditors. Creditors' response to the rating affects the firm's investment decision and credit quality, which is reflected in the rating. The CRA might reduce ex-ante economic efficiency, which results solely from the feedback effect of the rating: The CRA assigns more firms high ratings and allows them to gamble for resurrection. We derive empirical predictions on the determinants of rating standards and inflation and discuss policy implications.","Label":"0"},{"DOI":"10.1134/s1075700710050072","Abstract":"The paper describes the instruments developed by the author for imitation modeling of per capita meat and meat product consumption by the population of Russia taking into consideration the exogenously assigned trends of change in per capita cash incomes, consumer prices, and inflation rates. The results of prediction calculations for the period of 2010–2012 using the developed instruments are presented. The consequences of implementing the forecasts of the socioeconomic development of Russia until 2012 are analyzed on their basis.","Label":"0"},{"DOI":"10.1016/j.joep.2010.03.012","Abstract":"Since there are significant biases in the individuals’ inflationary expectations, the role of monetary policy credibility needs to be reconsidered. Theoretically, policy credibility can influence the policymaker’s plan of action or reflect his preference. Thus, when prices rise, perceived credibility not only stabilizes public expectations of inflation, but also becomes important information, which can be used by the individuals to improve their expectations. The econometric analysis of a large-scale survey largely confirms these theoretical predictions. The perceived policy credibility as well as inflation perceptions and education plays an important role in the individuals’ inflationary expectations.","Label":"0"},{"DOI":"10.1016/0304-3878(95)00006-2","Abstract":"This paper presents a theoretical and empirical analysis of policies aimed at setting a more depreciated level of the real exchange rate. An intertemporal optimizing model suggests that, in the absence of changes in fiscal policy, a more depreciated level of the real exchange rate can only be attained temporarily. This can be achieved by means of higher inflation and/or higher real interest rates, depending on the degree of capital mobility. Evidence for Brazil, Chile, and Colombia supports the model's prediction that undervalued real exchange rates are associated with higher inflation.","Label":"0"},{"DOI":"10.1016/j.jimonfin.2008.12.009","Abstract":"This paper develops a simple theoretical model that can be used to account for the determinants of exchange rate pass-through to consumer prices. While recent evidence has found low estimates of pass-through in many countries, there is little consensus on an explanation for this. Our paper argues that sticky prices represent a key determinant of exchange rate pass-through. We make this argument in two stages. First, holding the frequency of price change constant, we show that our model calibrated to data from low-inflation countries can reproduce the estimates of very low pass-through for these countries. The principal determinant of low pass-through in this case is the slow adjustment of prices. We then extend the model to allow the frequency of price change to be endogenous. Calibrating to a wider set of countries, including both low-inflation and high-inflation countries, we show that our model implies that exchange rate pass-through is increasing in average inflation, but at a declining rate. Performing the identical exercise on the data, we find a striking correspondence between the predictions of the model and those of the data.","Label":"0"},{"DOI":"10.2139/ssrn.779846","Abstract":"This paper develops a simple theoretical model that can be used to account for the determinants of exchange rate pass-through to consumer prices. While recent evidence has found low estimates of pass-through in many countries, there is little consensus on an explanation for this. Our paper argues that sticky prices represent a key determinant of exchange rate pass-through. We make this argument in two stages. First, holding the frequency of price change constant, we show that our model calibrated to data from low inflation countries can reproduce the estimates of very low pass-through for these countries. The principal determinant of low pass-through in this case is the slow adjustment of prices. We then extend the model to allow the frequency of price change to be endogenous. Calibrating to a wider set of countries, including both low-inflation and high-inflation countries, we show that our model implies that exchange rate pass-through is increasing in average inflation, but at a declining rate. Performing the identical exercise on the data, we find a striking correspondence between the predictions of the model and those of the data.","Label":"0"},{"DOI":"10.2139/ssrn.590044","Abstract":"This paper integrates a theory of equilibrium unemployment into a monetary model with nominal price rigidities. The model is used to study the dynamic response of the economy to a monetary policy shock. The labor market displays search and matching frictions and bargaining over real wages and hours of work. Search frictions generate unemployment in equilibrium. Wage bargaining introduces a microfounded real wage rigidity. First, I study a Nash bargaining model. Then, I develop an alternative bargaining model, which I refer to as right-to-manage bargaining. Both models have similar predictions in terms of real wage dynamics: bargaining significantly reduces the volatility of the real wage. But they have different implications for inflation dynamics: under right-to-manage, the real wage rigidity also results in smaller fluctuations of inflation. These findings are consistent with recent evidence suggesting that real wages and inflation only vary by a moderate amount in response to a monetary shock. Finally, the model can explain important features of labor-market fluctuations. In particular, a monetary expansion leads to a rise in job creation and to a hump-shaped decline in unemployment.","Label":"0"},{"DOI":"10.2139/ssrn.392280","Abstract":"Globally, the majority of countries using inflation targets have done so when inflation was neither low nor stable. Many such countries have changed their target each year, and our empirical estimates support theoretical predictions that annual changes to the target are endogenous to outcomes. We use a unique cross-country panel dataset of inflation targets and outcomes in 60 countries in the 1990s. Our estimates suggest the target revision may be predicted according to a simple 'forecasting' rule, and depends upon the outcome's deviation from both the short-run and long-run target. During disinflation, policy-makers may therefore be characterised as using two types of policy rule; one for setting interest rates, the other for revising annual targets. In designing roles for the legislator and the central bank in the monetary framework, it is necessary to take into account the likelihood that the process of setting the target may, in some circumstances, be inseparable from that of setting policy instruments. In the light of other literature, we also argue that during disinflation, short-run targets may help central banks to build credibility because they may increase transparency.","Label":"0"},{"DOI":"10.2139/ssrn.896360","Abstract":"The use of non-linear models to accurately estimate the Value at Risk (VaR) of financial portfolios is increasing. Specifically, the use of Autoregressive Conditional Heteroscedasticity (ARCH) models, which can forecast the time-varying volatility of a financial asset. In this research paper ARCH-type models are applied in order to estimate the VaR of an inflation-index futures portfolio for several time-horizons. The empirical analysis is carried out for Mexican inflation-indexed futures traded at the Mexican Derivatives Exchange (MEXDER). To analyse the VaR with time horizons of more than one trading day bootstrapping simulations were applied. The results show that these models are relatively accurate for time horizons of one trading day. However, the volatility persistence of ARCH-type models is reflected with relatively high VaR estimates for longer time horizons. This is considered undesirable given that an unnecessary amount of capital must be set aside in order to meet Minimum Capital Risk Requirements for a futures portfolio. However, when the ARCH-type specifications include a variable for volatility persistence the predictions are more accurate for time horizons up to ten trading days. These results have implications for short-term inflation forecasts. By estimating confidence intervals in the VaR, it is possible to have certain confidence about the future range of inflation (or extreme inflation values) for a specified time horizon. For this study time horizons from one trading day up to three months were considered.","Label":"0"},{"DOI":"10.2139/ssrn.2022656","Abstract":"This study documents empirical regularities related to structural changes in the exporting pattern and degree of competitiveness in selected Asian countries in the decade following the 1997 Asian crisis. We conceptually illustrate that the degree of competitiveness is determined by foreign-domestic wage inflation differentials, changes in the relative cost of capital, growth rate of total factor productivity, and foreign-domestic inflation differentials in the import sector. The contribution of these factors to the degree of competitiveness crucially depends on labor intensity and consumption expenditure shares. Hence, rising wage inflation may not result in a loss of competitiveness if it occurs in the sectors in which labor intensity is low and the consumption expenditure share is small. We confirm this prediction using data of 98 industries in nine Asian countries. Specifically, although we found that the exporting pattern in Asia and the degree of competitiveness of Asian economies substantially changed, these structural changes were not caused by labor intensity and wage inflation. However, due to data limitation, we cannot conclude whether these structural changes come from changes of the cost of capital or changes in total factor productivity.","Label":"0"},{"DOI":"10.1016/j.econlet.2021.109877","Abstract":"This paper tests whether volatility in inflation and GDP growth was higher at the ZLB across the period from 1990:1 to 2019:3 as predicted by conventional models. Contrary to the theoretical predictions, volatility was not higher at the ZLB.","Label":"0"},{"DOI":"10.2139/ssrn.3752523","Abstract":"How do macroeconomic expectations affect consumer decisions? We examine this question using a natural field experiment with 2,872 credit card customers from a large commercial bank. We conduct a survey to measure consumer expectations about future inflation and the nominal exchange rate and combine this with an information-provision experiment that generates exogenous variation in these expectations. We merge the survey and experimental data with detailed administrative data on the subjects' credit card transactions and balances. The experiment is designed to test three standard predictions from models of intertemporal consumption choice: inflation expectations should affect spending on durables; exchange rate expectations should affect spending on tradables; and, holding constant the nominal interest rate, inflation expectations should affect borrowing. We find that the information provided to participants strongly affects subjective expectations. However, we do not find any significant effects on actual consumer behavior (as measured in administrative data) or self-reported consumption plans (as measured in survey data). Our preferred interpretation is that consumers are not sophisticated enough to factor inflation and exchange rate expectations into their consumption decisions. The absence of a link between consumer expectations and behavior has potentially important implications for macroeconomic policies such as forward guidance.","Label":"0"},{"DOI":"10.1017/s0266466600003066","Abstract":"The prediction of future events and developments is an  exciting and perhaps mysterious task, often associated  with the aura of prophets and seers instead of probabilistic  models and computer screens. The reality of macroeconomic  forecasting, however, is quite mundane. Predictions of  macroeconomic aggregates play an important role in the  decision making of private enterprises, central banks,  and governments. In general, forecasts become less popular  if they turn out to be inaccurate ex post, and the postwar  history of macroeconomic forecasting has had its share  of disappointments. For instance, in the early 1980's,  economists tested inflation forecasts taken over the previous  20 years and found that the forecasts were poor, partly  as a result of the oil price shocks in the 1970's.  A recent study (Croushore, 1998) with data up to 1996 provides  a more favorable assessment of the quality of inflation  forecasts.","Label":"0"},{"DOI":"10.1515/ngoe-2015-0009","Abstract":"Abstract This paper brings to light an economic problem that frequently appears in practice: For the same variable, more alternative forecasts are proposed, yet the decision-making process requires the use of a single prediction. Therefore, a forecast assessment is necessary to select the best prediction. The aim of this research is to propose some strategies for improving the unemployment rate forecast in Romania by conducting a comparative accuracy analysis of unemployment rate forecasts based on two quantitative methods: Kalman filter and vector-auto-regressive (VAR) models. The first method considers the evolution of unemployment components, while the VAR model takes into account the interdependencies between the unemployment rate and the inflation rate. According to the Granger causality test, the inflation rate in the first difference is a cause of the unemployment rate in the first difference, these data sets being stationary. For the unemployment rate forecasts for 2010-2012 in Romania, the VAR models (in all variants of VAR simulations) determined more accurate predictions than Kalman filter based on two state space models for all accuracy measures. According to mean absolute scaled error, the dynamic-stochastic simulations used in predicting unemployment based on the VAR model are the most accurate. Another strategy for improving the initial forecasts based on the Kalman filter used the adjusted unemployment data transformed by the application of the Hodrick-Prescott filter. However, the use of VAR models rather than different variants of the Kalman filter methods remains the best strategy in improving the quality of the unemployment rate forecast in Romania. The explanation of these results is related to the fact that the interaction of unemployment with inflation provides useful information for predictions of the evolution of unemployment related to its components (i.e., natural unemployment and cyclical component).","Label":"0"},{"DOI":"10.1016/0169-2070(91)90050-6","Abstract":"This paper analyzes forecast precision as it pertains to four major us macroeconomic variables from 1983.II through 1988.III. The data set, comprised of Blue Chip consensus predictions of approximately fifty economists and informed business professionals, sequentially lengthens the forecast horizon from one through four quarters. Applying the Theil Mean Square Error measure to the forecasts of the Fed Funds rate, money growth, and inflation, the results show prediction accuracy declining as the forecast window is lengthened. Conversely, for real GNP growth, forecast accuracy improves with a longer horizon. A decomposition analysis of the errors reveals further insight into the nature of professional prediction performance. For all four variables, forecast bias is shown to be a systematic influence in the errors. This is especially true for inflation. Additionally, at longer horizons (with the exception of real GNP) we find slope error growing as the dominant systematic influence, replacing bias in the forecast error. This finding indicates forecasters are, in general, unable to anticipate changes in direction for these variables over time. Our results suggest that forecasters, in addition to more accurately tracking trend determinants, can improve prediction performance by more closely monitoring those factors which produce turning points in the data.","Label":"0"},{"DOI":"10.1016/j.jmoneco.2017.09.003","Abstract":"Many new-Keynesian models produce a deep recession with deflation at the zero bound. These models also make unusual policy predictions: Useless government spending, technical regress, capital destruction, and forward guidance can raise output. Moreover, these predictions are larger as prices become less sticky and as changes are expected further in the future. I show that these predictions are strongly affected by equilibrium selection. For the same interest-rate path, equilibria that bound initial jumps predict mild inflation, small output variation, negative multipliers, small effects of far-off expectations and a smooth frictionless limit. Fiscal policy considerations suggest the latter equilibria.","Label":"0"},{"DOI":"10.2139/ssrn.2550328","Abstract":"This paper presents an equilibrium bond pricing model driven by two stochastic factors: the real interest rate and the expected rate of inflation. The model’s parameters are estimated using a maximum likelihood technique based on a Kalman filter. Data on nominal U.S. Treasury securities and Survey of Professional Forecasters predictions of the GDP deflator are employed to identify the separate effects of real and nominal variables. The market prices of real interest rate risk and inflation risk are estimated, which allows us to construct yield curves for nominal and indexed U.S. Treasury securities. The relative costs of nominal and indexed bonds can then be assessed.","Label":"0"},{"DOI":"10.17016/feds.2022.054r1","Abstract":"Temporal aggregation biases estimates of monetary policy effects. We hypothesize that information mismatches between private agents and the econometrician—the source of temporal aggregationbias—are as important as the more studied mismatch between private agents and the centralbank (the “Fed information effect”) in the study of monetary policy transmission. In impulse responsesfrom both local projections and an unobserved components model, we find that the responseof daily inflation to high-frequency monetary shocks confirms theoretical predictions. If thereis an adverse-signed response such that inflation increases in response to a contractionary monetaryshock, it is much less prominent than previously thought and explained by frequency mismatches ofshocks and dependent variables.","Label":"0"},{"DOI":"10.1016/0304-3878(95)00007-0","Abstract":"This article explains why the existence of state-owned financial institutions makes it more difficult for a country to balance its budget. We show that states can use their financial institutions to transfer their deficits to the federal government. As a result, there is a bias towards large deficits and high inflation rates. Our model also predicts that state-owned financial institutions should underperform the market, mainly because they concentrate their portfolios on non-performing loans to their own shareholders, that is, the states. Brazil and Argentina are two countries with a history of high inflation that confirm our predictions.","Label":"0"},{"DOI":"10.2139/ssrn.2706512","Abstract":"We introduce a money demand motive in a life-cycle portfolio choice model and estimate the structural parameters that can generate limited stock market participation and plausible holdings of money, bonds and stocks. The model predicts an increase in bond holdings over the life cycle, and a declining share of money in portfolios as wealth increases. Both predictions are consistent with the data, even though the model overpredicts (underpredicts) stock (bond) holdings in early life. When mean inflation approaches zero, the share of money in the financial portfolio rises at the expense of both bond and stockholdings, generating simultaneously a lower stock market participation rate.","Label":"0"},{"DOI":"10.2139/ssrn.2173257","Abstract":"We propose simulation-based forecasting methods for the noncausal vector autoregressive model proposed by Lanne and Saikkonen (2012). Simulation or numerical methods are required because the prediction problem is generally nonlinear and, therefore, its analytical solution is not available. It turns out that different special cases of the model call for different simulation procedures. Simulation experiments demonstrate that gains in forecasting accuracy are achieved by using the correct noncausal VAR model instead of its conventional causal counterpart. In an empirical application, a noncausal VAR model comprised of U.S. inflation and marginal cost turns out superior to the best-fitting conventional causal VAR model in forecasting inflation.","Label":"0"},{"DOI":"10.2139/ssrn.1077520","Abstract":"This paper describes the official Riksbank forecasts for the period 2000-06. The forecast variables are those that are important for monetary policy analysis, i.e. inflation, GDP, productivity, employment, labour force, unemployment and financial variables such as interest rate and foreign exchange rate. The Riksbank's forecasts are presented and analyzed and compared with alternative forecasts, that is, those from other institutions and simple statistical models. One important message from the study is that macroeconomic forecasts are associated with an appreciable uncertainty; the forecast errors are often sizeable. The forecast memory, defined as how far the forecasts are more informative than the variables unconditional mean, is usually limited to the first year. Furthermore, we find that the inflation forecasts exhibit several appealing features, such as a predictability memory that (possibly) includes the second year, relatively low RMSE and weak efficiency. The forecasts for the investigated real variables are shown to be less precise and they have a shorter forecast memory. The exchange rate predictions demonstrate the least accurate (of the investigated variables) forecasts. Compared to other forecasters, the Riksbank's predictions are often more accurate. This holds for a comparison with the National Institute of Economic Research, even though the differences are statistically insignificant, as well as for a comparison with the participants in the Consensus Forecasts panel, where the Riksbank's predictions often are among the best. We also find indications that misjudgements for productivity growth have had effects on forecasts for both inflation and GDP, but the results suggest that the Riksbank has considered available information in an acceptable fashion. This is also true for the undertaken revisions (from one forecast occasion to another) of the published forecasts.","Label":"0"},{"DOI":"10.2139/ssrn.309943","Abstract":"The paper presents a theory of the demand for money that combines a special case of the shopping time exchange economy with the cash-in-advance framework. The model predicts that both higher inflation and financial innovation - that reduces the cost of credit - induces agents to substitute away from money towards exchange credit. This results in an interest elasticity of money that rises with the inflation rate rather than the constant elasticity found in standard shopping time specifications. A number of the key predictions of the banking time theory are tested using quarterly data for the US and Australia. We find empirical support for some aspects of the model.","Label":"0"},{"DOI":"10.2139/ssrn.1569064","Abstract":"Stock and Treasury bond comovement, volatilities, and their relations to their price valuations and fundamentals change stochastically over time, both in magnitude and direction. These stochastic changes are explained by a general equilibrium model in which agents learn about composite economic and inflation regimes. We estimate our model using both fundamentals and asset prices, and find that inflation news signal either positive or negative future real economic growth depending on the times, thereby affecting the direction of stock/bond comovement. The learning dynamics generate strong non-linearities between volatilities and price valuations. We find empirical support for numerous predictions of the model.","Label":"0"},{"DOI":"10.1007/s12197-009-9085-3","Abstract":"We use data from the Wall Street Journal’s semi-annual survey of professional economists to test whether individual economists’ six-month-ahead predictions of real GDP growth, unemployment, short-term interest rates and inflation reflect Okun’s Law and the Taylor Rule. We conclude the economists believe real growth is less responsive to unemployment-rate changes than the textbook version of Okun’s Law; we also find the economists believe the Federal Reserve sets short-term interest rates by placing more weight on unemployment and less weight on inflation than the Taylor Rule prescribes.","Label":"0"},{"DOI":"10.2139/ssrn.2561026","Abstract":"We propose a no-arbitrage term structure model with a Taylor rule and two macroeconomic variables, real activity growth and inflation, that each contain long-run and short-run components. Variance decompositions and impulse responses indicate that the impact of macroeconomic variables on the term structure differs from existing models. For short maturities, inflation is relatively more important than real activity growth at short forecast horizons. For longer maturity yields, the long-run component of inflation explains most of the long-horizon forecast variance, but real activity growth matters for short forecast horizons. Unlike existing macro models, the model implies plausible term premia and expectations of short rates. The long-run components also improve the prediction of bond excess returns relative to information in the yield curve and macro variables. Measures of in-sample and out-of-sample fit confirm the benefits of allowing for long- and short-run components.","Label":"0"},{"DOI":"10.1080/09603100050031570","Abstract":"The performance of the P∗ model is tested as an inflation forecaster for the Spanish economy. It is shown that log-run relationships work as expected according to the model and the Quantitative Theory of Money. The Error Correction Model constructed by using the gap between actual prices and the long-term equilibrium price level as an error correction term, offers a consistent explanation for the short-run dynamics in prices. On the other hand, the P∗ approach shows a forecasting ability similar to that presented for other countries in several studies, although the degree of accuracy in the prediction is not specially satisfactory, mainly for the period 1989:3- 1992:3, when the credibility effect generated by the inclusion of the Spanish peseta in the European Monetary System led to an inflation rate much lower than that predicted by the model. Results support the option of a direct inflation target (instead of a monetary aggregate) as the intermediate variable of the monetary policy.","Label":"0"},{"DOI":"10.48550/arxiv.2010.12263","Abstract":"This paper considers forecasts of the growth and inflation distributions of the United Kingdom with factor-augmented quantile autoregressions under a model averaging framework. We investigate model combinations across models using weights that minimise the Akaike Information Criterion (AIC), the Bayesian Information Criterion (BIC), the Quantile Regression Information Criterion (QRIC) as well as the leave-one-out cross validation criterion. The unobserved factors are estimated by principal components of a large panel with N predictors over T periods under a recursive estimation scheme. We apply the aforementioned methods to the UK GDP growth and CPI inflation rate. We find that, on average, for GDP growth, in terms of coverage and final prediction error, the equal weights or the weights obtained by the AIC and BIC perform equally well but are outperformed by the QRIC and the Jackknife approach on the majority of the quantiles of interest. In contrast, the naive QAR(1) model of inflation outperforms all model averaging methodologies.","Label":"1"},{"DOI":"10.1080/15140326.2020.1795526","Abstract":"In this paper we derive a new model on exchange rate response to a lasting higher interest rate level. Contemporary models do not provide a convincing explanation for this relationship, but recent research suggests that models based on demand-pull effects to be somewhat confined to small funding cost increases. This would make cost-push effects more relevant when the interest rate differential (IRD) is larger and longer-lasting. The new model accounts for cost-push effects and suggests that a persistent higher IRD can evoke multiple responses, including currency depreciation, specialization, inflation, and wage drift. The model suggests that excessive long-lasting IRD can spark a chronic interaction between inflation and currency depreciation. Empirical data substantiate the prediction capability of the new model. We also demonstrate how the uncovered interest rate parity (UIP) principle is a special case, which can explain its empirical research anomalies, and when carry trade is a profitable investment strategy.","Label":"0"},{"DOI":"10.51558/2303-680x.2021.19.1.3","Abstract":"The joint hypothesis test is a replicable interpretation of the quantity theory of money (QTM) when used as an inflation theory. This study examined the effect of money supply and gross domestic product (GDP) growth on inflation volatility. We used the cross- country data of 40 countries, both in 2002 and 2014, from the World Bank publications. We analyzed the data using both the unrestricted regression model and joint hypothesis testing (the Wald test). The unrestricted regression results pointed inflation volatility in 40 countries was mostly driven by the monetary side, not by the real sector. Meanwhile, the joint hypothesis test demonstrated Strong Wald and Weak Wald test for the QTM prediction were rejected. These findings implied undesirable results from a monetarist perspective. We proposed an alternative method to confirm the joint hypothesis test from the QTM. It would be interesting to see whether our findings hold in other countries.","Label":"0"},{"DOI":"10.2139/ssrn.3576296","Abstract":"How does competition affect information acquisition of firms and thus the response of inflation and output to monetary policy shocks? This paper addresses these questions in a new dynamic general equilibrium model with both dynamic rational inattention and oligopolistic competition. In the model, rationally inattentive firms acquire information about the endogenous beliefs of their competitors. Moreover, firms with fewer competitors endogenously choose to acquire less information about aggregate shocks – a novel prediction of the model that is supported by empirical evidence from survey data. A quantitative exercise disciplined by firm-level survey data shows that firms' strategic inattention to aggregate shocks associated with oligopolistic competition increases monetary non-neutrality by up to 77% and amplifies the half-life of output response to monetary shocks by up to 30%. Furthermore, the model matches the relationship between the number of firms' competitors and their uncertainty about inflation as a non-targeted moment.","Label":"0"},{"DOI":"10.1016/j.jempfin.2018.06.002","Abstract":"We propose a no-arbitrage term structure model with a Taylor rule and two macroeconomic variables, real activity growth and inflation, that each contain long-run and short-run components. Variance decompositions indicate that the impact of macroeconomic variables on the term structure differs from existing models. For short maturities, inflation is relatively more important than real activity growth at short forecast horizons. For longer maturity yields, the long-run component of inflation explains most of the long-horizon forecast variance, but real activity growth matters for short forecast horizons. Unlike existing macro models, the model implies plausible term premia and expectations of short rates. The long-run components also improve the prediction of bond excess returns relative to information in the yield curve and macro variables. Measures of in-sample and out-of-sample fit confirm the benefits of allowing for long- and short-run components.","Label":"0"},{"DOI":"10.2139/ssrn.1568006","Abstract":"We examine the Fisher hypothesis with weekly equity returns and latently obtained simulated expected weekly inflation rates for five sectors in USA, Japan, UK, Canada and South Africa between Jan. 1975 and May 2009 and for several sub-periods, including that for the global financial crisis. Three main interdependent innovations define this paper. First, market efficiency, combined with noisy rational expectations equilibrium, posits an insignificant relation in data with a frequency that matches the frequency of the inflation announcements. Our evidence from estimations with monthly data supports this prediction. Second, new ideas, based on the option role of levered equity, indicate a dynamic, non-linear, and not one-for-one Fisher relation for equity returns and expected inflation rates. In particular, this interpretation emphasizes for the first time the effect of the changes in the aggregate amount of outstanding corporate debt on the Fisher hypothesis and also exposes the economic forces, other than the alluded market efficiency, that lead to insignificance. Third, a novel simulation-based approach with weekly data, when the inflation announcements occur monthly, examines empirically these option-theoretic arguments. We (i) introduce the Brownian Bridge to construct a reliable and simulated path of weekly inflation rates, (ii) extract its expected / unexpected inflation rate paths via the Kalman filter, and (iii) perform an estimation. This procedure is repeated 10,000 for each sector, country, and (sub-) sample period, leading to more than 1,250,000 estimations and rich distributions for the estimates. Our work stays clear of the concern for the power of the test, which is inherent in the long-horizon data of previous literature. Further, this approach captures the rich information in short-horizon return data. We find evidence in support of the option-theoretic arguments and offer an explanation for the dynamic changes in the signs and magnitudes of the coefficient estimates over time.","Label":"0"},{"DOI":"10.1002/jae.3950060304","Abstract":"This paper presents a model of inflation in a small open economy which features both wage‐wage linkages and a wage‐price spiral. Hence we have a simultaneous structure which contains the conventional Scandinavian model of inflation as a special case. Full system estimation results are reported. Great emphasis is placed on data coherency and on parameter stability. One interesting finding is that both wage growth and the wage level in the exposed (E)‐sector are strongly influenced by the outside wage. This contradicts the predictions of the Scandinavian model, which defines the wage‐leading role of the E‐sector by the absence of outside wage effects in E‐sector wage formation. Another result is that the speed of adjustment to exogenous shocks is greater for prices than for wages. This finding may be important in explaining real wage flexibility, which is often seen as the hallmark of low unemployment economies such as the Norwegian.","Label":"0"},{"DOI":"10.9734/jamcs/2023/v38i51759","Abstract":"The goal of this study was to identify a reliable GARCH model for modeling and forecasting each economic variable in Nigeria, including the price of crude oil, the consumer price index, the exchange rate, and the inflation rate. Monthly secondary data and simulated data sets were the data sets that were used. Between January 2004 and December 2020, the secondary data are covered. Beta Volatility Coefficient (BVC) model was proposed for detecting volatility in research data. Using a proposed method called Beta Volatility Coefficient (BVC) and Model Accuracy Measure (MAM) for the different sample sizes: 50, 100, 150, and 200, robust models for each variable were found. Leverage impact was there, according to the Asymmetric models' results. All the variables have a statistically significant value for the value. Inflation rate series is 11% more volatile than the Crude Oil Price and Exchange rate series, and when the sample size is large, the Consumer Price Index is 55% more volatile than the Crude Oil Price and Exchange rate, according to the results of the BVC of the Symmetric and Asymmetric models at the various sample sizes (200). The asymmetric \"E-GARCH (1, 1) Model,\" the symmetric \"GARCH-M (1, 1) Model,\" the symmetric \"GARCH (1, 1) Model,\" and the symmetric \"E-GARCH (1, 1) Model\" are the identified robust models for the prediction of the Crude Oil Price series, the Inflation Rate series, the Exchange Rate series, and the Consumer Price Index series, respectively. In general, the Asymmetric GARCH model outperformed the Symmetric GARCH model for Exchange rate and Consumer Price Index, which is an improvement over earlier research. The Symmetric GARCH model outperformed the Asymmetric GARCH model for Crude Oil Price and Inflation Rate. For each variable, the found reliable models were utilized to create predictions between January 2022 and December 2024. The expected ranges for the price of crude oil are $31.82 ±1.08, the inflation rate is N14.65 ±0.03, the exchange rate is N/$756.76 ±53.84, and the consumer price index is N2.26 ±0.11.","Label":"0"},{"DOI":"10.55606/iceb.v1i2.185","Abstract":"The financial system plays an important role in the economy. An unstable financial system will be vulnerable to various problems that disrupt the rotation of a country's economy and be vulnerable to economic problems such as the global crisis in various countries. The problem that occurs is the occurrence of Covid-19 causing various fluctuations in the level of inflation, money supply, imports, the occurrence of unstable inflation from January 2019 to August 2021, low inflation resulting in a decrease in imports and an increase in the money supply in Mexico. , Vietnam, Philippines, Hongkong, Indonesia, Canada, Malaysia, Singapore, Peru, and China. The analytical method in this study uses the ARDL Panel (Autoregression Distributed Lag) approach. The ARDL Panel Model determines which country models from APEC countries are able to control long-term financial system-based economic fundamentals in Mexico, Vietnam, the Philippines, Hong Kong, Indonesia, Canada, Malaysia, Singapore, Peru, and China and the Different Test for modeling the impact of covid-19 19 on the economic fundamentals of the financial system. The results of the research found the ARDL Panel prediction model in modeling the impact of Covid-19 on economic fundamentals in the financial system. The main Leading Indicator of variable effectiveness in controlling Inflation In TAPEC is JUB where Vietnam, the Philippines, Hong Kong, Japan, Malaysia, Singapore, Peru and China have a significant influence in controlling Inflation. Then overall in the long term (Long Run) it turns out that only the JUB and CDV variables have an effect on INF In TAPEC, while in the short term (Short Run) it is JUB that influences Inflation In TAPEC.","Label":"0"},{"DOI":"10.2139/ssrn.916060","Abstract":"A linear and lagged relationship between inflation and labor force growth rate has been recently found for the USA. It accurately describes the period after the late 1950s with linear coefficient 4.0, intercept -0.03, and the lag of 2 years. The previously reported agreement between observed and predicted inflation is substantially improved by some simple measures removing the most obvious errors in the labor force time series. The labor force readings originally obtained from the Bureau of Labor Statistics (BLS) website are corrected for step-like adjustments. Additionally, a half-year time shift between the inflation and the annual labor force readings is compensated. GDP deflator represents the inflation. Linear regression analysis demonstrates that the annual labor force growth rate used as a predictor explains almost 82% (R^2=0.82) of the inflation variations between 1965 and 2002. Moving average technique applied to the annual time series results in a substantial increase in R^2. It grows from 0.87 for two-year wide windows to 0.96 for four-year windows. Regression of cumulative curves is characterized by R^2>0.999. This allows effective replacement of GDP deflation index by a \"labor force growth\" index. The linear and lagged relationship provides a precise forecast at the two-year horizon with root mean square forecasting error (RMSFE) as low as 0.008 (0.8%) for the entire period between 1965 and 2002. For the last 20 years, RMSFE is only 0.4%. Thus, the forecast methodology effectively outperforms any other forecasting technique reported in economic and financial literature. Moreover, further significant improvements in the forecasting accuracy are accessible through improvements in the labor force measurements in line with the US Census Bureau population estimates, which are neglected by BLS.","Label":"0"},{"DOI":"10.1007/978-3-319-95219-2_6","Abstract":"After Lionel Robbins withdrew his 1931 Foreword to the 1935s edition of Prices and Production, Hayek apparently did not repeat his fraud about having ‘predicted’ the Great Depression—until after he was awarded the 1974 Nobel Prize. Shortly before the announcement of his Nobel Prize for Economic Science, Hayek predicted ‘continued inflation’ and the disappearance of ‘the free market and free institutions’: ‘What I expect is that inflation will drive all the Western countries into a planned economy via price controls.’ Five years later—just before the onset of the low-inflation ‘Great Moderation’—Hayek played Cassandra again: ‘I must witness the heads of governments of all Western industrial countries promising their people that they will stop the inflation and preserve full employment. But I know that they cannot do this.’ Hayek’s abysmal forecasting record was matched by his (and Mises’) post-1931 silence about his alleged ‘prediction.’ Of the nine possible explanations why Hayek was unacceptable to the Economics Department, the most likely one is that they feared being tainted by his fraud: ‘It was all right to have him at the University of Chicago so long as he wasn’t identified with the economists.’ As George Stigler explained, to get a ‘professorship at a major American university’ required that ‘a professor be at least tolerably honest.’","Label":"0"},{"DOI":"10.1093/0195161211.003.0005","Abstract":"Abstract Wall Street strategists are susceptible to gambler's fallacy. In general, four important behavioral elements affect the market predictions of investors: overconfidence, betting on trends, anchoring and adjustment, and salience. Although gambler's fallacy generally afflicts Wall Street strategists, it typically does not afflict individual investors and technical analysts—they succumb to other errors. This point leads to a discussion about some of the key illusions that most people have about randomness, and why these illusions bias their predictions. Inflation adds an additional element of confusion.","Label":"0"},{"DOI":"10.1590/1980-53575245sng","Abstract":"Resumo Neste artigo, estimamos uma tendência para a inflação brasileira com a finalidade de apresentar uma medida alternativa de inflação de longo prazo e trazer um novo complemento aos tradicionais núcleos de inflação. Além da análise econômica do comportamento dessa estimativa, aplica-se uma avaliação de capacidade preditiva em pseudo tempo real. A obtenção da tendência também permitiu verificarmos a dinâmica da persistência e da volatilidade do gap da inflação durante o atual regime monetário. No período em análise, os resultados revelam-se correlacionados com a conjuntura brasileira, com contribuições positivas da tendência no processo preditivo da inflação. Ainda, eles mostram uma resistência de convergência da taxa de inflação aos níveis preestabelecidos pelo CMN, diante de um considerável nível de persistência do gap da inflação. Já a volatilidade do gap corrobora e identifica ao mesmo tempo as grandes oscilações presentes no cenário econômico doméstico e externo. Abstract In this article, we estimate a trend for Brazilian inflation in order to present an alternative measure of long-term inflation and provide a complement to the traditional core inflation measures. In addition to the economic analysis of the behavior of this estimation, a pseudo-real-time predictive capability assessment is applied. Obtaining the trend also allowed us to verify the dynamics of the persistence and volatility of the inflation gap during the current monetary regime. In the period under review, the results are correlated with the Brazilian situation, with positive contributions from the trend in the inflation prediction process. Still, they show a resistance convergence of the inflation rate to the levels pre-established by the CMN, in view of a considerable persistence of the inflation gap. The volatility of the gap, on the other hand, corroborates and identifies, at the same time, the great oscillations present in the domestic and external economic scenario.","Label":"1"},{"DOI":"10.35774/sf2018.02.089","Abstract":"Introduction. Prediction that price stability as well as inflation targeting in commodity rich countries is very fragile typically based on logical relation between commodity prices fluctuations and macroeconomic instability. But in the same time, while counter-cyclical instruments appear, commodity prices shock should be taken as supply shock. Thus, inflation instability in resource rich countries should be taken as consequences of macroeconomic mismanagement.  Purpose. The purpose of the paper is to validate rejection of fatalism in negative influence of resource richness on price stability. Also it is important to show that inflation targeting regime compatible with large commodities export. In the same time it is necessary to take into account political regime as a supporting factor of adoption that regime of macroeconomic policy that is consistent with price stability.  Results. It is proved empirically that commodity abundance per se is not in conflict with price stability. We rich such conclusions basing on simple multifactor regression model that combine macroeconomic policy regime dummies (maturity of inflation targeting, sovereign wealth fund in operation, central bank independence, exchange rate regime) and structural features of the resource rich economies like commodity export, economic complexity, financial depth, democracy. On example of 68 resource rich countries it is shown that price stability parameters (mean inflation, 1999-2017 and standard deviation of it) are not in undoubtfull relation with fraction of nonmerchandise export, but they are in opposite relation with inflation targeting and sovereign wealth funds dummies. Resource endowed countries are not homogenous from political regime point of you. Such regime is important driver of macroeconomic policy choice. Advanced democracies are likely to choose inflation targeting, flexible exchange rate and central bank independence, while wealthy autarkies are likely to prefer fixed exchange rates and sovereign wealth funds. It is mean that price stability is not just vulnerable to commodity factor but is to unstable political regime under which it is hard to implement counter-cyclical regime of macroeconomic policy.  Conclusions. Commodity wealth is not precondition to price instability. But political regime is important activate that type of macroeconomic policy regime that consistent with low and stable inflation. By the structural features Ukraine is closer to democracies with mean level of economic complexity and financial depth. Due this inflation targeting regime is more appropriate meaning priority of price stability and exchange rate flexibility.","Label":"0"},{"DOI":"10.1007/978-1-4614-0231-2_22","Abstract":"This study investigates whether the term structure of interest rates contains useful information about future real economic activity and inflation in Turkey during the 1991:7–2004:3 periods. In order to analyse these relationships, we have employed the Generalized Impulse Response (GIRF) analysis to the Logistic Smooth Transition Vector Autoregressive model. We have determined that the results of a GIRF analysis are consistent with the recursive Chow test and parameter stability tests. Besides, we have found out that the relationships between spread-real economic activity and spread inflation are negative. These negative relationships have also been examined by GIRF analysis; because of a negative reverse relationship between Expectation Hypothesis and Interest Transmission Channel, a negative correlation between real economic activity and spread has occurred. For the inflation and spread relationship, we find a negative Fisher effect and negative Expectation Hypothesis, which cause a negative relationship between these variables. Finally, we have found that Estrella’s (1997) theoretical prediction that “empirical relationships are not structural, and alternative monetary policy regimes could lead to very different outcomes” cannot be proven by the Turkish data.","Label":"0"},{"DOI":"10.2139/ssrn.2328460","Abstract":"In standard solutions, the new-Keynesian model produces a deep recession with deflation in a liquidity trap. The model also makes unusual policy predictions: Useless government spending, technical regress, and capital destruction have large multipliers. These predictions become larger as prices become less sticky. I show that both sets of predictions are strongly affected by equilibrium selection. For the same interest-rate path, different choices of equilibria -- either by the researcher's direct selection or the researcher's specification of expected Federal Reserve policy -- can overturn all these results. A set of \"local-to-frictionless\" equilibria predicts mild inflation, no output reduction and negative multipliers during the liquidity trap, and its predictions approach the frictionless model smoothly, all for the same interest rate path.","Label":"0"},{"DOI":"10.48550/arxiv.physics/0606064","Abstract":"We analyse, following recent work of Roehner, changes in house prices for both the UK and Ireland. We conclude that prices in London have reached a tipping point and prices relative to inflation are set to fall over the next few years. If inflation does not rise then a hard landing seems likely. House prices in the Irish Republic are shown to have broken away from the moderate rise still to be found in Northern Ireland and Dublin has emerged as another global 'hot spot'. An evolution of Dublin house prices similar to that in London can be anticipated. Keywords: Econophysics, house prices, real estate, prediction PACS: 89.65.Gh, 89.90.+n","Label":"1"},{"DOI":"10.2139/ssrn.479661","Abstract":"The paper presents a theory of the demand for money that combines a special case of the shopping time exchange economy with the cash-in-advance framework. The model predicts that both higher inflation and financial innovation - that reduces the cost of credit - induce agents to substitute away from money towards exchange credit. This results in an interest elasticity of money that rises with the inflation rate rather than the constant elasticity found in standard shopping time specifications. A number of the key predictions of the banking time theory are tested using quarterly data for the US and Australia. We find cointegration empirical support for the model, with robustness checks and a comparison to a standard specification.","Label":"0"},{"DOI":"10.1016/s0304-3932(03)00083-7","Abstract":"This paper tests the predictions of the Barro–Gordon model using US data on inflation and unemployment. To that end, it constructs a general game-theoretical model with asymmetric preferences that nests the Barro–Gordon model and a version of Cukierman's model as special cases. Likelihood Ratio tests indicate that the restriction imposed by the Barro–Gordon model is rejected by the data but the one imposed by the version of Cukierman's model is not. Reduced-form estimates are consistent with the view that the Federal Reserve weights more heavily positive than negative unemployment deviations from the expected natural rate.","Label":"0"},{"DOI":"10.1111/1536-7150.00122","Abstract":"When the money supply increased exogenously, Marshall’s vs. Wicksell’s versions of short run inflation transmission are shown to be different because of their ideas on money demand. During the approach to monetary equilibrium, the implication was that the demand for transactions cash balances would have to increase in order for inflation to stop. Marshall focused on the real, while Wicksell focused on the nominal, demand for such balances; Marshall assumed velocity of money was constant, while Wicksell assumed it to be pro‐cyclic. These assumptions about money demand caused them to make different predictions on how much prices would eventually rise: Marshall described a price‐undershoot, while Wicksell described a price‐overshoot mechanism.","Label":"0"},{"DOI":"10.1109/icie.2010.79","Abstract":"Inflation forecasts becomes a key input of monetary policy decision. CPI is a measure of inflation, however, an important economic indicator. Based on the monthly CPI data from January 2000 to December 2009, the thesis firstly statistically indentifies the correlation function and the partial correlation function of consumer price index, tests the stationarity of ADF, then uses ARIMA model to test residual serial autocorrelation, lastly makes a short-term estimation on monthly CPI of our country in 2010. Empirical results show that ARIMA (12,1,12) model provides a better prediction for the monthly consumer price index (CPI) of our country in 2010. CPI forecast based on the results of the Government formulating appropriate monetary policy.","Label":"0"},{"DOI":"10.1111/j.1465-7287.2007.00034.x","Abstract":"This article extends the model of Von Hagen and Harden that analyzed the impact of fiscal discipline on budgetary outcomes. We modify the model by adding monetary discipline to interact with fiscal discipline in order to analyze the effects of both on budgetary outcomes. The model predicts that while both inflation and budget deficits are negatively associated with fiscal discipline, they may be positively associated with monetary discipline, proxied by central bank independence. This result obtains due to optimizing agents internalizing the burden of spending: inflation. Although not conclusive due to data limitations, empirical findings also support these predictions. (JEL D73, E58, H61, H72)","Label":"0"},{"DOI":"10.58886/jfi.v4i2.2455","Abstract":"This abstract was created post-production by the JFI Editorial Board. In this study, we examined the ability of the strategist chosen by Investment Advisor, the leading trade magazine dedicated to financial planning, and quotedmonthly in its \"Asset Allocation\" column. Data was obtained for the entire fifteen years that this information has been published. Two of five economic forecasts statistically showed a great deal of accuracy over the 15-year span. The forecasts for the bond market and the inflation rate statistically have no bias over the years. However, when both early data and more recent data are looked at individually, the accuracy of Investment Advisor strategists' inflation rate forecast seems to be time sensitive. Segmenting of the data does not affect the bond market hypothesis results. Less accuracy was observed for the prediction of the other three economic measures, the stock market, economic growth, and short-term rates. However, over shorter periods, some of the predictions appear to have less bias. For instance, when the stock market data is split, the hypothesis of prediction accuracy was rejected for the fist half of the sample period but accepted for the second half. By contrast, short-term interest rate forecasts were statistically accurate during the first sub-period, but not the second sup-period. Predications of changes in gross domestic product were not accurate whether one used the data from 1991-1997, from 1998-2005, or the entire period.","Label":"0"},{"DOI":"10.2139/ssrn.2333459","Abstract":"I apply the model with unobserved components and stochastic volatility (UC-SV) to forecast the Russian consumer price index. I extend the model which was previously suggested as a model for inflation forecasting in the USA to take into account a possible difference in model parameters and seasonal factor. Comparison of the out-of-sample forecasting performance of the linear AR model and the UC-SV model by mean squared error of prediction shows better results for the latter model. Relatively small absolute value of the standard error of the forecasts calculated by the UC-SV model makes it a reasonable candidate for a real time forecasting method for the Russian CPI.","Label":"0"},{"DOI":"10.1111/j.1468-0343.2004.00139.x","Abstract":"We use evidence from detailed records of FOMC deliberations to argue that time inconsistency theory can help explain the excessive monetary expansion that characterized Arthur Burns's tenure as Federal Reserve Chairman (1970–1978). The records suggest that the Fed perceived a Phillips curve tradeoff and political pressures that made it difficult to adopt disinflationary policies,  the tendency toward excessively expansionary policy was exacerbated by the short‐run planning horizon the Committee faced in each of its meetings. We argue that comparative static predictions of the time inconsistency model are consistent with the rise of inflation during the Burns years and its subsequent fall.","Label":"0"},{"DOI":"10.1016/0164-0704(93)90053-o","Abstract":"This paper develops a political business cycle model based on partisanship and credibility arguments that explains the pre-electron behavior of inflation, output, and money growth. The approach taken is to introduce elections and a Mundell-Tobin effect into a structure similar to the Barro-Gordon (1983) model of governmental reputation. The model's predictions are similar to those of the simple manipulative models of Nordhaus (1975) and Frey and Schneider (1978), but the predictions do not rely on economic irrationally, myopia, or memory loss.","Label":"0"},{"DOI":"10.1016/j.jimonfin.2012.10.001","Abstract":"In this note, we correct two typos contained in the published version of Auray et al. (2012), which affect the quantitative results, without modifying the qualitative results and then the message of the paper. In addition, we present a modified pricing rule for exported goods, and allow export prices to be sticky as well. This extension slightly improves the quantitative predictions of the model. Finally, predictions are made closer to the data when considering an alternative inflation target.","Label":"0"},{"DOI":"10.1016/j.jdeveco.2020.102608","Abstract":"This paper presents a model of the labor market where public workfares increase private wages by reducing labor supply. In a dynamic setting, we show that when wages are downwardly rigid, forward-looking employers optimally compress wage increases in response to intertemporal variability in the level of program implementation. The model generates two key predictions: greater variability in program provision results in a larger compression of wage increases, and compression of wage increases is more severe under low inflation. We empirically verify these predictions using data from two large workfares from India.","Label":"0"},{"DOI":"10.35940/ijitee.l1017.10812s319","Abstract":"The growth of any country depends on its economy and economic growth is nothing but an increase in the inflation i.e. adjusted market value of the goods and services produced by an economy over time. Statisticians conventionally measure such inflation using the price indices. They are mainly WPI (Wholesale Price Index and CPI (Consumer Price Index). WPI is now known to be an older method of computation because the main focus has to be on consumer prices.CPI is a measure of consumer prices over a certain period. Changes in the CPI are used to assess price changes associated with the cost of living. It can be calculated for rural, urban areas as well as for both. In CPI rural, the workers and labourers are benefitted as their daily wages can be predicted by this approach. The CPI by state data represents the inflation of each of the states giving a concise view of the country. The data is collected and analysed using a mathematical approach called linear regression in future prediction for rural labours based on previous data.","Label":"0"},{"DOI":"10.2139/ssrn.1326464","Abstract":"A probabilistic forecast is the estimated probability with which a future event will satisfy a specified criterion. One interesting feature of such forecasts is their calibration, or the match between predicted probabilities and actual outcome probabilities. Calibration has been evaluated in the past by grouping probability forecasts into discrete categories. Here we show that we can do so without discrete groupings; the kernel estimators that we use produce efficiency gains and smooth estimated curves relating predicted and actual probabilities. We use such estimates to evaluate the empirical evidence on calibration error in a number of economic applications including recession and inflation prediction, using both forecasts made and stored in real time and pseudoforecasts made using the data vintage available at the forecast date. We evaluate outcomes using both first-release outcome measures as well as later, thoroughly-revised data. We find strong evidence of incorrect calibration in professional forecasts of recessions and inflation. We also present evidence of asymmetries in the performance of inflation forecasts based on real-time output gaps.","Label":"1"},{"DOI":"10.2139/ssrn.1102656","Abstract":"We analyze the effects of monetary policy on the equity premium and the cross-section of stock returns in a general equilibrium framework. Monetary policy is conducted using an interest-rate policy rule reacting to inflation and has real effects due to nominal rigidities in the production sector. The model predicts that higher price rigidities and lower policy responses to inflation generate higher equity premiums. Moreover, industries with lower price rigidities earn higher expected returns than industries with higher price rigidities. We provide a consumption-based explanation for this result. Real profits of industries with low rigidities are more sensitive to monetary policy shocks than profits of industries with high rigidities. Since profits are positively correlated with aggregate consumption, investors require higher compensations for holding stocks with lower profits when marginal utility is high. In addition, the difference in expected returns between high and low rigidity industries decreases when the response of monetary policy to inflation is more aggressive. We find empirical evidence supporting all model's predictions.","Label":"0"},{"DOI":"10.2139/ssrn.4407363","Abstract":"Following a period of subdued consumer price changes, inflation has recently surged to levels that are significantly impacting the behavior of households and firms. Although the underlying sources of inflation differ across major advanced economies, central banks have progressively tightened their monetary policy stance since late 2021 to ensure a prompt return to price stability.In the current macroeconomic discourse, inflation expectations have gained considerable attention. A suitable monetary policy response, aimed at anchoring these expectations to central bank targets, is crucial to minimizing the risk of a wage-price spiral, which could result in higher and more persistent inflation. This is especially important in the face of significant shocks such as the recent surge in gas prices in Europe, which has caused a decline in terms of trade that cannot be reversed but should be absorbed swiftly, with a view to protecting the most vulnerable members of society. Attempts to recover purchasing power losses in a generalized backward-looking manner could prolong the high inflation rates resulting from the rise in energy prices. This, in turn, could affect inflation expectations and give rise to second-round effects, which must be countered through more restrictive monetary policy measures.Thus, the crucial question that central banks face today is how to conduct monetary policy appropriately in these complex and highly uncertain times. To address this question, this paper will first briefly review the essential role of inflation expectations in the monetary transmission mechanism. We will then consider the issues related to their measurement and interpretation. Based on these theoretical and empirical considerations, we will discuss the recent evolution of inflation expectations in the euro area and draw some conclusions for the current and potential future conduct of the ECB's monetary policy.Monetary policy has a gradual and lengthy impact on the real economy and inflation through a complex system of channels known as the monetary transmission mechanism. Although central banks' actions and communications immediately affect financial market interest rates and asset prices, their transmission to households and businesses' financing conditions and subsequently to consumer prices is typically much slower.In this process, inflation expectations play a vital role, representing economic agents' beliefs or predictions about future price changes. These expectations shape the behavior of households and businesses, which, in turn, influence overall price dynamics. For example, in response to the expectation of a broad increase in the prices of goods and services, workers may demand higher wages, and firms may raise their prices. Under certain conditions, this behavior could result in a self-fulfilling prophecy, fuel actual inflation, and make it dangerously persistent.In macroeconomic models, the role of expectations is generally summarized by the augmented Phillips curve. This curve initially examined the relationship between wage growth and unemployment in the UK in the 1950s. Later studies focused on consumer price inflation and unemployment, which showed that in a booming economy, high employment and demand could cause workers to demand higher wages, and firms could raise their prices, and vice versa in a contracting economy. This relationship represents a reduced form of more structural models that determine production, consumer prices, and wages.With respect to wage inflation, macroeconometric models attempted to account for the role played by previous inflation in the bargaining process, which aimed to catch-up with actual inflation through explicit indexation clauses or anticipate future price changes by extrapolating them from past data. In this sense, the notion of an augmented Phillips curve was not new, but the role of expectations in shaping actual economic dynamics had been previously neglected. Expected inflation, therefore, became the primary additional factor in \"modern\" augmented Phillips curves.Although much has been added and debated over the last forty years, the empirical relevance of the Phillips curve has been progressively uncertain since the late 1980s, possibly due to the increasing perceived effectiveness of central banks in stabilizing inflation. Notably, a considerable reduction in the response of wage and price inflation to demand pressures in goods and labor markets","Label":"0"},{"DOI":"10.2139/ssrn.3890555","Abstract":"Traders closely watch the Bank of Korea (BOK) base rate decisions since theshort rate is the primary factor in bond and currency valuations. The surveyof professional forecasters (SPF) has been widely used as the most reliableBOK base rate decision forecaster. In this paper, we investigate whether theSPF's prediction ability can be improved further. To this end, we use adynamic multinomial ordered probit prediction model of the BOK base ratewith a large number of predictors, and apply a Bayesian variable selectionalgorithm. Through an empirical exercise, we show that our approachsubstantially outperforms the SPF in terms of out-of-sample prediction. Thekey predictors are found to be the SPF, short-term bond yields, lagged baserate, federal funds rate, and inflation expectation survey data. Further,allowing for the prediction abilities to change over time is essential forimproving predictive accuracy.","Label":"1"},{"DOI":"10.24843/mtk.2020.v09.i04.p304","Abstract":"The aim of this research is to determine the dynamic model equation of autoregressive distributed lag by using koyck method, to find out the effect of log US dollar exchange rate and log inflation on log stock price in 20142018, and to forecast value of log stock price on January 2019August 2019. The data used in 20142018. The data was transformed into logarithm format. Time series plot of log US dollar exchange rate, log inflation, and log stock price suggest that the fluctuation in the data, for instance, both upward and downward trends, during the period. We obtained that the Koyck transformation could changed the lag distribution model into autoregressive distributed lag (ARDL) dynamic model. Furthermore, the log of US dollar exchange rate and log inflation have negative effect on log stock price in particular period. We measured forecasting accuracy using mean absolute prediction error (MAPE) and concluded that ARDL forecasting using Koyck model shows a significant increase in stock price.","Label":"0"},{"DOI":"10.24148/wp2018-03","Abstract":"This paper analyzes the effects of the lower bound for interest rates on the distributions of inflation and interest rates. We study a stylized New Keynesian model where the policy instrument is subject to a lower bound to motivate the empirical analysis. Two equilibria emerge: In the “target equilibrium,” policy is unconstrained most or all of the time, whereas in the “liquidity trap equilibrium,” policy is mostly or always constrained. We use options data on future interest rates and inflation to study whether the decrease in the natural real rate of interest leads to forecast densities consistent with the theoretical model. Qualitatively, we find that the evidence is consistent with the theoretical predictions in the target equilibrium and find no evidence in favor of the liquidity trap equilibrium. Quantitatively, while the lower bound has a sizable effect on the distribution of future interest rates, its impact on forecast densities for inflation is relatively modest. We develop a lower bound indicator that captures the effects of the lower bound on the distribution of interest rates.","Label":"0"},{"DOI":"10.1109/dsa.2019.00058","Abstract":"Consumer price index (CPI) prediction is an effective approach to measure inflation and provide a reference to formulate economic development strategy. The Autoregressive Integrated Moving Average (ARIMA) model is a classic model to predict CPI. However, a main drawback of ARIMA model is that it only utilizes the time effect while ignoring inter-regional economic interaction which is another significant effect on CPI. Aiming at this, the Generalized Space Time Autoregressive Integrated (GSTARI) model is proposed. In this paper, we verify and compare the prediction accuracy of both GSTARI model and classic ARIMA model with the CPI data of 4 main cities (Dalian, Shenyang, Changchun and Harbin) in China. Our experiments show that for most of cities, GSTARI model have 7%-38% higher prediction accuracy than ARIMA model.","Label":"0"},{"DOI":"10.1093/0199296855.003.0011","Abstract":"Abstract This chapter is concerned with forecasting and prediction based on the UK model. It elaborates on the notion of probability forecasting, which provides a useful means of conveying the uncertainties surrounding forecasts obtained from the model. It illustrates the usefulness of probability forecasts with reference to the Bank of England’s inflation targets and the UK’s growth prospects.","Label":"0"},{"DOI":"10.30541/v29i3-4pp.327-344","Abstract":"This paper investigates the natural rate hypothesis, using the       Lucas and Hanson approaches for ten Latin American countries. The       pl,lIpose of using two methods to test this hypothesis is to ascertain       the robustness of the results to the underlying differences in the       assumptions of these methods. The evidence strongly supports the natural       rate hypothesis and the predictions of the Lucas model. The results of       the Hanson method are in general consistent with the natural rate       hypothesis, but they are not as conclusive as the results of the Lucas       method. The evidence from the Hanson model suggests that the monetary       growth predicted by past inflation performs better than the one       predicted by past monetary growth.","Label":"0"},{"DOI":"10.1016/0264-9993(89)90020-5","Abstract":"This paper develops a simple model of macroeconomic policy in which the government minimizes a loss function with inflation and unemployment as arguments, subject to a Phillips curve constraint. The model is solved and a discrete time approximation taken. The model's empirical predictions are derived and some test results are presented.","Label":"0"},{"DOI":"10.1111/jpet.12468","Abstract":"In this paper, we reassess the link between corruption, economic growth, and inflation. To this end, we build an endogenous growth model with transaction costs in which a corruption sector allows households evading from taxation. Several results emerge. First, seigniorage acts as a tax on corruption and therefore allows reducing the aggregate level of corruption in equilibrium. Second, corruption increases both the growth‐maximizing and the welfare‐maximizing seigniorage rate. Third, corruption can be identified as an autonomous channel of nonsuperneutrality of money. Fourth, our model exhibits a U‐shaped relation between corruption and inflation, contrasting with previous literature. On this last point, an empirical investigation based on a structural threshold regression framework confirms the predictions of the theoretical model.","Label":"0"},{"DOI":"10.1111/j.1468-0475.2012.00569.x","Abstract":"Abstract This study asks whether the accuracy of macroeconomic forecasts for Germany has improved over time. We examine one-year-ahead forecasts of rates of real GDP growth and inflation for the years 1967-2010, by three major German forecasters and the OECD. We find that overall error levels are high but not much different from those of the U.S. and U.K. In the 1980s and 1990s accuracy improved somewhat, but has now returned to its 1970s level, indicating that it reflects the variance of growth and inflation. Benchmark comparisons with these predictions with ex post forecasts of a macroeconometric model indicate that accuracy can be improved, but it will be difficult to achieve.","Label":"0"},{"DOI":"10.2139/ssrn.3068755","Abstract":"In retirement planning, the ignorance of inflation – so-called money illusion – can have severe consequences for future financial wellbeing. It thus seems important to make private investors aware of the divergence between future nominal wealth and real purchasing power. Surprisingly, existing research has hardly explored how different approaches to communicate inflation information affect behavior in long-term investment scenarios. To close this gap, we introduce a novel mechanism for experimental remuneration that mimics the divergence between nominal wealth and real purchasing power by a declining conversation rate. This mechanism allows to elicit investors’ unbiased preferences and to explore the deviations in informational settings that are more or less susceptible to money illusion. We predict that long-term investment products look overly attractive in conditions that foster the occurrence of money illusion and hypothesize that this bias is particularly strong for investment profiles with (nominal) money-back guarantees. The experimental data delivers only partial support for these predictions. Participants seem to understand that their attempts to adjust the long-term nominal returns for the annual inflation rate are susceptible to error. As a consequence they avoid extreme (high or low) investment levels and show an investment behavior that is not sufficiently sensitive to differences in the investment products’ (unbiased) attractiveness. We discuss policy implications and avenues for follow-up research.","Label":"0"},{"DOI":"10.2139/ssrn.1864529","Abstract":"Using post-1995 Japanese data we propose a theory-based sign-restriction SVAR approach to identify monetary policy shocks when the economy is at the zero-lower bound. The identifying restrictions accord with predictions of corresponding DSGE models. Our results show that while a quantitative easing shock leads to a significant but temporary rise in output, the effect on inflation is not significantly different from zero. This suggests that while the Japanese Quantitative Easing experiment was successful in stimulating real activity in the shortrun, it did not lead to any increase in inflation. These results are interesting not only for Japan, but also for other advanced economies where monetary policy is currently constrained by the ZLB.","Label":"0"},{"DOI":"10.32812/jibeka.v11i2.59","Abstract":"This study aims to determine the prediction of financial distress in the manufacturing industry sub-sector food and beverage listed on the Indonesia Stock Exchange. The research period is 2011-2015. In this study, using the indicator liquidity, profitability, inflation, and exchange rates. The study population includes all sub-sectors of food and beverages listed on the Indonesia Stock Exchange 2011-2015 period. The sample is determined by purposive sampling technique. Data analysis method used is logistic regression analysis.  The results showed that the current ratio, return on investment and the net profit margin, and the inflation rate is the most significant variable in predicting financial distress, while the exchange rate is the only variable that was not significant in influencing financial distress.","Label":"0"},{"DOI":"10.1007/s11079-013-9293-5","Abstract":"The effects of inflation are considered for a small open economy with overlapping generations and a cash-in-advance constraint on consumption. In an endowment economy with one good, the model recovers the adjustment mechanism underlying the monetary approach to the balance of payments, which incorporated the real balance effect in the savings function. Nevertheless, if the model has two goods that require different degrees of cash, the factor intensities of the goods also play a crucial role in determining the response of savings. In that case, the predictions of the monetary approach may be overturned; a result that is supported numerically.","Label":"0"},{"DOI":"10.2139/ssrn.1703351","Abstract":"This paper proposes a novel explanation of the vast empirical evidence showing that output and prices react asymmetrically to monetary policy innovations over contractions and expansions in the business cycle. We use VAR techniques to show that monetary policy exerts stronger effects on the U.S. GDP during contractionary phases, as compared to expansionary ones. As to prices, their response is not statistically different across different cyclical stages. We show that these facts are consistent with a New Neoclassical Synthesis model based on the assumption that households. utility partly depends on deviations of their consumption from a reference level below which aversion to loss is displayed. In line with the theory developed by Kahneman and Tversky (1979), losses in consumption utility loom larger than gains. This implies state-dependent degrees of real rigidity and elasticity of intertemporal substitution in consumption that generate competing effects on the responses of output and inflation following a monetary innovation. The key predictions of the model are in line with the data. We then explore the state-dependent trade-o¤ between inflation and output stabilization that naturally arises in this context. Greater elasticity of inflation to real activity during expansionary stages of the cycle promotes a stronger degree of policy activism in the response to the expected rate of inflation under discretion, compared to what is otherwise prescribed during contractions.","Label":"0"},{"DOI":"10.1016/j.worlddev.2016.08.019","Abstract":"Because the shadow economy cannot be taxed, it erodes the tax base and reduces tax revenues, forcing governments to resort to other ways to finance their expenditures. Accordingly, a larger shadow economy should give governments an incentive to shift revenue sources from taxes to inflation, in line with the public finance motive of inflation. In this paper, we recall that point in a simple canonical model, then empirically test it in a sample of up to 153 developed and developing countries over the 1999–2007 period. In line with the model’s prediction, we indeed observe a positive relation between inflation and the size of the shadow economy, and a negative relation between the tax burden and the size of the shadow economy. We find that both relations are conditional on central bank independence and on the exchange rate regime, implying that it is the strongest in institutional set-ups that constrain monetary policy the least. Both relations are present in the sub-sample of developed countries as well as the sub-sample of developing countries. Both relations survive several robustness checks, using various sets of control variables including the stock of debt, controlling for endogeneity, using alternative estimates of the shadow economy, and estimating the two relations as a system of equations.","Label":"0"},{"DOI":"10.1016/j.asieco.2011.10.003","Abstract":"The empirical literature on identification and measurement of the impact of monetary policy shocks on the real side of the economy is fairly comprehensive for developed economies, but very limited for emerging and transition economies. In this study, we propose an identification scheme for a developing economy (taking India as a case study), which is able to capture the monetary transmission mechanism for that economy without giving rise to empirical anomalies. Using a VAR approach with recursive contemporaneous restrictions, we identify monetary policy shocks by modelling the reaction function of the central bank and structure of that economy. The effect of monetary policy shocks on the exchange rate and other macroeconomic variables is consistent with the predictions of a broad set of theoretical models. This set-up is used to build a hypothetical case of inflation targeting where the monetary policy instrument is set after assessing the current values of inflation only. This is in contrast with the ‘multiple indicator approach’ currently followed by the Reserve Bank of India (RBI). The results in this study suggest that the demand effects of interest rate are stronger than the exchange rate effects. There is also evidence of the mitigation of potential conflict between exchange rate and interest rate, one of main monetary policy dilemmas of the RBI in inflation targeting.","Label":"0"},{"DOI":"10.3846/mla.2010.043","Abstract":"This article analyses the criterion of price stability, which plays an important role for Lithuanian ability to adopt the Euro. This work concentrates on analyses of price stability more deeply, presenting the methodologies of determination of inflation rate. The research is based on forecast of short and long-term tendencies of inflation rate in Lithuania and European Union in order to determine the future opportunities to meet price stability criterion and to adopt the Euro. Lithuanian Harmonised Index of Consumer Prices is forecasted for short and long-term, taking into account the present economical crises period and compared with predictions of other institutions such as Ministry of Finances, EC and SEB Bank. Article in English","Label":"0"},{"DOI":"10.22214/ijraset.2022.41733","Abstract":"Abstract: A number of studies have been conducted to model the stock market indices using pure time series models or regression models based on macro economic variables. In this study, instead of focusing on modeling the actual levels of stock market indices I focus on predicting the direction (up/down) as investors who rely on technical analysis are more interested in the direction of stock market index than the actual prediction value. Therefore, in this study I look at best modelling approach for the direction prediction: time series (ARMA) or macro factor models or combination of both (ARDL). My study shows that macro factor models outperform for direction prediction as compared to ARMA or ARDL models. The study was performed on stock market direction prediction of stock indices of three South Asia countries: India, Pakistan and Malaysia. The macro economic factors that are considered for direction prediction are: Inflation, Unemployment and Exchange Rate monthly data from March 2016 to September 2021. Keywords: stock, equity, prediction, models, direction, ARMA, ARDL,macro","Label":"0"},{"DOI":"10.48550/arxiv.0811.0892","Abstract":"A linear and lagged relationship between inflation and labor force change rate, p(t)= A1dLF(t-t1)/LF(t-t1)+A2 was found for developed economies. For the USA, A1=4.0, A2=-0.03075, and t1=2 years. It provides a RMS forecasting error (RMFSE) of 0.8% at a two-year horizon for the period between 1965 and 2002 (the best among other inflation forecasting models). This relationship is tested for cointegration. Both variables are integrated of order one according to the presence of a unit root in the series and its absence in their first differences. Two methods of cointegration testing are applied: the Engle-Granger one based on the unit root test of the residuals including a variety of specification tests and the Johansen cointegration rank test based on the VAR representation. Both approaches demonstrate that the variables are cointegrated and the long-run equilibrium relation revealed in previous study holds. According to the Granger causality test, the labor force change is proved to be a weakly exogenous variable - a natural result considering the time lead and the existence of a cointegrating relation. VAR and VECM representations do not provide any significant improvement in RMSFE. There are numerous applications of the equation: from purely theoretical - a robust fundamental relation between macroeconomic and population variables, to a practical one - an accurate out-of-sample inflation forecasting at a two-year horizon and a long-term prediction based on labor force projections. The predictive power of the relationship is inversely proportional to the uncertainty of labor force estimates. Therefore, future inflation research programs should start from a significant improvement in the accuracy of labor force estimations.","Label":"0"},{"DOI":"10.1109/iccict50803.2021.9510147","Abstract":"Stock market prediction is quite challenging as the market is volatile and its direction is stochastic. The stock market gets driven by several factors like investor sentiment, economic strength, market rumors, inflation. All these aspects together make the stock market quite turbulent and hence very difficult to predict with accuracy. In this paper, we analyzed traditional Machine Learning prediction models and figured out the drawbacks associated with them. Hence we scrutinized a range of stock prediction models and finally singled out the Bi-directional Long Short-Term Memory (Bi-LSTM) neural network. It intends to find out the title role of time series by analyzing historical data of different stocks and predict stock price trends. They form a unified framework for depth and time calculation learning faster than the one-directional approach. It can capture the temporal evolution of information which allows this model to attain the best performance.","Label":"1"},{"DOI":"10.2139/ssrn.4026493","Abstract":"We produce a social unrest risk index for 125 countries covering a period of 1996 to 2020. The risk of social unrest is based on the probability of unrest in the following year derived from a machine learning model drawing on over 340 indicators covering a wide range of macro-financial, socioeconomic, development and political variables. The prediction model correctly forecasts unrest in the following year approximately two-thirds of the time. Shapley values indicate that the key drivers of the predictions include high levels of unrest, food price inflation and mobile phone penetration, which accord with previous findings in the literature.","Label":"1"},{"DOI":"10.1016/j.jimonfin.2022.102668","Abstract":"Traders closely monitor the Bank of Korea (BOK) base-rate decisions since the short rate is the primary factor in bond and currency valuations. The Survey of Professional Forecasters(SPF) has been widely used and is considered the most reliable BOK base-rate decision forecast. In this study, we investigate whether the SPF’s prediction ability can be further improved. To this end, we use a dynamic multinomial ordered probit prediction model of the BOK base rate with a large number of predictors and apply a Bayesian variable selection algorithm. Through an empirical exercise, we show that our approach substantially outperforms the SPF in terms of out-of-sample prediction. The key predictors found are SPF, short-term bond yields, lagged base rate, federal funds rate, and inflation expectation survey data. Furthermore, allowing the prediction ability to change over time is essential for improving predictive accuracy.","Label":"1"},{"DOI":"10.1109/icmtma.2018.00113","Abstract":"According to the relationship between the consumer price index and inflation, the paper test of the Markov state transition between them, and then we will predict the currency state interval corresponding Xinjiang consumer price index, and the currency level in Xinjiang in recent years and the future for a long period of time are in the normal state.","Label":"0"},{"DOI":"10.2991/itms-15.2015.92","Abstract":"As crude oil is becoming even more important commodity in the world economy, the crude oil prices fluctuation has affected both many businesses’ decision based on the crude oil prices and consumers by price inflation on consumer goods. Accordingly, the crude oil prices forecasting has continuously been interested by a lot of researchers. Text data mining...","Label":"1"},{"DOI":"10.1109/gsis.2011.6044084","Abstract":"The percent change in the consumer price index (CPI) is one of the commonly used measures for estimating inflation and one of the most closely watched national economic statistics. A novel DGM (1,1) model is proposed in this paper for the CPI's prediction. A case study is used to demonstrate the procedure of the proposed method.","Label":"0"},{"DOI":"10.1002/jae.2834","Abstract":"The linear pool is the most popular method for combining density forecasts. We analyze its implications concerning forecast uncertainty, using a new framework that focuses on the means and variances of the individual and combined forecasts. Our results show that, if the variance predictions of the individual forecasts are unbiased, the well‐known “disagreement” component of the linear pool exacerbates the upward bias of its variance prediction. This finding suggests the removal of the disagreement component from the linear pool. The resulting centered linear pool outperforms the linear pool in simulations and an empirical application to inflation.","Label":"0"},{"DOI":"10.22158/jetmm.v1n1p1","Abstract":"Applying an extended Mundell-Fleming Model to Australia, this paper finds that expansionary fiscal policy does not affect output whereas expansionary monetary policy raises output. In addition, a higher real stock price, a lower real oil price or a lower expected inflation rate would increase output. Hence, the predictions of the Mundell-Fleming model works for Australia’s economy.","Label":"0"},{"DOI":"10.1080/07350015.2013.859618","Abstract":"Survey respondents who make point predictions and histogram forecasts of macro-variables reveal both how uncertain they believe the future to be, ex ante, as well as their ex post performance. Macroeconomic forecasters tend to be overconfident at horizons of a year or more, but overestimate (i.e., are underconfident regarding) the uncertainty surrounding their predictions at short horizons. Ex ante uncertainty remains at a high level compared to the ex post measure as the forecast horizon shortens. There is little evidence of a link between individuals’ ex post forecast accuracy and their ex ante subjective assessments.","Label":"0"},{"DOI":"10.2139/ssrn.3108479","Abstract":"This paper proposes a macroeconomic model with positive trend inflation that involves an important role for price points as well as sticky information. We argue that, in particular, a variant of our model that allows for a general distribution of price points is more successful in explaining several stylized facts of individual price setting than a benchmark model that is based on Calvo price-setting. More specifically, it makes empirically reasonable predictions with regard to the duration of price spells, the sizes of price increases and decreases, the shape of the hazard function, the fraction of price changes that are price increases, and the relationship between price changes and inflation. Moreover, our model implies plausible aggregate effects of monetary policy in contrast with a model with a prominent role for price points but no information rigidities.","Label":"0"},{"DOI":"10.1016/s0014-2921(03)00032-1","Abstract":"This paper investigates the implications of a nonlinear Phillips curve for the derivation of optimal monetary policy rules. Combined with a quadratic loss function, the optimal policy is also nonlinear, with the policy-maker increasing interest rates by a larger amount when inflation or output are above target than the amount it will reduce them when they are below target. Specifically, the main prediction of our model is that such a source of nonlinearity leads to the inclusion of the interaction between expected inflation and the output gap in an otherwise linear Taylor rule. We find empirical support for this type of asymmetries in the interest rate-setting behaviour of four European central banks but none for the US Fed.","Label":"0"},{"DOI":"10.1016/j.csda.2013.10.014","Abstract":"Simulation-based forecasting methods for a non-Gaussian noncausal vector autoregressive (VAR) model are proposed. In noncausal autoregressions the assumption of non-Gaussianity is needed for reasons of identifiability. Unlike in conventional causal autoregressions the prediction problem in noncausal autoregressions is generally nonlinear, implying that its analytical solution is unfeasible and, therefore, simulation or numerical methods are required in computing forecasts. It turns out that different special cases of the model call for different simulation procedures. Monte Carlo simulations demonstrate that gains in forecasting accuracy are achieved by using the correct noncausal VAR model instead of its conventional causal counterpart. In an empirical application, a noncausal VAR model comprised of U.S. inflation and marginal cost turns out superior to the best-fitting conventional causal VAR model in forecasting inflation.","Label":"0"},{"DOI":"10.1111/j.1467-8586.2007.00272.x","Abstract":"The paper examines the effects of exchange rate depreciation on real output and price in a sample of 11 developing countries in the Middle East. The theoretical model decomposes movements in the exchange rate into anticipated and unanticipated components. Unanticipated currency fluctuations determine aggregate demand through exports, imports, and the demand for domestic currency, and determine aggregate supply through the cost of imported intermediate goods. The evidence indicates that the supply channel attributed to anticipated exchange rate appreciation results in limited effects on output growth and price inflation. Consistent with theory's predictions, unanticipated appreciation of the exchange rate appears more significant with varying effects on output growth and price inflation across developing countries.","Label":"0"},{"DOI":"10.48550/arxiv.2110.12316","Abstract":"Discrete data are abundant and often arise as counts or rounded data. These data commonly exhibit complex distributional features such as zero-inflation, over-/under-dispersion, boundedness, and heaping, which render many parametric models inadequate. Yet even for parametric regression models, approximations such as MCMC typically are needed for posterior inference. This paper introduces a Bayesian modeling and algorithmic framework that enables semiparametric regression analysis for discrete data with Monte Carlo (not MCMC) sampling. The proposed approach pairs a nonparametric marginal model with a latent linear regression model to encourage both flexibility and interpretability, and delivers posterior consistency even under model misspecification. For a parametric or large-sample approximation of this model, we identify a class of conjugate priors with (pseudo) closed-form posteriors. All posterior and predictive distributions are available analytically or via direct Monte Carlo sampling. These tools are broadly useful for linear regression, nonlinear models via basis expansions, and variable selection with discrete data. Simulation studies demonstrate significant advantages in computing, prediction, estimation, and selection relative to existing alternatives. This novel approach is applied successfully to self-reported mental health data that exhibit zero-inflation, overdispersion, boundedness, and heaping.","Label":"1"},{"DOI":"10.1080/02692171.2010.495110","Abstract":"Existing evidence suggests that the Federal Reserve forecasts of inflation imply asymmetric loss, as the Fed has significantly over‐predicted inflation for the post‐Volcker period. Consistent with such evidence, we show that the Federal Reserve forecasts of growth in both unit labor costs and productivity, while directionally accurate for 1983–2003, imply asymmetric loss. That is, the forecasts of growth in unit labor costs are more (less) accurate in predicting the upward (downward) moves. The forecasts of growth in productivity, however, are less (more) accurate in predicting the upward (downward) moves. The interpretation of our findings may be that, in achieving long‐term price stability, the Fed is cautious not to incorrectly predict the upward (downward) moves in growth in unit labor costs (productivity).","Label":"0"},{"DOI":"10.24914/jeb.v19i2.463","Abstract":"In uncertain economic like today, research and modeling the inflation rate is considered necessary to provide estimates and predictions of inflation rates in the future. Adaptive Neuro Fuzzy approach is a combination of  Neural Network and Fuzzy Logic. This study aims to describe the movement ofinflation(output variable ) so it can beestimated by observing four Indonesia's macroeconomic data, namely the exchange rate, money supply, interbank interest rates, and the output gap (input variable). Observation period started from the data in 20011 to 20113. After the learning process is complete, fuzzy systems generate 45 fuzzy rules that can define the input-output behavior. The results of this study indicate a fairly high degree of accuracy with an average error rate is 0.5315.","Label":"1"},{"DOI":"10.1007/bf02707859","Abstract":"Nominal interest payments that come as a compensation for a fall in the real value of monetary assets can hardly be counted as income, if that variable is to have economic content. In spite of this obvious fact, and in a time when consumers are quite often modeled as being extremely rational, most econometric studies still use the disposable income data as if they were a good approximation of an economically meaningful variable even in times of inflation. Both theoretical and empirical work indicate that this is not the case. Perhaps the fact that the empirical work performed also has remarkably good prediction properties will help make econometricians think more carefully about the economic content of the data series they use.","Label":"0"},{"DOI":"10.2139/ssrn.292827","Abstract":"The \"New Keynesian\" Phillips Curve (NKPC) states that inflation has a purely forward-looking dynamics. In this paper, we test whether European and US inflation dynamics an be described by this model. For this purpose, we estimate hybrid Phillips curves, which include both backward and forward-looking components, for major European countries, the euro area, and the US. Estimation is performed using the GMM technique as well as the ML approach. We examine the sensitivity of the results to the choice of output gap or marginal cost as the driving variable, and test the stability of the obtained specifications. Our findings an be summarized as follows. First, in all countries, the NKPC has to be augmented by additional lags and leads of inflation, in contrast to the prediction of the core model. Second, the fraction of backward-looking price setters is large (in most cases, more than 50 percent), suggesting only limited differences between the US and the euro area. Finally, our preferred specification includes marginal cost in the case of the US and the UK, and output gap in the euro area.","Label":"0"},{"DOI":"10.1080/1331677x.2014.970453","Abstract":"The objective of this paper is to make a comparison between two methodologies used to assess the forecasts of uncertainty: a numerical method based on Monte Carlo simulations and a graphical representation represented by the fan charts. For the inflation rate predictions made for Romania over the period Q4:2012– Q4:2013, a fan chart based on BVAR models with non-informative priors presents a lower degree of uncertainty compared with a fan chart using VAR models. The numerical procedure is based on forecasts that use auto-regressive models and the Monte Carlo method. In this case, the probabilities that the inflation forecasts are greater than the National Bank of Romania’s (NBR’s) target and the previous value increased from a quarter to the next. Therefore, this method of assessing the forecast uncertainty is a better tool than the fan charts. Moreover, the simple NBR methodology that did not take into account the probability distribution of the forecasts should be replaced by the fan charts. The forecast’s uncertainty assessment is necessary for the establishment of monetary policy.","Label":"0"},{"DOI":"10.2139/ssrn.2968973","Abstract":"This study is an endeavour to analyse the aspect of adhering to simplicity instead of complexity when one is striving to make a forecast and faced by an unprecedented amount of uncertainty. There is substantial evidence on the exchange rate pass-through and its significant implications for the inflation in the United Kingdom. There is also ample evidence to suggest that the complex models of forecasting are outperformed by simple solutions and the use of heuristics. In that context, it seemed that the Bank of England forecast Post-Brexit is an example of sub-optimal performance of complex models in the face of high tides of uncertainty. In order to illustrate our point further, we employed the data on the consumer price index from Jan 1989 to June 2016. We compared the Post-Brexit inflation forecast by the Bank of England with an ARIMA model and a simple rule which was based on the Bank of England’s own estimates on pass-through due to exchange rate movements, similar in magnitude to the ones associated with Brexit. It showed that the actual path of inflation substantially diverged from the Bank of England’s forecast as the effects of depreciation started to kick in. It implied that in a highly uncertain environment Post-Brexit a better prediction could have been possible by allocating some weight to the effect of sharp depreciation, indeed, that would have been considering the judgment and simplicity.","Label":"0"},{"DOI":"10.36887/2415-8453-2021-3-29","Abstract":"The paper considers the monetary control in Ukraine beginning from the time of transition to the inflation targeting mode. It is stated that the NBU views the inflation targeting method as a monetary control mode aimed at the establishment and achievement of the target inflation index in the medium-term expectation. It is aimed at financial soundness which leads to the stable and low inflation. As a result, the price stability creates favourable conditions for ensuring economic growth and the employment level rise in the country. Thus, the main factors which assure these conditions are: national currency strengthening, favourable environment for making investments and consumer solutions, low interest rates, security of savings and income of the population against monetary depreciation. The key changes in the monetary control methods are defined that influence the process of inflation targeting in Ukraine, namely: the key method of the monetary strategy is the interest rate; implementation of the dynamic exchange rate; prediction and analysis of the financial risks becomes the basic analytical instruments; widespread application of meetings with the representatives of business, press-releases, media briefings, etc. As a result, the NBU has altered its communication policy coming from the expert audience of the financial market to the mass audience. The basic monetary indices of the national economy of Ukraine in the period from 2014 to 2020 are classified and analyzed. The regression analysis of the monetary policy impact upon the social and economic development from 2008 to 2020 and from 2016 to 2020 was made. A direct dependence of the GDP on the inflation level, cash in circulation, international foreign currency and gold reserve, aggregate volume of credit provided to business entities; linear dependence of the end consumer on bank loans, inflation, cash in circulation and cash in bank deposits as well as the exchange rate of the US dollar for the period from 2008 to 2020 were identified. During 2016-2020 a direct dependence of the real GDP on the gain in the individual consumption volume, M3 money supply, gain in the private consumption and the consumption reduced to the dollar exchange rate and the gain in bank loans extended to non-financial corporations was revealed and described. Keywords: monetary control, economic policy, monetary market, inflation targeting, social and economic development.","Label":"0"},{"DOI":"10.2139/ssrn.2662189","Abstract":"This paper evaluates in-sample and out-of-sample stock return predictability with inflation and output gap, the variables that typically enter the Federal Reserve Bank’s interest rate setting rule. To examine the role of monetary policy fundamentals for stock return predictability, we introduce inflation and output gap into the Fed model that relates stock returns to earnings and long-term yields. Using real-time data from 1970 to 2008, we find evidence that in-sample and out-of-sample fit is much stronger for the Fed model with Taylor rule fundamentals than for the constant return model and the Fed model that does not include inflation and output gap. In addition to standard mean squared prediction error based out-of sample comparisons, we use entropy-based tests for nonparametric dependence and find evidence of nonparametric dependence of stock returns on Taylor rule fundamentals. Finally, we evaluate economic significance of the stock return models and find that the models with Taylor rule fundamentals produce higher utility gains than either the constant return model or the original Fed model. The findings are robust to the choice of the measure of economic activity, data frequency, and window size.","Label":"1"},{"DOI":"10.2139/ssrn.2150327","Abstract":"We present an affine term structure model for the joint pricing of TIPS and Treasury yield curves that adjusts for TIPS’ relative illiquidity. Our estimation via linear regressions is computationally efficient and can accommodate a large number of pricing factors. The baseline specification with seven principal components extracted from Treasury and TIPS yields as well as a liquidity factor generates negligibly small pricing errors for both real and nominal yields. Model-implied expected inflation adjusted for risk premia and liquidity provides a better prediction of actual inflation than unadjusted breakeven inflation. Analysis of model-implied Treasury and TIPS decompositions shows that the Federal Reserve’s large-scale asset purchases lowered nominal and real Treasury yields primarily via a reduction of real term premia, the compensation investors demand for bearing real short-rate risk. Real term premia also account for the large response of long-term real forward rates to monetary policy surprises. The deflation floor embedded in TIPS is generally small in magnitude, but spiked during the recent crisis. We also show that the nominal and real term structures from the United Kingdom have qualitatively similar features to the U.S. yields.","Label":"0"},{"DOI":"10.2139/ssrn.1730173","Abstract":"The \"New Keynesian\" Phillips Curve (NKPC) states that inflation has a purely forward-looking dynamics. In this paper, we test whether European and US inflation dynamics can be described by this model. For this purpose, we estimate hybrid Phillips curves, which include both backward and forward-looking components, for major European countries, the euro area, and the US. Estimation is performed using the GMM technique as well as the ML approach. We examine the sensitivity of the results to the choice of output gap or marginal cost as the driving variable, and test the stability of the obtained specifications. Our findings can be summarized as follows. First, in all countries, the NKPC has to be augmented by additional lags and leads of inflation, in contrast to the prediction of the core model. Second, the fraction of backward-looking price setters is large (in most cases, more than 50 percent), suggesting only limited differences between the US and the euro area. Finally, our preferred specification includes marginal cost in the case of the US and the UK, and output gap in the euro area.","Label":"0"},{"DOI":"10.1016/j.jdeveco.2016.12.012","Abstract":"How should financial systems be designed to limit income inequality? Does the redistributive impact of inflation depend on the extent of financial development? Should optimal monetary policy vary across countries with different levels of financial development? In order to address these questions, we develop a monetary growth production model with heterogeneous agents. In our economy, optimal policy needs to weigh the effects of policy across two groups – capital owners and individuals who hold liquid assets. In this environment, we compare various economies that are identical in every aspect except for their level of financial development. Interestingly, we generally find that economies at the highest stages of financial development (economies in which money, bonds, and claims to capital are traded) experience the highest amount of capital formation and social welfare as long as inflation is low. Yet, regardless of the extent of financial development, there are generally redistributive consequences from inflation. Moreover, the model tends to predict that economies with relatively small stock markets produce the highest levels of income inequality. Empirical work examining the role of money growth and the implications of financial development across countries is consistent with predictions from the model.","Label":"0"},{"DOI":"10.4172/2162-6359.1000274","Abstract":"Artificial Neural Network (ANN) is a modelling technique which is based on the way the human brain process information. ANNs have proved to be good forecasting models in several fields including economics and finance. The ANN methodology is used by some central banks to predict various macroeconomic indicators such as the inflation, money supply, GDP growth etc. The use of the ANN for prediction is common in the forecasting literature but rare in Ghana. This paper forecasts inflation with the ANN method using the Ghanaian data. The monthly y-o-y data between 1991:01 and 2010:12 are used to estimate and forecast for the period 2011:01 to 2011:12. The result of the ANNs are also compared with traditional time series models such as the AR (12) and VAR (14) which use the same set of variables. The basis of comparison is the out-of-sample forecast error (RMSFE). The results show that the RMSFE of the ANNs are lower than their econometric counterparts. That is, by this comparative criterion forecast based on ANN models are more accurate.","Label":"1"},{"DOI":"10.15294/jejak.v11i1.12652","Abstract":"This study analyzes the effectiveness of monetary policy transmission of emerging market countries, both short and long-term in maintaining economic stability and reducing poverty. The main problem in this paper is that monetary transmission is incapable of controlling the economy and reducing poverty. There are five countries selected such as India, Brazil, China, Russia, and Indonesia. Long-term prediction analysis using Vector Auto Regression (VAR) model is performed to predict five emerging market countries using Regression Panel. It results suggest that monetary policy transmission affecting the number of poor people should be controlled in three stages. In the short-term, the transmission of export variables and inflation controls the number of poor people. In the medium-term, the control of the number of poor people uses variables of inflation and exports while in the long-term uses exports and Gross Domestic Product (GDP). Overall, all economic variables of emerging market countries are greatly influenced by the fluctuations of each country's exports, then by food price stability as measured by food price inflation. The result of regression panel analysis is known that the factor that most influence the poor people in emerging market country is GDP. Exports also affect poor people such as Indonesia, China, and Russia. Inflation also causes poor people like India and Brazil. The countries that have the most impact on economic fluctuations on the number of poor people are India, Indonesia, China, Brazil, and Russia.","Label":"0"},{"DOI":"10.2139/ssrn.3241390","Abstract":"This paper analyzes the effects of the lower bound for interest rates on the distributions of expectations for future inflation and interest rates. We study a stylized New Keynesian model where the policy instrument is subject to a lower bound to motivate the empirical analysis. Two equilibria emerge: In the “target equilibrium,” policy is unconstrained most or all of the time, whereas in the “liquidity trap equilibrium,” policy is mostly or always constrained. We use options data on future interest rates and inflation to study whether the decrease in the natural rate of interest leads to forecast densities consistent with the theoretical model. We develop a lower bound indicator that captures the effects of the lower bound on the distribution of interest rates. Qualitatively, we find that the evidence is largely consistent with the theoretical predictions in the target equilibrium and find no evidence in favor of the liquidity trap equilibrium. Quantitatively, while the lower bound has a sizable effect on the distribution of future interest rates, its impact on forecast densities for inflation is relatively modest.","Label":"0"},{"DOI":"10.2139/ssrn.2496433","Abstract":"Application of the Bernhardt, Campello and Kutsoati (2006) test of herding to the calendar-year annual output growth and inflation forecasts suggests forecasters tend to exaggerate their differences, except at the shortest horizon when they tend to herd. We consider whether these types of behaviour can help to explain the puzzle that professional forecasters sometimes make point predictions and histogram forecasts which are mutually inconsistent.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2022.09.002","Abstract":"We provide a comprehensive assessment of the predictive power of combinations of dynamic stochastic general equilibrium (DSGE) models for GDP growth, inflation, and the interest rate in the euro area. We employ a battery of static and dynamic pooling weights based on Bayesian model averaging principles, prediction pools, and dynamic factor representations, and entertain six different DSGE specifications and five prediction weighting schemes. Our results indicate that exploiting mixtures of DSGE models produces competitive forecasts compared to individual specifications for both point and density forecasts over the last three decades. Although these combinations do not tend to systematically achieve superior forecast performance, we find improvements for particular periods of time and variables when using prediction pooling, dynamic model averaging, and combinations of forecasts based on Bayesian predictive synthesis.","Label":"0"},{"DOI":"10.3390/economies7040097","Abstract":"Considering the goals of Modern Monetary Theorists, this article examines inflation stabilization and employment maximization through a Taylor Rule for fiscal policy, similar to John Taylor’s foundational examination of the behavior of the Federal Reserve. If it is the role of the federal government to aid in the maintenance of the dual mandate of the Federal Reserve, then their behavior should follow a similar policy of setting an intermediate target of deficits relative to the maximum employment (the “Federal Job Guarantee”) and the inflation target. The paper will compare the historical data with the rule. When the predictions of the Deficit Rule are compared to historical data from 1965, we find that fiscal policy aligns with what the Deficit Rule predicts with two exceptions: the stagflation of the 1970s and the current increases in budget deficits.","Label":"0"},{"DOI":"10.1257/jep.26.4.185","Abstract":"Irving Fisher's monograph Appreciation and Interest (1896) proposed his famous equation showing expected inflation as the difference between nominal interest and real interest rates. In addition, he drew attention to insightful remarks and numerical examples scattered through the earlier literature, and he derived results ranging from the uncovered interest arbitrage parity condition between currencies to the expectations theory of the term structure of interest rates. As J. Bradford DeLong wrote in this journal (Winter 2000), “The story of 20th century macroeconomics begins with Irving Fisher” and specifically with Appreciation and Interest because “the transformation of the quantity theory of money into a tool for making quantitative analyses and predictions of the price level, inflation, and interest rates was the creation of Irving Fisher.” I discuss the message of Appreciation and Interest, and assess how original he was.","Label":"0"},{"DOI":"10.1111/1468-0335.00132","Abstract":"This paper investigates how unemployment persistence affects the optimal delegation of monetary policy to an independent central banker (CB). Two opposing forces are shown to be at work: with more persistence, the government’s incentive to stabilize the economy is greater; but (if the CB is forward‐looking) its incentive to create inflation surprises is also greater. We show that, owing to the second effect, the government may wish not to delegate at all, unlike the case where there is no persistence. In the event that the government does delegate, the paper identifies conditions under which either effect dominates in the government’s choice of conservatism of the CB. We compare delegation to discretion and precommitment, using a diagrammatic approach that may be of independent interest. We also present some preliminary empirical evidence on the cross‐country relationship between unemployment persistence and inflation that appears consistent with the model’s predictions.","Label":"0"},{"DOI":"10.1016/j.jpolmod.2022.03.001","Abstract":"We examine the economic performance (inflation and growth) associated with different monetary policy frameworks, presenting unconditional and conditional analyses, and using predictions of countries’ monetary policy framework choices to address the issue of endogeneity. We find some differences in performance associated with the different monetary policy frameworks, together with a general improvement over time which is explained in part by the trends towards inflation targeting and more precise monetary control, that is from changes in the choice of framework, but in part, and perhaps more strongly, reflects a more general trend towards better economic performance related to changes in decision-making within the frameworks. Our results suggest that the choice of MPF is an important, but by no means the only, determinant of economic performance, and therefore not the only consideration for policymakers looking to improve economic performance.","Label":"0"},{"DOI":"10.2139/ssrn.1992890","Abstract":"This paper deals with the analysis of price-setting in U.S. manufacturing industries. Recent studies have heavily criticized the ability of the New Keynesian Phillips curve (NKPC) to …fit aggregate infl‡ation [see, e.g., Rudd and Whelan, 2006, Can Rational Expectations Sticky-Price Models Explain Inflation Dynamics, American Economic Review, vol. 96(1), pp. 303-320 ]. We challenge this evidence, showing that forward-looking behavior as implied by the New Keynesian model of price-setting is widely supported at the sectoral level. In fact, current and expected future values of the income share of intermediate goods emerge as an effective driver of in‡ation dynamics. Unlike alternative proxies for the forcing variable, the cost of intermediate goods presents dynamic properties in line with the predictions of the New Keynesian theory.","Label":"0"},{"DOI":"10.1016/s0731-9053(04)19005-1","Abstract":"This work applies state-of-the-art artificial intelligence forecasting methods to provide new evidence of the comparative performance of statistically weighted Divisia indices vis-à-vis their simple sum counterparts in a simple inflation forecasting experiment. We develop a new approach that uses co-evolution (using neural networks and evolutionary strategies) as a predictive tool. This approach is simple to implement yet produces results that outperform stand-alone neural network predictions. Results suggest that superior tracking of inflation is possible for models that employ a Divisia M2 measure of money that has been adjusted to incorporate a learning mechanism to allow individuals to gradually alter their perceptions of the increased productivity of money. Divisia measures of money outperform their simple sum counterparts as macroeconomic indicators.","Label":"1"},{"DOI":"10.1111/1467-6419.00126","Abstract":"We survey recent empirical evidence on monetary policy rules, and find that the emphasis in the political economy literature on institutional design (e.g. central bank independence and inflation targeting) is exaggerated. Formal institutional reform seems neither a necessary nor a sufficient condition for the observation of shifts in monetary policy rules. However, there is no doubt that in some cases (e.g. the UK following the start of inflation targeting in 1992, and Bank of England Independence in 1997), a major shift in monetary policy conduct is detectable. We also highlight the problems in explicitly testing the predictions of the political economy literature. Semi‐structural modelling approaches, such as time‐varying VAR models may be more useful in understanding policy rules, and the interaction between policy shifts and changes in the transmission mechanism.","Label":"0"},{"DOI":"10.1016/0014-2921(71)90011-0","Abstract":"The paper develops a simple analytical framework in which the shortrun affects of wage indexation on the dynamic stability of inflation can be analyzed. It consists of a unlonized labor market faced by a competitive demand. Without indexation, the wage contract is based upon the union's prediction of the price level during the period of the contract. With indexation, the same objective is achieved by contracting only once at some initial period, subject to the stipulation that the nominal wage is linked to the price level. The main result is that when the demand for money is sensitive to changes in the expected rate of inflation, nominal variables like prices and wages are more likely to yield an unstable dynamic response with wage indexation, thus endangering the monetary system.","Label":"0"},{"DOI":"10.1162/rest_a_00723","Abstract":"Abstract The basic New Keynesian model predicts that positive supply shocks are less expansionary at the zero lower bound (ZLB) compared to periods of active monetary policy. We test this prediction empirically using Fernald's (2014) utilization-adjusted total factor productivity series, which we take as a measure of exogenous productivity. In contrast to the predictions of the model, positive productivity shocks are estimated to be more expansionary at the ZLB compared to normal times. We find that there is no significant difference in the response of expected inflation to a productivity shock at the ZLB compared to normal times.","Label":"0"},{"DOI":"10.14505/arle.v11.2(48).37","Abstract":"Many mathematical models have been developed in the last years in order to analyze economic phenomena and processes. Some of these models are optimization models, static or dynamic, while others are developed specially to study the evolution of economic phenomena. The topic of this paper is forecasting with nonlinear models. A few well-known nonlinear models are introduced, and their properties are discussed. The variety of nonlinear relationships is important both from the perspective of estimation and from the precision of forecasts in the medium and especially long term. Most nonlinear forecasting methods and all methods based on neural networks lead to predictions that have a better quality than the forecasts obtained by linear methods. The last section of this paper contains a detailed study of the relationship between inflation and unemployment and a numerical application with numerical data from Romania.","Label":"1"},{"DOI":"10.1109/ssci44817.2019.9002869","Abstract":"With the impact of green trade barriers in recent years, China’s green trade economy is facing enormous challenges. Using data from the website of the General Administration of Customs of the People’s Republic of China (GACC), this paper aims to employ Seasonal Autoregressive Integrated Moving Average (SARIMA) model and Long Short Term Memory (LSTM) model to forecast the total import and export volume of China’s green trade, and error analysis is made according to the forecasting result. Considering that inflation is an important influence factor in forecasting economics, the models are optimized by eliminating inflation through consumer price index (CPI) and the following results are obtained. Firstly, the LSTM model obtains better performance than the SARIMA model. Secondly, forecasting accuracy of the optimized models is improved. Thirdly, China‘s green trade economy shows a steady trend in the near future.","Label":"1"},{"DOI":"10.2139/ssrn.4157228","Abstract":"In this paper, we revisit the fiscal theory of the price level (FTPL) within the New Keynesian (NK) model. We show in which cases the average maturity of government debt matters for the transmission of policy shocks. The central task of this paper is to shed light on the theoretical predictions of the maturity structure on macro dynamics with an emphasis on model-implied expectations. In particular, we address the transmission channels of monetary and fiscal policy shocks on the interest rate and inflation dynamics. Our results illustrate the role of the maturity of existing debt in the wake of skyrocketing debt-to-GDP ratios and increasing government expenditures. We highlight our results by quantifying the effects of the large-scale US fiscal packages (CARES) and predict a surge in inflation if the deficits are not sufficiently backed by future surpluses.","Label":"0"},{"DOI":"10.2139/ssrn.964955","Abstract":"This paper considers the prediction of large depreciations (both nominal and real) in a panel of industrialized countries using a probit methodology. The current account balance/GDP ratio has a modest but statistically significant effect on the estimated probability of a large depreciation, and gives slight predictive power in an out-of-sample forecasting exercise. The CPI inflation rate also has a modest but statistically significant effect in predicting nominal depreciations and has slight predictive power, but this effect is not present for real exchange rates. The GDP growth rate occasionally has a significant effect. A higher current account balance (surplus) tends to reduce the probability of a sharp depreciation; a higher inflation rate tends to increase the probability of a sharp depreciation; and a higher GDP growth rate perhaps tends to reduce the probability of a sharp depreciation.","Label":"0"},{"DOI":"10.2202/1558-3708.1845","Abstract":"This paper studies optimal real-time monetary policy when the central bank takes the exogenous volatility of the output gap and inflation as proxy of the undistinguishable uncertainty on the exogenous disturbances and the parameters of its model. The paper shows that when the exogenous volatility surrounding a specific state variable increases, the optimal policy response to that variable should increase too, while the optimal response to the remaining state variables should attenuate or be unaffected. In this way the central bank moves preemptively to reduce the risk of large deviations of the economy from the steady state that would deteriorate the distribution forecasts of the output gap and inflation. When an empirical test is carried out on the U.S. economy the model predictions tend to be consistent with the data.","Label":"0"},{"DOI":"10.1109/ic3sis54991.2022.9885249","Abstract":"Managing strategic commodities prices in the market is considered an important task since they have a significant contribution to the calculation of the inflation rate. Inflation management has a strong connection to the public’s economic activities and buying power. To aid this problem, it is necessary to find the best forecasting model that can predict commodities daily price. This paper aims to find the best prediction model between Recurrent Neural Network (RNN) variants, LSTM and GRU, in forecasting the daily price of three Indonesia’s strategies commodities: rice, broiler meat, and chicken egg. The result shows that the GRU model achieves higher accuracy in predicting the daily price of rice, broiler meat, and chicken egg, based on two evaluation metrics Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE). The GRU model also managed to finish the computational process faster than LSTM by$\\sim$20 seconds.","Label":"1"},{"DOI":"10.1063/1.4734403","Abstract":"We review the calculation of the primordial curvature spectrum generated during warm inflation, including shear viscous effects. The primordial spectrum is dominated by the thermal fluctuations of the radiation bath, sourced by the dissipative term of the inflaton field. The dissipative coefficient Υ computed from first principles in the close-to-equilibrium approximation depends in general on the temperature T, and this dependence renders the system of the linear fluctuations coupled, inducing a growing mode in the fluctuations before horizon crossing. However, dissipation intrinsically means departures from equilibrium, and therefore the presence of a shear viscous pressure in the radiation fluid. This in turn acts as an extra friction term for the radiation fluctuations which tends to damp the growth of the perturbations. Independently of the T functional dependence of the dissipation and the shear viscosity, we find the condition under which the shear effect kills the growing mode in the spectrum.","Label":"0"},{"DOI":"10.1007/978-1-349-20460-1_3","Abstract":"Economists build macroeconomic models so as to be able to make quantified predictions. What will be the level of unemployment, or the rate of inflation in a year’s time? What difference would it make if the Chancellor cut taxes again in next year’s budget, or if he put interest rates up by 2 per cent now?","Label":"0"},{"DOI":"10.1017/cbo9780511571749.003","Abstract":"If we are to believe official government statistics, the U.S. economy of the 1970's displayed symptoms of economic maladies that earlier generations of economists thought could not coexist. The decade was plagued with high rates of inflation, unacceptable levels of unemployment, slowed growth, and declining productivity. The simultaneous occurrence of inflation and recession baffled economic diagnosticians and precipitated what has been called a crisis in macroeconomic analysis. The inconsistency between the predictions of conventional macroeconomic theories and the “facts” of economic life have led to a reexamination of both the theories and the facts. During the earlier decade of the 1960's, our theories and experience led us to believe that the economy was characterized by a stable downward-sloping Phillips curve, a menu of trade-offs between unemployment and inflation from which to choose the most socially desirable combination. Macroeconomic models provided relatively accurate forecasts of future economic activity. Policymakers pursued conventional Keynesian policies in efforts to fine tune the economy, working to stabilize it at full employment. The prevailing optimism of the time encouraged the belief that relatively low levels of unemployment could be attained while maintaining reasonable price stability and a healthy rate of economic growth. Since inflation was thought to have negligible economic consequences, full-employment policies could be pursued that would cyclically balance budgets, while providing the economic growth necessary to generate the government revenues required to finance the growing demands for social expenditure programs. These optimistic hopes were rudely shattered by the economic facts of the past fifteen years.","Label":"0"},{"DOI":"10.1080/10370196.1996.11733236","Abstract":"This essay examines Milton Friedman influence as a political economist, focusing attention on his successful prediction that inflation would be associated with increasing rates of unemployment. As a consequence of this predictive success, it became widely accepted that policy-induced unemployment would produce long term benefits as unemployment gravitated back towards its Natural-Rate (a magnitude influenced by frictional and structural factors) at a lower level of inflation. This article presents an alternative view of this policy-revolution by suggesting that the magnetic pull of the Natural-Rate of unemployment is not required to explain the stagflation which ended the Old Keynesian era. As inflation was increasing in the 1960s, several economists argued that rates of unemployment were also increasing. These perceptions were clearly at variance with the prevailing trade-off interpretation of the Phillips curve, which suggested that the rise in inflation would be accompanied by a reduction in rates of unemployment. This article, therefore, attempts to describe the largely forgotten, dissenting pre-history of Friedman’s successful assault on the trade-off orthodoxy of the 1960s. These dissenting perceptions were mostly based on factors other than expectational considerations. They consisted of insights based on observations of labour market behaviour. In contrast, Friedman’s insight was couched in macroeconomic terms, with strong microeconomic foundations. This episode may shed some light on the nature of influence in the economics profession in the 1960s. It may abo serve to question the validity of the Natural-Rate Expectations Augmented Phillips (N-RFAP) curve model.","Label":"0"},{"DOI":"10.2139/ssrn.956014","Abstract":"Previously, a linear and lagged relationship between inflation and labor force change rate, π(t)= A1dLF(t-t1)/LF(t-t1)+A2 (where A1 and A2 are empirical country-specific coefficients), was found for developed economies. The relationship obtained for the USA is characterized by A1=4.0, A2=-0.03075, and t1=2 years. It provides a root mean square forecasting error (RMFSE) of 0.8% at a two-year horizon for the period between 1965 and 2002 (the best among other inflation forecasting models) and has a perfect parsimony - only one predictor. The relationship is tested for cointegration. Both variables are integrated of order one according to the presence of a unit root in the series and its absence in their first differences. Two methods of cointegration testing are applied - the Engle-Granger one based on the unit root test of the residuals including a variety of specification tests and the Johansen cointegration rank test based on the VAR representation. Both approaches demonstrate that the variables are cointegrated and the long-run equilibrium relation revealed in previous study holds. According to the Granger causality test, the labor force change is proved to be a weakly exogenous variable - a natural result considering the time lead and the existence of a cointegrating relation. VAR and VECM representations do not provide any significant improvement in RMSFE. There are numerous applications of the equation: from purely theoretical - a robust fundamental relation between macroeconomic and population variables, to a practical one - an accurate out-of-sample inflation forecasting at a two-year horizon and a long-term prediction based on labor force projections. The predictive power of the relationship is inversely proportional to the uncertainty of labor force estimates. Therefore, future inflation research programs should start from a significant improvement in the accuracy of labor force estimations.","Label":"0"},{"DOI":"10.1007/978-3-642-48356-1_17","Abstract":"The theory of equal division payoff bounds in its modified form (SELTEN 1985) has proved to be more successful in the prediction of 3-person characteristic function experiments than various versions of the bargaining set. In this paper the question is raised whether the hypotheses “order of strength” (applied to zero-normalizations) and “exhaustivity” introduced earlier as parts of equal share analysis (SELTEN 1972) lead to improvements of predictions, if they are added to other theories. Order of strength improves predictions for games where one-person coalitions receive zero-payoffs, but not for other games. Exhaustivity improves predictions for experimental procedures with free verbal communication but if communication is restricted to the exchange of formal offers, predictions are better without exhaustivity as an additional hypothesis. These conclusions are based on reevaluation of 11 data sets from various published and unpublished sources.","Label":"0"},{"DOI":"10.1016/j.econmod.2018.02.004","Abstract":"We contribute to recent research on the optimality of macroeconomic forecasts. We start from the assumption that forecasters may have a flexible rather than a symmetric (quadratic) loss function assumed in standard tests. This assumption leads to the prediction that variables available to a forecaster when a forecast was formed should have no predictive value for a binary 0/1-indicator that captures the sign of the forecast error. A test of forecast optimality, thus, can be interpreted as a classification problem. We use random forests to model this classification problem. Random forests are a powerful nonparametric modeling instrument originally developed in the machine-learning literature. Unlike conventional linear-probability or logit/probit-models, random forests account in a natural way for potential nonlinear links between the signed forecast error and the variables in a forecaster's information set. Random forests also can handle a situation in which the number of forecasts is small relative to the number of predictor variables that a researcher uses to proxy a forecaster's information set. Random forests, therefore, are a powerful modeling device that is of interest for every researcher who studies the properties of macroeconomic forecasts. Upon estimating random forests on forecasts of four German research institutes, we document that optimality of longer-term inflation forecasts cannot be rejected and that inflation forecasts are weakly efficient. For shorter-term inflation forecasts, our results are heterogeneous across research institutes. When we pool the data across the research institutes, we reject optimality of both shorter-term and longer-term forecasts.","Label":"1"},{"DOI":"10.1016/s0169-2070(99)00046-1","Abstract":"To successfully implement monetary policy, the Federal Reserve System (FED) must make forecasts about the future state of the economy. This paper examines some of the characteristics of these forecasts. The analysis presents the usual error measures and tests for rationality. The paper compares these predictions with those generated by ARIMA models and the ASA/NBER surveys. In addition, we analyze (1) the relationship between accuracy and the length of the forecast horizon, (2) whether accuracy has improved over time, and (3) the accuracy of the forecasts in the vicinity of turning points. We conclude that the FED predictions tended to yield the same type of errors that private forecasters have displayed: in some periods either real GNP or inflation had systematic errors; turning point errors occurred prior to recessions; the forecasts were unbiased, but showed evidence of inefficiency. However, the FED forecasts were not significantly different from the predictions of the ARIMA models or ASA/NBER surveys.","Label":"0"},{"DOI":"10.55324/iss.v1i5.120","Abstract":"Background: The volume of electronic money transactions in Indonesia tends to fluctuate, before finally experiencing a decrease at the beginning of the Covid-19 pandemic and reaching the lowest level in May 2020 which then slowly increased again until September 2021. Bank Indonesia (BI) with the government and relevant authorities cooperated in taking steps to monitor, assess, and mitigate the impact of the spread of the Covid-19 virus. Aim: This study aims to find out how the variable effect of electronic money transaction volume (e-money) influences inflation in Indonesia and how accurate the prediction of the volume of electronic money transactions in the future Method: The method used in this research is a quantitative research method with an associative type of research approach. This study uses a type of secondary data involving a quantitative variable where data in the form of Time series that takes the object of the State of Indonesia as a reference. Data involves a single quantitative predictor variable. Findings: Based on this study, the authors found that there needs to be an increase in the volume of electronic transactions by 484,630,000 to increase inflation to reach the target in 2021.","Label":"0"},{"DOI":"10.1007/978-981-16-1978-6_32","Abstract":"The impact of climate change on electricity demand is an influential factor regarding load forecasting in Middle-East countries including Iraq. Selection of appropriate weather variables for prediction of electricity demand is crucial as it affects the accuracy and reliability of the forecasting. Recently, the slight upward temperature campaign with aired weather leads the trend of rising electricity demand as the dominate factors in Iraq. This is almost associated with air-conditioning loads. The factors relevant to the temperature such as maximum and minimum temperature and the average temperature are investigated in this paper. The paper introduces an efficient methodology of forecasting that consider the correlation among the different parameters involved in the forecasting. A statistical analysis is essential to reduce the data and retaining the independent variable sets that contribute substantially to the model of load forecasting. Hence, this paper discusses the potential problem of collinearity and multicollinearity among the variable sets that may create inflation in data which, in turn, creates a biased forecasting model. The variance inflation factor (VIF) and the variance–decomposition proportion (VDP) are financial tools used in economic studies and utilized in this study to build efficient forecasting models. This paper utilizes a real data set for 12 months in year 2018 in Baghdad city, central Iraq. A statistical analysis is implemented using MATLAB and Microsoft Excel to identify the sources of multicollinearity and validate the proposed methodology.","Label":"0"},{"DOI":"10.19044/esj.2018.v14n10p68","Abstract":"The mortgage market is the market for financing real estate assets. Mortgage financing is vital in financing the property market. This study seeks to determine the relationship between selected macro factors and mortgage market growth in Kenya. The study is based on the arbitrage pricing theory, capital assets pricing theory, title theory and lien theory of mortgages. The study utilizes descriptive research design and quarterly secondary data for a period of 10 years from 2007 to 2016. Analysis of data is carried out through descriptive and inferential statistical techniques. Inferential statistics such as linear correlations and multiple linear regressions are used to draw conclusions and make predictions on the relationship between the independent variables and the dependent variable. The research establishes that there is a positive and significant relationship between interest rates, inflation and the mortgage market growth. The research also finds that there is insignificant relationship between exchange rates, gross domestic product and the mortgage market growth. The research concludes that the mortgage market growth in Kenya is influenced by interest rates and inflation. The research recommends that the central bank of Kenya should ensure that interest rates are stable and inflation levels are low to ensure that they do not affect the mortgage market growth.","Label":"0"},{"DOI":"10.1198/jbes.2009.07208","Abstract":"A popular account for the demise of the U.K.’s monetary targeting regime in the 1980s blames the fluctuating predictive relationships between broad money and inflation and real output growth. Yet ex post policy analysis based on heavily revised data suggests no fluctuations in the predictive content of money. In this paper, we investigate the predictive relationships for inflation and output growth using both real-time and heavily revised data. We consider a large set of recursively estimated vector autoregressive (VAR) and vector error correction models (VECM). These models differ in terms of lag length and the number of cointegrating relationships. We use Bayesian model averaging (BMA) to demonstrate that real-time monetary policymakers faced considerable model uncertainty. The in-sample predictive content of money fluctuated during the 1980s as a result of data revisions in the presence of model uncertainty. This feature is only apparent with real-time data as heavily revised data obscure these fluctuations. Out-of-sample predictive evaluations rarely suggest that money matters for either inflation or real output. We conclude that both data revisions and model uncertainty contributed to the demise of the U.K.’s monetary targeting regime.","Label":"0"},{"DOI":"10.2139/ssrn.4397485","Abstract":"In macroeconomic forecasting, principal component analysis (PCA) has been the most prevalent approach to the recovery of factors, which summarize information in a large set of macro predictors. Nevertheless, the theoretical justification of this approach often relies on a convenient and critical assumption that factors are pervasive. To incorporate information from weaker factors, we propose a new prediction procedure based on supervised PCA, which iterates over selection, PCA, and projection. The selection step finds a subset of predictors most correlated with the prediction target, whereas the projection step permits multiple weak factors of distinct strength. We justify our procedure in an asymptotic scheme where both the sample size and the cross-sectional dimension increase at potentially different rates. Our empirical analysis highlights the role of weak factors in predicting inflation, industrial production growth, and changes in unemployment.","Label":"1"},{"DOI":"10.1109/icsengt.2012.6339339","Abstract":"Economic crisis that had happened at 1997-1998 in Indonesia has stimulated researchers to study it further by utilizing economic indicators. The economic indicators, GDP (Gross Domestic Product) and inflation per year from 1980-2011, will be tested using time series analysis and system dynamic optimized by genetic algorithm. This research have applied system dynamic in order to get characteristic value of prediction economic crisis in Indonesia with various conditions besides genetic algorithm (GA) is used to help the dynamic system in finding a coefficient of data historic optimization. The methods prior to predict consist of two phases, i.e. training and testing. The result shows 93%-99% accuracy for training and up to 90% for testing. It concludes that the prediction system is able to fit data in finding historical optimal without avoid error.","Label":"1"},{"DOI":"10.2478/v10033-012-0017-3","Abstract":"Econometric modeling and exponential smoothing techniques are two quantitative forecasting methods with good results in practice, but the objective of the research was to find out which of the two techniques are better for short run predictions. Therefore, for inflation, unemployment and interest rate in the Czech Republic various accuracy indicators were calculated for the predictions based on these methods. Short run forecasts on a horizon of 3 months were made for December 2011-February 2012, the econometric models being updated. For the Czech Republic, the exponential smoothing techniques provided more accurate forecasts than the econometric models (VAR(2) models, ARMA procedure and models with lagged variables). One explication for the better performance of smoothing techniques would be that in the chosen countries the short run predictions were more influenced by the recent evolution of the indicators.","Label":"0"},{"DOI":"10.2139/ssrn.1113719","Abstract":"A motivation for central bank independence (CBI) is that policy delegation helps politicians manage diverse coalitions. This paper develops a model of coalition formation that predicts when delegation will occur. An analysis of policy preferences survey data and CBI indicators supports the predictions. The model also explains why the expected negative relationship between CBI and inflation is not empirically robust: endogenous selection biases the estimated effect towards zero. The data confirm this.","Label":"0"},{"DOI":"10.1016/j.ejpoleco.2008.05.002","Abstract":"A motivation for central bank independence (CBI) is that policy delegation helps politicians manage diverse coalitions. This paper develops a model of coalition formation that predicts when delegation will occur. An analysis of policy preferences survey data and CBI indicators supports the predictions. The model also explains why the expected negative relationship between CBI and inflation is not empirically robust: endogenous selection biases the estimated effect towards zero. The data confirm this.","Label":"0"},{"DOI":"10.2470/rf.v2016.n3.8","Abstract":"Although a substantial amount of durable assets is included in many households’ investment portfolios, these assets are hard to measure. As a result, it is difficult to form return expectations based on a theoretical framework. This chapter examines what the investment performance of durable assets has been in the past to help make predictions about their future returns. It also shows how durable assets can help with diversification (but not inflation hedging) in investors’ portfolios.","Label":"0"},{"DOI":"10.1108/01443589610149906","Abstract":"Analyses parallel exchange rate behaviour in African countries, using a monetary approach. Employs quarterly data over the 1980‐1991 period, pooled across 18 countries and the predictions of the monetary approach are not contradicted by the data. Finds, in particular, that monetary expansion, depreciation of official exchange rate, expectation of inflation, and rising interest rate cause depreciation of domestic currency in the black market while rising real income causes its appreciation.","Label":"0"},{"DOI":"10.1016/j.ejpoleco.2009.08.006","Abstract":"About a decade ago, papers by Grüner and Hefeker (1999) and Cukierman and Lippi (2001) predicted that European Monetary Union may lead to higher inflation and unemployment in some participating countries. Meanwhile, we know that these predictions have not come true. The present paper develops a model of trade union behavior that explains why EMU was more successful than we predicted. The paper also sheds new light on the macroeconomic role of central bank flexibility.","Label":"0"},{"DOI":"10.2139/ssrn.4372186","Abstract":"We examine the incremental value of news-based data relative to the FRED-MD economic indicators for quantile predictions (now- and forecasts) of employment, output, inflation and consumer sentiment. Our results suggest that news data contain valuable information not captured by economic indicators, particularly for left-tail forecasts. Methods that capture quantile-specific non-linearities produce superior forecasts relative to methods that feature linear predictive relationships. However, adding news-based data substantially increases the performance of quantile-specific linear models, especially in the left tail. Variable importance analyses reveal that left tail predictions are determined by both economic and textual indicators, with the latter having the most pronounced impact on consumer sentiment.","Label":"1"},{"DOI":"10.48550/arxiv.2302.13999","Abstract":"We examine the incremental value of news-based data relative to the FRED-MD economic indicators for quantile predictions (now- and forecasts) of employment, output, inflation and consumer sentiment. Our results suggest that news data contain valuable information not captured by economic indicators, particularly for left-tail forecasts. Methods that capture quantile-specific non-linearities produce superior forecasts relative to methods that feature linear predictive relationships. However, adding news-based data substantially increases the performance of quantile-specific linear models, especially in the left tail. Variable importance analyses reveal that left tail predictions are determined by both economic and textual indicators, with the latter having the most pronounced impact on consumer sentiment.","Label":"1"},{"DOI":"10.1016/s2212-5671(14)00143-9","Abstract":"The forecasts accuracy evaluation became a constant preoccupation of specialists in forecasting, because of the failure of predictions that caused the actual economic crisis. The objective of this research is to model and predict some economic variables corresponding too few macroeconomic blocks for Romanian economy. The forecast method is represented by econometric models. Moreover, the accuracy of these predictions is assessed, VARMA models generating more accurate short-run forecasts for inflation, real GDP and interest rate in Romania (horizon: 2012-2013) compared to VAR and AR models. The econometric models proposed for unemployment rate, exchange rate and rate of monetary supply determined better forecasts than random walk.","Label":"0"},{"DOI":"10.1016/s0304-3932(01)00054-x","Abstract":"This paper links the term structure to perceptions of monetary policy. Long-horizon forecasts of short rates required by no-arbitrage term structure models are heavily influenced by the endpoints, or limiting conditional forecasts, of the short rate process. Common assumptions that the short rate is mean-reverting or contains a unit root are shown to generate unrealistic yield predictions. Failures occur because these assumptions inadequately account for historical shifts in market perceptions of the policy target for inflation. This paper links endpoint shifts to agent learning about shifts in long-term policy goals. Shifting endpoints in short rate processes significantly improve yield predictions.","Label":"0"},{"DOI":"10.1111/1468-5876.00117","Abstract":"This paper develops several simple separate (or non‐nested) procedures for testing autoregressive versus moving average errors in regression models. These asymptotically valid tests are straightforward to calculate: after estimating both models by maximum likelihood methods, the procedure involves testing the significance of variables added to a linearized version of the null model, the added variables being the predictions, or the residuals from the specified alternative model, or the difference of the predictions of the two models. Some small sample evidence on the properties of the tests is presented, as is an empirical application on the Australian unexpected inflation rate series. JEL Classification Numbers: C12, C22, C52, E31.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2012.12.002","Abstract":"This paper investigates the problem of constructing prediction regions for forecast trajectories 1 to H periods into the future—a path forecast. When the null model is only approximative, or completely unavailable, one cannot either derive the usual analytic expressions or resample from the null model. In this context, this paper derives a method for constructing approximate rectangular regions for simultaneous probability coverage that correct for serial correlation in the case of elliptical distributions. In both Monte Carlo studies and an empirical application to the Greenbook path-forecasts of growth and inflation, the performance of this method is compared to the performances of the Bonferroni approach and the approach which ignores simultaneity.","Label":"1"},{"DOI":"10.1142/s0217590823500224","Abstract":"Based on a New Keynesian model with a transient interest rate peg and energy inputs in production, we examine the impact of China’s interest rate liberalization on the transmission of energy supply shocks. Theoretical analysis shows that in the face of negative supply shocks, output decreases less or even increases while inflation rises more under a fixed interest rate compared with a flexible interest rate. We construct the Divisia energy index based on Chinese data to test the model predictions. We identify energy supply shocks following the strategy of Kilian ( 2009 ) and obtain impulse responses using the local projection (LP) method proposed by Jordà ( 2005 ). The empirical results are generally consistent with our model predictions.","Label":"0"},{"DOI":"10.1007/978-981-16-5685-9_10","Abstract":"Prediction of gold price has always been most fascinated due to its nonlinearity and dynamic time series behavior, which is constrained by so many influencing factors such as economic data, monetary policy, supply and demand, inflation, and currency movements. Immemorial gold is always having the highest degree of monetary rewards and has been termed as oldest precious metal used in global currency. After understanding the hidden pattern behind the prediction of various things, which needs very fast decisions to make the computational cost of the market, researchers have proposed many statistical and machine learning models for gold price prediction. In this study, an evolutionary extreme learning machine (ELM) is designed for future gold price prediction, where two evolutionary estimation paradigms are suggested such as particle swarm optimization (PSO) and differential evolution (DE) during the training stage to optimize the weights of the network. The performance of the prediction model is measured through mean square error (MSE) and evaluated on GOLD/USD collected with six-year period of time. Through this study, a better prediction model can be designed, which will help the gold investor in taking decision for the best time of investing money in the gold market.","Label":"1"},{"DOI":"10.14710/medstat.6.1.1-9","Abstract":"The inflation data is one of the financial time series data that has a high volatility, so if the data is modeled with parametric models (AR, MA and ARIMA), sometimes occur problems because there was an assumption that cannot be satisfied. The developed model of parametric to cope with the volatility of the data is the ARCH and GARCH models. This alternative parametric models still requires the normality assumption in the data that often cannot be satisfied by financial data. Then a nonparametric method that does not require strict assumptions as parametric methods is developed. This research aims to conduct a study in Indonesia inflation data modeling using nonparametric methods is spline regression model with truncated spline bases. Goodness of a spline regression model is determined by an orde and knots location . However, the knots location are more dominant in spline regression model. One way to get the optimal knots location are by minimizing the value of Generalized Cross Validation (GCV). By modeling the annual inflation data of Indonesia in December 2006 - December 2011, the inflation target in 2012 is 4.5% + 1% can be achieved while the inflation target in 2013 is 4.5% + 1% cannot be achieved, because that prediction in 2013 is 8.55%. It was caused by government policy to raise the price of basic electricity and the fuel prices in 2013. Keywords : Inflation, Spline Regression Model, Generalized Cross Validation. Normal 0 false false false IN X-NONE X-NONE /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-qformat:yes; mso-style-parent:\"\"; mso-padding-alt:0cm 5.4pt 0cm 5.4pt; mso-para-margin-top:0cm; mso-para-margin-right:0cm; mso-para-margin-bottom:10.0pt; mso-para-margin-left:0cm; line-height:105%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:\"Times New Roman\"; mso-fareast-theme-font:minor-fareast; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;}","Label":"1"},{"DOI":"10.1016/j.jedc.2020.104009","Abstract":"Motivated by Merton (1973), we propose a novel bivariate intertemporal asset pricing model, which relates expected equity and bond market returns to their conditional covariance. Investors’ dynamic hedging demand coincides with covariance risk, which in turn plays a central role in explaining contemporaneous time-variation in expected market returns. Our model predictions are consistent with variations in expected equity and bond returns that include flight-to-quality and fear-of-missing-out episodes, both of which coincide with low levels of equity-bond covariance. We identify determinants of time-variation in conditional covariance and thus potential drivers of flight-to-quality and fear-of-missing-out. Unanticipated changes in expected inflation, market illiquidity and stock market uncertainty predict changes in the equity-bond covariance, where the contribution of each variable is state-dependent. In particular, the non-linear effects of shocks to inflation act as a key driver.","Label":"0"},{"DOI":"10.1504/ijims.2020.107944","Abstract":"Trend in the producer price is of much value to the central bank authorities in identifying the cost-push inflation that can improve their understanding of future directions of inflation in the aggregate economy and informulating sound policies and macroeconomic plans. Forecasting of the producer price movement is complex, the popular use of conventional methods is fraught with inaccuracies which often produces misleading results. This study explored the reliability and accuracy of the use of artificial neural networks (ANNs) for modelling and predicting producer price index (PPI) trend in New Zealand. The study also compared ANNs results with those produced by the autoregressive integrated moving average (ARIMA) as an alternative. Results showed that the ANNs model outperformed the ARIMA model as a more reliable and accurate tool for time series data prediction. The method developed could guide economists and macroeconomic policymakers in making more accurate forecasts.","Label":"0"},{"DOI":"10.2139/ssrn.1977024","Abstract":"This study investigates capital structure of nonfinancial firms registered on Karachi Stock Exchange (Pakistan) from 2003 to 2008 to find which independent variables determine the capital structure of Pakistani firms. We find statistically significant coefficients for profitability, size, tangibility, growth, dividend and inflation. The negative relationships between profitability and leverage; positive relationships between growth and long term debt and dividend and total debt of firms confirm the presence of pecking order theory in determining the financing behavior of Pakistani firms. The strong positive relationships between tangibility and leverage and size and leverage support the theoretical predictions of trade-off theory. The positive relationship between expected future inflation and current borrowing supports market timing theory. The research finds significant change in financing behavior of firms across industries. We find partially different results from other studies in Pakistan as well as in developing countries. Conclusion from prior research from developed world is also valid in Pakistan.","Label":"0"},{"DOI":"10.1016/j.latcb.2022.100072","Abstract":"This paper provides evidence of the relationship between fiscal and monetary policy in Colombia through an empirical exploration of the credit risk channel. Under this empirical approach, fiscal policy serves as an important explanatory role in the sovereign risk premium which, in turn, could affect the exchange rate and inflation expectations. The colombian central bank reacts to inflation expectations by using the policy interest rate; consequently, such reaction could be indirectly influenced by fiscal policy behavior. Using monthly data from January 2003 to December 2019, we estimate a reduced-form system of equations that describes the credit risk channel in a small open economy. Our findings are in line with the theoretical predictions. Fiscal policy affected the country’s sovereign risk during this period, although its incidence was not particularly large. Thus, we infer that there could be insufficient evidence of fiscal dominance in Colombia during the period analyzed.","Label":"0"},{"DOI":"10.2139/ssrn.997490","Abstract":"Assessing the magnitude of the output gap is critical to achieving an optimal policy mix. Unfortunately, the gap is an unobservable variable, which, in practice, has been estimated in a variety of ways, depending on the preferences of the modeler. This model selection problem leads to a substantial degree of uncertainty regarding the magnitude of the output gap, which can reduce its usefulness as a policy tool. To overcome this problem, in this paper we attempt to insert some discipline into this search by providing two metrics-inflation forecasting and business cycle dating-against which different options can be evaluated using aggregated euro-area GDP data. Our results suggest that Gali, Gertler, and Lopez-Salido's (2001) inefficiency wedge performs best in inflation forecasting and production function methodology dominates in the prediction of turning points. If, however, a unique methodology must be selected, the quadratic trend delivers the best overall results.","Label":"0"},{"DOI":"10.17016/ifdp.1976.99","Abstract":"During the 1970's, the prediction error of U.S. trade forecasting models has increased substantially. This increase in forecasting error can be attributed in large part to upheavels in the internaional economic environment that have latered teh historical relationships (of the 1950's and 1960's) between U.S. trade flows and their income, relative price and cyclical determints. Over the past five years, world price inflation has accelerated, and divergences in inflation rates across countries have widened, accompanied by a transition from relatively stable to sharply fluctuating exchange rates. There have also been significant changes in the cyclical behavior of economic activity in industrial countries and in the purchasing power of developing countries. This paper describes the countruction and performance of the forecasting model that follows in the tradition of partial equilibrium econometric models of U.S. trade, but with several important modifications in light of these and other recent changes in the world economy.","Label":"0"},{"DOI":"10.1002/jae.2634","Abstract":"The paper compares the pseudo real‐time forecasting performance of three dynamic factor models: (i) the standard principal component model introduced by Stock and Watson in 2002; (ii) the model based on generalized principal components, introduced by Forni, Hallin, Lippi, and Reichlin in 2005; (iii) the model recently proposed by Forni, Hallin, Lippi, and Zaffaroni in 2015. We employ a large monthly dataset of macroeconomic and financial time series for the US economy, which includes the Great Moderation, the Great Recession and the subsequent recovery (an update of the so‐called Stock and Watson dataset). Using a rolling window for estimation and prediction, we find that model (iii) significantly outperforms models (i) and (ii) in the Great Moderation period for both industrial production and inflation, and that model (iii) is also the best method for inflation over the full sample. However, model (iii) is outperformed by models (ii) and (i) over the full sample for industrial production.","Label":"0"},{"DOI":"10.1504/ijcsyse.2020.109130","Abstract":"Mutual funds are excellent medium for investors to invest, who do not have much know-how about financial markets. Investors generally take fund's historical performance and their funds rating as harbinger for its performance prediction. This myopic selection and prediction criterion sometimes lead to wrong funds allocation and hence poor portfolio performance. Performance prediction depends upon number of internal factors like GDP growth, inflation, business sentiments and external factors too like fed rates, political stability, world growth, currency fluctuations, etc., which are very difficult to predict precisely. However, in past, there had been many studies in India as well as abroad which tried to predict the performance by using various statistical techniques. This review paper covers such studies and various techniques used to check the fund's performance. Through this survey it is observed that performance analysis of mutual funds needs an extensive in-depth analysis of various factors and further study can be done to improve the predictability and volatility of mutual fund performance. In end, this paper gives a brief literature review of mutual funds' performance prediction models used domestically and internationally.","Label":"1"},{"DOI":"10.1016/s0169-2070(02)00060-2","Abstract":"This article studies the usefulness of low order ARMA models in the prediction of long memory time series with fractionally differenced ARFIMA(0,d,0) structure, −0.5","Label":"0"},{"DOI":"10.2139/ssrn.298843","Abstract":"Assessing the magnitude of the output gap is a critical input in achieving an optimal policy mix. Unfortunately, the gap is an unobservable variable which, in practice, has been estimated in a variety of ways, depending on the preferences of the modeler. This model selection problem leads to a substantial degree of uncertainty regarding the position of the output gap and can reduce its usefulness as a policy tool. To overcome this problem, in this paper we attempt to insert some discipline into this search by providing two metrics-inflation forecasting and business cycle dating-against which different options can be evaluated using aggregated euro-area GDP data. Our results suggest that Gali, Gertler, and Lopez-Salido's (2001) inefficiency wedge performs best in inflation forecasting and production function methodology dominates in the prediction of turning points. If, however, a unique methodology must be selected, the quadratic trend delivers the best overall results.","Label":"0"},{"DOI":"10.1016/j.euroecorev.2019.06.006","Abstract":"This paper evaluates the role of monetary policy in understanding the U.S. post-war macroeconomic fluctuations. We construct a medium-size DSGE model in which the central bank—through a real-time learning process—can make mistakes in estimating key elasticities between macroeconomic aggregates and the central banks objectives may change over time. The model also features time-varying volatilities of non-policy shocks. We find that misperceptions of the persistence of inflation and the slope of the Phillips curve could affect optimal monetary policy decision making. Therefore, their accurate prediction is key for achieving successful monetary policy outcomes. In addition, we argue that the monetary policy shift geared toward inflation stabilization in the late 1970s changed the composition of output making the marginal efficiency of investment shock—that proxies for the functioning of the financial sector—the most important contributor to the business cycle.","Label":"0"},{"DOI":"10.1111/j.1467-9485.2006.00369.x","Abstract":"This paper assesses the transmission of fiscal policy shocks in a New Keynesian framework where government expenditures contribute to aggregate production. It is shown that even if the impact of government expenditures on production is small, this assumption helps to reconcile the models' predictions about fiscal policy effects with recent empirical evidence. In particular, it is shown that government expenditures can lead to a rise in private consumption, real wages, and employment if the government share is not too large and public finance does not solely rely on distortionary taxation. When government expenditures are partially financed by public debt, unit labor costs fall in response to a fiscal expansion, such that inflation tends to decline. Households are willing to raise consumption if monetary policy is active, i.e. ensures that the real interest rate rises with inflation. Otherwise, private consumption can also be crowded out, as in the conventional case where government expenditures are not productive.","Label":"0"},{"DOI":"10.1016/j.techfore.2020.120172","Abstract":"This study is an endeavour to analyse the aspect of adhering to simplicity instead of complexity when one is striving to make a forecast and facing an unprecedented amount of uncertainty. There is substantial evidence on the exchange rate pass-through and equally ample evidence to suggest that the complex models are outperformed by simple solutions and heuristics. In this context, it seems that the Bank of England's post-Brexit forecast is an example of the sub-optimal performance of complex models in the face of high tides of uncertainty. To illustrate this point further, this study employed the data on the consumer price index from January 1989 to June 2019 and compared the post-Brexit inflation forecast by the Bank of England with an ARIMA model and a simple rule which was based on the Bank of England's estimates on pass-through due to exchange rate movements, similar in magnitude to the ones associated with Brexit. It showed that the actual path of inflation substantially diverged from the Bank of England's forecast as the effects of depreciation started to kick in. It implied that in the highly uncertain environment post-Brexit, a better prediction could have been possible by allocating some weights to the effects of sharp depreciation, indeed, that would have been a matter of judgment and simplicity.","Label":"0"},{"DOI":"10.1080/14631370601008613","Abstract":"In this study I describe the relationship between monetary policy and medium and long-term swap rates. I focus especially on explanation of the instability of the level and relations of swap and forward rates on the Czech swap market in the context of the Czech National Bank's (CNB) disinflation policy based on direct inflation targeting. Theoretically the main source of this problem is the inconsistency between the central bank's current and expected policy and the anticipated course of economic fundamentals. A common feature is that during disinflation the level of monetary policy restriction is not stable over time and is hard to predict for investors. Besides objective factors such as fluctuating economic growth or limited scope of information, this is also a result of the instability of sensitivity parameters of the central bank's reaction function and of the character of the monetary strategy pursued. Empirical analysis showed a limited effect of changes in the CNB repo rate on the instantaneous adaptation of swap and forward rates. In addition, problems connected with the CNB's weakened credibility were immediately identified, along with related erroneous expectations of investors. I interpret the instability of relations as evidence of differences in investors' inflation predictions of a gradual tendency for the economy to reach a state of low inflation.","Label":"0"},{"DOI":"10.2139/ssrn.3755250","Abstract":"We examine the impact of changes in U.S. monetary policy stance on income inequality of open economies. Using a Heterogeneous Agents New Keynesian model with price and wage rigidities, we show that in an expansionary (contractionary) monetary shock by Fed increases (decreases) income inequality in open economies. This impact is much higher in inflation targeting regime than in pegged exchange rate regime. We also find that while the impact of U.S monetary shock on inequality in pegged exchange rate regime is critical function of wage rigidity in the economy, it is independent of wage rigidity in inflation targeting economies. Our analysis indicate that in presence of hand to mouth households, an increase in wage flexibility certainly reduces welfare in in a pegged exchange rate economies. Our empirical estimates confirm our model prediction. More precisely, the estimates produce robust evidence that 100 basis point increase in Fed Fund Rate lower income inequality in open economies by nearly 0.15% over two years.","Label":"0"},{"DOI":"10.1109/smc.2018.00206","Abstract":"This paper applies the Behavior Pattern Learning (BPL) approach to automatically discover the conditions previous to specific macroeconomic events from the historical evolution of macroeconomic variables, as well as historical events. Every time the target macroeconomic event (e.g. Consumer Price Index (CPI) inflation greater than 5.5%) takes place, BPL constructs several snapshots at specific previous times. Each snapshot, called a behavior summary, includes information about its present, past, and future. The set of behavior summaries is used by a regression tree approach to discover the conditions for the target event to take place. In this paper, we used BPL to automatically discover the conditions for the occurrence of specific events associated with the CPI inflation and Gross domestic product (GDP) deflactor using macroeconomic data, and war and political events. Comparisons with other prediction models on the same problem show that the BPL provides automatic forecasts that are similar in performance as those forecasts done by models assisted by experts.","Label":"1"},{"DOI":"10.1016/j.jimonfin.2017.10.003","Abstract":"Using a dynamic stochastic general equilibrium (DSGE) model, we examine the impact of anticipated and unanticipated terms of trade (ToT) shocks on aggregate output, inflation and the trade balance (TB). This allows us to offer an alternative explanation of the J-curve phenomenon. We find that an unanticipated ToT shock increases real output as well as inflation but the J-curve phenomenon may not exist under a certain condition. However, under the same condition, an anticipated ToT shock leads to the J-curve effect. We find that our main result, concerning the J-curve phenomenon, continues to hold even if the assumption of rational expectations about the ToT is relaxed. Further analysis reveals that the presence of a cost channel of monetary policy increases the intensity of the J-curve effect. Assuming plausible parameter values, while using a more general model, calibration results support our theoretical predictions.","Label":"0"},{"DOI":"10.17016/ifdp.2004.791","Abstract":"In the past few years, observers increasingly have pointed to China as a source of downward pressure on global prices. This paper evaluates the theoretical and empirical evidence bearing on the question of whether China's buoyant export growth has led to significant changes in the inflation performance of its trading partners. This evidence suggests that the impact of Chinese exports on global prices has been, while non-negligible, fairly modest. On a priori grounds, our theoretical analysis suggests that China's economy is still too small relative to the world economy to have much effect on global inflation: a back-of-the-envelope calculation puts that effect at about 1/3 percentage point in recent years. In terms of the empirical evidence, we identify a statistically significant effect of U.S. imports from China on U.S. import prices, but given the size of this effect and the relatively low share of imports in U.S. GDP, the ultimate impact on the U.S. consumer prices has likely been quite small. Moreover, imports from China had little apparent effect on U.S. producer prices. Finally, using a multi-country database of trade transactions, we estimate that since 1993, Chinese exports lowered annual import inflation in a large set of economies by 1/4 percentage point or less on average, similar to the prediction of our theoretical model.","Label":"0"},{"DOI":"10.1002/for.3980030103","Abstract":"This paper reports on the accuracy of quarterly multiperiod predictions of inflation, real growth, unemployment and percentage changes in nominal GNP and two of its more volatile components. The survey data are highly differentiated; they cover 79 professional forecasters (mostly economists, analysts and corporate executives). Combining corresponding predictions from different sources can result in significant gains; thus the group mean forecasts are on the average over time more accurate than most of the corresponding sets of individual forecasts. But there is also a moderate degree of consistency in the relative performance of a sufficient number of the survey members, as evidenced in positive rank correlations among ratios of the individual to group root mean square errors.","Label":"0"},{"DOI":"10.1016/j.euroecorev.2009.10.003","Abstract":"A comparison of the point forecasts and the probability distributions of inflation and output growth made by individual respondents to the US Survey of Professional Forecasters indicates that the two sets of forecasts are sometimes inconsistent. We evaluate a number of possible explanations, and find that not all forecasters update their histogram forecasts as new information arrives. This is supported by the finding that the point forecasts are more accurate than the histograms in terms of first-moment prediction.","Label":"0"},{"DOI":"10.2753/pke0160-3477310306","Abstract":"In this paper, the Taylor rule and the Keynesian monetary policy rules recently introduced by Atesoglu are empirically compared for the 1994:2-2007:4 period. The findings reveal that the Atesoglu rule and the inflation-augmented Atesoglu rule are able to provide a better explanation of the federal funds rate than the Taylor rule. Results suggest that the Atesoglu rules based on the neutral interest rate idea of Keynes are likely to provide better predictions of future developments in monetary policy.","Label":"0"},{"DOI":"10.1002/for.2358","Abstract":"Application of the Bernhardt et al. (Journal of Financial Economics 2006; 80(3): 657–675) test of herding to the calendar‐year annual output growth and inflation forecasts suggests forecasters tend to exaggerate their differences, except at the shortest horizon, when they tend to herd. We consider whether these types of behaviour can help to explain the puzzle that professional forecasters sometimes make point predictions and histogram forecasts which are mutually inconsistent. Copyright © 2015 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.1080/09603107.2012.665592","Abstract":"This article uses the Survey of Professional Forecasters (SPF) to investigate the added value of the Taylor rule in interest rate forecasting. We interpret the Taylor rule as a set of macroeconomic restrictions that can be imposed on each individual professional forecaster's predictions of interest rates, inflation and economic activity. We study whether conforming to these restrictions improves forecast accuracy. We find that using the Taylor rule improves forecasts four quarters ahead and conclude that the Taylor rule is a useful tool in forming expectations about future monetary policy.","Label":"0"},{"DOI":"10.1007/978-3-030-39512-4_168","Abstract":"The VN-Index prediction problem is a part of a research project that predicts macroeconomic indicators for developing economies to detect the risk of inflation and economic crisis. In this study, given the records of VN-Index in the Vietnam Stock Exchange (VSE), we compare two different VN-Index forecast methods: the ARIMA econometric model and the Deep-learning approach with the LSTM-RNN model. Empirical results shows that: (1) the LSTM-RNN model is more accurate than the ARIMA model in the VN-Index forecast problems, (2) when applying the LSTM-RNN model, the window size would converge if it was larger than 15 days for LSTM-256 and 10 days for LSTM-512. From such results, we conclude that the LSTM-RNN model based on one-month data is optimal, which is appropriate according to the Wave theory and the psychology of the market.","Label":"1"},{"DOI":"10.54691/bcpbm.v38i.4180","Abstract":"Intensified worldwide inflation has added panic to the public about confidence of monetary currency value. People devote themselves to searching for relative constant measurement on country or world economic level evaluation frequently. Under economic uncertainty and on account of precious metal being a great hedge against inflation, gold or diamond are usually applied into economic analysis or prediction. ​The Diamond, as an equivalent to currency, has extensive acceptance worldwide. Hence, predicting diamond price has the same function compared to economic future forecasting through financial fluctuation. Advances in information technology have facilitated the development of video games and provided opportunities for video game competitions. More and more international tournaments are recognized by sports and sports organizations, and some competitive sports have become official events of the Asian Games. As a sport, fairness is essential, and League of Legends as a 5V5 combat game, fairness on both sides is the basis to maintain the game environment, which means that the winning rate of both sides will be close to 50%. This paper intends to predict diamond price by using simple linear regression. Besides, the forecasting of outcome for League of Legends will be also displayed in this paper, based on the platform R as analysis tool and standard indication. These results shed light on two practical applications of regression models in statistics and the corresponding explanations of their causes will be discussed.","Label":"0"},{"DOI":"10.1109/icomitee53461.2021.9650304","Abstract":"The exchange rate is the value or price of a currency in front of other currencies divided into selling rates and buying rates. The differences and alteration of exchange rates are caused by interest rates, inflation, and many other factors. The General Regression Neural Network method is applied to build a prediction system for the Yuan to IDR exchange rate, using the input to determine the output. The dataset is taken from the Bank Indonesia website with 191 records after pre-processing. Based on the resulting test, we found that the MSE score is 106.13, the RMSE score is 10.30, and the MAE score is 8.73. The model can find and recognize training data patterns to provide excellent data output with the results given.","Label":"1"},{"DOI":"10.2139/ssrn.3473023","Abstract":"The linear pool is the most popular method for combining density forecasts. We analyze the linear pool's implications concerning forecast uncertainty in a new theoretical framework that focuses on the mean and variance of each density forecast to be combined. Our results show that, if the variance predictions of the individual forecasts are unbiased, the well-known 'disagreement' component of the linear pool exacerbates the upward bias of the linear pool's variance prediction. Moreover, we find that disagreement has no predictive content for ex-post forecast uncertainty under conditions which can be empirically relevant. These findings suggest the removal of the disagreement component from the linear pool. The resulting centered linear pool outperforms the linear pool in simulations and in empirical applications to inflation and stock returns.","Label":"0"},{"DOI":"10.2139/ssrn.4350978","Abstract":"Methodologies such as situational importance and Shapley Additive explanations (SHAP) are increasingly used to explain machine learning (black-box) models predictions. Based on parametric inference, we have developed a methodological framework that employs Shapley values to generalize the data-generating process learned by neural networks. By leveraging Shapley-input relations, we propose the SHAPoly as a parametric function directly interpretable with a comparable predictive ability to the parent model. We implemented a Monte-Carlo analysis which demonstrates how well our methodology can unveil nonlinearities in the data without requiring a priori knowledge. Finally, we have developed an empirical application where artificial neural network (ANN) and long-short-term memory (LSTM) models were trained on US macroeconomic data (1960Q1 to 2007Q4) to predict inflation levels and make inferences on the data-generating process. Our SHAPoly model maintains the same level of interpretability as that of the Phillips Curve, but provides more precise predictions. We find meaningful and verifiable polynomial relations between the variables, which were consistent during the out-of-sample test period from 2008Q1 to 2022Q2. Specifically, we discovered a nonlinear relationship between unemployment and future inflation levels, which starts off as negative but turns positive once unemployment reaches a certain threshold. The tool we offer can provide policymakers with insights into potential relations between the evolution of future price levels and economic activity.","Label":"1"},{"DOI":"10.1016/s0169-2070(01)00082-6","Abstract":"A complete procedure for calculating the joint predictive distribution of future observations based on the cointegrated vector autoregression is presented. The large degree of uncertainty in the choice of cointegration vectors is incorporated into the analysis via the prior distribution. This prior has the effect of weighing the predictive distributions based on the models with different cointegration vectors into an overall predictive distribution. The ideas of Litterman [Mimeo, Massachusetts Institute of Technology, 1980] are adopted for the prior on the short run dynamics of the process resulting in a prior which only depends on a few hyperparameters. A straightforward numerical evaluation of the predictive distribution based on Gibbs sampling is proposed. The prediction procedure is applied to a seven-variable system with a focus on forecasting Swedish inflation.","Label":"0"},{"DOI":"10.1016/j.ejpoleco.2004.04.002","Abstract":"How does central bank conservatism affect labor market regulation? In this paper, we examine the economic forces at work. An increase in conservatism triggers two opposite effects. It reduces the inflation bias of discretionary monetary policy and hence the cost of regulation. It also increases unemployment variability, making regulation more costly. In combination, the two effects produce a hump-shaped relation between conservatism and labor market regulation. To test this prediction, we use data for 19 OECD countries for the period 1980–1994. Our proxies for regulation are unemployment, different labor market institutions, and indices of labor market regulation. Conservatism is proxied by two common measures of central bank independence. We find support for the prediction of a hump-shaped relation between conservatism and labor market regulation.","Label":"0"},{"DOI":"10.2118/162629-ms","Abstract":"Abstract In 2005 a series of statistical calculations were presented for Canadian hydrocarbon prices [1]. There were two main conclusions: long-term historical data indicates that hydrocarbon prices tend to revert back to historical averages, short-term price fluctuations are unpredictable. It is more clear than ever that short-term prices are unpredictable, but this paper will attempt to demonstrate once more that mean reversion should be included in any long-term model. This paper demonstrates that any discussion of oil and gas prices in Canada must consider inflation. Several different means of adjusting for inflation are presented but all show that Canadian hydrocarbon prices are strongly variable, but mean reverting. This paper also argues that, while convenient, discussing the price of a commodity in terms of only one currency ignores changes in the relative value between currencies and basis differentials. These factors can have significant economic impact. This paper updates the previous price fluctuation model for prices up to the end of 2012. As before, the model incorporates a random walk with mean reversion that was developed and tuned to fit Canadian hydrocarbon prices. Starting with the current spot price, the model will generate a random but equiprobable prediction of future prices. The model can be used as input into a Monte-Carlo simulation. Alternately, the model can be run multiple times in order to generate \"high\", \"low\", and \"expected\" price predictions.","Label":"0"},{"DOI":"10.30880/ijscet.2022.13.02.009","Abstract":"The absence of concerns about the problem of housing overhang in developer’s inventory can result in the growth rate of supply exceeding the growth rate of demand. The uncertainty of the economic sector at the international level has a direct impact on the economy in Malaysia, especially the real estate sector. This discussion paper applies literature review, analysis as well as regression approach to develop the supply prediction model for high-cost multi-storey houses. The published documents such as GDP per capita, inflation rate, unemployment rate and per centage of housing overhang for 10 years from beginning 2010 until 2020 are analyzed using secondary data analysis before regressed. Based on such findings, the GDP factor resulted in an increase in the percentage of house price supply for categories between RM 300,000 to RM 400,000, RM 600,000 to RM 700,000 and RM 800,000 to RM 900,000. Second, the factor of unemployment rate resulted in an increase in the percentage of house price supply for a category between RM 300,000 to RM400,000. Third, the factor of inflation rate resultsin an increase in the percentage of house price supplyfor categories between RM 400,000 to RM 500,000, RM 700,000 to RM 800,000 and above RM1,000,000. This model allows the developers to predict a better outcome for their housing development project besides to help them easily carry out the feasibility studyphase without wasting time.","Label":"0"},{"DOI":"10.1109/tensymp52854.2021.9550819","Abstract":"We present a thorough analysis of socio-economic impacts of COVID-19 on public health through data mining strategies including correlation index matrix, auto-regressive integrated moving average, decision trees, heatmaps and statistical performance evaluation. We acquired and filtered data for mortality and outbreak prediction through key features such as total cases, daily new cases, active cases, total deaths, daily new deaths, newly recovered, death rate and recovery rate for 54 days. The socio-economic impacts of the pandemic through quantitative analysis of stock market index, currency inflation, gasoline prices, interest rate, consumer price index and crude oil prices were also investigated. With correlation index matrix and heatmaps, we discovered the nature and intensity of interdependency of these features and developed the regressive estimation model to forecast the values of inter-related features for 10 days. We observed a highest correlation of +0.95 between recovery rate and total infected cases. We also observed an inverse correlation of -0.81 between daily new cases and recovery rate due to unexpected rise in outbreak. Also, the mild but positive index for economic impacts, such as currency inflation, depict the virus’ adverse impact on the fiscal situation. The statistical representation of the developed prediction models through bar charts show outstanding performance when evaluated on the benchmarking merits of mean absolute error, root mean square error, relative error and percentage accuracy.","Label":"1"},{"DOI":"10.1023/a:1003206009476","Abstract":"In this paper, it is shown that inflation differentials and trade deficits were significant determinants for exchange rate movements in the European monetary system. Since the target zone prevents EMS exchange rates from adjusting gradually to changing economic conditions, a standard regression model cannot detect this influence however. Therefore, a new econometric model is introduced, in which deteriorating competitiveness increases the probability of large depreciations and high volatility. These depreciations can be due to large devaluations or to panic reactions of the market due to expected devaluations. It is shown that the out-of-sample predictions of the model outperform the random walk, and that large arbitrage gains can be made in the foreign exchange market if our model predictions are used.","Label":"0"},{"DOI":"10.1007/s10663-020-09479-1","Abstract":"In this study we evaluate the dynamic response of different macroeconomic variables to shocks in agents’ perception of three dimensions of uncertainty (economic, inflation and employment). First, we apply a geometric indicator to compute the proportion of disagreement in business and consumer expectations of eight European countries and the Euro Area. Next, we use a bivariate vector autoregressive framework to estimate the impulse response functions to innovations in disagreement. While we find an adverse reaction in unemployment rates to shocks in discrepancy, results differ markedly between disagreement in business and in consumer surveys with regard to economic growth and inflation: shocks to manufacturing production discrepancy lead to a decrease in economic activity, as opposed to shocks to consumer economic discrepancy; and the opposite in the case of a shock in the perception of price uncertainty. Finally, we perform a forecasting exercise to assess the predictive performance of the disagreement indicators for different time horizons, obtaining more accurate out-of-sample recursive forecasts of economic growth with the indicators of discrepancy of manufacturing firms and, of unemployment with the indicators of consumer discrepancy. When compared to recursive autoregressive predictions used as a benchmark, we find that vector autoregressions with industry discrepancy tend to outperform the benchmark in more cases that models with indicators of consumer discrepancy.","Label":"0"},{"DOI":"10.2139/ssrn.3163872","Abstract":"I study how a credit crunch affects output price dynamics. I build a unique micro-level dataset that combines scanner-level prices and quantities with producer information, including the producer's banking relationships, inventory, and cash holdings. I exploit the Lehman Brothers' failure as a quasi-experiment and find that firms facing a negative credit supply shock decrease their output prices approximately 15% relative to their unaffected counterparts. I hypothesize that such firms reduce prices to liquidate inventory and to generate additional cash flow from the product market. I find strong empirical support for this hypothesis: (i) firms facing a negative bank shock temporarily decrease their prices and inventory and increase their market share and cash holdings relative to their counterparts, and (ii) this effect is stronger for firms and sectors with high initial inventory or small initial cash holdings. To discuss the aggregate implications of these findings, I integrate this micro-level study into a business cycle model by explicitly allowing for two identical groups of producers facing different degrees of credit supply shock. The model predicts that a negative credit supply shock leads to a large temporary drop in aggregate inflation - as a result of the aggressive liquidation of inventory - followed by an increase in inflation as producers eventually run out of inventory. This prediction for inflation and inventory dynamics is fully consistent with observations for the 2007-09 recession.","Label":"1"},{"DOI":"10.4038/suslj.v6i1.1689","Abstract":"This study investigates the effects of macroeconomic variables on stock prices in emerging Sri Lankan stock market using monthly data for the period from September 1991 to December 2002. The multivariate regression was run using eight macroeconomic variables for each individual stock.  The null hypothesis which states that money supply, exchange rate, inflation rate and interest rate variables collectively do not accord any impact on equity prices is rejected at 0.05 level of significance in all stocks. The results indicate that most of the companies report a higher R2  which justifies  higher explanatory power of macroeconomic variables in explaining stock prices.  Consistent with similar results of the developed as well as emerging market studies, inflation rate and exchange rate react mainly negatively to stock prices in the Colombo Stock Exchange (CSE). The negative effect of Treasury bill rate implies that whenever the interest rate on Treasury securities rise, investors tend to switch out of stocks causing stock prices to fall. However, lagged money supply variables do not appear to have a strong prediction of movements of stock prices while stocks do not provide effective hedge against inflation specially in Manufacturing, Trading and Diversified sectors in the CSE.  These findings hold practical implications for policy makers, stock market regulators, investors and stock market analysts. DOI: 10.4038/suslj.v6i1.1689 Sabaragamuwa University Journal, vol 6, no. 1, pp 50-67","Label":"0"},{"DOI":"10.2139/ssrn.3827815","Abstract":"Following the 2008 financial crisis, inflation rates in advanced economies have been at odds with the prediction of a standard Phillips curve. This puzzle has triggered a debate on the global determinants of domestic prices. We contribute to this debate by investigating the impact of exchange rate shocks on consumer prices from 1995 to 2018. We focus on cost-push inflation through global value chains, using three sectoral world input-output datasets. Depending on countries, the absolute value of the elasticity of the household consumption expenditure (HCE hereafter) deflator to the exchange rate ranges from 0.05 to 0.35, confirming the importance of global value chains in channelling external shocks to domestic inflation. Using data from WIOD on a sample of 43 countries, we find that the mean output-weighted elasticity of the HCE deflator to the exchange rate increased in absolute value from 0.075 in 2000 to 0.094 in 2008. After peaking in 2008, it declined to 0.088 in 2014. World Input-Output tables (WIOT hereafter) are released with a lag of several years and the latest WIOT dates back to 2015. To fill this gap, we approximate the impact of an exchange rate shock on the HCE deflator from 2016 onwards using up-todate GDP and trade data. Our extrapolations suggest that the decline in the elasticity of the HCE deflatorcontinued until 2016, before reversing in 2017 and 2018. Our findings are robust to using three different datasets.","Label":"0"},{"DOI":"10.3846/1392-8619.2009.15.267-280","Abstract":"The article deals with economic bubbles and analyses causes, means of prevention and results of economic bubbles. The exact cause of economic bubbles has been analyzed by many economists. The article discusses with different theories explaining the causes of bubbles formation and presents the possibilities to apply Logistic function for prediction of bubbles enabling to take preventive measures against bubbles creation. Some economists think that bubbles are related to inflation and therefore believe that the factors causing inflation could also be the same factors that cause bubbles to occur. Other economists think that there is a basic fundamental value to every asset and the bubbles represent an increase or rise over that fundamental value. There are also chaotic theories regarding the formation of bubbles. These theories argue that bubbles come from certain critical states on the market that originate from the communication of economic players. The aim of the article is to present a new theory explaining formation of economic bubbles based on Logistic growth models encountering the limited (financial, natural, physical, human etc.) capital resources.","Label":"0"},{"DOI":"10.1016/j.econmod.2017.03.007","Abstract":"We use the recently proposed linear opinion pool methodology of Garratt et al. (2014) to construct real-time output gap estimates for Switzerland over the out-of-sample period from 2003:Q1 to 2015:Q4. The model space consists of a large number of bivariate VAR specifications for the output gap and inflation, with each VAR specification using a different estimate of the output gap, lag order, and structural break information. We find that the linear opinion pool performs rather poorly. Real-time estimates of the output gap are no more accurate than those from some simple benchmark models, no more robust to ex post revisions than the real-time estimates of the individual univariate output gaps, and do not produce more accurate forecasts of inflation. The key driver of ‘good’ forecast performance is structural break information. Once the same structural break information is conditioned upon in all prediction models, the gain from averaging over many different pools of models that utilize various output gap estimates or lag structures in the VAR specification is of negligible magnitude.","Label":"0"},{"DOI":"10.1109/yac51587.2020.9337665","Abstract":"Under the guidance of the reform and opening-up policy, China's economy has developed at a high speed for about 40 years. Fiscal revenue is not only the symbol of a country's economic strength but also an important indicator to evaluate the financial resources of a country's government as it can be driven by the economic growth. However, China's economic growth has begun to slow down in recent years due to unstable international relationships although its the second largest economy in the world. Therefore, it's imperative for us to explore future development of China's fiscal revenue to take corresponding reactions in advance. The objective of this paper is applying SARIMA model and LSTM model to forecast China's fiscal revenue. The impact of inflation is taken into consideration when studying economic data, the consumer price index (CPI) is used to eliminate the impact of it. This is the first time that the impact of inflation is taken into consideration to forecast China's fiscal revenue and successfully achieve better performance.","Label":"1"},{"DOI":"10.2307/3866969","Abstract":"Money demand theory within a rational expectations framework predicts discontinuous jumps in the price level and a serially uncorrelated inflation rate. Both of these predictions seem to be contradicted by observations of price level behavior. To reconcile theory with observation, this paper suggests that a general price index, such as the consumer price index, is a weighted average of spot and previously contracted prices. Applying a rational expectations framework to the demand for money, this paper shows that the spot price level jumps discontinuously, while the general price level tends to approach its long-run equilibrium slowly. The spot price will either jump to, or will overshoot, its long-run level, depending on whether the spot price level or the general price level, respectively, is the proper money demand deflator. The paper also suggests various applications of this theory to other issues, such as the relationship between the interest rate and the inflation rate, the empirical formulation of money demand, and the purchasing-power-parity theory.","Label":"0"},{"DOI":"10.1007/978-981-16-2543-5_58","Abstract":"Price of the gold plays a major role in monetary as well as financial systems. Prediction and forecasting the upcoming tendency of gold prices and other valuable metals will be helpful for investors and money managers to evade choosing when to supply this commodity. Central banks throughout the globe uphold gold reserves to assure the currency holders, the money of their shareholders, and foreign-debt creditors. They also utilize the gold treasury as a means to manage inflation and toughen their country’s economic standing. During this procedure, the prediction of the gold rate has become the biggest issue now a days. So, various methods, especially intelligent techniques, have played a vital role in predicting gold prices. Moreover, a comparative investigation on the impact of machine learning (ML) algorithms such as support vector machine (SVM), random forest (RF), linear regression (LR), decision tree (DT), and other hybrid methods for gold price forecasting has been made. Some significant research directions for additional research on gold price prediction are highlighted which may assist the researchers to widen proficient intelligent techniques for the prediction of gold rate.","Label":"1"},{"DOI":"10.1088/1757-899x/662/2/022050","Abstract":"Abstract The purpose of this study is to deals with a data mining to extract knowledge regarding factors which affect tuition fee and predict future amount of the tuition fee. Specifically this paper aims to know what factors do affect tuition fee of a private university in eastern part of Indonesia. We used a vector autoregressive (VAR) model with variables including tuition fee, inflation rate, number of enrolled students and regional minimum wage. The data covers from January 2010 to December 2018 and were collected from the private university, the Bank Indonesia, the Central Bureau of Statistics (CBS), and the South Sulawesi office CBS. We carried out a step-by-step procedure that consists of stationarity test, optimal lag determination, and significance of parameters test as well as un-correlatedness of residuals and structure stability tests. We found that the tuition fee and the number of students are affected by inflation. This result gives impact on tuition fee prediction.","Label":"0"},{"DOI":"10.2139/ssrn.1311914","Abstract":"Most empirical studies on price setting that use micro data focus on advanced industrial countries. In this paper we analyze the experience of an emerging economy, Slovakia, using a large micro-level dataset that accounts for a substantial part of the consumer price index (about 5 million observations). We find that market structure is an important determinant of pricing behavior. The effect of market structure on persistence of inflation results from two conflicting forces. Increased competition may reduce persistence by increasing the frequency of price changes. In contrast, higher competition may increase persistence through inertial behaviour induced by the strategic complementarity among price setters. In our case study, we find that the latter effects dominate. Indeed, the dispersion of prices is higher while persistence is lower in the non-tradeable sectors, suggesting that higher competition is not conducive to lower persistence. Furthermore, we find that the frequency of price changes depends negatively on the price dispersion and positively on the product-specific inflation. These results seem consistent with predictions of Calvo's staggered price model.","Label":"1"},{"DOI":"10.1007/978-3-030-79757-7_5","Abstract":"In this empirical study, we would like to do a performance analysis of EUR/USD FOREX rates by adding three moving averaged methods and four financial factors (Dollar Index, the US Interest rate, Inflation rate, and Real Gross Domestic Product). Four FOREX datasets are FOREX, FOREX with factors, FOREX with MAs, and FOREX with factors and MAs to forecast FOREX rates. In the previous research, we used four factors and Simple Moving Average (SMA) along with FOREX dataset as input data on Linear regression Model (LM) and MultiLayer Perceptron (MLP) and the result showed the Mean Square Error (MSE) on LM is better than MLP. So in this research, we used research efforts on LM, MLP, and Recurrent Neural Networks (RNNs) for predicting EUR/USD FOREX rates. And MSE was used for evaluating the result.","Label":"1"},{"DOI":"10.1111/j.1540-5907.2005.00155.x","Abstract":"We construct a model of speculative trading to examine how the mean and volatility of stock prices is affected both by government partisanship and by traders' expectations of electoral victory by the right‐wing or left‐wing party. Our model predicts that rational expectations of higher inflation under left‐wing administrations lowers the volume of stocks traded in the stock market. The decline in trading volume leads to a decrease in the mean and volatility of stock prices not only during the incumbency of left‐wing governments, but also when traders expect the left‐wing party to win elections. Conversely, expectation of lower inflation under right‐wing administrations leads to higher trading volume. This leads to an increase in the mean and volatility of stock prices during the tenure of right‐wing governments and when traders anticipate the right‐wing party to win elections. Daily and monthly data from U.S. and British equity markets between 1930 and 2000 statistically corroborate the predictions from our formal model.","Label":"0"},{"DOI":"10.2139/ssrn.1005410","Abstract":"This paper examines the asymptotic and finite-sample properties of tests of equal forecast accuracy applied to direct, multi-step predictions from both non-nested and nested linear regression models. In contrast to earlier work in the literature, our asymptotics take account of the real-time, revised nature of the data. Monte Carlo simulations indicate that our asymptotic approximations yield reasonable size and power properties in most circumstances. The paper concludes with an examination of the real-time predictive content of various measures of economic activity for inflation.","Label":"1"},{"DOI":"10.1080/07474930500405683","Abstract":"This paper examines the asymptotic and finite-sample properties of tests of equal forecast accuracy and encompassing applied to direct, multistep predictions from nested regression models. We first derive asymptotic distributions; these nonstandard distributions depend on the parameters of the data-generating process. We then use Monte Carlo simulations to examine finite-sample size and power. Our asymptotic approximation yields good size and power properties for some, but not all, of the tests; a bootstrap works reasonably well for all tests. The paper concludes with a reexamination of the predictive content of capacity utilization for inflation.","Label":"0"},{"DOI":"10.2139/ssrn.958163","Abstract":"A motivation for central bank independence (CBI) is that policy delegation helps politicians manage diverse coalitions. This paper develops a model of coalition formation that predicts when delegation will occur. An analysis of policy preferences survey data and CBI indicators supports the predictions. Case studies, drawn from several countries'& recent past and the nineteenth-century United States, provide further support. Finally, the model explains why the expected negative relationship between CBI and inflation is not empirically robust: endogenous selection biases the estimated effect towards zero. The data confirm this.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2011.08.003","Abstract":"In this paper, we propose a simulation-based method for computing point and density forecasts for univariate noncausal and non-Gaussian autoregressive processes. Numerical methods are needed for forecasting such time series because the prediction problem is generally nonlinear and therefore no analytic solution is available. According to a limited simulation experiment, the use of a correct noncausal model can lead to substantial gains in forecast accuracy over the corresponding causal model. An empirical application to US inflation demonstrates the importance of allowing for noncausality in improving point and density forecasts.","Label":"0"},{"DOI":"10.1016/0304-3932(89)90059-7","Abstract":"The paper develops a model in which the monetary authority successfully targets the nominal interest rate, while also holding down the forecast variance of the price level. The latter objective pins down the extent of monetary accommodation to shifts in the demand for money and other shocks, and thereby makes determinate the levels of money and prices at each date. Empirical evidence for the United States suggests that the model's predictions accord reasonably well with observed behavior for nominal interest rates, growth rates of the monetary base, and rates of inflation.","Label":"0"},{"DOI":"10.1109/iciict1.2019.8741439","Abstract":"The objective of this research was to generate an indicator of global political stability, by predicting the annual S&P 500 stock market index. This was done through machine learning, using a genetic programming approach, creating an algorithm with a template that takes into account the previous years' data of S&P 500 stock index, gold prices, the number of casualties in U.S. wars, crude oil prices, Dow Jones Industrial Average and rates of inflation in U.S. The prediction of this algorithm was highly accurate, within 14%.","Label":"1"},{"DOI":"10.1093/acprof:oso/9780195171648.003.0023","Abstract":"Abstract The two major economic crises of the Weimar Republic — the inflation at the beginning and the Depression at the end — accelerated the stagnation and economic decline that had already begun before World War I. As early as 1933, a social worker predicted that German Jews would experience such grave restrictions in their “economic sphere” that their standard of living would be reduced to the point of ending their “middle-class existence”. This chapter shows how this prediction came true, with the onslaught of discrimination, boycotts, and ultimately “Aryanization” — a euphemism for the Nazi expropriation of Jews.","Label":"0"},{"DOI":"10.2139/ssrn.738385","Abstract":"This paper assesses the transmission of fiscal policy shocks in a New Keynesian framework where government expenditures contribute to aggregate production. It is shown that even if the impact of government expenditures on production is small, this assumption helps to reconcile the models' predictions about fiscal policy effects with recent empirical evidence. In particular, it is shown that government expenditures can cause a rise in private consumption, real wages, and employment if the government share is not too large and public finance does not solely rely on distortionary taxation. When government expenditures are partially financed by public debt, unit labor costs fall in response to a fiscal expansion, such that inflation tends to decline. Households are willing to raise consumption if monetary policy is active, i.e. ensures that the real interest rate rises with inflation. Otherwise, private consumption can also be crowded-out, as in the conventional case where government expenditures are not productive. The interaction between monetary and fiscal policy is thus decisive for the short-run macroeconomic effects of government expenditure shocks.","Label":"0"},{"DOI":"10.2753/eee0012-8775460504","Abstract":"This paper investigates the effects of EU enlargement on price convergence. The internal market is expected to boost integration and increase efficiency and welfare through a convergence of prices in product markets. Two principal drivers are crucial to explain price developments. On one hand, higher competition exerts downward pressure on prices because of lower markups. On the other hand, the catching-up process of lowincome countries leads to a rise in price levels and higher inflation over a transition period. Using comparative price levels for forty-one product categories, price convergence can be established. However, the speed of convergence is rather slow, with half-lives of approximately ten years. The enlargement has stimulated convergence slightly toward the mean price; this effect is robust across different groups of countries. Moreover, the driving forces of convergence are explored. In line with theoretical predictions, the rise in competition exerts downward pressure on prices, whereas catching-up of low-income countries leads to a rise in price levels and higher inflation. The findings have important implications, as price convergence facilitates the working of common economic policies.","Label":"0"},{"DOI":"10.2139/ssrn.879220","Abstract":"We propose a theory to explain why, and under what circumstances, a politician gives up rent and delegates policy tasks to an independent agency. We apply this theory to monetary policy by extending a standard dynamic New-Keynesian stochastic general equilibrium model. This model gives a new theory of central bank independence that is unrelated to the standard inflation bias problem. We derive several new predictions and show that they are consistent with the data. Finally, we show that while instrument independence of the central bank is desirable, goal independence is not.","Label":"0"},{"DOI":"10.1590/s1807-76922008000400005","Abstract":"This paper studies the information content of survey-based predictions for the Brazilian short-term interest rate. We perform vector autoregression analysis to test for the dynamic relationship between market expectations of interest rates and spot interest rates, and a single regression forecasting approach. Empirical results suggest that surveys may be useful in assessing market expectations (contain relevant information) and in building Central Bank credibility. Within an inflation targeting framework they are crucial in order to receive timely feedback on market sentiment regarding the conduct of monetary policy.","Label":"0"},{"DOI":"10.1111/1467-6419.00187","Abstract":"This paper focuses on the relationship between political instability, policy–making and macroeconomic outcomes. The theoretical section explores various models that explain the effect of instability (and political uncertainty) on growth, budget formation, inflation and monetary policy. The empirical section discusses the evidence on the predictions generated by theoretical models. Preliminary to this discussion, however, is the analysis of a few general issues concerning the specification and estimation of econometric models with political variables. Some new results are then produced on the empirical relevance of theories of strategic use of fiscal deficit.","Label":"0"},{"DOI":"10.1016/j.jimonfin.2021.102536","Abstract":"This paper provides an empirical assessment of the power of forward guidance at different horizons, shedding new light on the strength of the “forward guidance puzzle”. Our identification strategy allows us to disentangle target and forward guidance shocks from central bank private information. We investigate to what extent the horizon of guidance matters for its macroeconomic effects, and find that as the communication horizon lengthens, its impact on output and inflation weakens. This runs contrary to the prediction from standard New Keynesian models that the power of forward guidance increases with its horizon.","Label":"0"},{"DOI":"10.2139/ssrn.3579765","Abstract":"Concerns of prolonged near zero interest rates and below target inflation have become widespread in the advanced world. We build an analytical framework that incorporates two hypotheses of persistent ZLB episodes: expectations-driven liquidity traps and secular stagnation driven liquidity traps. We estimate the DSGE model with Japanese data from 1998:Q1 to 2012:Q4. Using Bayesian prediction pools, we find that a policymaker faces considerable real-time uncertainty in identifying the dominant narrative. We propose robust policies that eliminate expectations-driven traps and are expansionary under secular stagnation.","Label":"0"},{"DOI":"10.2139/ssrn.1564746","Abstract":"In this paper, we propose a simulation-based method for computing point and density forecasts for univariate noncausal and non-Gaussian autoregressive processes. Numerical methods are needed to forecast such time series because the prediction problem is generally nonlinear and no analytic solution is therefore available. According to a limited simulation experiment, the use of a correct noncausal model can lead to substantial gains in forecast accuracy over the corresponding causal model. An empirical application to U.S. inflation demonstrates the importance of allowing for noncausality in improving point and density forecasts.","Label":"0"},{"DOI":"10.1016/s0022-1996(02)00024-7","Abstract":"Euro-interest rates are well-known to be persistent, as are their differentials across countries for a given maturity. The international CCAPM implies that the rates are persistent because forecasts of national consumption growth or inflation are persistent too. We examine this prediction for a panel of countries. The standard CCAPM with power utility is augmented to allow for external habit, government consumption, and adaptive learning. In all cases, we find little evidence that the persistence in Euro-rates is consistent with the CCAPM.","Label":"0"},{"DOI":"10.1080/758527106","Abstract":"Short-run and long-run relationships between Swiss francs per dollar and economic determinants are determined, namely money supply or growth in money supply, interest rates, differences in inflation rates, deviations from purchasing power parity and trade balances. A long-run relationship is estimated by using the Phillips–Hansen methodology while a short-run error correction model is estimated by performing non-parametric corrections for endogeneity and serial correlation. The predictions from the estimated error correction model outperform random-walk model for the period January 1989 to June 1990.","Label":"0"},{"DOI":"10.2139/ssrn.1198982","Abstract":"We present a comprehensive macroeconomic model for the U.S. There exist strict long-term relations between real GDP, price inflation, labor force participation, productivity, and unemployment. The evolution of real GDP depends only on exogenous demographic forces. Other macro-variables follow up the real GDP. The links between the variables have been valid during the last several decades. All relations were (successfully) tested for cointegration. Statistical estimates are also presented. The relationships allow a reliable prediction of the macroeconomic state at very large (more than 9 years) time horizons.","Label":"0"},{"DOI":"10.1016/j.asieco.2018.10.005","Abstract":"Using a Markov-switching prediction-pooling method (Waggoner & Zha, 2012) for density forecasts, we compare the time-varying forecasting performance of a DSGE model incorporating a financial accelerator à la Bernanke, Gertler, and Gilchrist (1999) with the frictionless model by focusing on periods of financial crisis including the so-called “bubble period” and the “lost decade” in Japan. According to our empirical results, the accelerator improves the forecasting of investment over the whole sample period, while forecasts of consumption and inflation depend on the fluctuation of an extra financial premium between the policy interest rate and the corporate loan rates. In particular, several drastic monetary policy changes might disrupt the forecasting performance of the model with the accelerator. A robustness check with a dynamic pooling method (Del Negro, Hasegawa, & Schorfheide, 2016) also supports these results.","Label":"0"},{"DOI":"10.1109/iadcc.2015.7154749","Abstract":"Time series analysis is one of the major prediction techniques for forecasting of time dependent variables. These days the time series analysis is applicable to a variety of applications. In this work the time series analysis technique using ARIMA model is applied on per capita disposable income for future forecasting. Per capita disposable income is the average available money per person after income taxes have been accounted for. It is an indicator of the overall state of an economy. Forecasting of per capita disposable income is necessary as it may help government assess country's economic condition in comparison with the economy of other countries of the world. Forecasting per capita disposable income may also help assess inflation and financial critical situation. The results obtained from this work can be used by the planning commission of a country to formulate future policies and plans.","Label":"0"},{"DOI":"10.1016/0169-2070(87)90008-2","Abstract":"This study analyzes mean probability distributions reported by ASA-NBER forecasters on two macroeconomic variables, GNP and the GNP implicit price deflator. In the derivation of expectations, a critical assertion has been that the aggregate average expectation can be regarded as coming from a normal distribution. We find that, in fact, this assumption should be rejected in favor of distributions which are more peaked and skewed. For IPD, they are mostly positively skewed, and for nominal GNP the reverse is true. We then show that a non-central scaled t-distribution fit the empirical distributions remarkably well. The practice of using the degree of consensus across a group of predictions as a measure of a typical forecasters' uncertainty about the prediction is called to question.","Label":"0"},{"DOI":"10.15611/eada.2019.3.04","Abstract":"The last financial crisis affected the SMEs sector in different countries at different levels and strength. SMEs represent the backbone of the economy of every country. Therefore, they need bankruptcy prediction models easily adaptable to their characteristics. In our analysis we verified hypothesis: including information about macroeconomic conditions significantly increases the effectiveness of the bankruptcy model. The data set used in our research contained information about 1,138 SMEs. All information was taken from the financial statements covering the period 2002-2010. The sample included enterprises from sectors: industry, trade and services. Selected financial ratios were used to build the model and the macroeconomic variables were added: GDP, inflation, and the unemployment rate. Logistic regression as the research method was applied. In our study we showed that the incorporation of the macro variables improved the prediction of the SMEs bankruptcy risk.","Label":"0"},{"DOI":"10.55041/ijsrem15027","Abstract":"We predict future gold rates supported twenty two market variables victimization machine learning technique.One machine learning algorithm, random forest regression were used in analyzing these knowledge[1]. Historically, gold was used for supporting trade transactions around the world besides alternative modes of payment. Various states maintained and increased their gold reserves and were recognized as rich and progressive states. In present times, precious metals like gold area unit control with central banks of all countries to make sure re-payment of foreign debts, and conjointly to control inflation. Moreover, it conjointly reflects the Imoney strength of the country[2]. Besides government agencies, varied transnational firms and people have conjointly invested with in gold reserves. In ancient events of Asian countries, gold is in addition presented as gifts/souvenirs and in marriages, gold ornaments are conferred as gift in Republic of India. KEYWORDS: Price prediction, Machine Learning, Supervised Learning, Linear Regression, Python , Power Bi , Tableau.","Label":"1"},{"DOI":"10.2139/ssrn.1173622","Abstract":"This paper presents an analysis of the effect of bureaucratic corruption on economic growth through a public finance transmission channel. At the theoretical level, we develop a simple dynamic general equilibrium model in which financial intermediaries make portfolio decisions on behalf of agents, and bureaucrats collect tax revenues on behalf of the government. Corruption takes the form of the embezzlement of public funds, the effect of which is to increase the government's reliance on seigniorage finance. This leads to an increase in inflation which, in turn, reduces capital accumulation and growth. At the empirical level, we use data on 82 countries over a 20-year period to test the predictions of our model. Taking proper account of the government's budget constraint, we find strong evidence to support these predictions under different estimation strategies. Our results are robust to a wide range of sensitivity tests.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2018.10.006","Abstract":"There is general agreement in many forecasting contexts that combining individual predictions leads to better final forecasts. However, the relative error reduction in a combined forecast depends upon the extent to which the component forecasts contain unique/independent information. Unfortunately, obtaining independent predictions is difficult in many situations, as these forecasts may be based on similar statistical models and/or overlapping information. The current study addresses this problem by incorporating a measure of coherence into an analytic evaluation framework so that the degree of independence between sets of forecasts can be identified easily. The framework also decomposes the performance and coherence measures in order to illustrate the underlying aspects that are responsible for error reduction. The framework is demonstrated using UK retail prices index inflation forecasts for the period 1998–2014, and implications for forecast users are discussed.","Label":"1"},{"DOI":"10.1016/0169-2070(91)90052-w","Abstract":"This paper adopts an econometric framework which makes it possible to analyse the determi- nants of total as well as non-contingent wage adjustment, the elasticity of indexation and contract duration. A sample of Canadian labour contracts arrived at in the non-controlled private sector is used and detailed in-sample wage adjustment predictions by indexation status are presented. The model predicts wage change in indexed and non-indexed contracts satisfactorily and, consistent with the actual data and particular time period used, indicates that non-indexed contracts do better in general and particularly so in periods of decelerating inflation. Out-of-sample wage adjustment predictions appear reasonable. The in- and out-of-sample behaviour of the ex ante elasticity of indexation and contract duration are also considered.","Label":"0"},{"DOI":"10.1016/j.jedc.2020.104045","Abstract":"I investigate how professional forecasters update their uncertainty forecasts of output and inflation in response to macroeconomic news. I obtain a measure of individual uncertainty from the density forecasts of the Survey of Professional Forecasters for the United States (US-SPF) and the Euro area (ECB-SPF) and use it to test the prediction of Bayesian learning that uncertainty should decline as the forecast date nears the target date. Empirically, I find that the prediction is occasionally violated, in particular when forecasters experience unexpected news in the most recent data release, and following quarters in which they produce narrow density forecasts. The evidence indicates also significant heterogeneity in the updating behavior of forecasters in response to changes in these variables. In addition, I propose a method to solve the problem of the truncation of the density forecasts that occurs when a significant amount of probability is assigned to the open intervals.","Label":"1"},{"DOI":"10.1080/10800379.2013.12097255","Abstract":"This paper considers the ex post accuracy of two published sets of macroeconomic forecasts: the Economist Intelligence Unit’s (EIU’s) Country Report and the “Economist of the Year” consensus forecast, sponsored by Media 24. Root weighted mean square errors (RWMSEs) of these two competing entities’ forecasts are, on average, about 60% of the RWMSEs of adaptive naïve predictions for current-year forecasts and about 75% of the RWMSEs of adaptive naïve predictions for one- year-ahead forecasts. There is no substantial difference in the forecast accuracy of the two entities, despite large differences in forecasting methodology. Forecasts are revised on a monthly basis. Monthly revisions in Media 24’s consensus forecast are substantially more likely to reduce forecast errors than the EIU’s monthly forecast revisions. Revisions in the next-year forecasts for GDP growth and inflation are only marginally better than random, and thus such revisions have little credibility.","Label":"0"},{"DOI":"10.1016/j.chieco.2010.02.005","Abstract":"Our principal purpose here is to assess the extent to which both the official and black market exchange rates for the Chinese economy exhibit compatibility with the Balassa–Samuelson model over the period from 1985 to 2006. We employ annual measures of inflation and industry input on an aggregated, disaggregated and sector basis, all of which have been especially constructed for this study. Both the time series and panel cointegration tests applied to this data are generally inconsistent with the prediction of the Balassa–Samuelson model that the tradable goods sector is compatible with purchasing power parity. However, our analysis also shows that other predictions of the Balassa–Samuelson model – most notably that there will be a strong long-run relationship between the real exchange rate and the relative productivity differential between China and the U.S. – does hold up for the Chinese economy. Moreover, the black market exchange rate appears to be more consistent with the predictions of the Balassa–Samuelson model than the official exchange rate.","Label":"0"},{"DOI":"10.1504/ijds.2019.102789","Abstract":"This paper describes a study that used data collected from the Central Bank statistical web database system in Nigeria to evaluate and compare the forecasting performance of the nonstationary linear state space model and Box-Jenkins (ARIMA) model at different historic time periods. The comparison uses data series on inflation rates (core and non-core) in Nigeria for a specified period. The performances were evaluated based on three metrics: mean absolute error (MAE), mean absolute percentage error (MAPE) and root mean square percentage error (RMSPE). The one-year forecast evaluation results indicated that predictions from the nonstationary linear state space model outperformed the seasonal ARIMA model at different time periods. Furthermore, the proposed nonstationary linear state space model captured the dynamic structure of the inflationary series reasonably and requires no new cycle of identification and model estimation given the availability of new data.","Label":"0"},{"DOI":"10.1007/978-3-030-51971-1_40","Abstract":"The objective of this research is to implement a Deep Learning model with Long Short-Term Memory (DLSTM) for prediction of the currency exchange rate. The system predicts the currency exchange rate using a fusion of data from the following financial inputs: gross domestic product rate (GDP), interest rate, inflation rate, balance account and trade balance as well as a finite set of previous exchange rates. We have evaluated the model performance by considering the currency exchange rates of the Thai Baht to the US dollar using historical data from the Bank of Thailand for ten years, from April 2009 to April 2019. To evaluate the effectiveness of the DLSTM model, we have considered the mean square error (MSE) and the mean absolute percentage error (MAPE). The best results have shown that the DLSTM model leads to a very low error value for the MSE and the MAPE at 0.0027 and 0.2844, respectively. We have compared the proposed DLSTM model prediction performances with those of the NARX neural network model; our research results show the obvious advantage of the proposed DLSTM model.","Label":"1"},{"DOI":"10.2139/ssrn.812086","Abstract":"In this paper we construct output gap and inflation predictions using a variety of DSGE sticky price models. Predictive density accuracy tests related to the test discussed in Corradi and Swanson (2005a) as well as predictive accuracy tests due to Diebold and Mariano (1995) and West (1996) are used to compare the alternative models. A number of simple time series prediction models (such as autoregressive and vector autoregressive (VAR) models) are additionally used as strawman models. Given that DSGE model restrictions are routinely nested within VAR models, the addition of our strawman models allows us to indirectly assess the usefulness of imposing theoretical restrictions implied by DSGE models on unrestricted econometric models. With respect to predictive density evaluation, our results suggest that the standard sticky price model discussed in Calvo (1983) is not outperformed by the same model augmented either with information or indexation, when used to predict the output gap. On the other hand, there are clear gains to using the more recent models when predicting inflation. Results based on mean square forecast error analysis are less clear-cut, although the standard sticky price model fares best at our longest forecast horizon of 3 years, and performs relatively poorly at shorter horizons. When the strawman time series models are added to the picture, we find that the DSGE models still fare very well, often winning our forecast competitions, suggesting that theoretical macroeconomic restrictions yield useful additional information for forming macroeconomic forecasts.","Label":"0"},{"DOI":"10.2139/ssrn.4139912","Abstract":"Using CPI micro data for 11 euro area countries covering about 60% of the euro area consumption basket over the period 2010-2019, we document new findings on consumer price rigidity in the euro area: (i) each month on average 12.3% of prices change, which compares with 19.3% in the United States; when we exclude price changes due to sales, however, the proportion of prices adjusted each month is 8.5% in the euro area versus 10% in the United States; (ii) differences in price rigidity are rather limited across euro area countries but much larger across sectors; (iii) the median price increase (resp. decrease) is 9.6% (13%) when including sales and 6.7% (8.7%) when excluding sales; cross-country heterogeneity is more pronounced for the size than for the frequency of price changes; (iv) the distribution of price changes is highly dispersed: 14% of price changes in absolute values are lower than 2% whereas 10% are above 20%; (v) the overall frequency of price changes does not change much with inflation and does not react much to aggregate shocks; (vi) changes in inflation are mostly driven by movements in the overall size; when decomposing the overall size, changes in the share of price increases among all changes matter more than movements in the size of price increases or the size of price decreases. These findings are consistent with the predictions of a menu cost model in a low inflation environment where idiosyncratic shocks are a more relevant driver of price adjustment than aggregate shocks.","Label":"0"},{"DOI":"10.52903/wp2022302","Abstract":"Using CPI micro data for 11 euro area countries covering about 60% of the euro area consumption basket over the period 2010-2019, we document new findings on consumer price rigidity in the euro area: (i) each month on average 12.3% of prices change, which compares with 19.3% in the United States; when we exclude price changes due to sales, however, the proportion of prices adjusted each month is 8.5% in the euro area versus 10% in the United States; (ii) differences in price rigidity are rather limited across euro area countries but much larger across sectors; (iii) the median price increase (resp. decrease) is 9.6% (13%) when including sales and 6.7% (8.7%) when excluding sales; cross-country heterogeneity is more pronounced for the size than for the frequency of price changes; (iv) the distribution of price changes is highly dispersed: 14% of price changes in absolute values are lower than 2% whereas 10% are above 20%; (v) the overall frequency of price changes does not change much with inflation and does not react much to aggregate shocks; (vi) changes in inflation are mostly driven by movements in the overall size; when decomposing the overall size, changes in the share of price increases among all changes matter more than movements in the size of price increases or the size of price decreases. These findings are consistent with the predictions of a menu cost model in a low inflation environment where idiosyncratic shocks are a more relevant driver of price adjustment than aggregate shocks.","Label":"0"},{"DOI":"10.48550/arxiv.1010.0055","Abstract":"Large-scale clustering of highly biased tracers of large-scale structure has emerged as one of the best observational probes of primordial non-Gaussianity of the local type (i.e. f_{NL}^{local}). This type of non-Gaussianity can be generated in multifield models of inflation such as the curvaton model. Recently, Tseliakhovich, Hirata, and Slosar showed that the clustering statistics depend qualitatively on the ratio of inflaton to curvaton power \\xi after reheating, a free parameter of the model. If \\xi is significantly different from zero, so that the inflaton makes a non-negligible contribution to the primordial adiabatic curvature, then the peak-background split ansatz predicts that the halo bias will be stochastic on large scales. In this paper, we test this prediction in N-body simulations. We find that large-scale stochasticity is generated, in qualitative agreement with the prediction, but that the level of stochasticity is overpredicted by ~30%. Other predictions, such as \\xi independence of the halo bias, are confirmed by the simulations. Surprisingly, even in the Gaussian case we do not find that halo model predictions for stochasticity agree consistently with simulations, suggesting that semi-analytic modeling of stochasticity is generally more difficult than modeling halo bias.","Label":"1"},{"DOI":"10.1145/3229345.3229382","Abstract":"Investing in the stock market is a complex process due to its high volatility caused by factors as exchange rates, political events, inflation and the market history. To support investor's decisions, the prediction of future stock price and economic metrics is valuable. With the hypothesis that there is a relation among investment performance indicators, we applied multi-target regression (MTR) methods to estimate 6 different indicators aiming at creating an automated prediction tool for decision support. The experiments were based on 4 datasets, corresponding to 4 different time periods, composed of 63 combinations of weights of stock-picking concepts each, simulated in the US stock market. We compared traditional machine learning approaches with four state-of-the-art MTR solutions: Stacked Single Target, Ensemble of Regressor Chains, Deep Structure for Tracking Asynchronous Regressor Stacking and Multi-output Random Forest (MORF). With the exception of MORF, traditional approaches and the MTR methods were evaluated with Random Forest and Support Vector Machine regressors. By means of extensive experimental evaluation, our results showed that the most recent MTR solutions can achieve suitable predictive performance, improving all the scenarios (12.6% in the best period, considering all target variables). In this sense, MTR is a proper strategy for building stock market decision support system based on prediction models.","Label":"1"},{"DOI":"10.2139/ssrn.3306035","Abstract":"A numerical measure of central bank credibility, which can be incorporated into a New Keynesian model under bounded rationality, is proposed and analyzed. This measure arises mainly due to the existence of the drifts in private long-term predictions, which are different from those of the central bank. It is shown that central bank credibility matters for macroeconomic stability. As the credibility increases, macroeconomic variables vary less. This generates endogenous volatility changes. Lastly, the magnitude of response of inflation to monetary policy depends on the level of credibility. This suggests that ignoring credibility changes might leads to overestimate of the cost of disinflation.","Label":"0"},{"DOI":"10.1111/sjpe.12199","Abstract":"Over a long horizon, this paper examines joint economic crises and determines the power of 49 variables in predicting such episodes. While incorporating dynamism in the prediction, we generate the predictive power of various specifications and model the uncertainty in the parameters of interest. The results reveal that growth of real gross domestic product per capita, regulation, bank non‐performing loans, interest rate and inflation rate are the most significant variables in predicting the joint economic crises. These variables predict economic crises with about 93% accuracy and can predict joint economic crises in developing countries and recent joint crises.","Label":"0"},{"DOI":"10.1111/coep.12051","Abstract":"This article theoretically examines the impact of different forms of government spending on national income in a financially open economy with a significant net international investment position the central bank of which sets domestic interest rates to target inflation. It shows that whether government spending is expansionary or contractionary ultimately depends on the productivity of that expenditure, a result that has major implications for the efficacy of fiscal policy deployed for either stimulus or austerity reasons. The key prediction of the model is that public consumption and unproductive public investment are procyclical, whereas only productive public investment is countercyclical. (JEL F41)","Label":"0"},{"DOI":"10.1111/j.1465-7295.1989.tb00790.x","Abstract":"It is widely believed that monetary aggregates have failed to predict economic performance over 1983‐87. This paper observes that the traditional definition of money (M1 lessother checkable deposits, or M1A) shows no evidence of structural change, and yields lower prediction errors for both real GNP and inflation over 1983‐87Q2 than the errors obtained using M1 or M2. If there is a mystery, it is not why MIA has done so well, but why economists abandoned it for M1 or what was once called M1B (currency, demand deposits, and other checkable deposits).","Label":"0"},{"DOI":"10.1016/s0164-0704(98)00063-9","Abstract":"In this paper we develop a voter model which builds on the partisan theory of macroeconomic policy. In the voter model, vote decisions are based on the economic performance of the incumbent and the type of economic problems a country faces. Like the conventional retrospective voter model, our model predicts that the incumbent benefits from favorable economic outcomes. In addition, our model leads to the prediction that Democratic presidents suffer more from inflation and benefit less from economic booms than Republican presidents. Estimates of popularity functions provide strong support for the hypotheses derived from our model.","Label":"0"},{"DOI":"10.1007/978-1-349-22919-2_1","Abstract":"Ever since Keynes challenged the classical automaticity approach to macroeconomics, the economics profession has been engaged in a prolonged debate over the appropriate roles of monetary, fiscal, debt and exchange rate policies in economic management. In the two decades following the publication of the General Theory, Keynesian views were predominant in macroeconomic theory and economic policy. Classical views, however, were sustained by the abortive Keynesian prediction of a post-war depression. Control of inflation became a major objective of macroeconomic policy.","Label":"0"},{"DOI":"10.1162/rest_a_00300","Abstract":"We revisit the relation between stock market volatility and macroeconomic activity using a new class of component models that distinguish short-run from long-run movements. We formulate models with the long-term component driven by inflation and industrial production growth that are in terms of pseudo out-of-sample prediction for horizons of one quarter at par or outperform more traditional time series volatility models at longer horizons. Hence, imputing economic fundamentals into volatility models pays off in terms of long-horizon forecasting. We also find that macroeconomic fundamentals play a significant role even at short horizons.","Label":"0"},{"DOI":"10.2139/ssrn.3531182","Abstract":"I construct a simple model with sticky prices and interest rate targets, closed by fiscal theory of the price level with long-term debt and fiscal and monetary policy rules. Fiscal surpluses rise following periods of deficit, to repay accumulated debt, but surpluses do not respond to arbitrary unexpected inflation and deflation, so fiscal policy remains active. This specification avoids many puzzles and counterfactual predictions of standard active-fiscal specifications. The model produces reasonable responses to fiscal and monetary policy shocks, including smooth and protracted disinflation following monetary or fiscal tightening.","Label":"0"},{"DOI":"10.1016/j.econlet.2018.10.005","Abstract":"Yes, they mattered. To reply to this question, we assess the predictive content of macroeconomic and financial latent factors on the key variables (Industrial Productivity, Short-term interest rate, and Inflation) during the Great Recession period (2007–2009) in the United States. In this respect, we propose a forecasting analysis using a Factor Augmented VAR model. When we estimate the model with only financial factors, we improve the predictions in the short and medium horizons. Meanwhile, when we estimate the model with only macroeconomic factors, we improve the forecasting performance in the longer horizon.","Label":"0"},{"DOI":"10.1016/j.chieco.2005.03.002","Abstract":"This article investigates the causes of deflation China has experienced since 1998. The analysis is based on a theoretical model which makes the distinction between tradable and non-tradable goods and on the estimation of a reduced equation of consumer price variations for the period 1986–2002. The empirical results corroborate the theoretical predictions. The main conclusion is that the slowing down of inflation and the fall of prices are chiefly explained by Chinese macroeconomic policy. Moreover and contrary to current opinion we find that deflation is partly due to the deceleration of productivity growth in the tradable sector.","Label":"0"},{"DOI":"10.2139/ssrn.1772971","Abstract":"Specifications of the Federal Reserve target rate that have more realistic features mitigate in-sample over-fitting and are favored in the data. Imposing a positivity constraint and discrete increments significantly increase the accuracy of model out-of-sample forecasts for the level and volatility of the Federal Reserve target rates. In addition, imposing the constraints produces different estimates of the response coefficients. In particular, a new and simple specification where the target rate is the maximum between zero and the prediction of an ordered-choice Probit model is more accurate and has higher response coefficients to information about inflation and unemployment.","Label":"0"},{"DOI":"10.1016/j.econ.2016.12.002","Abstract":"This paper investigates the expectations formation process of economic agents about inflation rate. Using the Market Expectations System of Central Bank of Brazil, we perceive that agents do not update their forecasts every period and that even agents who update disagree in their predictions. We then focus on the two most popular types of inattention models that have been discussed in the recent literature: sticky-information and noisy-information models. Estimating a hybrid model we find that, although formally fitting the Brazilian data, it happens at the cost of a much higher degree of information rigidity than observed.","Label":"0"},{"DOI":"10.1080/1226508x.2020.1748083","Abstract":"On a sample of 150 economies, we characterise the safety of public debt by both ordinary least square and instrument variable regressions. For demand analysis, the public debt is safer for a larger financial market size, a higher financial development level, a lower inflation rate and greater political stability. For supply analysis, the safety of debt improves for a huger debt stock in economies with high income per capita but deteriorates in economies with low income per capita. Cases studies record that, compared with the prediction by economic fundamentals, the investors overestimate the debt safety of China but underestimate that of Greece and Japan.","Label":"0"},{"DOI":"10.1016/j.jmoneco.2019.05.007","Abstract":"A standard model of price-setting is extended to include an important role for price points as well as sticky information. It makes empirically reasonable predictions about the frequency of price adjustments, the sizes of price increases and decreases, the shape of the hazard function, the fraction of price changes that are price increases, and the relationship between price changes and inflation. When the model of price-setting is integrated into a small-scale DSGE model, it implies plausible aggregate effects of monetary policy in contrast to a model with a prominent role for price points but no information rigidities.","Label":"0"},{"DOI":"10.2139/ssrn.1761028","Abstract":"This paper contributes to the ongoing debate about the existence and the source of asymmetric information between the Federal Reserve and the public by examining the federal funds rate forecasts. It shows that the Federal Reserve has superior information about its own future policy actions, the future federal funds rate. It compares the Federal Reserve forecasts with the predictions of alternative forecasting models and forecasts from the futures market for federal funds. It also displays that the source of the private information of the Federal Reserve about inflation is its superior knowledge about its own policy actions.","Label":"0"},{"DOI":"10.1016/s0165-1765(02)00240-9","Abstract":"In this article we test for the structural stability of an output growth forecasting equation that includes the term structure of interest rates as a regressor, for the USA and Canada. We are able to confirm that there is parameter instability as the coefficient associated with the term structure is reduced in size as the policy maker becomes more averse to inflation. Our empirical results are in accordance with the theoretical predictions.","Label":"0"},{"DOI":"10.4337/roke.2021.01.07","Abstract":"Liquidity trap economics seems to have fared particularly well on all counts of its predictions, in the aftermath of the 2008 global financial crisis. Therefore, in this paper we evaluate formally the effectiveness of unconventional monetary policy in a liquidity trap, based on data from Japan, the USA, and the eurozone over periods of liquidity trap conditions (1994–2018 for Japan and 2009–2018 for the USA and the eurozone). Under effective unconventional policies, changes in the base money-growth regime should be associated with similar regime changes in either inflation or investment expenditure growth and the estimation of a switching regimes model allows us to test whether significant joint regime shifts occur in the data. Also, a test of liquidity trap conditions is based on a discrepancy of regime shifts between growth rates of base money and broad money, since this implies a collapse of the money multiplier. Our findings show that drastic shifts in the growth rate of the monetary base do not produce similar behavior for the inflation rate, investment expenditure growth, and broad money growth, thus pointing to liquidity trap conditions and unconventional monetary policy ineffectiveness.","Label":"0"},{"DOI":"10.30541/v57i2pp.175-202","Abstract":"This study empirically examines the contribution of monetary       fundamentals in explaining nominal exchange rate movements in the case       of Pak-rupee vis-à-vis US-dollar over the period 1982Q2 to 2014Q2. The       empirical results support the existence of cointegration relationship       between nominal exchange rate and monetary fundamentals. The results       reveal that relative money stocks and real income are the key drivers of       exchange rate determination in Pakistan in the long-run. For dynamic       interaction, the Structural Vector Autoregressive (SVAR) method is       applied. Results from the SVAR show that the responses of exchange rate       to shocks, originated from money supply, income, interest rate and       inflation differentials, are consistent with the predictions of the       flexible-price variant of the monetary model of exchange rate in the       short-run. More specifically, the results indicate that inflation and       interest rate differential explain maximum variations in exchange rate       in the short-run. In essence, results suggest that monetary fundamentals       are the key drivers of exchange rate fluctuations in Pakistan,       especially in the short-run. JEL Classification: F31, F33, C32, F41       Keywords: Monetary Model, Exchange Rate, SVAR, Pakistan","Label":"0"},{"DOI":"10.2139/ssrn.607663","Abstract":"In this paper, we consider estimation of a time-varying parameter model for a forward-looking monetary policy rule, by employing ex-post data. A Heckman-type (1976) two-step procedure is employed in order to deal with endogeneity in the regressors. This allows us to econometrically take into account changing degrees of uncertainty associated with the Fed's forecasts of future inflation and GDP gap when estimating the model. Even though such uncertainty does not enter the model directly, we achieve efficiency in estimation by employing the standardized prediction errors for inflation and GDP gap as bias correction terms in the second-step regression. We note that no other empirical literature on monetary policy deals with this important issue. Our empirical results also reveal new aspects not found in the literature previously. That is, the history of the Fed's conduct of monetary policy since the early 1970's can in general be divided into three sub periods: the 1970's, the 1980's, and 1990's. The conventional division of the sample into pre-Volcker and Volcker-Greenspan periods could mislead the empirical assessment of monetary policy.","Label":"0"},{"DOI":"10.1080/00036846.2013.807025","Abstract":"Government spending has often varied with the business cycle to stimulate the economy and to revive economic conditions. However, the state of public finances has often necessitated higher borrowing to finance widening fiscal deficits. Indeed, recent austerity packages around the globe have crystalized the importance of fiscal consolidation against the backdrop of rising public debt. To shed light on recent debates regarding fiscal multipliers, the article estimates variation in these multipliers with the method of financing, using annual data for a sample of industrial countries. There is a large variation in the effects of expansionary and contractinary government spending shocks on economic variables within and across countries. The significant effects of negative government spending shocks (fiscal contraction) appear more prevalent than those of expansionary shocks on real output growth, price inflation and nominal wage inflation. Consistent with theory’s predictions, the fiscal multiplier is more likely to be negative when government spending is financed by issuing debt and less likely in the case of monetization. The evidence confirms concerns about the negative effect of higher debt and more expensive financing on private activity, countering the effectiveness of fiscal policy.","Label":"0"},{"DOI":"10.1111/j.1467-6435.2008.00390.x","Abstract":"This paper tests for the Euro zone the hypothesis put forward by Sapir and Sekkat (1999) that synchronizing elections might improve welfare. Implementing political business cycle features into a politico‐macroeconomic model of the Euro zone allows us to simulate the effects of adopting a common election day in the 12 Euro zone member states. The results support most of the theoretical predictions by Sapir‐Sekkat: (i) Synchronizing the elections could enhance GDP growth, reduce unemployment, but leads to increased inflation and in some countries to a deterioration of the budget; higher inflation could force the ECB to monetary restrictions. (ii) If the synchronization happens asymmetrically – either only in the large or only in the small Euro zone countries – the result depends on the size of the spillovers. (iii) As anticipated in Sapir‐Sekkat a common election day is a further step towards the desired ‘European business cycle’, however, at the cost of increasing its amplitude. Harmonizing elections is another method of policy coordination. Whether this leads to higher welfare is a matter of weighting the different macroeconomic outcomes and it also depends on the model applied.","Label":"0"},{"DOI":"10.2139/ssrn.3666196","Abstract":"This paper studies the comparative predictive accuracy of forecasting methods using mixed-frequency data, as applied to nowcasting Philippine inflation, real GDP growth, and other related macroeconomic variables. It focuses on variations of mixed-frequency dynamic latent factor models (DFM for short) and Mixed Data Sampling (MIDAS) Regression. DFM is parsimonious and dependent on a much smaller data set that needs to be updated regularly but technically and computationally more complicated, especially when there are mixed-frequency data. On the other hand, MIDAS is data-intensive but computationally more tractable. The analysis is done through comparison of forecast performance measures (such as mean squared prediction error) and application of statistical tests of comparative predictive accuracy and tests of forecast encompassing. Results obtained so far indicate that just about every method in the pool of forecasting methods studied performs best in some cases and worst in other cases. Thus, there is no clear winner. Under the circumstances, one viable approach in applications is to combine the forecasts from these powerful techniques to improve predictive accuracy. In most cases, least squares weights perform better for purposes of forecast averaging.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2019.04.004","Abstract":"We use a broad-range set of inflation models and pseudo out-of-sample forecasts to assess their predictive ability among 14 emerging market economies (EMEs) at different horizons (1–12 quarters ahead) with quarterly data over the period 1980Q1-2016Q4. We find, in general, that a simple arithmetic average of the current and three previous observations (the RW-AO model) consistently outperforms its standard competitors—based on the root mean squared prediction error (RMSPE) and on the accuracy in predicting the direction of change. These include conventional models based on domestic factors, existing open-economy Phillips curve-based specifications, factor-augmented models, and time-varying parameter models. Often, the RMSPE and directional accuracy gains of the RW-AO model are shown to be statistically significant. Our results are robust to forecast combinations, intercept corrections, alternative transformations of the target variable, different lag structures, and additional tests of (conditional) predictability. We argue that the RW-AO model is successful among EMEs because it is a straightforward method to downweight later data, which is a useful strategy when there are unknown structural breaks and model misspecification.","Label":"0"},{"DOI":"10.1016/b978-008043858-0/50064-4","Abstract":"This chapter discusses the development of an approach that uses an evolutionary strategy as a predictive tool. This approach is simple to implement yet produces results that compare favorably with the neural network predictions. A preferred inflation-forecasting model is achieved using the networks that employ a Divisia M2 measure of money, adjusted to incorporate a learning mechanism to allow individuals to alter their perceptions of the increased productivity of money. The role of monetary aggregates in the major economies today has largely been relegated to one of a leading indicator of economic activity, along with a range of other macroeconomic variables. The empirical work on Divisia money and, in particular, close monitoring of Divisia constructs that have been adjusted to accommodate financial innovation, may serve to restore confidence in former well established money-inflation links. Neural networks clearly provide more accurate forecasts over larger sample sizes as they can learn the data perfectly. Evolutionary strategies are found to compete very favorably with neural networks over smaller sample sizes and can also learn the data perfectly in extreme cases.","Label":"1"},{"DOI":"10.1504/ijcee.2020.107371","Abstract":"The problem of optimal linear filtering, smoothing and trend extraction for m-period differences of processes with a unit root is studied. Such processes arise naturally in economics and finance, in the form of rates of change (price inflation, economic growth, financial returns) and finding an appropriate smoother is thus of immediate practical interest. The filter and resulting smoother are based on the methodology of singular spectrum analysis (SSA). An explicit representation for the asymptotic decomposition of the covariance matrix is obtained. The structure of the impulse and frequency response functions indicates that the optimal filter has a 'permanent' and a 'transitory component', with the corresponding smoother being the sum of two such components. Moreover, a particular form for the extrapolation coefficients that can be used in out-of-sample prediction is proposed. In addition, an explicit representation for the filtering weights in the context of SSA for an arbitrary covariance matrix is derived. This result allows one to examine the specific effects of smoothing in any situation. The theoretical results are illustrated using different datasets, namely US inflation and real GDP growth.","Label":"0"},{"DOI":"10.1007/s10101-012-0117-7","Abstract":"In this paper we test for the populist view of inflation in South America during the eventful period between 1970 and 2007, a period which captures the latest democratic transition in the continent, episodes of hyperinflation and finally macroeconomic stabilisation. The results—based on panel time-series data and analysis—confirm the prediction which suggests that recently elected governments coming into power after periods of political dictatorship, and which are faced with demand for redistribution, end up engaging in populist (or redistributive) policies, which tend to lead to high inflation and overall poor macroeconomic performance. All in all, we suggest that the implementation of democracy as such requires not only the “right political context”—or an appropriately constrained executive—to work well, but it also must come with certain economic institutions (central bank independence and a credible and responsible fiscal authority), institutions that were (coincidentally) absent in South America right after re-democratisation, but which would presumably raise the costs of pursuing populist policies in the first place.","Label":"0"},{"DOI":"10.1002/mde.1480","Abstract":"Most empirical studies on price setting that use micro data focus on advanced industrial countries. In this paper we analyze the experience of an emerging economy, Slovakia, using a large micro‐level dataset that accounts for a substantial part of the consumer price index (about 5 million observations). We find that market structure is an important determinant of pricing behavior. The effect of market structure on persistence of inflation results from two conflicting forces. Increased competition may reduce persistence by increasing the frequency of price changes. On the contrary, higher competition may increase persistence through inertial behaviour induced by the strategic complementarity among price setters. In our case study, we find that the latter effects dominate. Indeed, the dispersion of prices is higher while persistence is lower in the non‐tradable sectors, suggesting that higher competition is not conducive to lower persistence. Furthermore, we find that the frequency of price changes depends negatively on the price dispersion and positively on the product‐specific inflation. These results seem consistent with predictions of Calvo's staggered price model. Copyright © 2009 John Wiley & Sons, Ltd.","Label":"1"},{"DOI":"10.1109/citsm56380.2022.9935930","Abstract":"Digital technology has been implemented into various sectors in Indonesia, such as the education, health, tourism sectors, and one of the most important is in the financial sector. Along with the continued development of technology in the financial sector, it will surely have a good affect to economic development. Along with the development of technology in the financial sector, it will surely have a good affect to economic development. Google trends is one of the open-source tools that can represent what keywords are most often searched by the public. In this study, author conducted research related to the relationship between the development of digital technology in the financial sector and economic development using one of the indicators, namely the inflation rate. The analysis that has been conduct use several data science algorithms and inform algorithm that has the best performance, namely Lasso Regression with MAPE value of 0.16 or 16% which means it can be interpreted as Good Forecasting. And the worst algorithm is Linear Regression with a MAPE value of 0.57 or 57%, which means it can be interpreted as Inaccurate Forecasting.","Label":"1"},{"DOI":"10.17016/ifdp.1995.503","Abstract":"This paper presents a dynamic general equilibrium model of a small, open, monetary economy in order to analyze the short-run effects of credible stabilization plans that fix the nominal exchange rate in a regime of free convertibility. In this model inflation acts as a tax on domestic market transactions. In particular, it generates a wedge between the rate of return on investment in domestic capital and the rate of return on investment in foreign assets. The model stresses the importance of adjustment costs (including gestation lags) in explaining the precise character of the initial dynamics. The main stylized facts of this type of programs namely an initial phase characterized by several months of real exchange rate appreciation, trade balance deterioration and expansion in aggregate demand and production, followed by a deflationary slowdown in real activity, are replicated without resorting to credibility problems, sticky prices, adaptive expectations, or gradual disinflation schemes. Finally, the model is calibrated using long-run relations from the Argentinean economy, and its quantitative predictions are compared to the initial effects of that country's Convertibility Plan of April 1991.","Label":"0"},{"DOI":"10.1057/978-1-349-95121-5_1132-2","Abstract":"Milton Friedman is widely regarded as one of the most important economists of the 20th century. He is famous for his rehabilitation of money as a major determinant of macroeconomic outcomes. For many academic economists, A Theory of the Consumption Function (1957) is his greatest work. Friedman showed that the Keynesian concept of household behaviour was fundamentally flawed, arguing that people adjusted their consumption to variations in their long-term expected (‘permanent’) income. As such, his theory foreshadows the approach to microfoundations that is the cornerstone of modern macroeconomics. His advocacy of economic freedom and market solutions to various socio-economic problems made him a leading policy thinker.","Label":"0"},{"DOI":"10.1590/s0034-71402009000400003","Abstract":"We investigate the role of financial dollarization and systemic risks in the determination of real interest rates in Brazil. In a simple currency-choice portfolio model, we show that a strategy of reducing dollarization, if it fails to address fundamental macroeconomic risks, leads to higher domestic real interest rates. We confirm this prediction in an empirical panel-based model, involving systemic risk variables, but find that the effect is small after controlling for the risks of dilution and default. We apply our empirical estimates to the case of Brazil - a natural case study given its low degree of financial dollarization and very high real interest rates. The estimated model is unable to explain the high interest rate levels in the aftermath of Brazil's 1994 inflation stabilization. However, since the adoption in 1999 of inflation targeting and floating exchange rates, Brazil's real interest rates are found to be gradually converging to the model's predicted values. The estimation also shows that further reductions in Brazil's real interest rates could be achieved through sound fundamentals that led to investment-grade status rather than financial dollarization.","Label":"0"},{"DOI":"10.1016/j.irle.2004.08.004","Abstract":"In this paper we examine the extent to which fluctuations in a number of macroeconomic variables impact on the volume of federal litigation cases. In particular, the impact of aggregate U.S. GDP, consumption, inflation, unemployment, and interest rates on the volume of antitrust, bankruptcy, contract, personal injury, and product liability cases between the years 1960 and 2000 is examined using Granger causal analysis and vector autoregression models [see e.g., Granger, C. W. J. (1988). Some recent developments in a concept of causality. Journal of Econometrics, 39, 199–211]. Our empirical findings suggest that there are several linkages between macroeconomic variables and the volume of litigation cases, in broad agreement with the findings of Siegelman and Donohue [1995; The selection of employment discrimination disputes for litigation: using business cycle effects to test the Priest–Klein hypothesis. Journal of Legal Studies, 24, 427–462], who find that unemployment is an important determinant of the (number and) quality of employment cases filed. Most noteworthy, we find that there is a causal linkage from output, consumption and inflation to the total volume of federal litigation, so that predictions of future litigation volume can be improved by using information contained in current macroeconomic aggregates. Causation in the other direction (i.e. from the volume of litigation to macroeconomic activity) is not found in the data, however. Based on impulse response analysis, it is seen that shocks to income, consumption and inflation immediately lead to an increase in the volume of litigation, with shocks to inflation having the largest impact, and shocks to consumption having a rather moderate impact. In addition, the long run impact that shocks to each of these variables has on the volume of litigation is positive, regardless of whether the VAR or VEC model is used. Here, again, the impact of consumption is quite moderate, though. Additionally, similar results arise when examining the relation between various individual measures of federal litigation volume and the macroeconomy. Thus, the volume of federal litigation does not appear to be immune to the business cycle, a finding which is in broad agreement with the findings of Siegelman and Donohue.","Label":"0"},{"DOI":"10.2139/ssrn.2430177","Abstract":"Paul Krugman recently attacked the Swedish Riksbank for its monetary policy that it has caused a deflationary process because it raised its key interest rate in 2010 and 2011 and by this triggered unnecessarily a deflationary process afterwards. He used the term sadomonetarist for this kind of policy. This response on his accusation of the author of this paper is that Krugman has overdone his challenge of the monetary policy of the Riksbank. He has not looked sufficiently at the empirical facts of the past development in Sweden. In particular at the real GDP growth and the inflation performance it was from the standard approach reasonable to increase interest rates in Sweden after a very strong rebound of Swedish growth in 2010 with 6,6% and further strong economic growth afterwards. Inflation predictions have never been a simple problem due to the multitude of channels through which monetary policy influences economic development. Therefore it is always easy afterwards to claim that policy makers should have done better. However, this is only true ex post by ignoring the uncertainty about the future. Furthermore Sweden has experienced a significant deceleration of its inflation rate, i.e. disinflation, but not deflation for a couple of years. This might, however, be caused by external factors like a global slowdown in economic growth and a recession in the Euro area in particular. If unforeseen by the Swedish Riksbank probably due to overoptimistic forecasts of the EU-Commission, this is caused by a forecasting error, but it is not caused by a monetary policy error. A deflationary spiral is even now not in sight in Sweden. The risk of a global deflation has its origins elsewhere in the global economy.","Label":"0"},{"DOI":"10.2139/ssrn.2426244","Abstract":"The Economist magazine has been publishing the Big Mac Index using it as a rule of thumb to determine the over- or under-valuation of international currencies based on the theory of Purchasing Power Parity since 1986. According to the theory, using the Big Mac as a tradable single-good basket, the Dollar-value of the hamburger should be equalized around the world due to arbitrage. The popularity and following of the Big Mac Index led us to the following two questions: 1) How effective is the Big Mac price as an indicator of overall inflation? And 2) to what extent do exchange rate predictions on under- and over-valued currencies have come to fruition? We find that Big Mac prices tend to lag overall inflation rates, which is highly important in studies that use Big Mac prices as measures of affordability or real incomes over time. As a guide to exchange rate movements, we find support for the theory of Purchasing Power Parity but only as a qualitative indicator of movement in the nominal exchange rate in rich and economically stable countries, proving less effective in forecasting exchange rate movements in emerging markets. The statistical analysis is carried out using data from 1986 to 2012 from The Economist and from the World Bank for 54 countries. The importance of these findings lie on the widespread use of the index and thus perpetuation of perceptions on the relative value of currencies in the areas of corporate finance, international trade and finance, and international business.","Label":"0"},{"DOI":"10.1111/j.1468-0084.2005.00145.x","Abstract":"In this paper we construct output gap and inflation predictions using a variety of dynamic stochastic general equilibrium (DSGE) sticky price models. Predictive density accuracy tests related to the test discussed in Corradi and Swanson [Journal of Econometrics (2005a), forthcoming] as well as predictive accuracy tests due to Diebold and Mariano [Journal of Business and Economic Statistics (1995), Vol. 13, pp. 253–263]; and West [Econometrica (1996), Vol. 64, pp. 1067–1084] are used to compare the alternative models. A number of simple time‐series prediction models (such as autoregressive and vector autoregressive (VAR) models) are additionally used as strawman models. Given that DSGE model restrictions are routinely nested within VAR models, the addition of our strawman models allows us to indirectly assess the usefulness of imposing theoretical restrictions implied by DSGE models on unrestricted econometric models. With respect to predictive density evaluation, our results suggest that the standard sticky price model discussed in Calvo [Journal of Monetary Economics (1983), Vol. XII, pp. 383–398] is not outperformed by the same model augmented either with information or indexation, when used to predict the output gap. On the other hand, there are clear gains to using the more recent models when predicting inflation. Results based on mean square forecast error analysis are less clear‐cut, although the standard sticky price model fares best at our longest forecast horizon of 3 years, it performs relatively poorly at shorter horizons. When the strawman time‐series models are added to the picture, we find that the DSGE models still fare very well, often outperforming our forecast competitions, suggesting that theoretical macroeconomic restrictions yield useful additional information for forming macroeconomic forecasts.","Label":"0"},{"DOI":"10.1007/978-3-030-56219-9_24","Abstract":"Pinto, Jeronymo MarcondesMarçal, Emerson FernandesInflation rate forecasting is one most discussed topics on time-series analysis due to its importance on macroeconomic policy. The majority of these papers’ findings point out that forecasting combination methods usually outperform individual models. In this sense, we evaluate a novel method to combine forecasts based on Extreme Learning Machine Method [15], which is becoming very popular but, to the best of our knowledge, has not been used to this purpose. We test Inflation Rate forecasting for a set of American countries, for one, two, three, ten, eleven and twelve steps ahead. The models to be combined are automatically estimated by Rforecast package, as SARIMA, Exponential Smoothing, ARFIMA, Spline Regression, and Artificial Neural Networks. Another goal of our paper is to test our model against classical combination methods such Granger Bates, Linear Regression, and Average Mean of models as benchmarks, but also test it against basic forms of new models in the literature, like [8, 10, 26]. Therefore, our paper also contributes to the discussion of forecast combination by comparing versions of some methods that have not been tested against each other. Our results indicate that none of these methods have an indisputable superiority against the others, however, the Extreme Learning Method proved to be the most efficient of all, with the smaller Mean Absolute Error and Mean Squared Error for its predictions.","Label":"1"},{"DOI":"10.1108/ijhma-05-2020-0050","Abstract":"Purpose Housing price is a barometer of a national economy. In recent years, Iran experienced high inflation in its economy, which affects everything, including housing. The purpose of this study is the estimation of the value of residential apartments of Tehran using ordinary least square (OLS) and geographically weighted regression (GWR) methods.   Design/methodology/approach This paper proposed a method for determining the compound variables and used them to estimate and evaluate the prices in the district six of Tehran city. Also, this paper compared the GWR and OLS methods with different types of factors and their influences in house price estimations.   Findings During the high inflation period of the study period, the age of buildings, inflation, parking, storage room and their locations are the most critical factors that affect the price of apartments in district six of Tehran. Besides, compound variables have the most influence on the prediction of the prices.   Research limitations/implications The exact location of the apartments in the study area were unknown. Therefore, the positions are extracted from their addresses. The uncertainty of location forced us to ignore the neighborhood terms in the hedonic method.   Practical implications The exact locations of the apartments in the study area were unknown. Therefore, the positions are extracted from their addresses. The uncertainty of location forced us to ignore the neighborhood terms in the hedonic method.   Originality/value The originality of the proposed method is that it used a different approach to determine the valid variables of the apartment prices. Also, the evaluation of the method showed that the proposed variables are significantly useful.","Label":"0"},{"DOI":"10.1061/41173(414)389","Abstract":"Regional regression models can be employed to estimate hydrologic statistics at ungauged river sites. The increased availability of watershed characteristics and the use of GIS-based methods to process this data have created situations where a large number of highly correlated watershed characteristics are available as potential model explanatory variables. The use of ordinary least squares (OLS) regression procedures with highly correlated variables can produce multicollinearity, creating highly sensitive parameter estimators with inflated variances, and improper model selection. A Monte Carlo simulation is developed to compare four techniques for handling multicollinearity: OLS, OLS with Variance Inflation Factor screening (VIF), principal component regression (PCR), and partial least squares regression (PLS). Results show the impact of multicollinearity is magnified at smaller samples sizes, higher correlations, and larger model error variances. Although PCR and PLS yield parameter estimators with reduced variances, there is no improvement in model prediction compared to OLS and VIF. Using VIF for screening variables produced small improvements in model predictions. The use of OLS appears warranted as the complexity of using biased regression techniques to address multicollinearity does little to improve model predictions.","Label":"1"},{"DOI":"10.1063/5.0053192","Abstract":"This study is aimed to determine the factors contributing to the prediction of the total Consumer Price Index (CPI) in Malaysia through model selection using LASSO regression. The outliers are identified using the leverage values and studentized deleted residuals while the multicollinearity variables will undergo progressive elimination based on Variance Inflation Factor (VIF) values. K-fold Cross-Validation (CV) method and Mean Square Error of Prediction (MSE(P)) were used to identify the best model. Model-building without removal of outliers (Set A), model-building with the remove outliers based on leverage points and studentized deleted residuals (Set B), model-building after removal of extreme outliers based on the boxplot (Set C) were carried out. The multicollinearity variables were removed for all the three sets. The results showed that the MSE(P) of the best LASSO model in Set C is the smallest compared to the other two sets. The nine major categories such as food and non-alcoholic beverages, alcoholic beverages and tobacco, clothing and footwear, transport, communication, recreation service and culture, education, restaurants and hotels, miscellaneous goods and services have significant contribution in prediction of the total CPI in Malaysia.","Label":"1"},{"DOI":"10.2139/ssrn.971310","Abstract":"We revisit the relation between stock market volatility and macroeconomic activity using a new class of component models that distinguish short run from secular movements. We combine insights from Engle and Rangel (2007) and the recent work on mixed data sampling (MIDAS), as in e.g. Ghysels, Santa-Clara, and Valkanov (2005). The new class of models is called GARCH-MIDAS, since it uses a mean reverting unit daily GARCH process, similar to Engle and Rangel (2007), and a MIDAS polynomial which applies to monthly, quarterly, or bi-annual macroeconomic or financial variables. We study long historical data series of aggregate stock market volatility, starting in the 19th century, as in Schwert (1989). We formulate models with the long term component driven by inflation and industrial production growth that are at par in terms of out-of-sample prediction for horizons of one quarter and out-perform more traditional time series volatility models at longer horizons. Hence, imputing economic fundamentals into volatility models pays off in terms of long horizon forecasting. We also find that at a daily level, inflation and industrial production growth, account for between 10 % and 35 % of one-day ahead volatility prediction. Hence, macroeconomic fundamentals play a significant role even at short horizons. Unfortunately, all the models - purely time series ones as well as those driven by economic variables - feature structural breaks over the entire sample spanning roughly a century and a half of daily data. Consequently, our analysis also focuses on subsamples - pre-WWI, the Great Depression era, and post-WWII (also split to examine the so called Great Moderation). Our main findings remain valid across subsamples.","Label":"0"},{"DOI":"10.18800/economia.202201.006","Abstract":"In this paper we introduce a “power booster factor” for out-of-sample tests of predictability. The relevant econometric environment is one in which the econometrician wants to compare the population Mean Squared Prediction Errors (MSPE) of two models: one big nesting model, and another smaller nested model. Although our factor can be used to improve finite sample properties of several out-of-sample tests of predictability, in this paper we focus on the widely used test developed by Clark and West (2006, 2007). Our new test multiplies the Clark and West t-statistic by a factor that should be close to one under the null hypothesis that the short nested model is the true model, but that should be greater than one under the alternative hypothesis that the big nesting model is more adequate. We use Monte Carlo simulations to explore the size and power of our approach. Our simulations reveal that the new test is well sized and powerful. In particular, it tends to be less undersized and more powerful than the test by Clark and West (2006, 2007). Although most of the gains in power are associated to size improvements, we also obtain gains in size-adjusted-power. Finally we illustrate the use of our approach when evaluating the ability that an international core inflation factor has to predict core inflation in a sample of 30 OECD economies. With our “power booster factor” more rejections of the null hypothesis are obtained, indicating a strong influence of global inflation in a selected group of these OECD countries.","Label":"0"},{"DOI":"10.2139/ssrn.2667881","Abstract":"A prolonged period of extremely low nominal interest rates has not resulted in high inflation. This has led to increased interest in the “Neo-Fisherian” proposition according to which low nominal interest rates may themselves cause inflation to be lower. The fact that standard models of the effects of monetary policy have the property that perfect foresight equilibria in which the nominal interest rate remains low forever necessarily involve low inflation (at least eventually) might seem to support such a view. Here, however, we argue that such a conclusion depends on a misunderstanding of the circumstances under which it makes sense to predict the effects of a monetary policy commitment by calculating the perfect foresight equilibrium consistent with the policy. We propose an explicit cognitive process by which agents may form their expectations of future endogenous variables. Under some circumstances, such as a commitment to follow a Taylor rule, a perfect foresight equilibrium (PFE) can arise as a limiting case of our more general concept of reflective equilibrium, when the process of reflection is pursued sufficiently far. But we show that an announced intention to fix the nominal interest rate for a long enough period of time creates a situation in which reflective equilibrium need not resemble any PFE. In our view, this makes PFE predictions not plausible outcomes in the case of policies of the latter sort. According to the alternative approach that we recommend, a commitment to maintain a low nominal interest rate for longer should always be expansionary and inflationary, rather than causing deflation; but the effects of such “forward guidance” are likely, in the case of a long-horizon commitment, to be much less expansionary or inflationary than the usual PFE analysis would imply.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2018.10.009","Abstract":"The paper proposes a method for forecasting conditional quantiles. In practice, one often does not know the “true” structure of the underlying conditional quantile function, and in addition, we may have a large number of predictors. Focusing on such cases, we introduce a flexible and practical framework based on penalized high-dimensional quantile averaging. In addition to prediction, we show that the proposed method can also serve as a predictor selector. We conduct extensive simulation experiments to asses its prediction and variable selection performances for nonlinear and linear time series model designs. In terms of predictor selection, the approach tends to select the true set of predictors with minimal false positives. With respect to prediction accuracy, the method competes well even with the benchmark/oracle methods that know one or more aspects of the underlying quantile regression model. We further illustrate the merit of the proposed method by providing an application to the out-of-sample forecasting of U.S. core inflation using a large set of monthly macroeconomic variables based on FRED-MD database. The application offers several empirical findings.","Label":"1"},{"DOI":"10.3923/jai.2018.48.54","Abstract":"Stock market is considered the primary indicator of a country’s economic strength and development. Stock Market prices are volatile in nature and are affected by factors like inflation, economic growth, etc. Prices of a share market depend heavily on demand and supply. High demanded stocks will increase in price whereas heavily sold stocks will decrease in price. Fluctuating stock prices affects the investor’s belief and thus there is a need to predict the future stock value. The objective of this review is to predict the stock market prices in order to make more informed and accurate investment decisions. Recent trends in stock market prediction are surveyed. Different types of machine learning classifiers and their respective variants. Various approaches and the results of past years are compared based on methodologies, datasets and efficiency and then it is represented in the form of a Graph. The survey describes different theories and conventional approaches to stock market prediction. Along with it, it discusses recent machine learning techniques along with pros and cons of each technique for effectively predicting the future stock prices followed by various researchers.","Label":"1"},{"DOI":"10.2139/ssrn.3057523","Abstract":"The paper proposes a method for forecasting conditional quantiles. In practice, one often does not know the \"true\" structure of the underlying conditional quantile function. In addition, we may have a potentially large number of the predictors. Mainly intended for such cases, we introduce a flexible and practical framework based on penalized high-dimensional quantile averaging. In addition to prediction, we show that the proposed method can also serve as a valid predictor selector. We conduct extensive simulation experiments to asses its prediction and variable selection performances for nonlinear and linear model designs. In terms of predictor selection, the approach tends to select the true set of predictors with minimal false positives. With respect to prediction accuracy, the method competes well even with those benchmark/oracle methods that know one or more aspects of the underlying quantile regression model. To further illustrate the merit of the proposed method, we provide an application to the out-of-sample forecasting U.S. core inflation using a large set of monthly macroeconomic variables based on the recently developed FRED-MD database. The application offers several empirical findings.","Label":"1"},{"DOI":"10.2139/ssrn.2605533","Abstract":"Standard zero-lower-bound New Keynesian models generate large fiscal multipliers and expansionary negative supply shocks. Thus, according to these models, a political party that implements fiscal contraction coupled with policies to increase aggregate supply should unambiguously cause economic contraction, compared to a party that implements the opposite policies. I test this prediction using high-frequency prediction- and financial-market data from the night of the 2015 U.K. election, which featured two such parties. By analysing financial-market movements caused by clearly exogenous changes in expectations about the election winner, I find that market participants expected higher equity prices and a stronger exchange rate under a Conservative Prime Minister than under a Labour P.M. There were little to no partisan differences in interest rates, expected inflation, or commodity prices. These results cast doubt on the empirical validity of zero-lower-bound New Keynesian models.","Label":"0"},{"DOI":"10.1111/j.1539-6975.2013.12012.x","Abstract":"This article extends the insolvency prediction literature by incorporating macroeconomic conditions and state‐specific factors. The models achieve greater generalizability and predictive accuracy than earlier research while giving fewer false positives. At the firm level, we find insurers with less diversified business, sufficient cash flow, high return on equity, lower leverage, fewer failed Insurance Regulatory Information System ratio tests, and membership in a larger group are less likely to become insolvent. Our findings support the argument that insolvency likelihood increases for insurers domiciled in states with stricter solvency supervision and/or states with less favorable insurance market conditions, and during soft markets; insolvency risk is negatively related to the slope of the yield curve. Our findings also imply that insurers respond efficiently to changes in such market factors as market return, inflation, and catastrophic losses.","Label":"0"},{"DOI":"10.1016/j.jedc.2011.08.011","Abstract":"We explore the role of evolving beliefs regarding the structure of the macroeconomy in improving our understanding of the term structure of interest rates within the context of a simple macro-finance model. Using quarterly vintages of real-time data and survey forecasts for the United States over the past 40 years, we show that a recursively estimated VAR on real GDP growth, inflation and the nominal short-term interest rate generates predictions that are more consistent with survey forecasts than a benchmark fixed-coefficient counterpart. We then estimate a simple term structure model under the assumption that investor risk attitude is driven by near-term expectations of the three state variables. When we allow for evolving beliefs about the macroeconomy, the resulting term structure model provides a better fit to the cross section of yields than the benchmark model, especially at longer maturities, and exhibits better performance in out-of-sample predictions of future yield movements.","Label":"0"},{"DOI":"10.1016/j.jeconom.2016.02.006","Abstract":"We apply a novel methodology for estimating time-varying weights in linear prediction pools, which we call Dynamic Pools, and use it to investigate the relative forecasting performance of DSGE models with and without financial frictions for output growth and inflation from 1992 to 2011. We find strong evidence of time variation in the pool’s weights, reflecting the fact that the DSGE model with financial frictions produces superior forecasts in periods of financial distress but does not perform as well in tranquil periods. The dynamic pool’s weights react in a timely fashion to changes in the environment, leading to real-time forecast improvements relative to other methods of density forecast combination, such as equal-weights combination, Bayesian model averaging, optimal static pools, and dynamic model averaging. We show how a policymaker dealing with model uncertainty could have used a dynamic pool to perform a counterfactual exercise (responding to the gap in labor market conditions) in the immediate aftermath of the Lehman crisis.","Label":"0"},{"DOI":"10.1111/j.1475-4932.1996.tb00953.x","Abstract":"This paper tests a simple open economy growth model on a cross section of OECD countries. The predictions are that the savings rate and population growth rate significantly affect net foreign asset positions. We test these predictions and find support for this hypothesis. We also use this as a starting point to test for additional explanations for the variety of net foreign asset changes during the 1980s. We reject the hypotheses that low productivity or low export penetration, or tight monetary policy has any effect upon net asset accumulation across the OECD countries. These relate to policy debates within Australia. We find the evidence on the effect of fiscal policy on net asset positions is ambiguous, that rates of immigration have no effect on net asset positions, and that tax and inflation distortions are significant in explaining net foreign asset or liability positions.","Label":"0"},{"DOI":"10.2139/ssrn.1777242","Abstract":"We explore the role of evolving beliefs regarding the structure of the macroeconomy in improving our understanding of the term structure of interest rates within the context of a simple macro-finance model. Using quarterly vintages of real-time data and survey forecasts for the United States over the past 40 years, we show that a recursively estimated VAR on real GDP growth, inflation and the nominal short-term interest generates predictions that are more consistent with survey forecasts than a benchmark fixed-coefficient counterpart. We then estimate a simple term structure model under the assumption that the investors' risk attitude is driven by near-term expectations of the three state variables. When we allow for evolving beliefs about the macroeconomy, the resulting term structure model provides a better fit to the cross section of yields than the benchmark model, especially at longer maturities, and exhibits better performance in out-of-sample predictions of future yield movements.","Label":"0"},{"DOI":"10.2139/ssrn.3544987","Abstract":"We study how Medicaid drug procurement rules affect private markets, leveraging new data and changes implemented as part of the Affordable Care Act (ACA). Using a stylized model, we illustrate how the rules of the Medicaid Drug Rebate Program (MDRP) qualitatively distorts pricing and innovation outcomes. Consistent with previous literature, the model predicts that larger mandatory rebates cause firms to set higher initial list prices. However, after factoring in the MDRP's inflation penalty and “best price” provisions, the model predicts that higher Medicaid rebates reduce list price growth, increase private market rebates, and can even encourage higher quality line extensions. We test these predictions using a difference-in-difference analysis that exploits an increase in the minimum Medicaid rebate implemented as part of the ACA. Our empirical results are consistent with the predictions of the model and provide a more nuanced view of the impact of government procurement rules on private drug market outcomes.","Label":"0"},{"DOI":"10.2991/978-94-6463-010-7_20","Abstract":"The price of Bitcoin has soared from $10,000 in 2021 to an all-time high of $60,000 in 2022, with a total market capitalization of more than $1 trillion, and gold has been used as the ultimate asset to protect the economy and protect against inflation. Therefore, it is predicted that gold and Bitcoin Investors can gain more income by monitoring the price trend of the currency and formulating a reasonable investment strategy. In order to obtain a better prediction effect, this paper divides the analysis of gold price prediction into two stages: before the epidemic and after the epidemic. Before the epidemic, the CEEMDAN-WD-WOA-BiLSTM model was used, and after the epidemic, the neural network was used in this paper. For Bitcoin prediction, PCA is used to select indicators with greater impact, and the ARMIA model is used to predict. After the prediction, this article combines various situations, uses the bull and bear market model, pricing index strategy and quantitative evaluation model to decide the amount of gold and Bitcoin to buy, and finally the profit obtained by this method has reached more than 30 within five years times, to provide investors with a practical and effective investment plan.","Label":"1"},{"DOI":"10.1002/for.2729","Abstract":"One of the major motivations for the analysis and modeling of time series data is the forecasting of future outcomes. The use of interval forecasts instead of point forecasts allows us to incorporate the apparent forecast uncertainty. When forecasting count time series, one also has to account for the discreteness of the range, which is done by using coherent prediction intervals (PIs) relying on a count model. We provide a comprehensive performance analysis of coherent PIs for diverse types of count processes. We also compare them to approximate PIs that are computed based on a Gaussian approximation. Our analyses rely on an extensive simulation study. It turns out that the Gaussian approximations do considerably worse than the coherent PIs. Furthermore, special characteristics such as overdispersion, zero inflation, or trend clearly affect the PIs' performance. We conclude by presenting two empirical applications of PIs for count time series: the demand for blood bags in a hospital and the number of company liquidations in Germany.","Label":"0"},{"DOI":"10.30541/v22i3pp.191-210","Abstract":"In this note we point out the importance of using the standard       deviation, S, in economic analysis. not merely as an indicator of       confidence level for prediction, but also as a basic analytical tool. It       is shown that new insights into economic problems may be obtained by       giving closer attention to this statistical index, in addition to the       other more commonly used indices. If the standard deviation for an       economic index is too high. it may be more appropriate to dispense with       the one index for the entire sample and break the sample into two or       more parts, each of which has a reasonable standard       deviation.","Label":"0"},{"DOI":"10.2139/ssrn.1835747","Abstract":"Standard present-value models suggest that exchange rates are driven by expected future fundamentals, implying that current exchange rates contain predictive information about future fundamentals. We test the validity of this key empirical prediction of present-value models in a sample of 35 currency pairs ranging from 1900 to 2009. Employing a variety of tests, we find that exchange rates have strong and significant predictive power for nominal fundamentals (inflation, money balances, nominal GDP), whereas predictability of real fundamentals and risk premia is much weaker and largely confined to the post-Bretton Woods era. Overall, we uncover ample evidence that future macro fundamentals drive current exchange rates.","Label":"0"},{"DOI":"10.1016/0304-3878(91)90004-f","Abstract":"The relationship between market form and price adjustment patterns is examined by using disaggregated price data for Mexico over the 1940–1984 period. Frequency of price adjustment and characteristics of goods and industries appear to be related, as predicted by menu cost and customer market models. The pattern of response followed by individual prices to inflationary shocks is related to their frequency of price adjustment. The typical pattern of response to small and large shocks may differ, contrary to predictions based on models with overlapping contracts. In addition, the empirical results have implications for the relationship between inflation and relative price variability.","Label":"0"},{"DOI":"10.1111/1468-0106.t01-1-00021","Abstract":"A variety of accuracy measures, error diagnostics and rationality tests are applied to the OECD's macroeconomic forecasts for Japan of aggregate demand and output, inflation and the balance of payments. It is found that the OECD forecasts are superior to naive no‐change predictions and forecasts generated by simple autoregressive time‐series models. Most forecasting error is nonsystematic. As predictors of direction the OECD's six‐month ahead forecasts should be considered valuable; this cannot be said for forecasts which look ahead a year and 18 months. Many forecasts fail bias, efficiency and consistency tests so that the rational expectations hypothesis is not generally supported.","Label":"0"},{"DOI":"10.1111/j.1467-8586.2010.00383.x","Abstract":"Motivated by a central banker with an inflation target, we show that the optimal forecast bias under non‐quadratic loss functions and non‐normal forecast errors can decrease or initially increase and then decrease with the forecast horizon. We initially proof that, if the variable to forecast can be described by a generalized Rayleigh distribution, its conditional mean does in general not constitute the optimal prediction under a symmetric target zone loss function. Subsequently, we approximate the target zone loss function to show the potential for variation in optimal bias over the forecast horizon.","Label":"0"},{"DOI":"10.2139/ssrn.883857","Abstract":"Based on a simple model, the paper provides an explanation for illegal oil trade between Nigeria and its neighboring countries. The analysis focuses on the linkages between the level of smuggling and changes in the Government`s fiscal, monetary, and domestic pricing policies. It is shown that smuggling has implications for inflation and currency depreciation. A vicious circle emerges when financial policies are expansionary and policy makers attempt to hold the domestic sale price of oil constant. Macroeconomic indicators of Nigeria over the period 1986-1993 appear to support the predictions of the model. Policy implications of the analysis are also noted.","Label":"0"},{"DOI":"10.1109/icbaie49996.2020.00017","Abstract":"Exchange rate plays a vital role in the healthy development of a country’s economy. The back propagation (BP) neural network is used to predict the trend of the exchange rate of US dollar to China Yuan (USD-CNY) in this paper. And the result indicates that USD-CNY shows a trend of decline in recent years. Through constructing the relational expressions and the analysis of the factor affecting USD-CNY we find that the balance of payments, commodity prices and USD-CNY has a negative correlation; the rate of inflation, gross domestic product (GDP), foreign exchange reserves and USD-CNY has a positive correlation.","Label":"1"},{"DOI":"10.2139/ssrn.1993335","Abstract":"A novel Bayesian method for inference in dynamic regression models is proposed where both the values of the regression coefficients and the importance of the variables are allowed to change over time. We focus on forecasting and so the parsimony of the model is important for good performance. A prior is developed which allows the shrinkage of the regression coefficients to suitably change over time and an efficient Markov chain Monte Carlo method for posterior inference is described. The new method is applied to two forecasting problems in econometrics: equity premium prediction and inflation forecasting. The results show that this method outperforms current competing Bayesian methods.","Label":"0"},{"DOI":"10.1111/jmcb.12106","Abstract":"Standard present‐value models suggest that exchange rates are driven by expected future fundamentals, implying that exchange rates contain information about future fundamentals. We test this key empirical prediction of present‐value models in a sample of 35 currency pairs ranging from 1900 to 2009. Employing a variety of tests, we find that exchange rates have strong and significant predictive power for nominal fundamentals (inflation, money balances, nominal GDP), whereas predictability of real fundamentals and risk premia is much weaker and largely confined to the post–Bretton Woods era. Overall, we uncover ample evidence that future macrofundamentals drive current exchange rates.","Label":"0"},{"DOI":"10.1016/j.jeconom.2013.10.012","Abstract":"A novel Bayesian method for inference in dynamic regression models is proposed where both the values of the regression coefficients and the importance of the variables are allowed to change over time. We focus on forecasting and so the parsimony of the model is important for good performance. A prior is developed which allows the shrinkage of the regression coefficients to suitably change over time and an efficient Markov chain Monte Carlo method for posterior inference is described. The new method is applied to two forecasting problems in econometrics: equity premium prediction and inflation forecasting. The results show that this method outperforms current competing Bayesian methods.","Label":"0"},{"DOI":"10.2139/ssrn.3848067","Abstract":"We extend the Smooth Transition Vector Autoregressive model to allow for identification via external instruments and sign restrictions, while estimating rather than calibrating the parameters ruling the nonlinearity of the model. We hence offer an alternative to using the recursive identification with selected calibrated parameters, which is the main approach currently available. We use the model to study how the effects of monetary policy shocks change over the business cycle. We show that financial variables, inflation and output respond to a monetary shock more in a recession than in an expansion, in line with the predictions from the financial accelerator literature.","Label":"0"},{"DOI":"10.2139/ssrn.2465917","Abstract":"We present a model in which an outside bank and a default penalty support the value of fiat money, and experimental evidence that the theoretical predictions about the behavior of such economies, based on the Fisher-condition, work reasonably well in a laboratory setting. The import of this finding for the theory of money is to show that the presence of a societal bank and default laws provide sufficient structure to support the use of fiat money and use of the bank rate to influence inflation or deflation, although other institutions could provide alternatives.","Label":"0"},{"DOI":"10.1016/j.jedc.2014.04.013","Abstract":"We present a model in which an outside bank and a default penalty support the value of fiat money, and experimental evidence that the theoretical predictions about the behavior of such economies, based on the Fisher-condition, work reasonably well in a laboratory setting. The import of this finding for the theory of money is to show that the presence of a societal bank and default laws provide sufficient structure to support the use of fiat money and use of the bank rate to influence inflation or deflation, although other institutions could provide alternatives.","Label":"0"},{"DOI":"10.1016/j.jmoneco.2023.05.004","Abstract":"Using disaggregated industry-level data, this paper empirically evaluates predictions for the cross-sectional price change distribution made by input-output models with sticky prices. The response of prices to shocks is found to be consistent with the price sensitivities predicted by the input-output model. Moreover, moments of the sectoral price change distribution vary over time in response to the evolution of the network structure. Finally, through a quantitative analysis, demand and supply shocks are disentangled during the pandemic period. Counterfactual analyses show that sectoral supply shocks, aggregate demand shocks and the production network structure contributed significantly to the inflation surge in 2021-2022.","Label":"0"},{"DOI":"10.1016/j.latcb.2022.100047","Abstract":"In this paper, we investigate the growing prominence of credit in the systemic banking crisis prediction literature. Through the application of the signal extraction model and multivariate probit panel regression, we evaluate the performance of the absolute change in credit-to-GDP ratio as an early warning system indicator of systemic banking crises. The findings reveal that the accelerated financialisation of economies turns the excess supply of credit into generating conditions that increase the likelihood of a systemic banking crisis. The findings also indicate that even with persistently low and stable inflation, systemic risk could gradually accumulate through an excessive supply of credit.","Label":"0"},{"DOI":"10.2139/ssrn.3949039","Abstract":"We develop a model of temporary short-selling bans by extending the infinite-horizon speculative bubble model of Scheinkman and Xiong (2003). Our model predicts that a short-selling ban leads to a price inflation that is the highest at the beginning of the ban and gradually converges to zero at the end of the ban. Examining the 2008 short-selling ban of financial stocks in the U.S., we find evidence consistent with this prediction. The innovation of our empirical design is to use the financial segments of non-banned stocks as a control group for the banned financial stocks.","Label":"0"},{"DOI":"10.1016/0261-5606(82)90014-6","Abstract":"Imposing a small number of common, but strong, assumptions allows the varianve of the ex post forecast error in forward exchange rates to be decomposed into its parts—that part due to errors in forecasting relative inflation (the ‘nominal’ error) and that part due to ‘real’ shocks. For a sample of large and small industrial countries we show that real shocks have been predominant in the post-Bretton Woods world. This result implies that models of exchange rate determination which do not explicitly incorporate real shocks are inappropriate for explaining recent exchange rate volatility.","Label":"0"},{"DOI":"10.1016/s0304-3878(00)00111-5","Abstract":"This paper views the budgetary process as a limited contingencies contract between the Treasury and the ministers, allowing a minister to ask for budget revisions. Upon costly verification by the Treasury, the minister may obtain extra funds. For significant state verification costs and for low volatility, the contract is non-contingent. For volatility significant enough, the contract becomes state-contingent — it reduces the initial allocation, and reduces the threshold associated with budgetary revisions. In volatile economics, the projected revenue understates the realized budget, and the average budget error is positive. The model's predictions are confirmed using data from Latin America.","Label":"0"},{"DOI":"10.2139/ssrn.3198687","Abstract":"We propose a new data-rich environment model of the yield curve, the macroeconomy, monetary policies and effective exchange rates for a panel of 11 countries: the iDREAM. The endogenous variables are observable (short- and long-term interest rates, exchange rates) and latent factors (economic activity, inflation, monetary policy). Local economies are modeled in a FAVECM with weakly exogenous variables and then linked by means of a connectedness matrix estimated with a network approach. We show that our approach outperforms alternative forecasting models, including a standard Global VAR, in particular for predictions on international business cycles and long-term interest rates.","Label":"0"},{"DOI":"10.1016/j.jeconom.2014.04.016","Abstract":"We introduce quasi-likelihood ratio tests for one sided multivariate hypotheses to evaluate the null that a parsimonious model performs equally well as a small number of models which nest the benchmark. The limiting distributions of the test statistics are non-standard. For critical values we consider: (i) bootstrapping and (ii) simulations assuming normality of the mean square prediction error difference. The proposed tests have good size and power properties compared with existing equal and superior predictive ability tests for multiple model comparison. We apply our tests to study the predictive ability of a Phillips curve type for the US core inflation.","Label":"0"},{"DOI":"10.2139/ssrn.4234838","Abstract":"We develop a model of temporary short-selling bans by extending the infinite-horizon speculative bubble model of Scheinkman and Xiong (2003). Our model predicts that a temporary short-selling ban leads to a price inflation that is the highest at the beginning of the ban and gradually converges to zero at the end of the ban. Examining the 2008 short-selling ban of financial stocks in the U.S., we find evidence consistent with this prediction. The innovation of our empirical design is to use the financial segments of non-banned stocks as a control group for the banned financial stocks.","Label":"0"},{"DOI":"10.48550/arxiv.2010.10435","Abstract":"In this paper, we propose a new nonparametric estimator of time-varying forecast combination weights. When the number of individual forecasts is small, we study the asymptotic properties of the local linear estimator. When the number of candidate forecasts exceeds or diverges with the sample size, we consider penalized local linear estimation with the group SCAD penalty. We show that the estimator exhibits the oracle property and correctly selects relevant forecasts with probability approaching one. Simulations indicate that the proposed estimators outperform existing combination schemes when structural changes exist. Two empirical studies on inflation forecasting and equity premium prediction highlight the merits of our approach relative to other popular methods.","Label":"1"},{"DOI":"10.2139/ssrn.2920496","Abstract":"We explore empirically the theoretical prediction that optimism or pessimism have aggregate effects, in the context of monetary policy. First, we quantify the tone conveyed by FOMC policymakers in their statements using computational linguistics. Second, we identify sentiment as the unpredictable component of tone, orthogonal to fundamentals, expectations, monetary shocks and investors’ sentiment. Third, we estimate the impact of FOMC sentiment on the term structure of private interest rate expectations using a high-frequency methodology and an ARCH model. Optimistic FOMC sentiment increases policy expectations primarily at the one-year maturity. We also find that sentiment affects inflation and industrial production beyond monetary shocks.","Label":"1"},{"DOI":"10.1080/00220380902935840","Abstract":"This paper examines the determinants of household saving in China and India over the last few decades using the life cycle model, with appropriate modifications to account for the expected benefits of pension saving. Consistent with the predictions made in the life cycle model, higher income growth promotes more household saving, and higher age dependency does the opposite. An increase in the inflation rate appears to encourage household saving. Interestingly, the evidence suggests that an increase in expected pension benefits tends to discourage household saving in China in the long run, but the reverse is found in India.","Label":"0"},{"DOI":"10.2139/ssrn.3245027","Abstract":"This paper highlights the relation of two independent streams of the literature, the literature on bond covenants and literature on credit rating inflation and addresses how bond covenants are used to inflate bond ratings to comply with regulation on market access. Agency cost theory predicts that bond covenants can decrease the borrowing cost of issuers, especially for low-grade bonds. In contrast to this prediction, our generalized DID estimations find that in the Chinese bond market, investors require a much higher risk premium (180 bps) for AA bonds that are secured with collateral and guarantees than they do for AAA bonds. AA bonds also have worse ex post performance than other bonds, and their issuers engage in more earnings management ex ante than other issuers. More importantly, such an effect clusters in AA bonds, which is the threshold for credit ratings set by regulation. These findings cannot be explained by agency costs, the pay-model of credit rating agencies (CRAs) or competition. This effect is much weaker in a different segmented bond market that is not subject to such rating-based regulation, and we further estimate the deadweight loss of AA bonds (i.e., the marginal bonds most influenced by regulation) to be at least 84 bps.","Label":"0"},{"DOI":"10.2139/ssrn.2831045","Abstract":"Many firms that produce expert product reviews have a vested interest in increased consumption of the products they review. The classic example is the Michelin Guide, which reviews restaurants, originally conceived to stimulate usage of automobiles and therefore also demand for automobile-related goods and services. The result is a conflict of interest; such firms have financial incentive to give better reviews than products merit. I compare video game reviews from two sources: one a video game magazine owned by a game retailer and the other a game website that does not sell games. The goal of the research is to evaluate to what extent, if any, the retailer-owned outlet inflates its reviews in order to boost sales. Results show no evidence of seasonal or cyclical effects. However, there is some evidence of increased inflation in periods shortly following the release of a game's corresponding piece of hardware. Other literature on this industry finds that reviews have the largest effect on the sales of low-quality games, and I find evidence of review inflation for these games. These results are consistent with theoretical predictions for a firm that optimizes the trade-off between sales revenue and the reputational costs associated with biasing reviews.","Label":"0"},{"DOI":"10.1051/shsconf/202213201007","Abstract":"The Phillips curve was supposed to mean an expansion of the doctrine based on the original regulatory ideas of J. M. Keynes. At the time of its inception (1950s), it gave governments theoretical hope, coming from the possibility of choosing a negative correlation between the price level (P) and the product (Y). Her early denial (at least in the short term) by Milton Friedman, on the other hand, has not changed anything about other applications that are still relevant until present time. In the fact, advantage of Phillips curve is her ability based on broad-spectrum use for any type of national economy. The aim of this work is to determine the shape of the Phillips curve for the Czech Republic in the period from 2000 to the present and to compare its shape with the shape of the original Phillips curve. The method of regression analysis is used here, comparison and prediction are performed using time series. In this paper, we find out what the short-term Phillips curve looks like for the Czech Republic, that it does not coincide with the original Phillips curve, and that in the future we can count on a growing correlation between inflation and unemployment.","Label":"0"},{"DOI":"10.11594/ijmaber.04.01.01","Abstract":"The global economy in recent years has shown a downward trend and is predicted by the World Bank to become a recession in 2023. As a global economic phenomenon, this condition will affect every country, including Indonesia’s. This study analyzed the ability of Indonesia's economic fundamentals in a qualitative descriptive and literature study based on five indicators of the economic crisis, namely: economic growth, the exchange rate of the rupiah against the US dollar; inflation; economic growth; and total foreign debt, by comparing conditions during the economic crisis in 1998 and 2008, with Indonesia's current economic situation (in 2022). The results of this study indicated that Indonesia's economic condition is considered quite ready and stable to face the threat of a global economic crisis in 2023. However, as a country that depends on global economic relations, Indonesia will indirectly or directly impact the economic fluctuations and inflation that occur in many countries during the crisis because the economic crisis will have social and political impacts. This research suggests that Indonesia should focus on maintaining economic continuity in the real sector, maintaining the supply of basic needs at the community level, building economic independence by encouraging more production, and supporting political and security stability.","Label":"0"},{"DOI":"10.1080/00036846.2015.1013619","Abstract":"This study presents a first attempt at investigating whether the international co-movements of real economic activity conform to the same international co-movements of financial activity. This study tests the international co-movements of real economic activity, on the one hand, and financial variables such as stock returns, interest rates, inflation rates and risk premiums, on the other hand. We employ a dynamic correlation model on data from OECD countries for the period 1980–2010. Our findings demonstrate that international stock markets co-react in accordance with the underlying international economic forces. We also document three other results. First, the correlation among countries with respect to real economic activity is statistically positive, but the level of this correlation is lower than that of financial variables. Second, there is a significant increase over time in the international correlation level with respect to the financial variables. Finally, the creation of the Euro Monetary Union and the adoption of an inflation targeting policy in many countries have increased the international correlation of all of the financial variables tested. The article concludes with two implications from these findings: (1) predictions in the context of international portfolio diversification, and (2) policy making at the fiscal and monetary levels.","Label":"0"},{"DOI":"10.2139/ssrn.4162347","Abstract":"The goal of this study is to model the global annual natural gas production using a variety of machine learning models in order to predict future production and determine a peak production date. World GDP (at PPPs), inflation percentage, Henry Hub Price, Euro Price, cumulative natural gas resources, and annually discovered new resources were taken as descriptor variables, and Shapley analysis was conducted to observe the importance of features on the dataset. It was revealed according to this analysis that, Henry Hub price, inflation percentage, and newly discovered resources had minor effects on natural gas production, so they were left out. A variety of machine learning algorithms were employed and the one with the highest prediction ability was found to be the stochastic gradient descent algorithm. Nest, this model was tested under four different scenarios, each with different GDP and natural gas price projections. Finally, natural gas production was found to reach its peak sometime between 2034 and 2046. It was then concluded that rather than relying on a traditional approach based on the Hubbert Curve, a machine learning model that takes into account all relevant factors can be used to accurately forecast natural gas production and its peak time, allowing governments and policymakers to make the necessary preparations.","Label":"1"},{"DOI":"10.2139/ssrn.3762355","Abstract":"This paper investigates the effect of sales and promotions on the pricing decisions of firms by providing a novel theoretical model where firms face menu costs when adjusting their price and offer items on sale to attract bargain hunters. It is demonstrated that in a recession, the frequency of items on sale increases as well as the effort of consumers to locate such offers. Since the decrease in the cost of living following a recession comes both from price decreases and the combination of more frequent sales and more active bargain hunting by consumers, a price index that simply focuses on prices and neglects high frequency sales and their weight in the consumer's basket appears to be less responsive to shocks. This can explain the low response of inflation in the post-crisis period and thus the breakdown of the Phillips curve as sales items are under-represented in common price indexes. This study also show that a price index created by placing more weight on sale items in the UK CPI correlates better with the output gap, confirming the model's predictions. Additionally, if agents form inflation expectations using indices that neglect sales and promotions, recessions are exacerbated.","Label":"0"},{"DOI":"10.2139/ssrn.3269862","Abstract":"Movements in the stock market should reflect expectations regarding future economic conditions and lead the macroeconomy. However, evidence for stock returns providing such predictive power is mixed. We argue this arises as stock returns are noisy and consider the predictive ability of derived expected returns, as well as, the price-earnings ratio, VIX and the stock/bond return correlation. Results reveal that expected stock returns and the stock/bond return correlation exhibit predictive power for output and consumption growth and inflation at monthly and quarterly frequencies. The VIX has predictive power at the monthly frequency for consumption growth and inflation, while the price-earnings ratio predicts the shape of the future term structure. Results reveal that higher current expected returns are consistent with to higher future output and consumption growth, while greater risk results in lower future economic activity. The results are robust to considerations of structural breaks and alternative variables. Further, expected returns provides a noticeably more accurate recession prediction than realised returns. Thus, while stock returns are a weak predictor, expected returns and alternative proxies for stock market risk do reveal predictive power. Such information provides a leading role indicator for the macroeconomy and reveals links between financial markets and the economy.","Label":"0"},{"DOI":"10.1109/icoict.2018.8528774","Abstract":"Stock is a high risk and high return investment. The risk-comparison scale for both losses and profits are not much different. The lure of profits temptations can be given by playing shares, sometimes make people less cautious and eventually fail to invest in stocks. To make right and profitable investment decisions, investors need to face uncertainty and fluctuating stock price movements. These phenomena cause investors to predict stock price movements for minimizing risks. The purpose of this study is to predict the Indonesian composite stock price index by using macroeconomic variables as a reflection of economic condition and as a good signal to forecast stock prices. This research is using Inflation, Interest Rates, and Exchange Rates as the macroeconomic variables. This study uses secondary data from Bank Indonesia and Indonesian Statistics Center from December 2005 to November 2017. The prediction uses Artificial Neural Network (ANN) Backpropagation method. The results gained the accuracy of 96,38% and mean-squared error of 0.0046 with the best time delay of 2 months before the predicted month. Based on the accuracy level and the error, macroeconomic variables (exchange rate, interest rate, inflation rate, and money supply M2) are the proper indicator to predict IDX Composite movement.","Label":"1"},{"DOI":"10.54691/bcpbm.v38i.3902","Abstract":"The Federal Reserve Board of Governors made the decision to increase the target range for the federal funds rate for the fourth time in 2022 on July 27. Due to the fact that many global events took place, such as the Covid-19 Pandemic, the China-US trade war, and the Russia-Ukraine war, these changes brought about the worst economic collapse seen in the United States since the Great Depression, which led to the highest inflation rate seen in the 21st century. The decision was made by the government of the United States to raise the federal funds rate in order to reduce inflation and achieve market stability and smoothness. The effects of rate rise by the Federal Reserve are substantial in a variety of contexts, particularly in the semiconductor sector. This research chose a well-known Chinese company, Taiwan Semiconductor Manufacturing Company, and intercepted its stock data from 2019 to 2022. It then used both the VAR model and the ARMA-GARCH model to simulate and analyze the data, studied the influence of Fed rate hikes on this Chinese semiconductor company’s yield and volatility rate, also made a future prediction of this Chinese semiconductor company’s development, and finally offered some comments and suggestions for the company.","Label":"0"},{"DOI":"10.1007/s00181-022-02243-3","Abstract":"This paper investigates the effect of sales and promotions on the pricing decisions of firms by providing a novel theoretical model where firms face price adjustment costs and offer items on sale to attract bargain hunters. It is demonstrated that in a recession, the frequency of items on sale increases as well as the effort of consumers to locate such offers. Since the decrease in the cost of living following a recession comes both from price decreases and the combination of more frequent sales and more active bargain hunting by consumers, a price index that simply focuses on prices and neglects high-frequency sales and their weight in the consumer’s basket appears to be less responsive to shocks. This can explain the low response of inflation in the post-crisis period and thus the breakdown of the Phillips curve as sales items is under-represented in common price indexes. This study also shows that a price index created by placing more weight on sale items in the UK CPI correlates better with the output gap, confirming the model’s predictions. Additionally, if agents form inflation expectations using indices that neglect sales and promotions, recessions are exacerbated.","Label":"0"},{"DOI":"10.1109/icoten52080.2021.9493468","Abstract":"Digital transformation forces the utilization of e-money during the economic transaction. Behind its advantages, e-money has been influenced by the inflation rate, thus accelerating the country’s money circulation. Moreover, the fragile Covid-19 economy triggers each country’s need to anticipate the circulation of e-money to deter future inflation. Therefore, this paper deployed the Backpropagation approach integrated with the Genetic Algorithm to forecast the dissemination of e-money in Indonesia by exploiting time-series Bank Indonesia (BI) data from January 2009 to December 2019. Here, 120 data with 12 variables are considered to thoroughly predict the Year 2020 circulation focusing on the previous 12 months. This study reveals that e-money circulation in Indonesia is increasing monthly in 2020. The testing result shows that the lowest mean square error (MSE) is found at 0.000035 for data training division at 90%:10%, learning rate parameter at 0.8, the combination of crossover probability and mutation at 0.4:0.6, and the total generation and population at 350 and 200, respectively. In a nutshell, Backpropagation with a Genetic Algorithm has been expected to a successful outcome for e-money circulation and provides large values compared with actual data and original BPNN.","Label":"1"},{"DOI":"10.1109/sain.2018.8673347","Abstract":"The economic crisis could take place all over again. It can be prevented and overcome by forecasting economic conditions. The common way to forecast economic conditions is to measure economic growth using inflation-adjusted Gross Domestic Product (GDP) or real GDP. Economic growth gives information about how well the economy performed. Prediction using Artificial Neural Network (ANN) is commonly used. ANN is a computational system inspired by the works of a human brain. The difference between ANN and other computational method is that ANN can solve highly complex and nonlinear problems. Interest in using ANN for forecasting has led to a tremendous surge in research activities in the past decade. ANN provides great prediction result and better accuracy compared to other methods for non-linear variable relations. This research purpose is to predict the Indonesian economic growth by using macroeconomic variables as a good reflection of the economic condition. Prediction with ANN has 95.81% of forecast accuracy and 4.19% of forecast error with the best ANN configuration using 2N+1 formula. Based on accuracy, the ANN method using macroeconomic indicators such as consumption, investment, government expenditure, gross export and gross import is the best way to forecast economic growth.","Label":"1"},{"DOI":"10.48550/arxiv.1710.05944","Abstract":"Economic indicators such as Consumer Price Index (CPI) have frequently used in predicting future economic wealth for financial policy makers of respective country. Most central banks, on guidelines of research studies, have recently adopted an inflation targeting monetary policy regime, which accounts for high requirement for effective prediction model of consumer price index. However, prediction accuracy by numerous studies is still low, which raises a need for improvement. This manuscript presents findings of study that use neuro fuzzy technique to design a machine-learning model that train and test data to predict a univariate time series CPI. The study establishes a matrix of monthly CPI data from secondary data source of Tanzania National Bureau of Statistics from January 2000 to December 2015 as case study and thereafter conducted simulation experiments on MATLAB whereby ninety five percent (95%) of data used to train the model and five percent (5%) for testing. Furthermore, the study use root mean square error (RMSE) and mean absolute percentage error (MAPE) as error metrics for model evaluation. The results show that the neuro fuzzy model have an architecture of 5:74:1 with Gaussian membership functions (2, 2, 2, 2, 2), provides RMSE of 0.44886 and MAPE 0.23384, which is far better compared to existing research studies.","Label":"1"},{"DOI":"10.1111/rssa.12314","Abstract":"Summary With the increasing relevance and availability of on-line prices that we see today, it is natural to ask whether the prediction of the consumer price index (CPI), or related statistics, may usefully be computed more frequently than existing monthly schedules allow for. The simple answer is ‘yes’, but there are challenges to be overcome first. A key challenge, addressed by our work, is that web-scraped price data are extremely messy and it is not obvious, a priori, how to reconcile them with standard CPI statistics. Our research focuses on average prices and disaggregated CPI at the level of product categories (lager, potatoes, etc.) and develops a new model that describes the joint time evolution of latent daily log-inflation rates driving prices seen on the Internet and prices recorded in official surveys, with the model adapting to various product categories. Our model reveals the differing levels of dynamic behaviour across product category and, correspondingly, differing levels of predictability. Our methodology enables good prediction of product-category-specific CPI immediately before their release. In due course, with increasingly complete web-scraped data, combined with the best survey data, the prospect of more frequent intermonth aggregated CPI prediction is an achievable goal.","Label":"1"},{"DOI":"10.2139/ssrn.4342487","Abstract":"We propose a novel time series forecasting method designed to handle vast sets of predictive signals, many of which are irrelevant or have only short-lived predictive power. Examples of such data types are macroeconomic and financial time series. The method transforms heterogeneous (scalar-valued) predictive signals into candidate density forecasts via time-varying coefficient models and, subsequently, combines them into a final density forecast via time-varying subset combination. Our forecasting method is computationally fast because it uses online prediction and updating. In our empirical work, we forecast daily aggregate stock returns using over 12,000 signals and quarterly inflation using over 400 signals. In both applications, we find superior forecasting performance of our approach relative to competitive benchmark methods.","Label":"0"},{"DOI":"10.1016/j.jimonfin.2004.05.003","Abstract":"We examine the movements of exchange rates and capital inflows in an environment where an optimizing central bank pursuing the joint goals of inflation and output targeting engages in costly sterilization activities. Our results predict that when faced with increased sterilization costs, the central bank will choose to limit its sterilization activities allowing target variables, such as the nominal exchange rate, to adjust. We then test the predictions of a linearized version of the saddle-path solution to the model for a cross-country panel of developing countries. We use OLS, IV, and GMM specifications to allow for the endogeneity of capital inflows. Our results confirm that monetary policy does respond to sterilization costs.","Label":"0"},{"DOI":"10.2139/ssrn.1551223","Abstract":"To forecast an aggregate, we propose adding disaggregate variables, instead of combining forecasts of those disaggregates or forecasting by a univariate aggregate model. New analytical results show the effects of changing coefficients, mis-specification, estimation uncertainty and mis-measurement error. Forecastorigin shifts in parameters affect absolute, but not relative, forecast accuracies; mis-specification and estimation uncertainty induce forecast-error differences, which variable-selection procedures or dimension reductions can mitigate. In Monte Carlo simulations, different stochastic structures and interdependencies between disaggregates imply that including disaggregate information in the aggregate model improves forecast accuracy. Our theoretical predictions and simulations are corroborated when forecasting aggregate US inflation pre- and post 1984 using disaggregate sectoral data.","Label":"1"},{"DOI":"10.2139/ssrn.1744127","Abstract":"This paper develops and applies tools to assess multivariate aspects of Bayesian Dynamic Stochastic General Equilibrium (DSGE) model forecasts and their ability to predict comovements among key macroeconomic variables. The authors construct posterior predictive checks to evaluate the calibration of conditional and unconditional density forecasts, in addition to checks for root-mean-squared errors and event probabilities associated with these forecasts. The checks are implemented on a three-equation DSGE model as well as the Smets and Wouters (2007) model using real-time data. They find that the additional features incorporated into the Smets-Wouters model do not lead to a uniform improvement in the quality of density forecasts and prediction of comovements of output, inflation, and interest rates.","Label":"0"},{"DOI":"10.1016/j.iref.2017.03.019","Abstract":"This paper revisits bear market predictability by employing a number of variables widely used in forecasting stock returns. In particular, we focus on variables related to the presence of imperfect credit markets. We evaluate prediction performance using in-sample and out-of-sample tests. Empirical evidence from the US stock market suggests that among the variables we investigate, the default yield spread, inflation, and the term spread are useful in predicting bear markets. Further, we find that the default yield spread provides superior out-of-sample predictability for bear markets one to three months ahead, which suggests that the external finance premium has an informative content on the financial market.","Label":"0"},{"DOI":"10.1016/j.econlet.2014.08.027","Abstract":"This paper suggests using a unit t-value criterion in imposing restrictions on lags to formulate a subset vector autoregressive (VAR) model for the purpose of point forecasts. Among any other alternative models nested to the initial VAR model, this less restrictive modeling strategy produces the smallest log determinant of the residual covariance matrix adjusted by degrees of freedom. Each equation of the finally derived subset VAR model has a maximized R̄2 adjusted by degrees of freedom in samples and consequently a minimized 1-step-ahead prediction error in out-of-samples. The applicability of this modeling strategy is excised to the case of a bivariate VAR model for output growth and inflation.","Label":"0"},{"DOI":"10.1155/2013/954071","Abstract":"We find that individuals’ opinions concerning protectionist policies match with how their revenue could be affected in the medium or long term by trade liberalisation in line with predictions of the comparative advantage models. An adverse macroeconomic context (large increase in the unemployment rate or inflation rate) increases protectionist attitudes, thus reflecting that people do not trust that free trade will lead to lower prices or create jobs despite trade theory optimism. People share a mercantilist view of trade since more imports increase protectionism support, while people positively value exports, especially in small countries. Regarding policy measures, while protectionist measures do not influence protectionism support in general, easy access to exports reduces people’s support for protectionism.","Label":"0"},{"DOI":"10.1111/jmcb.12728","Abstract":"This paper examines point and density forecasts of real GDP growth, inflation, and unemployment from the European Central Bank's Survey of Professional Forecasters. We analyze individual uncertainty measures as well as introduce individual point‐ and density‐based disagreement measures. The analysis indicates forecasters’ uncertainty and disagreement display substantial heterogeneity and persistence, with the latter feature challenging a key prediction of expectations models emphasizing information frictions. We also find that uncertainty is characterized by prominent respondent effects and disagreement by prominent time effects, suggesting these divergent properties underlie the well‐documented weak uncertainty–disagreement linkage. Taken together, our results provide a basis for further development of expectations models.","Label":"0"},{"DOI":"10.1111/j.1465-7295.2007.00021.x","Abstract":"This paper explores how the optimal mode of public finance depends on the level of economic development. The theoretical analysis suggests that in the presence of capital market imperfection and liquidity shocks, the detrimental effect of inflation on growth is stronger (weaker) at lower (higher) levels of economic development. Consequently, income taxation (seigniorage) is a relatively less distortionary way of financing public expenditure for low‐income (high‐income) countries. We provide empirical support for our model’s predictions using a panel of 21 Organization for Economic Cooperation and Development countries and 40 developing countries observed over the period 1972–1999. (JEL E44, E6, H6, O42)","Label":"0"},{"DOI":"10.20849/iref.v6i2.1179","Abstract":"Credit risk prediction is a vital issue in empirical studies as it has attracted the interests of many researchers. In the current study, a logistic regression model is used to evaluate determinants of payment default risks of companies in the service sector.Data, which consist of six financial variables and two macro-economic variables, have been collected from the Tunisian Central Bank and World Development Indicators.The obtained results show that debt, solvency and profitability ratios and a loan amount are the key firm-specific factor determining credit risk. Moreover, we further find that high level of inflation and the decrease of GDP growth rate are able to increase corporate credit risk.","Label":"0"},{"DOI":"10.53384/inbe.101518620035","Abstract":"Based on an extended Mundell-Fleming model, this paper finds that both fiscal expansion and monetary expansion raise output in Malaysia and that a lower real interest rate, a higher stock value, a lower real oil price and a lower expected inflation rate increase output. Hence, a managed floating system with no predetermined path of the exchange rate adopted by Malaysia may lead to better outcomes than the predictions of the Mundell- Fleming model that fiscal expansion does not raise output under a floating exchange rate but increases output under a fixed exchange rate whereas monetary expansion increases output under a floating exchange rate but does not affect output under a fixed exchange rate (Mankiw, 2019).","Label":"0"},{"DOI":"10.2139/ssrn.1288211","Abstract":"This paper examines the movements of exchange rates and capital inflows in an environment where an optimizing central bank pursuing the joint goals of inflation and output targeting engages in costly sterilization activities. Our results predict that when faced with increased sterilization costs, the central bank will choose to limit its sterilization activities allowing target variables, such as the nominal exchange rate, to adjust. We then test the predictions of a linearized version of the saddle-path solution to the model for a cross-country panel of developing countries. We use IV, GMM and simultaneous equation specifications to allow for the endogeneity of capital inflows. Our results confirm that monetary policy does respond to sterilization costs.","Label":"0"},{"DOI":"10.1016/0304-3878(94)00068-n","Abstract":"Exchange rate-based stabilization programs in chronic-inflation countries have often been accompanied by an initial expansion of private consumption followed by a contraction. This consumption cycle has been attributed to lack of credibility, in the sense that the public views the reduction in the devaluation rate as temporary. This paper assesses the quantitative relevance of the ‘temporariness’ hypothesis by comparing the predictions of a simple model to the actual figures for seven major programs. The paper concludes that nominal interest rates must fall substantially for the ‘temporariness’ hypothesis to account for an important fraction of the observed consumption booms.","Label":"0"},{"DOI":"10.1287/mnsc.2022.4297","Abstract":"Researchers have often attributed discrete messages such as ratings to a difference in preferences between sender and receiver. By extending a standard model of information transmission, we show that discreteness can also arise when preferences are identical but misinterpretation is possible. Whereas discrete messages are less precise, they are easier to interpret. We provide predictions for the distribution of ratings. If we believe that an observed distribution results from cooperative behavior, the model provides a method for inferring the objectives of the sender and receiver. Ratings inflation and deflation arise as emergent properties of an optimal distribution. This paper was accepted by Gustavo Manso, finance. Supplemental Material: The data files are available at https://doi.org/10.1287/mnsc.2022.4297 .","Label":"0"},{"DOI":"10.2139/ssrn.882790","Abstract":"We suggest an alternative use of disaggregate information to forecast the aggregate variable of interest, that is to include disaggregate information or disaggregate variables in the aggregate model as opposed to first forecasting the disaggregate variables separately and then aggregating those forecasts or, alternatively, using only lagged aggregate information in forecasting the aggregate. We show theoretically that the first method of forecasting the aggregate should outperform the alternative methods in population. We investigate whether this theoretical prediction can explain our empirical findings and analyse why forecasting the aggregate using information on its disaggregate components improves forecast accuracy of the aggregate forecast of euro area and US inflation in some situations, but not in others.","Label":"0"},{"DOI":"10.1016/j.jedc.2006.10.003","Abstract":"Under the assumption of bounded rationality, economic agents learn from their past mistaken predictions by combining new and old information to form new beliefs. The purpose of this paper is to investigate how the policy-maker, by affecting private agents’ learning process, determines the speed at which the economy converges to the rational expectation equilibrium. I find that by reacting strongly to private agents’ expected inflation, a central bank increases the speed of convergence and shortens the length of the transition to the rational expectation equilibrium. I use speed of convergence as an additional criterion for evaluating alternative monetary policies. I find that a fast convergence is not always desirable.","Label":"0"},{"DOI":"10.1016/s0165-1889(06)80002-3","Abstract":"Growing recognition of the importance of stock market phenomena to the real economy underscores the need for models linking exogenous uncertainty, asset market performance, and the rest of the economy in an optimizing framework without certainty equivalence. This paper constructs a three-agent model with continuous-time stochastic variables, uncertain private production and government expenditure, and forward-looking rational agents. The growth rate of output, physical capital accumulation, financial asset returns, and uncertain inflation are determined as functions of the exogenous uncertainty in the economy. Analysis of the model finds that increased risk associated with government policy often reverses in an explainable way the conventional comparative static predictions of nonstochastic macro models.","Label":"0"},{"DOI":"10.1162/asep_a_00548","Abstract":"In this paper we investigate the effect of aging population on property (land) prices. A theory of very-long-run portfolio choice is developed for a transition economy from young and growing to rapidly aging population and applied to estimate property price inflation in Japanese municipal markets. The results are stunning. The simulation results in which income factors are assumed to be fixed at the 2005-10 growth level suggest that the average residential property price (land price) in the Japanese municipalities may decrease by as much as 19 percent from the present to 2020, 24 percent to 2030, and 32 percent to 2040.","Label":"0"},{"DOI":"10.2139/ssrn.878880","Abstract":"The output gapwhich measures the deviation of actual output from its potentialis frequently used as an indicator of slack in an economy. This paper estimates the Finnish output gap using various empirical methods. It evaluates these methods against economic history and each other by a simulated out-of-sample forecasting exercise for Finnish CPI inflation. Only two gap measures, stemming from a frequency domain approach and the Blanchard-Quah decomposition, perform better than the naïve prediction of no change in inflationbut do not improve upon a simple autoregressive forecast. The pronounced volatility of output in Finland makes it particularly difficult to estimate potential output, producing considerable uncertainty about the size (and sign) of the gap.","Label":"0"},{"DOI":"10.5753/eniac.2018.4470","Abstract":"This paper describes the application of KIII, a biologically more plausible neural network model, for forecasting economic time series. K-sets are connectionist models based on neural populations and have been used in many machine learning applications. In this paper, this method was applied to IPCA, a Brazilian consumer price index surveyed by IBGE. The values ranged from August 1994 to June 2017. Experiments were performed using four non-parametric models and seven parametric methods. The statistical metric RMSE was used to compare methods performance. Freeman KIII sets worked well as a filter, but it was not a good prediction method. This paper contributes with the use of non-parametrics models for forecasting inflation in a developing country.","Label":"1"},{"DOI":"10.2139/ssrn.114730","Abstract":"This paper shows that some key stylized facts of exchange-rate-based stabilization plans can be explained by the uncertain duration of the plans themselves. Uncertain duration is modeled to reflect evidence showing that devaluation probabilities are higher when the plans are introduced and abandoned than in the period in between. If contingent-claims markets are incomplete, this uncertain duration distortion introduces temporary fiscal cuts with large wealth effects. Investment and employment are also distorted, and the resulting supply-side effects play a critical role. Stabilizations of uncertain duration entail large welfare costs, but they are preferred to persistent high inflation. Mexico's experience is examined in the light of these predictions.","Label":"0"},{"DOI":"10.1016/j.jeconom.2012.06.008","Abstract":"This paper develops and applies tools to assess multivariate aspects of Bayesian Dynamic Stochastic General Equilibrium (DSGE) model forecasts and their ability to predict comovements among key macroeconomic variables. We construct posterior predictive checks to evaluate conditional and unconditional density forecasts, in addition to checks for root-mean-squared errors and event probabilities associated with these forecasts. The checks are implemented on a three-equation DSGE model as well as the Smets and Wouters (2007) model using real-time data. We find that the additional features incorporated into the Smets–Wouters model do not lead to a uniform improvement in the quality of density forecasts and prediction of comovements of output, inflation, and interest rates.","Label":"0"},{"DOI":"10.1002/for.2969","Abstract":"American popular and Electoral College presidential elections are forecast for 2020 and 2024, employing auto‐regressive time series and cross‐section probit models. Predictions are between the Republican and Democratic parties, not named persons. Year 2020: In July 2020, the Democrats' two party popular vote was predicted to be 52.7%. They received 52.2%. The cross‐section Electoral College model showed Democrats could not win the White House without winning all of Pennsylvania, Michigan, Wisconsin, and Nevada, which they did with 306 Electoral Votes. Year 2024: Democrats are predicted to win the 2024 presidency with 272 electoral votes, including Nevada's six votes and most of the large states they won in 2020. Democrats are predicted to win 53.7% of the popular vote. Fed's policies are expected to reduce inflation to 5.5%. Trump announced his candidacy in November 2022; however, other candidates are announcing for 2024. Trump's extreme positions in office and erratic behavior after losing in 2020 and then encouraging the January 6 insurrection are experiences Democrats can exploit. Events occurring after December 31, 2022, do not influence the predictions presented here.","Label":"0"},{"DOI":"10.1007/s12197-023-09616-z","Abstract":"Abstract As technological innovations gain the capacity to replace human labour, it is increasingly possible that artificial intelligence can lead to higher unemployment rates. This paper is devoted to forecasting unemployment that is based on artificial intelligence as an input of interest by using an artificial neural network learning process. The simulation is performed based on a sample including 23 of the most high-tech and developed economies, over the period from 1998 to 2016. The proposed artificial neural network with one layer and 10 neurons offers good results in terms of unemployment prediction, with an overall coefficient of determination of 0.912. Artificial intelligence input is a top contributor to the prediction of unemployment, along with foreign direct investment, total population, labour productivity, and lagged unemployment. Inflation and government size register a modest contribution. This suggests that forecasts that include this new variable will be more accurate.","Label":"1"},{"DOI":"10.2139/ssrn.875404","Abstract":"Traditionally, models of economic decision-making assume that individuals are rational and emotionless. This chapter argues that the neglect of emotion in economic models explains their inability to predict important aspects of the labor market. We focus on one example: the scarcity of nominal wage cuts. Firms frequently cut real wages of workers, by increasing nominal wages by less than the inflation rate, but seldom cut nominal wages, in contrast to the predictions of the standard, rational model. This pattern suggests that workers exhibit a special resistance to nominal wage cuts, which is hard to explain if they are purely rational. We argue that strong resistance to nominal wage cuts is best understood in terms of a model where, consistent with evidence from psychology and neuroscience, salient features of a situation trigger emotional responses and sway judgment of the entire situation. Since a cut in the wage is a very salient feature, we argue that cutting the nominal wage leads to a reaction that is mainly dominated by emotions. On the other hand, we hypothesize that an increase in the nominal wage produces a more deliberative evaluation, because there is no immediately salient feature: the individual needs to compare the inflation rate to the wage change before it becomes clear whether the change increases or decreases utility, thus producing a more measured response. We present evidence from experiments that supports this argument: self-reported emotions such as anger and surprise respond strongly to nominal wage cuts, but not to decreases in the real wage achieved through increasing the nominal wage by less than the inflation rate. Although emotions may benefit individual workers, by strengthening their bargaining position and preventing wage cuts, we argue that overall impact on labor market outcomes is ambiguous, because a survey of the evidence suggests that higher wages tend to lead to higher unemployment.","Label":"0"},{"DOI":"10.2139/ssrn.2521607","Abstract":"We provide a novel methodology for estimating time-varying weights in linear prediction pools, which we call dynamic pools, and use it to investigate the relative forecasting performance of dynamic stochastic general equilibrium (DSGE) models, with and without financial frictions, for output growth and inflation in the period 1992 to 2011. We find strong evidence of time variation in the pool’s weights, reflecting the fact that the DSGE model with financial frictions produces superior forecasts in periods of financial distress but doesn’t perform as well in tranquil periods. The dynamic pool’s weights react in a timely fashion to changes in the environment, leading to real-time forecast improvements relative to other methods of density forecast combination, such as Bayesian model averaging, optimal (static) pools, and equal weights. We show how a policymaker dealing with model uncertainty could have used a dynamic pool to perform a counterfactual exercise (responding to the gap in labor market conditions) in the immediate aftermath of the Lehman crisis.","Label":"0"},{"DOI":"10.1080/10800379.2016.12097296","Abstract":"This paper evaluates the forecasting accuracy of private sector forecasters who participate in the annual “Media24 Economist of the Year” forecasting competition in South Africa. Our primary aim is to examine whether the accuracy of private sector forecasters improved over time, particularly their ability to predict the 2008/2009 recession and whether there was a distinct change in forecasting accuracy along this turning point of the business cycle. Our estimates from a forecasting error measure known as Theil's U-Statistic show that, on the average, the Root Weighted Mean Squared Error (RWMSE) of the growth forecast for the current period was 0.62 of an adaptive-naïve forecast, whereas the inflation forecast was 0.71 of an adaptive-naïve forecast. In order to determine whether there was an improvement in forecasting accuracy after the recession, we segregate the sample period along this break date and compare the size of the forecast errors between the two periods. To this end, we find that with respect to the growth predictions, there was a marginal reduction in the magnitude of the forecasting errors. However, in the case of inflation forecasts (both current and year-ahead), there was a marked reduction in the size of both the RWMSE and Theil's U-Statistic, implying that the post recessionary period was characterized by an improvement in accuracy of inflation forecasts made by the private sector. Furthermore, with respect to year-ahead forecasts, the results from both the nonparametric and the more formal parametric test allows us to reject the hypothesis of equality between the mean squared errors of the competing forecasts. Although the private sector forecasters were unable to accurately predict the recession, they were at the least able to produce forecasts that were more accurate than the adaptive-naïve model.","Label":"0"},{"DOI":"10.17016/feds.2010.21","Abstract":"Stylized facts on U.S. output and interest rates have so far proved hard to match with DSGE models. But model predictions hinge on the joint specification of economic structure and a set of driving processes. In a model, different shocks often induce different comovements, such that the overall pattern depends as much on the specified transmission mechanisms from shocks to outcomes, as well as on the composition of these driving processes. I estimate covariances between output, nominal and real interest rate conditional on several shocks, since such evidence has largely been lacking in previous discussions of the output-interest rate puzzle. Conditional on shocks to neutral technology and monetary policy, the results square with simple models, like the standard RBC model or a textbook version of the New Keynesian model. In addition, news about future productivity help to explain the overall counter-cyclical behavior of the real rate. A sub-sample analysis documents also interesting changes in these pattern. During the Great Inflation (1959-1979), permanent shocks to inflation accounted for the counter-cyclical behavior of the real rate and its inverted leading indicator property. Over the Great Moderation (1982-2006), neutral technology shocks were more dominant in explaining comovements between output and interest rates, and the real rate has been pro-cyclical.","Label":"0"},{"DOI":"10.2139/ssrn.2996699","Abstract":"The open-economy dimension is central to the discussion of the trade-offs that monetary policy faces in an increasingly integrated world. I investigate the monetary policy transmission mechanism in a two-country workhorse New Keynesian model where policy is set according to Taylor (1993) rules. I find that a common monetary policy isolates the effects of trade openness on the cross-country dispersion alone, and that the establishment of a currency union as a means of deepening economic integration may lead to indeterminacy. I argue that the common (coordinated) monetary policy equilibrium is the relevant benchmark for policy analysis showing that in that case open economies tend to experience lower macro volatility, a flatter Phillips curve, and more accentuated trade-offs between inflation and slack. Moreover, the trade elasticity often magnifies the effects of trade integration (globalization) beyond what conventional measures of trade openness would imply. I also discuss how other features such as the impact of a common and stronger anti-inflation bias, technological diffusion across countries, and the sensitivity of labor supply to real wages influence the quantitative effects of policy and openness in this context. Finally, I conclude that these theoretical predictions are largely consistent with the stylized facts of the Great Moderation.","Label":"0"},{"DOI":"10.1080/01621459.1988.10478646","Abstract":"A methodology for estimating expected real interest rates and making inflation forecasts, together with appropriate confidence intervals, is presented. The role of price expectations in determining real interest rates is also analyzed. Structural breaks in the process generating real interest rates are detected in 1980 and 1983 by tracking the accuracy of interest-rate forecasts. Analysis of these structural breaks reveals that the break at the beginning of 1983 returns the process to its pre-1980 formulation. During 1953-1985, price forecasts derived from the interest-rate model are found to be unbiased once the structural breaks in the real rate process are handled through heteroscedastic corrections. Invoking the rational-expectations hypothesis, we construct a general yet parsimonious dynamic model for estimating economic agents' anticipations of the real rate of interest. By using quarterly data for 1953-1985 the model is efficiently estimated by two-step two-stage least squares. Results provide support for a random-walk process and for the existence of a negative price expectations (Tobin-Mundell) effect on real interest rates. The U.S. economy was subjected to a number of shocks in the early 1980s. A new chairman took the helm of the Federal Reserve System (Fed) in 1979, and almost immediately the Fed announced that it would change its operating procedure from controlling interest rates to targeting the money supply. The Fed then returned to its pre-1979 operating procedure in October 1982. Added to these changes were the tightening of credit controls in the first half of 1980, the advent of the large fiscal deficits of the Reagan administration, and a fall in petroleum prices. To some degree, all of these shocks probably contributed to the greater volatility of the economy in the first few years of the 1980s. In fact, some researchers have recently argued that there have been shifts in the process generating real interest rates in October 1979 and 1982 coincident with the Fed's changes in operating procedure. To investigate the existence and timing of any breaks in the early 1980s we constructed exact (small-sample) confidence intervals for the interest-rate forecasts of investors and tracked them with actual interest rates. We identified a break in the first quarter of 1980 when the actual interest rate no longer fell within the confidence interval for the forecast, and another break in the first quarter of 1983. Adapting the model to account for these structural shifts, we show that, although the 1980-1982 period is significantly different from the pre-1980 period (in terms of parameter values), the post-1982 period is not significantly different from the pre-1980 period. We also construct investors' ex ante forecasts of inflation from the interest-rate model and show them to be unbiased, whereas the inflation forecasts from the Livingston survey are biased. The mean squared prediction error of inflation forecasts improves significantly when price expectations are included as a determinant of ex ante real interest rates. We also find that the forecasting performance of this model compares favorably with the inflation forecasts from the American Statistical Association/National Bureau of Economic Research Business Outlook Surveys.","Label":"0"},{"DOI":"10.1007/s41775-021-00119-4","Abstract":"The aim of this paper is to explore the macroeconomic determinants of corporate financial distress using a data from the Indian corporate sector. We also consider a set of quasi-macro variables to develop a hybrid model of financial distress. For this purpose, we use accounting information-based three-factor criteria to construct a series for probability of financial distress of firms. We initially use a systematic variable selection approach to develop alternative models of financial distress and then apply the bounds test to establish a long-run equilibrium relationship between financial distress of firms and its determinants. We find that macroeconomic factors play crucial role in determining financial distress. Results suggest that aggregate output, flow of international funds, international demand, and corporate profitability are negatively associated with probability of financial distress. However, periods of high inflation may not be beneficial as the results suggest that a high inflation leads to high financial distress. The findings are important in the sense that movement in these macroeconomic and quasi-macro factors can be useful in monitoring the buildup of risk or financial distress in the balance sheet of firms over time. The set of indicators identified in the study can be used to develop an efficient distress prediction models.","Label":"1"},{"DOI":"10.2139/ssrn.3544060","Abstract":"Density forecast combinations are examined in real-time using the log score to compare five methods: fixed weights, static and dynamic prediction pools, as well as Bayesian and dynamic model averaging. Since real-time data involves one vintage per time period and are subject to revisions, the chosen actuals for such comparisons typically differ from the information that can be used to compute model weights. The terms observation lag and information lag are introduced to clarify the different time shifts involved for these computations and we discuss how they influence the combination methods. We also introduce upper and lower bounds for the density forecasts, allowing us to benchmark the combination methods. The empirical study employs three DSGE models and two BVARs, where the former are variants of the Smets and Wouters model and the latter are benchmarks. The models are estimated on real-time euro area data and the forecasts cover 2001–2014, focusing on inflation and output growth. We find that some combinations are superior to the individual models for the joint and the output forecasts, mainly due to over-confident forecasts of the BVARs during the Great Recession. Combinations with limited weight variation over time and with positive weights on all models provide better forecasts than those with greater weight variation. For the inflation forecasts, the DSGE models are better overall than the BVARs and the combination methods.","Label":"1"},{"DOI":"10.1016/j.jmoneco.2005.10.017","Abstract":"In this paper, we consider estimation of a time-varying parameter model for a forward-looking monetary policy rule, by employing ex post data. A Heckman-type (1976. The common structure of statistical models of truncation, sample selection, and limited dependent variables and a simple estimator for such models. Annals of Economic and Social Measurement 5, 475–492) two-step procedure is employed in order to deal with endogeneity in the regressors. This allows us to econometrically take into account changing degrees of uncertainty associated with the Fed's forecasts of future inflation and GDP gap when estimating the model. Even though such uncertainty does not enter the model directly, we achieve efficiency in estimation by employing the standardized prediction errors for inflation and GDP gap as bias correction terms in the second-step regression. We note that no other empirical literature on monetary policy deals with this important issue. Our empirical results also reveal new aspects not found in the literature previously. That is, the history of the Fed's conduct of monetary policy since the early 1970s can in general be divided into three subperiods: the 1970s, the 1980s, and the 1990s. The conventional division of the sample into pre-Volcker and Volcker–Greenspan periods could mislead the empirical assessment of monetary policy.","Label":"0"},{"DOI":"10.1016/j.resourpol.2022.103224","Abstract":"The goal of this study is to model the global annual natural gas production using a variety of machine learning models in order to predict future production and determine a peak production date. World gross domestic product (GDP) based on purchasing power parities (at PPPs), inflation percentage, Henry Hub Price, Euro Price, cumulative natural gas resources, and annually discovered new resources were taken as descriptor variables, and Shapley analysis was conducted to observe the importance of features on the dataset. It was revealed according to this analysis that, Henry Hub price, inflation percentage, and newly discovered resources had minor effects on natural gas production, so they were left out. Then, a variety of machine learning algorithms were employed and the one with the highest prediction ability was found to be the stochastic gradient descent (SGD) algorithm. Next, this model was tested under four different scenarios, each with different GDP and natural gas price projections. Finally, natural gas production was found to reach its peak sometime between 2034 and 2046. It was then concluded that rather than relying on a traditional approach based on the Hubbert Curve, a machine learning model that takes into account all relevant factors can be used to accurately forecast natural gas production and its peak time, allowing governments and policymakers to make the necessary preparations.","Label":"1"},{"DOI":"10.1016/j.resourpol.2021.102297","Abstract":"We find the number of initial public offerings (NIPO) a simple but efficient oil price predictor, and provide new evidence that U.S. dollar index (USDX) also has significant out-of-sample forecasting power on oil price. Furthermore, we reveal the highly complementary relation between NIPO and USDX in forecasting oil price and explain it from the points of linear correlation and economic transmission mechanism. With the help of multivariate prediction methods, both the statistical and economic performance of NIPO and USDX can be tremendously boosted. The oil predictabilities of NIPO and USDX partially stem from the forecasting power on oil market sentiment and inflation, respectively, and they can be further enhanced using appropriate nonlinear model.","Label":"0"},{"DOI":"10.1057/9780230801479_7","Abstract":"The Lucas Critique notwithstanding, applied economic research has paid a great deal of attention in recent decades to the potential for changes in monetary regimes to induce lasting changes in economic structures and behaviour. In particular, given the key role of inflation expectations in wage setting, and the presumed endogeneity of such practices as indexation to the price environment, theorists have developed increasingly sophisticated models of the interaction between central banking and labour market institutions.1 The creation of the euro presents a natural opportunity for the investigation of these models’ predictions. Economies that varied substantially in wage bargaining institutions and practices suddenly underwent a simultaneous shift in monetary regime.","Label":"0"},{"DOI":"10.1002/jae.2430","Abstract":"We examine matched point and density forecasts of output growth, inflation and unemployment from the ECB Survey of Professional Forecasters. We construct measures of uncertainty from individual histograms, and find that the measures display countercyclical behavior and have increased across all forecast horizons since 2007. We also derive measures of forecast dispersion and forecast accuracy, and find that they are not reliable proxies for uncertainty. There is, however, evidence of a meaningful co‐movement between uncertainty and aggregate point predictions for output growth and unemployment. These results are robust to changes in the composition of the survey respondents over time. Copyright © 2015 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.1111/j.1468-0300.2008.00199.x","Abstract":"This paper conjoins the disparate empirical literatures on exchange rate models and monetary policy models, with special reference to the importance of output, inflation gaps and exchange rate targets. It focuses in on the dollar/euro exchange rate, and the differential results arising from using alternative measures of the output gap for the US and for the Euro area. A comparison of ‘in‐sample’ prediction against alternative models of exchange rates is also conducted. In addition to predictive power, I also assess the various models' plausibility as economic explanations for exchange rate movements, based on the conformity of coefficient estimates with priors. Taylor rule fundamentals appear to do as well, or better, than other models at the 1‐year horizon.","Label":"0"},{"DOI":"10.1109/conit55038.2022.9848000","Abstract":"Over the previous decade, Cryptocurrency has maintained a steady increase in popularity. The very nature of cryptocurrencies is such that its imperceptible and ungovernable. These qualities intrigue a large number of people to forecast the future value of distinct cryptocurrencies based on their historical price inflation. This research paper assesses and estimates the price projections and volatility of the cryptocurrency named Ethereum (ETH). We accomplish this objective by the use of 4 machine learning algorithms and 3 deep learning techniques to time series analysis of Ethereum (ETH) prices from August 2015 to December 2021 (2315 days). In terms of RMSE, MAE, MSE, and R2 score, deep learning technique LSTM demonstrated superior prediction accuracy when compared to other learning methods.","Label":"1"},{"DOI":"10.2202/1540-8884.1028","Abstract":"Professor Carpenter challenges the conventional wisdom that George W. Bush must avoid the fate of his father by focusing on the economy. He argues that the economic picture was quite different for father and son, such as dissimilar rates of change in unemployment and inflation during their tenures in office. More importantly, economic approval ratings fail to predict accurately their overall approval ratings. In contrast to the conventional wisdom, Carpenter’s analysis shows that perceptions of foreign policy leadership appear to be more important in predicting approval for both presidencies. And even though the combination of economic and foreign approval ratings appear to drive Bush II’s performance ratings overall, these played a rather insignificant role for Bush I.","Label":"0"},{"DOI":"10.2139/ssrn.1687574","Abstract":"Using a Bayesian likelihood approach, we estimate a dynamic stochastic general equilibrium model for the US economy using seven macro-economic time series. The model incorporates many types of real and nominal frictions and seven types of structural shocks. We show that this model is able to compete with Bayesian Vector Autoregression models in out-of-sample prediction. We investigate the relative empirical importance of the various frictions. Finally, using the estimated model we address a number of key issues in business cycle analysis: What are the sources of business cycle fluctuations? Can the model explain the cross-correlation between output and inflation? What are the effects of productivity on hours worked? What are the sources of the “Great Moderation”?","Label":"0"},{"DOI":"10.1016/j.jebo.2012.10.010","Abstract":"We use a panel dataset to test the stability of measured discount rates over time in response to changes in both macroeconomic events and household-level labor market outcomes. While discount rate measures are constructed to capture a rate of time preference, our evidence is inconsistent with such an interpretation. Our results more closely align with the interpretation that standard methods to elicit discount rates reveal the market interest rate faced by an individual rather than their pure rate of time preference. It follows directly from such an interpretation that factors which influence the interest rate at which a household can borrow and lend, such as the inflation rate and household income, ought to be correlated with the elicited discount rate – a prediction supported by our data.","Label":"0"},{"DOI":"10.1016/j.jimonfin.2012.02.005","Abstract":"The purpose of this paper is to contribute a new model of the Gold Standard, focusing on the interaction between resource scarcity and demographics. In a dynamic micro-founded model we find that: i) prices and equilibrium gold holdings increase with population (a scale effect), but decrease with the population growth rate; ii) that the Gold Standard implies deflation unless extraction resources outstrip population growth; and iii) there is no optimal quantity of money. The predictions of the model are examined using a structural VAR. Our results also shed light on debates about the viability of a return to the Gold Standard, and, more generally, on the interaction between policy variables and scarce resources.","Label":"0"},{"DOI":"10.2139/ssrn.4326865","Abstract":"Standard portfolio theory predicts that investors should invest in diversified portfolios, whatever their risk aversion. The asset management industry, however, is characterized by a lot of differentiated investment funds advertised to investors. This is inconsistent with the predictions of standard portfolio theory and standard rationality assumptions. Apart from the recent inflation of funds there exists also an increase of fund families, which is inconsistent with portfolio theory. The number of funds managed by managing companies has increased tremendously. The paper aims at providing an explanation based on behavioural aspects as documented by the behavioural economics literature. We focus on the flow-performance relationship and show how the convexity of the flow-performance relationship creates incentives for management companies to inflate the family of funds offered.","Label":"0"},{"DOI":"10.2139/ssrn.958687","Abstract":"Using a Bayesian likelihood approach, we estimate a dynamic stochastic general equilibrium model for the US economy using seven macro-economic time series. The model incorporates many types of real and nominal frictions and seven types of structural shocks. We show that this model is able to compete with Bayesian Vector Autoregression models in out-of-sample prediction. We investigate the relative empirical importance of the various frictions. Finally, using the estimated model we address a number of key issues in business cycle analysis: What are the sources of business cycle fluctuations? Can the model explain the cross-correlation between output and inflation? What are the effects of productivity on hours worked? What are the sources of the \"Great Moderation\"?","Label":"0"},{"DOI":"10.1016/j.jmoneco.2021.07.002","Abstract":"This paper studies the dollarization of prices in retail markets of emerging economies. We develop a model of the firm’s optimal currency choice in retail markets in inflationary economies. We derive theoretical predictions regarding the optimality of dollar pricing, and test them using data from the largest e-trade platform in Latin America. Across countries, price dollarization is positively correlated with asset dollarization and inflation, and negatively correlated with exchange rate volatility. At the micro level, larger sellers are more likely to price in dollars, and more tradeable goods are more likely to be posted in dollars. We then show that the currency of prices determines the short-run reaction of both prices and quantities to a nominal exchange rate shock.","Label":"0"},{"DOI":"10.2139/ssrn.2673529","Abstract":"This paper tests whether it is possible to improve point, quantile and density forecasts of realized volatility by conditioning on macroeconomic and financial variables. We employ quantile autoregressive models augmented with a plethora of macroeconomic and financial variables. Complete subset combinations of both linear and quantile forecasts enable us to efficiently summarise the information content in the candidate predictors. Our findings suggest that no single variable is able to provide more information for the evolution of the volatility distribution beyond that contained in its own past. The best performing variable is the return on the stock market followed by the inflation rate. Our complete subset approach achieves superior quantile, density and point predictive performance relative to the univariate models and the autoregressive benchmark.","Label":"1"},{"DOI":"10.3390/jrfm13030044","Abstract":"Professional forecasters can rely on an econometric model to create their forecasts. It is usually unknown to what extent they adjust an econometric model-based forecast. In this paper we show, while making just two simple assumptions, that it is possible to estimate the persistence and variance of the deviation of their forecasts from forecasts from an econometric model. A key feature of the data that facilitates our estimates is that we have forecast updates for the same forecast target. An illustration to consensus forecasters who give forecasts for GDP growth, inflation and unemployment for a range of countries and years suggests that the more a forecaster deviates from a prediction from an econometric model, the less accurate are the forecasts.","Label":"0"},{"DOI":"10.1111/j.1465-7295.2011.00426.x","Abstract":"Dynamic Euler equations restrict multivariate forecasts and so can be estimated and tested using the predictions of professional forecasters. We illustrate this novel, empirical method by studying the links between forecasts of U.S. nominal interest rates, inflation, and real consumption growth since 1981. Using forecast data for both returns and macroeconomic fundamentals exploits the complete panel of forecasts from the Survey of Professional Forecasters, which yields 3,400 observations, many more than the 117 quarterly time‐series observations. Harnessing the full panel enhances precision in testing asset‐pricing models and may avoid aggregation bias. We find clear evidence for the Fisher effect but mixed evidence of a relationship between expectations of real interest rates and real consumption growth. (JEL E17, E21, E43)","Label":"0"},{"DOI":"10.1016/s0261-5606(96)00042-3","Abstract":"We study the effects of a credible, gradual exchange-rate-based disinflation program in a two sector economy. After an initial exchange rate depreciation, the reductions in the rate of devaluation reduce the monetary wedge generated by the cash-in-advance constraint, leading to a gradual increase in absorption that yields progressive real exchange rate appreciations and current account deficits. An initial boom in economic activity is not followed by a later contraction, as labour supply expands during the whole length of the program. Many of the model's predictions are in accordance with the stylized facts on disinflation in chronic-inflation countries, in particular those of the Mexican program of 1988–1992.","Label":"0"},{"DOI":"10.1007/bf01048203","Abstract":"In this paper seven hypotheses to explain variation in central bank independence across countries are tested. The predictions based upon the theory that delegation of authority by politicians to the central bank is used as a commitment device are not supported: central bank independence is not higher the larger the employment motivated inflationary bias, the higher political instability or the larger the government debt. Central bank independence is positively related to historical inflation experience and negatively with political instability. We do only find limited support for the view that countries with a universal banking system and countries whose central banks do not regulate financial institutions have more independent central banks.","Label":"0"},{"DOI":"10.2139/ssrn.926045","Abstract":"We find in cross-sectional investigations that wage restraint is either unchanged or increased following EMU in the vast majority of countries. This contradicts the predictions of a widely-cited family of models of labor market bargaining. In those, Germany would have been expected to display the greatest decline in wage restraint post-EMU, and we find no indication of such a decline. The time-series evidence on Italy shows a significant increase in wage restraint after eurozone entry. This pattern is consistent with the models that emphasise the gains from monetary credibility. The eurozone increase in wage restraint is matched by the increase seen in the UK and Sweden after adopting inflation targeting, another means to credibility.","Label":"0"},{"DOI":"10.1016/j.jfds.2020.04.001","Abstract":"We propose a machine learning toolkit applied to the detection of rare events, namely banking crises. For this purpose, we consider a broad set of macroeconomic series (credit-to-GDP gap, house prices, stock prices, inflation rates, long-term and short-term interest rates, etc.), in combination with their leads and lags, various filtering methodologies, and datascience models that complement time series analysis. The main advantages of the approach are its robustness, its flexibility and its prediction performance. Based on the best model specification, our methodology allows to compute an indicator for the probability of banking crisis along with an alert threshold up to 6 quarters ahead in real time for various developed economies.","Label":"1"},{"DOI":"10.1198/jbes.2010.08110","Abstract":"We propose a method for comparing density forecasts that is based on weighted versions of the continuous ranked probability score. The weighting emphasizes regions of interest, such as the tails or the center of a variable’s range, while retaining propriety, as opposed to a recently developed weighted likelihood ratio test, which can be hedged. Threshold- and quantile-based decompositions of the continuous ranked probability score can be illustrated graphically and provide insight into the strengths and deficiencies of a forecasting method. We illustrate the use of the test and graphical tools in case studies on the Bank of England’s density forecasts of quarterly inflation rates in the United Kingdom, and probabilistic predictions of wind resources in the Pacific Northwest.","Label":"0"},{"DOI":"10.1109/tcss.2022.3229772","Abstract":"One of the problems experienced by micro, small, and medium enterprises (MSMEs) during this pandemic is that most MSME actors do not understand plan-making during a crisis. This situation was exacerbated by erratic commodity prices, which resulted in several MSME players choosing to temporarily close because their turnover got a drastic decline. To help MSME actors maintain their business by knowing commodity price predictions, we propose a deep learning model using the long short-term memory (LSTM) method to predict commodity prices in Indonesia. LSTM is a type of recurrent neural network (RNN) with a memory cell to store information and solve the vanishing gradient problem in RNN. Furthermore, multivariate LSTM leverages the model to predict datasets with more than one feature. This study used a dataset collected from the Pusat Informasi Harga Pangan Strategis Nasional (PIHPS Nasional) managed by the Indonesian Ministry of Finance and Bank Indonesia consisting of significantly contributed food commodities to the formation of (strategic) inflation rates in Indonesia. The time range of commodity prices is from August 1, 2017, to July 30, 2021. There are 11 commodity price features in the dataset, namely, rice, chicken meat, eggs, onions, garlic, large red chilies, curly red chilies, red chilies, green chilies, cooking oil, and sugar. The lowest mean absolute error (MAE) on prediction is up to 255.998 obtained by the attention multivariate LSTM model with the Adam optimizer, adding batch normalization (Batchnorm) layer, reducing LSTM layer, hidden size, and grouped features. It makes the prediction more accurate and avoids overfitting and underfitting in this case.","Label":"1"},{"DOI":"10.35741/issn.0258-2724.55.6.43","Abstract":"This study describes a new idea about comparing two new estimations in nonparametric regression for multiresponse cases or simultaneously model based on Fourier series and kernel estimators enabling the prediction of Indonesian strategic commodity prices during the COVID-19 pandemic. Based on the National Strategic Food Price Information Center in Indonesia, there are 10 strategic commodities in the agriculture, livestock, fishery, and horticultural sectors, which have had the biggest endowment to secure food supplies and the formation of inflation figures in Indonesia. These commodities include rice, chicken meat, beef, chicken, egg, onion, garlic, chili, cayenne, cooking oil, and sugar. Using the goodness estimator of criteria in nonparametric regression, such as the smaller Generalized Cross-Validation, the smaller Mean Square Error, and the larger determination coefficient (R2), the result of this study is Fourier series estimator to predict the prices of 10 food commodities, simultaneously. When compared with the kernel estimator, the Fourier series estimator meets the criteria of goodness with a smaller Mean Square Error value of 0.052 and a larger determination coefficient of 99.0472%. The selected estimator has very good performance to predict the prices of 10 food commodities, because the prediction result has very small Mean Absolute Percentage Error equaling 0.0443%. This prediction result can be used for the government to monitor and evaluate price fluctuations for 10 commodities so that the stability of national strategic commodities becomes daily consumption to be maintained, especially during the COVID-19 pandemic.","Label":"1"},{"DOI":"10.33633/jais.v7i1.6124","Abstract":"In this modern era, one of the businesses that continues to grow is investment. Gold has a more stable value. In Indonesia, there are futures exchange companies that offer gold investment with an online transaction system (E-Trade). The amount of demand and supply, the rate of inflation, economic conditions, and many more can affect the high and low prices of gold. Due to changes in the conditions above, the price of gold may increase, decrease, or remain constant every day. The price of gold that can go up and down causes the need for gold price predictions so that future gold trading investment prospects can be seen. In this final project, the accuracy of Support Vector Regression will be investigated to find out how accurate it is in predicting gold prices with High, Low, Open, Close, and Volume variables. Based on the calculation of the best RMSE in the study, it was found that the best RMSE was to use a Linear kernel with a C of 35 and using a Y variable dataset of 7.4615. The Support Vector Regression Algorithm can predict quite well, as evidenced by the acquisition of fairly good RMSE results. It is necessary to do a simulation of buying and selling gold based on the prediction results and comparing the advantages of the testing data and the actual data.","Label":"1"},{"DOI":"10.2139/ssrn.3529010","Abstract":"This paper provides a detailed assessment of the real-time forecast accuracy of a wide range of vector autoregressive models (VAR) that allow for both structural change and indicators sampled at different frequencies. We extend the literature by evaluating a mixed-frequency time-varying parameter VAR with stochastic volatility (MF-TVP-SV-VAR). Overall, the MF-TVP-SV-VAR delivers accurate now- and forecasts and, on average, outperforms its competitors. We assess the models' accuracy relative to expert forecasts and show that the MF-TVP-SV-VAR delivers better inflation nowcasts in this regard. Using an optimal prediction pool, we moreover demonstrate that the MF-TVP-SV-VAR has gained importance since the Great Recession.","Label":"0"},{"DOI":"10.2139/ssrn.62687","Abstract":"Within a simple formal model, we show that there is a link between workers' consumption patterns and their preferred real wage. A large budget share of illiquid durable consumption goods (such as houses and cars) makes workers more willing to accept a low wage in order to reduce the probability of unemployment, but less willing to lower the real wage if labor demand unexpectedly falls. Moreover, as long as durable consumption goods are financed through imperfectly indexed credit, the budget share of illiquid durable goods affects the impact of inflation on the real wage. These predictions are confronted with data from sixteen OECD countries. We find that high household indebtedness lowers the natural rate of unemployment and increases real and nominal wage rigidity.","Label":"0"},{"DOI":"10.53964/mem.2022001","Abstract":"Background: Stock exchange price prediction is one of the most researched topics, attracting interest from both academics and industry. Various algorithms have been developed since the introduction of Artificial Intelligence (AI) and have been used to forecast equities market movement. Despite all these researches, less attention has been paid to the use of cross validation (CV) approaches for better stock price prediction. Objective: The aim of this work is to predict Nigerian stock prices using machine learning models with K-fold and repeated K-fold CVs. Methods: In this work, we consider the prediction performance of machine learning models under two cross validation approaches, namely K-fold and repeated K-fold CVs and when no cross validation technique is used. The models consider here are simple linear regression model, random forest (RF), classification and regression tree (CART), and artificial neural network and the support Vector Machine model. Standard strategic indicators such as root mean square error and mean absolute error are used to evaluate the models. The financial data including real gross domestic product, inflation rate, exchange rate and interest rate are used as the input units in the model. Results: Predicting models with CVs technique exhibit superior performance to models with no CV technique involved. Conclusion: Modelling and forecasting stock exchange prices using RF model with CV are conducive to prediction for stock exchange price in Nigeria. Future research are warranted to consider other machine learning models with CVs approaches.","Label":"1"},{"DOI":"10.3390/su142114659","Abstract":"In recent years, the bitcoin market has developed rapidly and has been recognized as a new type of gold by many investors. It may replace gold as a hedge against inflation and become a new investment asset for financial management. The investment relationship with gold has increasingly important research value and practical significance. This paper modeled daily price flow data from 11 September 2016 to 10 September 2021 to help market traders determine whether they need to buy, hold, or sell assets in their portfolios daily. The model predicts price fluctuations through linear regression prediction of machine learning, K-Nearest Neighbor (KNN) algorithm. In the linear regression prediction, the goodness of fit of gold is 89.44%, and the goodness of fit of Bitcoin is 98.43%. In the test set prediction of KNN algorithm, the goodness of fit of gold is 97.25%, and the goodness of fit of Bitcoin is 95.06%. Based on this, the optimal investment strategy and the initial investment value are obtained. Empirical analysis shows that bitcoin price volatility and gold price volatility have a strong substitution effect; gold and currency used will be a suitable combination of hedging, which will bring momentum for the development of the market economy and become an important force in the sustainable development of a high-quality-driven economy.","Label":"1"},{"DOI":"10.5937/sjm8-3235","Abstract":"The objective of this study is to introduce new forecasts' accuracy measures for two types of predictions: point forecasts (radical of order n of the mean of squared errors, mean for the difference between each predicted value and the mean of the effective values, ratio of radicals of sum of squared errors (RRSSE- for forecasts comparisons), different versions of U2 Theil's statistic)) and for forecast intervals (number of intervals including the realization, difference between the realization and the lower limit, the upper one, respectively the interval centre). Comparisons are made to present the differences in results determined by the application of the classical measures of predictions accuracy for the inflation and unemployment rate forecasts provided for Romania by Institute for Economic Forecasting (IEF) and National Commission of Prognosis (NCP) on the horizon 2010- 2012 and the values of new point forecasts accuracy measures. The hierarchy of predictions provided by the classical indicators and by the new ones are different. A novelty in literature is also brought by the methods of building the forecasts intervals. In addition to the classical interval based on historical error method, some new techniques of building forecasts are used: intervals based on the standard deviation and those constructed using bootstrap technique bias-corrected-accelerated (BCA) bootstrap method.","Label":"1"},{"DOI":"10.1080/01621459.1987.10478542","Abstract":"Forecasting requires estimates of the error of prediction; however, such estimates for autoregressive forecasts depend nonlinearly on unknown parameters and distributions. Substitution estimators of mean squared error (MSE) possess bias that varies with the underlying model, and Gaussian-based prediction intervals fail if the data are not normally distributed. This article proposes methods that avoid these problems. A second-order Taylor expansion produces an estimator of MSE that is unbiased and leads to accurate prediction intervals for Gaussian data. Bootstrapping also suggests an estimator of MSE, but it is approximately the problematic substitution estimator. Bootstrapping also yields prediction intervals, however, whose coverages are invariant of the sampling distribution and asymptotically approach the nominal content. Parameter estimation increases the error in autoregressive forecasts. This additional error inflates one-step prediction mean squared error (PMSE) by a factor of 1 + p/T, where p is the number of parameters and T is the series length (Bloomfield 1972; Box and Jenkins 1976; Davisson 1965). The increase at greater extrapolation involves parameters of the process (Yamamoto 1976). Simple substitution estimators of squared error possess bias that can dominate attempts to estimate the inflation. The proposed bias-corrected estimator alleviates this problem. For example, in simulations of short series (T + 24) from a first-order model with a coefficient of .8 (.4), the substitution estimator at forecast leads 2 and 3 underestimated the true PMSE by 4.7% and 6.4% (−.4% and −2.2%). The corrected estimator erred by less than .5%. Prediction intervals based on the bootstrap are preferable unless the sampling distribution is known. The bias-corrected estimator of PMSE leads to a very accurate prediction interval for Gaussian data, but its coverage depends on the normality assumption. A bootstrap interval asymptotically approaches the desired coverage but is less efficient. For non-Gaussian data, only the bootstrap intervals necessarily tend toward the correct coverage. Although numerical results show bootstrap intervals tend to lack the nominal coverage by several percentages, this deficiency is consistent across sampling distributions and rapidly decays with increasing series length.","Label":"0"},{"DOI":"10.46338/ijetae0122_02","Abstract":"- Foreign Exchange (Forex) is the exchange / trading of currencies from different countries with the aim of making profit. Exchange rates on Forex markets are always changing and it is hard to predict. Many factors affect exchange rates of certain currency pairs like inflation rates, interest rates, government debt, term of trade, political stability of certain countries, recession and many more. Uncertainty in Forex prediction can be reduced with the help of technology by using machine learning. There are many machine learning methods that can be used when predicting Forex. The methods used in this paper are Long Short Term Memory (LSTM), Gated Recurrent Unit (GRU), Support Vector Regression (SVR). XGBOOST, and ARIMA. The outcome of this paper will be comparison results that show how other major currency pairs have influenced the performance and accuracy of different methods. From the results, it was proven that XGBoost outperformed other models by 0.36% compared to ARIMA model, 4.4% compared to GRU model, 8% compared to LSTM model, 9.74% compared to SVR model. Keywords— Forex Forecasting, Long Short Term Memory, Gated Recurrent Unit, Support Vector Regression, ARIMA, Extreme Gradient Boosting","Label":"1"},{"DOI":"10.1198/jbes.2009.07214","Abstract":"Many recent articles have found that atheoretical forecasting methods using many predictors give better predictions for key macroeconomic variables than various small-model methods. The practical relevance of these results is open to question, however, because these articles generally use ex post revised data not available to forecasters and because no comparison is made to best actual practice. We provide some evidence on both of these points using a new large dataset of vintage data synchronized with the Fed’s Greenbook forecast. This dataset consist of a large number of variables as observed at the time of each Greenbook forecast since 1979. We compare realtime, large dataset predictions to both simple univariate methods and to the Greenbook forecast. For inflation we find that univariate methods are dominated by the best atheoretical large dataset methods and that these, in turn, are dominated by Greenbook. For GDP growth, in contrast, we find that once one takes account of Greenbook’s advantage in evaluating the current state of the economy, neither large dataset methods, nor the Greenbook process offers much advantage over a univariate autoregressive forecast.","Label":"0"},{"DOI":"10.2139/ssrn.3499940","Abstract":"We show how to study time-varying dynamic causal effects of structural shocks using external instruments in a generalized Factor-Augmented-VAR(FAVAR) model with time-varying parameters and stochastic volatility. Specifically, we employ the Bayesian MCMC estimation methodology and focus on global factors of outputs, inflation rates, interest rates, and exchange rates in five representative advanced economies, namely the United States, Canada, Germany, Japan, and the United Kingdom, to study time-varying impacts of an exogenous U.S. monetary policy shock on these open economies. We find uniformly strong evidence over time in support of Dornbusch's theoretical prediction of the exchange rate overshooting in response to an exogenous monetary policy shock. The ``delayed overshooting puzzle'' commonly documented in the literature disappears, likely thanks to the better identification of the exogenous U.S. monetary policy shock via external instruments. We also find that the U.S. monetary policy shock has significant contributions to the dynamics of the exchange rates overall, and the contributions were particularly large during the period of global financial crisis in 2007-2008. We document a great deal of time variations of impacts of the U.S. monetary policy shock on global factors of all other economic variables including interest rates, inflation rates, and outputs. These empirical results lend strong support to the extension of the baseline model to the more general model with time-varying parameters and stochastic volatility.","Label":"0"},{"DOI":"10.1109/icicv50876.2021.9388593","Abstract":"The main objective is to predict GDP Growth by help of other parameters like GDP Per Capita, Inflation Rate, Government Debt, Total Investment, Remittance, Unemployed Rate. The complex relations are obtained by machine learning algorithm among GDP Growth Rate and other parameters to predict GDP Growth Rate that may help everyone to get connected to the field of economy and also to the economist to demonstrate their prediction about the economy. With help of this it is easy to find out the possible way to improve the desire growth of GDP. This project can help to demonstrate our eco-social scenario of future. This project can help to set economic goals for our country and can find out which parameters are most directly related to our GDP Growth and which are less related to our GDP Growth and which are accountable for reducing our GDP Growth. For any country GDP growth is a very important think to follow up. This project will give the analyzed data and we will get proper information to take certain action to keep the growth in higher rate. Through this system it is possible to achieve accurate information about the GDP Growth.","Label":"1"},{"DOI":"10.1109/icoei.2019.8862557","Abstract":"This article is based on a study conducted to understand the relationship between gold price and selected factors influencing it, namely stock market, crude oil price, rupee dollar exchange rate, inflation and interest rate. Monthly price data for the period January 2000 to December 2018 was used for the study. The data was further split into two periods, period I from January 2000 to October 2011 during which the gold price exhibits a raising trend and period II from November 2011 to December 2018 where the gold price is showing a horizontal trend. Three machine learning algorithms, linear regression, random forest regression and gradient boosting regression were used in analyzing these data. It is found that the correlation between the variables is strong during the period I and weak during period II. While these models show good fit with data during period I, the fitness is not good during the period II. While random forest regression is found to have better prediction accuracy for the entire period, gradient boosting regression is found to give better accuracy for the two periods taken separately.","Label":"1"},{"DOI":"10.1007/978-981-19-0098-3_68","Abstract":"Computer researchers and economic experts have been attracted to estimate stock values for many years. As external variables such as inflation and currency rates, socio-economic conditions, and market attitudes are regularly affected by inventory price variations, this problem is highly difficult, nonlinear, and dynamic. Neural network architectures have shown great promise toward solving this problem and have outperformed classical approaches toward stock price forecasting. In the methodology proposed, the stock price is forecasted using two unique architectures—one based on LSTM-RNNs, and the other based on transformers and time embeddings—that deal with time series sequences that are augmented by an NLP-based market sentiment-analyzing plugin that utilizes FinBERT. Stocks that are listed on the NYSE that have been considerably affected by recent developments in their respective sectors are used. Experiments show that this framework shows considerable improvement in stock price prediction compared with other standard methods in time series forecasting.","Label":"1"},{"DOI":"10.1063/5.0075657","Abstract":"The aim of this research is to determine the factors contributing to the prediction of the total Consumer Price Index (CPI) in Malaysia through model selection using two methods which are the best subset and LASSO regression. The outliers are identified using the leverage values and studentized deleted residuals while the multicollinearity variables will undergo progressive elimination identified through Variance Inflation Factor (VIF) values. Both methods were compared using the Mean Square Error of Prediction (MSE(P)) to find the best procedure to display the CPI data. The model with the smallest MSE(P) will be chosen as the best model. The result showed that the MSE(P) of the best model using both the best subset regression and LASSO regression is almost the same. Therefore, the model selection using LASSO regression will be chosen as the best approach due to the simple process of identifying the best model. The best LASSO model consists of nine major categories such as food and non-alcoholic beverages (X1), tobacco and alcoholic beverages (X2), footwear and clothing (X3), transport (X7), communication (X8), culture and recreation service (X9), education (X10), hotels and restaurants (X11), miscellaneous service and goods (X12).","Label":"1"},{"DOI":"10.2139/ssrn.2720427","Abstract":"We examine the macroeconomic effects of forward guidance shocks at the zero lower bound. Empirically, we identify forward guidance shocks using unexpected changes in futures contracts around monetary policy announcements. We then embed these policy shocks into a standard vector autoregression to trace out their macroeconomic implications. Forward guidance shocks that lower expected future policy rates lead to significant increases in economic activity and inflation. After examining forward guidance shocks in the data, we show that a standard model of nominal price rigidity can reproduce our empirical findings. To estimate our theoretical model, we generate a model-implied futures curve which closely links our model with the data. Our results suggest no disconnect between the empirical effects of forward guidance shocks and the predictions from a simple theoretical model.","Label":"0"},{"DOI":"10.1111/j.1468-0343.2006.00162.x","Abstract":"This paper offers an alternative to the view that budgetary decisions are incremental because they are complex, extensive, and conflicted. Our model interprets incrementalism as the result of a legislative political strategy in response to interest group politics and economic conditions. Accordingly, a legislator chooses between single‐period budgeting or multiperiod budgeting, where single‐period budgeting is associated with a greater chance of non‐incremental budgeting outcomes. We use a statistical procedure developed by Dezhbakhsh et al. (2003) for identifying non‐incremental outcomes to test the implications of the model. Results support the model's predictions: a higher discount rate and a persistently large deficit appear to cause departures from incremental budgeting; Democrats' control over the political process have a similar effect, while a higher inflation rate has an opposite effect.","Label":"0"},{"DOI":"10.1787/jbcma-v2009-art3-en","Abstract":"A dynamic factor model is applied to a large panel dataset of Singapore’s macroeconomic variables and global economic indicators with the initial objective of analysing business cycles in a small open economy. The empirical results suggest that four common factors – which can broadly be interpreted as world, regional, electronics and domestic economic cycles – capture a large proportion of the co-variation in the quarterly time series. The estimated factor model also explains well the observed fluctuations in real economic activity and price inflation, leading us to use it in forecasting Singapore’s business cycles. We find that the forecasts generated by the factors are generally more accurate than the predictions of univariate models and vector autoregressions that employ leading indicators.","Label":"0"},{"DOI":"10.1016/j.jinteco.2005.11.002","Abstract":"This paper explores the role of exchange rate regimes in explaining deviations from the classic theory of purchasing power parity. Examining a broad panel of countries, I find that developing countries with fixed exchange rate regimes have national price levels that are 20 percent higher than those with flexible regimes. For industrial countries, the relation between regimes and price levels is qualitatively similar but weaker. I investigate several explanations for this pattern, and find that exchange-rate overshooting in floats, inflation inertia in pegs and expansionary policies can explain only 5 percentage points of the observed differences. I also show that even though the observed pattern could be the outcome of a class of open economy models pioneered by Obstfeld and Rogoff, the data provides limited empirical support for the predictions of this model.","Label":"0"},{"DOI":"10.4324/9780203448298","Abstract":"First published in 1981, Labour Market Economics develops the basic economic theory of introductory courses within the context of labour market analysis and applies it both to particular features and special problems of the subject. The author begins by outlining the nature of the area and the structure of the UK labour market at the time, and proceeds to explain and elaborate the tools of theoretical analysis. These are then applied in subsequent chapters to a variety of issues, including the economic analysis of trade unions, collective bargaining and the effects of unions, unemployment, wage inflation and the inequality of pay. Throughout the book, emphasis is placed on the economic theory of the labour market and the role of empirical work in testing its predictions, and wherever available, evidence from studies of the UK labour markets is cited.","Label":"0"},{"DOI":"10.1080/09538259.2020.1810887","Abstract":"Though Minsky developed a compelling verbal model of the ‘Financial Instability Hypothesis' (FIH), he abandoned his early attempts to build a mathematical model. I show that the essential characteristics of Minsky's hypothesis are emergent properties of a complex systems macroeconomic model which is derived directly from macroeconomic definitions, augmented by the simplest possible assumptions for relations between system states, and the simplest possible behavioural postulates. I also show that credit is an essential component of aggregate demand and aggregate income, given that bank lending creates money. Minsky's Financial Instability Hypothesis is thus derived from sound macrofoundations. This stylized complex-systems model reproduces both the core predictions of Minsky's verbal hypothesis, and empirical properties of the real world which have defied Neoclassical understanding, which were not predictions of Minsky's verbal model: the occurrence of a ‘Great Moderation' — a period of diminishing cycles in employment, inflation, and economic growth — prior to a ‘Minsky Moment' crisis; and a tendency for inequality to rise over time. The simulations in this paper use the Open Source system dynamics programme Minsky, which was named in Minsky’s honour.","Label":"0"},{"DOI":"10.1016/s0304-3932(01)00111-8","Abstract":"This paper investigates the predictions of a simple optimizing model of nominal price rigidity for the dynamics of inflation. Taking as given the paths of nominal labor compensation and labor productivity to approximate the evolution of marginal costs, I determine the path of prices predicted by the solution of the firms’ optimal pricing problem. Model parameters are chosen to maximize the fit with the data. I find evidence of a significant degree of price stickiness and substantial support for the forward-looking model of price setting. The results are robust to the use of alternative forecasting models for the path of unit labor costs, alternative measures of marginal costs, and alternative specifications the model of price staggering.","Label":"0"},{"DOI":"10.2139/ssrn.3939316","Abstract":"We quantify the effects of wage bargaining shocks on macroeconomic aggregates using a structural vector auto-regression model for Germany. We identify exogenous variation in bargaining power from episodes of minimum wage introduction and industrial disputes. This narrative information disciplines the impulse responses to a wage bargaining shock of un-employment and output, and sharpens inference on the behaviour of other variables. The implied transmission mechanism is in line with the theoretical predictions of a large class of search and matching models. We also find that wage bargaining shocks explain a sizeable share of aggregate fluctuations in unemployment and inflation, that their pass-through to prices is very close to being full, and that they imply plausible dynamics for the vacancy rate, firms’ profits, and the labour share.","Label":"0"},{"DOI":"10.1109/conecct50063.2020.9198668","Abstract":"In this work, we have applied machine learning-based algorithms that predicts the cost at which a player can be sold in the Indian Premier League Auction. We estimated the players’ selling price using their past performance parameters like runs, balls, innings, wickets and matches played. Tests were carried out in various machine learning models like Decision Tree Regressor, K-Nearest Neighbors (KNN), Linear Regression, Stochastic Logistic Regression, Random Forest Regressor and Support Vector Regression (SVR). Among these SVR and Linear Regression gave best results for predicting batsman and bowlers respectively. These algorithms can produce fast and accurate results within 3 seconds, helping auctioneers make quick decisions. We have also considered inflation factor and mapping of the same to the budget during the training of the model.","Label":"1"},{"DOI":"10.32609/0042-8736-2006-9-4-20","Abstract":"The quality of fiscal forecasts in 1999-2005 is examined. Substantial and systematic error in the key macroeconomic and fiscal forecasts is found. Independent forecasts generally prove to be even less accurate. One can conclude that fiscal planning was not based on conservative approach, envisaging purposeful underestimation of budget revenues. Full effect of erroneous prediction of external variables is calculated, taking into account direct, indirect impact, and implicit influence of stabilization measures by the government and the Central Bank. We find that shifts in exchange rate and inflation in response to increase in oil and gas prices set limits to spending windfall gains, as either the budget looses revenues due to the ruble appreciation or outlays are deflated with price growth.","Label":"0"},{"DOI":"10.2139/ssrn.1437506","Abstract":"This paper presents a general equilibrium model that is consistent with recent empirical evidence showing that the U.S. price level and inflation are much more responsive to aggregate technology shocks than to monetary policy shocks. The model of this paper builds on recent work by Mackowiak and Wiederholt (2009), who show that models of endogenous attention allocation deliver prices to be more responsive to more volatile shocks as, everything else being equal, firms pay relatively more attention to more volatile shocks. In fact, according to the U.S. data, aggregate technology shocks are more volatile than monetary policy shocks inducing in this paper, firms to pay more attention to the former than to the latter. However, most important, this work adds to the literature by showing that the ability of the model of this paper to account for observed price dynamics crucially depends on monetary policy. In particular, this paper shows how interest rate feedback rules affect the incentives faced by firms in allocating attention. A policy rate responding more actively to expected inflation and output fluctuations induces firms to pay relatively more attention to more volatile shocks. This new mechanism of transmission of monetary policy helps rationalizing the observed behavior of prices in response to technology and monetary policy shocks, and implies novel predictions about the impact of changes in Taylor rules coefficients on economic fluctuations.","Label":"0"},{"DOI":"10.3390/jrfm13090187","Abstract":"This Editorial evaluates 14 invaluable and interesting articles in the Special Issue “Applied Econometrics” for the Journal of Risk and Financial Management (JRFM). The topics covered include recovering historical inflation data from postage stamps prices, FHA loans in foreclosure proceedings through distinguishing sources of interdependence in competing risks, information in earnings forecasts, nonlinear time series modeling, a systemic approach to management control through determining factors, economic freedom and FDI versus economic growth, efficient cash use of the Taiwan dollar, financial health prediction in companies from post-Communist countries, influence of misery index on U.S. Presidential political elections, multivariate student versus Gaussian regression models in finance, financial derivatives markets and economic development, income inequality and economic growth in middle-income countries, abnormal returns, mis-measured risk, network effects, and risk spillovers in stock returns.","Label":"0"},{"DOI":"10.2139/ssrn.2955235","Abstract":"I estimate and evaluate a model with a representative agent who is concerned that the persistence properties of her baseline model of consumption and inflation are misspecified. Coping with model uncertainty, she discovers a pessimistically biased worst-case model that dictates her behavior. I combine interest rates and aggregate macro series with cross-equation restrictions implied by robust control theory to estimate this worst-case distribution and show that (1) the model’s predictions about key features of the yield curve are in line with the data, and (2) the degree of pessimism underlying these findings is plausible. Interpreting the worst-case as the agent’s subjective belief, I derive model implied interest rate forecasts and compare them with analogous survey expectations. I find that the model can replicate the dynamics and average level of bias found in the survey.","Label":"0"},{"DOI":"10.1007/s11294-011-9304-5","Abstract":"A simple theoretical model of monetary unification and data from 11 euro members are used to investigate the common currency’s role in the macroeconomic performance of these countries. Euro membership has been typically accompanied by lower (or steady) inflation, but also by higher business-cycle volatility. In addition, synchronization of cyclical output was substantially affected by the common currency only in Greece (where it declined considerably) and Finland and Ireland (where it increased). Consistent with the theoretical predictions, the empirical evidence shows a strong negative relationship between cyclical synchronizations and volatilities, which however is not much stronger under the euro than it was during the Maastricht period.","Label":"0"},{"DOI":"10.3390/stats5020023","Abstract":"Many people are concerned about the stock market in 2022 as it faces several threats, from rising inflation rates to geopolitical events. The S&P 500 Index has already dropped about 10% from the peak in early January 2022 until the end of February 2022. This paper aims at updating the crisis indicator to predict when the market may experience a significant drawdown, which we developed in Crisis Risk Prediction with Concavity from Polymodel (2022). This indicator uses regime switching and Polymodel theory to calculate the market concavity. We found that concavity had not increased in the past 6 months. We conclude that at present, the market does not bear inherent dynamic instability. This does not exclude a possible collapse which would be due to external events unrelated to financial markets.","Label":"0"},{"DOI":"10.48550/arxiv.2010.13456","Abstract":"Models of discrete-valued outcomes are easily misspecified if the data exhibit zero-inflation, overdispersion or contamination. Without additional knowledge about the existence and nature of this misspecification, model inference and prediction are adversely affected. Here, we introduce a robust discrepancy-based Bayesian approach using the Total Variation Distance (TVD). In the process, we address and resolve two challenges: First, we study convergence and robustness properties of a computationally efficient estimator for the TVD between a parametric model and the data-generating mechanism. Second, we provide an efficient inference method adapted from Lyddon et al. (2019) which corresponds to formulating an uninformative nonparametric prior directly over the data-generating mechanism. Lastly, we empirically demonstrate that our approach is robust and significantly improves predictive performance on a range of simulated and real world data.","Label":"1"},{"DOI":"10.3846/bm.2020.581","Abstract":"In this work, the economic development and relation to social and demography indices in Albania were studied. Four time series (yearly data for the period 1995–2018) were considered: consumer price index (CPI), unemployment rate, inflation and life expectancy. In our approach, a first and fifth order multivariate Markov chain model was proposed to predict the economic situation in Albania in the proceedings years. Tests and accuracy analysis of the model were performed. The prediction probabilities fall in the interval of 0.47 to 0.52 and the accuracy of both models is 75%. Our approach is a short term probability forecast model that can be used by the policymakers to evaluate and undertake initiatives to improve the situation in the country. DOI: https://doi.org/10.3846/bm.2020.581","Label":"0"},{"DOI":"10.1080/09638199.2019.1629616","Abstract":"This paper proposes a novel approach of classifying and modeling the nonlinear behavior of commodity prices using regime-switching models with exogenous transition variables. The approach rests on using the International Commercial Terms (Incoterms), also known as border prices, to classify commodities in groups that tend to display similar dynamics. The suggested border price classification is useful in identifying the key exogenous driving variables in each group. In particular, the classification suggests that inflation and oil price are the best transition candidates that are capable of capturing the nonlinear dynamics of free on board (FOB) and cost insurance and freight (CIF) prices respectively. Our statistical linearity tests and estimation results confirm this prediction and highlight the importance of the suggested border price classification in improving our understanding of the behavior of commodity prices.","Label":"0"},{"DOI":"10.2139/ssrn.1102405","Abstract":"We generalize the Cooper and Kaplanis (1994) methodology for estimating the costs that could reconcile international portfolio holdings with CAPM predictions. First, we can simultaneously estimate inward and outward investment costs and even interactions between home and host country. Second, the risk aversion parameter is estimated rather than postulated. Third, we control for exchange rate risk, inflation hedging, fixed-interest investments, round-tripping and omitted countries. Our estimates of implicit investment costs for the developed countries are much lower than those reported in prior studies. Over the period 2001-2004, our estimates of the average inward shadow costs range from 0.01 (US) to 37 (Indonesia) percent per annum. We find that the equity home bias is related to a mixture of market frictions, such as information asymmetries, institutional factors and explicit costs.","Label":"0"},{"DOI":"10.1016/j.jet.2021.105225","Abstract":"I estimate and evaluate a model with a representative agent who is concerned that the persistence properties of her baseline model of consumption and inflation are misspecified. Coping with model uncertainty, she discovers a pessimistically biased worst-case model that dictates her behavior. I combine interest rates and aggregate macro series with cross-equation restrictions implied by robust control theory to estimate this worst-case distribution and show that (1) the model's predictions about key features of the yield curve are in line with the data, and (2) the degree of pessimism underlying these findings is plausible. Interpreting the worst-case as the agent's subjective belief, I derive model implied interest rate forecasts and compare them with analogous survey expectations. I find that the model can replicate the dynamics and average level of bias found in the survey.","Label":"0"},{"DOI":"10.1080/1226508x.2012.655026","Abstract":"There has been much interest in whether fixed exchange rates can provide a strong source of discipline over domestic monetary and fiscal policies. We argue that previous studies, however, have not paid sufficient attention to the distinction between constraint and incentive effects and that these operate quite differently for hard and soft fixes. Using annual data for 31 emerging and 32 developing countries during 1990–2003, our analysis implies that hard fixes should have much stronger discipline effects on money growth and inflation and our empirical study supports their prediction. Our theoretical analysis suggests that neither hard nor soft fixes are likely to provide strong discipline over fiscal policy and this is confirmed by our empirical analysis as well.","Label":"0"},{"DOI":"10.2139/ssrn.1977372","Abstract":"We explore the role of interest rate policy in the exchange rate determination process. Specifically, we derive exchange rate equations from interest rate rules that are theoretically optimal under a few alternative settings. The exchange rate equation depends on its underlying interest rule and its performance could vary across evaluation criteria and sample periods. The exchange rate equation implied by the interest rate rule that allows for interest rate and inflation inertia under commitment offers some encouraging results – exchange rate changes “calibrated” from the equation have a positive and significant correlation with actual data, and offer good direction of change prediction. Our exercise also demonstrates the role of the foreign exchange risk premium in determining exchange rates and the difficulty of explaining exchange rate variability using only policy based fundamentals.","Label":"0"},{"DOI":"10.1080/07350015.2016.1186029","Abstract":"This article considers in-sample prediction and out-of-sample forecasting in regressions with many exogenous predictors. We consider four dimension-reduction devices: principal components, ridge, Landweber Fridman, and partial least squares. We derive rates of convergence for two representative models: an ill-posed model and an approximate factor model. The theory is developed for a large cross-section and a large time-series. As all these methods depend on a tuning parameter to be selected, we also propose data-driven selection methods based on cross-validation and establish their optimality. Monte Carlo simulations and an empirical application to forecasting inflation and output growth in the U.S. show that data-reduction methods outperform conventional methods in several relevant settings, and might effectively guard against instabilities in predictors’ forecasting ability.","Label":"1"},{"DOI":"10.1007/978-981-19-4182-5_32","Abstract":"Ethereum, a blockchain platform inspired by Bitcoin, was introduced in 2015. It is a worldwide computing platform fueled by Ether (ETH), its native currency. As the demand for processing power on the Ethereum blockchain rises, so will the price of ETH. Several studies are working to project its price based on previous price inflations of the cryptocurrency. This topic has become a prominent research topic all around the world. In this work, the price of ETH is predicted using a hybrid model consisting of Long short-term memory (LSTM) and Vector Auto Regression (VAR). The hybrid model gave the least values for the evaluation metrics compared to the standalone models.","Label":"1"},{"DOI":"10.2139/ssrn.2882521","Abstract":"Is the Mundell-Fleming trilemma alive and well? International co-movement of asset prices takes place along side synchronized business cycles, complicating the identification of financial spillovers and assessments of monetary policy autonomy. A benchmark for interest rate co-movement is to impose the null hypothesis that central banks respond only to the outlook for domestic inflation and output. We show that common approaches used to estimate interest rate spillovers tend to understate the degree of monetary autonomy enjoyed by small open economies with flexible exchange rates. We propose an empirical strategy that partials out those spillovers that are associated with impaired monetary autonomy. Using this approach, we revisit the predictions of the trilemma and find more compelling evidence that flexible exchange rates deliver monetary autonomy than prior work has suggested.","Label":"0"},{"DOI":"10.2139/ssrn.305705","Abstract":"This paper examines the asymptotic and finite-sample properties of tests of equal forecast accuracy and encompassing applied to predictions from nested long-horizon regression models. We first derive the asymptotic distributions of a set of tests of equal forecast accuracy and encompassing, showing that the tests have non-standard distributions that depend on the parameters of the data-generating process. Using a simple parametric bootstrap for inference, we then conduct Monte Carlo simulations of a range of data-generating processes to examine the finite-sample size and power of the tests. In these simulations, the bootstrap yields tests with good finite-sample size and power properties, with the encompassing test proposed by Clark and McCracken (2001a) having superior power. The paper concludes with a reexamination of the predictive content of capacity utilization for core inflation.","Label":"0"},{"DOI":"10.1016/0261-5606(91)90006-6","Abstract":"Data on forward foreign exchange rates during the German hyperinflation after World War I provide direct observations of expected changes in the spot rate. Although levels of these forward rates seem to be efficient predictors of the spot rate, the predicted changes in the spot rate are biased downward substantially and do not meet the specific conditions of rationality. Indeed, the bias in the forward rate predictions is similar to bias in adaptive expectations of the spot rate. The behavior of the forward rate can be rationalized as a gradual market adaptation to a new regime of volatile and escalating inflation, reasonably represented by adaptive expectations. The strict definition of rational expectations needs to be broadened to allow for the difficulty of distinguishing between permanent and transitory shocks.","Label":"0"},{"DOI":"10.1177/0256090920040204","Abstract":"In the era of globalization and liberalization, important investment and business decisions have to carefully consider long-term performance and prospects of different national economies. National governments would also compete with one another on the strength of their economic performance and policies. Several organizations make regular efforts to evaluate prospects and rank countries for different purposes but research identifying the top performing economies considering different dimensions of their long-term performance is conspicuous by its absence. Using seven indicators of economic performance of 187 countries, this paper identifies the top 50 performers during the decades of 1981-90 and 1991-2000. Five of these indicators are the trend rates of growth over a decade in imports, foreign direct investment (FDI), capital formation, per capita income, and forex reserves. Average inflation rate and Human Development Index (HDI) are the remaining indicators. The selected indicators are very distinct from one another not only during the decade of eighties but also during the nineties. It is found that economic performance of countries, which was already specialized in a few dimensions, is becoming more specialized and focused during the nineties when compared to the eighties. This paper also examines the inter-relationship among the indicators over time. This study has generated findings for national policy making and for businesses to assess macroeconomic prospects. There are 26 common countries in the two sets of top 50 performers during the eighties and the nineties. High performance on the consumer inflation and/or human development front has emerged practically as a pre-condition for consistently good overall performance. On this count, it appears that a large number of the new entrants to the club of 50 top performers during the nineties are not likely to hold on to their position in the coming decade. Such emerging economies may prove to be risky. The experience of the eighties and the nineties suggests that high inflation during a decade does not deter the solid real economic performance on other dimensions during the same decade but may create problems of maintaining consistency of relative performance over time, if not checked. For predicting the overall performance of countries, past performance does not help in general. However, three indicators, viz., growth of per capita income, growth of FDI, and HDI can be predicted to some extent through past performance on various dimensions. The findings suggest the following: A trade-off exists between high inflation and future high growth and between high inflation and future high HDI. Long-term growth of investment may negatively affect the future long-term growth of output and long-term growth of forex reserves may negatively affect future long-term growth of FDI in a country. Growth causes human capital and not vice-versa. Based on the prediction of partial performance, the study identifies 15 economies likely to be among the top 50 performers in the first decade of the 21st century. Since four of the seven performance indicators do not depend on past performance, the remaining 35 top performers may spring genuine surprises. Economic environment and policies of countries during the decade would decide their relative performance.","Label":"0"},{"DOI":"10.1016/j.apenergy.2014.12.011","Abstract":"Selection of appropriate climatic variables for prediction of electricity demand is critical as it affects the accuracy of the prediction. Different climatic variables may have different impacts on the electricity demand due to the varying geographical conditions. This paper uses multicollinearity and backward elimination processes to select the most appropriate variables and develop a multiple regression model for monthly forecasting of electricity demand. The former process is employed to reduce the collinearity between the explanatory variables by excluding the predictor which has highly linear relationship with the other independent variables in the dataset. In the next step, involving backward elimination regression analysis, the variables with coefficients that have a low level of significance are removed. A case study has been reported in this paper by acquiring the data from the state of New South Wales, Australia. The data analyses have revealed that the climatic variables such as temperature, humidity, and rainy days predominantly affect the electricity demand of the state of New South Wales. A regression model for monthly forecasting of the electricity demand is developed using the climatic variables that are dominant. The model has been trained and validated using the time series data. The monthly forecasted demands obtained using the proposed model are found to be closely matched with the actual electricity demands highlighting the fact that the prediction errors are well within the acceptable limits.","Label":"0"},{"DOI":"10.2139/ssrn.4449894","Abstract":"With the advent of Big Data and machine learning/AI technologies, actuaries can now develop advanced models in a data-rich environment to achieve better forecasting performance and provide added value in many applications. Traditionally, economic forecasting for actuarial applications is developed using econometric models based on small datasets including only the target variables (usually around 4-6) and their lagged variables. This paper explores the value of economic forecasting using deep learning with a big dataset (FRED Database) consisting of 121 economic variables and their lagged variables covering periods before, during, after GFC, and during COVID (2019-2021). Four target variables considered in this paper include inflation rate, interest rate, wage rate, and unemployment rate, which are common variables for social security funds forecasting. The proposed model combines dimension reduction via principal component analysis (PCA) and Neural Networks (including CNNs, LSTMs, and fully-connected layers), which is suitable for economic forecasting in a data-rich environment. The results show that the proposed model consistently outperforms the benchmark vector auto-regression (VAR) model, although the level of benefits varies across different economic variables and forecast periods. Using residual bootstrapping, this paper provides prediction intervals to quantify the prediction uncertainty. To provide explanations for the black-box Neural Networks, this paper uses SHAP values to understand how different economic variables influence the prediction outcome. The model performance is demonstrated using a social security fund forecasting application.","Label":"1"},{"DOI":"10.2139/ssrn.2294110","Abstract":"A number of recent studies in the economics literature have focused on the usefulness of factor models in the context of prediction using \"big data\". In this paper, our over-arching question is whether such \"big data\" are useful for modelling low frequency macroeconomic variables such as unemployment, inflation and GDP. In particular, we analyze the predictive benefits associated with the use dimension reducing independent component analysis (ICA) and sparse principal component analysis (SPCA), coupled with a variety of other factor estimation as well as data shrinkage methods, including bagging, boosting, and the elastic net, among others. We do so by carrying out a forecasting \"horse-race\", involving the estimation of 28 different baseline model types, each constructed using a variety of specification approaches, estimation approaches, and benchmark econometric models; and all used in the prediction of 11 key macroeconomic variables relevant for monetary policy assessment. In many instances, we find that various of our benchmark specifications, including autoregressive (AR) models, AR models with exogenous variables, and (Bayesian) model averaging, do not dominate more complicated nonlinear methods, and that using a combination of factor and other shrinkage methods often yields superior predictions. For example, simple averaging methods are mean square forecast error (MSFE) \"best\" in only 9 of 33 key cases considered. This is rather surprising new evidence that model averaging methods do not necessarily yield MSFE-best predictions. However, in order to \"beat\" model averaging methods, including arithmetic mean and Bayesian averaging approaches, we have introduced into our \"horse-race\" numerous complex new models involve combining complicated factor estimation methods with interesting new forms of shrinkage. For example, SPCA yields MSFE-best prediction models in many cases, particularly when coupled with shrinkage. This result provides strong new evidence of the usefulness of sophisticated factor based forecasting, and therefore, of the use of \"big data\" in macroeconometric forecasting.","Label":"1"},{"DOI":"10.1111/j.1540-5982.2007.00421.x","Abstract":"Abstract. The authors develop and estimate an equilibrium‐based model of the Canadian term structure of interest rates. The proposed model incorporates a vector‐autoregression description of key macroeconomic dynamics and links them to those of the term structure, where identifying restrictions are based on the first‐order conditions that describe the representative investor's optimal consumption and portfolio plan. A remarkable result is that the in‐sample average pricing errors obtained with the equilibrium‐based model are only slightly larger than those obtained with a far more flexible no‐arbitrage model. The gains associated with parsimony become obvious out‐of‐sample, where the equilibrium model delivers much more accurate predictions, especially for yields with longer‐term maturities. The preferred equilibrium model has impulse responses that are consistent with long‐term inflation expectations being anchored, so a surprise increase in inflation does not necessarily raise expectations of higher future inflation. Les auteurs élaborent et estiment un modèle d'équilibre de la structure des taux d'intérêt canadiens, dans lequel la dynamique des principales variables macroéconomiques est représentée sous une forme vectorielle autorégressive et reliée à celle de la structure des taux. Les contraintes d'identification du modèle découlent des conditions de premier ordre qui définissent le plan optimal de consommation et de placement de l'investisseur représentatif. Résultat frappant, l'erreur moyenne de prévision des prix obtenue en échantillon est à peine plus élevée dans le modèle d'équilibre que dans un modèle beaucoup plus souple fondé sur l'absence d'arbitrage. Les gains découlant du caractère parcimonieux du modèle sont très nets au delà de la période d'estimation: le modèle d'équilibre produit des prévisions de qualité bien supérieure hors échantillon, surtout dans le cas des taux d'intérêt à long terme. Les profils de réaction que génère le modèle d'équilibre privilégié cadrent avec un ancrage des attentes d'inflation à long terme, en ce sens qu'une hausse imprévue de l'inflation n'accentue pas nécessairement les attentes d'une augmentation de l'inflation dans l'avenir.","Label":"0"},{"DOI":"10.2139/ssrn.4055944","Abstract":"Recent studies show that the consensus forecasts of professional forecasters and central bankers underreact to news relative to full-information rational expectations. However, can the treasury bond market anticipate such underreaction through information aggregation? To answer this question, we extract macroeconomic expectations in bond returns from a large panel dataset of real-time macro series and compare them to the projection of survey forecasts on bond returns. We find that the extracted macroeconomic expectations subsume the information in survey forecasts, forecast revisions and even the ex-post forecast errors in bond return prediction. However, macroeconomic expectations in bond returns do not anticipate the underreaction by the major market players. Furthermore, we assess a macro-finance term structure model including inflation expectations and the extracted macroeconomic expectations. We find that macroeconomic expectations generate significant fluctuations in term premiums over business cycles and produce lower term premiums in the most recent decade.","Label":"0"},{"DOI":"10.2139/ssrn.1087159","Abstract":"This paper characterizes exchange market pressure as a nonlinear Markov-switching phenomenon, and examines its dynamics in response to money growth and inflation over three regimes. The empirical results identify episodes of exchange market pressure in the Kyrgyz Republic and confirm the statistical superiority of the nonlinear regime-switching model over a linear VAR version in understanding exchange market pressure. The nonlinear empirical approach adequately characterizes the data generation process and yields results that are consistent with theoretical predictions, particularly the dampening effect of monetary contraction on depreciation pressure. During periods of appreciation pressure, however, the reverse policy option-monetary expansion-may not be efficient, particularly where PPP rather than UIP drives exchange rates. In addition, monetary expansion in such cases defeats the primary objective of monetary policy-price stability-and may exacerbate the instability.","Label":"0"},{"DOI":"10.1109/ises47678.2019.00023","Abstract":"Inflation has come up as a leading concern of India’s economic policymakers and citizens over the last decade. The prices of various commodities is getting higher day by day in various parts of India like Bangalore, hence it is high time that something must be done in order to decrease the price of commodities so that each and every citizen of India could afford to purchase the products he or she desires. To accommodate these, in this paper, an attempt has been made in order to analyze the prices of fruits and vegetables in the region of Bengaluru, Karnataka. To exemplify the price prediction, seasonal ARIMA is used to forecast the prices of fruits and vegetable. This will certainly help the people if the predicted prices are getting higher in the upcoming months then proper strategies can be made in order to decrease the prices of fruits and vegetables.","Label":"0"},{"DOI":"10.2139/ssrn.2317445","Abstract":"In the present scenario of the world financial market, there seems to be stock exchange in almost every country expressing the financial health of the respective economy. In spite of this tremendous expansion of world trading, the basics of the market have remained more or less the same. Stock exchange index like any other index follows a cycle or set pattern of flow. This economic cycle have been analyzed with the help of the leading and lagging indicators with respect to the trends in the financial markets. In this study a comprehensive analysis has been done to qualitatively compare the S&P CNX Nifty with major macro economic variable like GDP, inflation, Exchange rate, industrial production, foreign institutional investment, unemployment, crude oil. Thus all the variable contains some significant information for the prediction of the index.","Label":"0"},{"DOI":"10.2139/ssrn.318723","Abstract":"Existing results on the properties and performance of forecast combinations have been derived in the context of mean squared error loss. Under this loss function empirical studies have generally found that estimates of optimal forecast combination weights lead to higher losses than equally-weighted combined forecasts which in turn outperform the best individual predictions. We show that this and other results can be overturned when asymmetries are introduced in the loss function and the forecast error distribution is skewed. We characterize the optimal combination weights for the most commonly used alternatives to mean squared error loss and demonstrate how the degree of asymmetry in the loss function and skews in the underlying forecast error distribution can significantly change the optimal combination weights. We also propose estimation methods and investigate their small sample properties in simulations and in an inflation forecasting exercise.","Label":"1"},{"DOI":"10.1017/s1365100514000741","Abstract":"We model agents' endogenous updating of information sets over time under changing macroeconomic conditions. Building on sticky information models, the degree of inattentiveness is endogenized by allowing agents to choose between a costly full-information predictor and a costless sticky-information predictor. This is modeled as a choice between discrete alternatives under rational inattention. Recursive simulation shows that the dynamic equilibrium paths of aggregate variables are highly persistent and match the moments of U.S. data better than a model with fixed sticky information or with sticky prices, especially with regard to higher moments and the degree of persistence. Predictors are chosen in line with the predictions from rational inattention models, as the aggregate degree of attentiveness increases with rising variance of the forecast variable. Moreover, the model can generate hump-shaped impulse responses of inflation to a monetary policy shock if the degree of inattentiveness is sufficiently high.","Label":"0"},{"DOI":"10.1002/(sici)1099-1255(199907/08)14:4<379::aid-jae516>3.0.co","Abstract":"This paper estimates a policy rule that explains the sign and the magnitude of the Federal Reserve's (Fed's) discount rate changes. It sets out a two‐sided Type II Tobit model and develops a procedure for its estimation, considering the discrete and censored nature of the changes. The results suggest that the Fed has conducted discount rate policy counter‐cyclically to influence output and to curb inflation, and that the Fed's response to policy indicators varies over monetary regimes. Furthermore, consistency is found between the model prediction of the discount rate change and a classification based on whether the change is technical or non‐technical. Copyright © 1999 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.1007/bf01000719","Abstract":"Using a new set of survey data on EMS exchange rates, we investigate exchange rate expectations and risk premia between December 1985 and August 1991 to assess credibility of the system. It appears that the EMS—with the exception of the Italian lira—had become credible since early 1990. Moreover, one of the core predictions of the target zone literature—the inverse correlation between the position of the spot rate in the fluctuation band with its expected change—is corroborated for several currencies in the period after April 1990. Although the system appeared to be more credible, the persistence of interest differentials suggested the existence of risk premia. For four out of six currencies we find a significant relationship between the risk premium and the inflation differential relative to Germany.","Label":"0"},{"DOI":"10.1016/j.jimonfin.2012.11.020","Abstract":"Using post-1995 Japanese data we propose a new sign restriction SVAR approach to identify monetary policy shocks when the economy is at the Zero Lower Bound (ZLB). The identifying restrictions are based on predictions of Eggertsson's (2010) New Keynesian DSGE models when the economy is stuck at the ZLB. A quantitative easing shock leads to a significant decrease in long-term interest rates and significantly increases output and the price level. However, the effects are only transitory. This suggests that while the Japanese quantitative easing experiment was successful in temporarily stimulating real activity, it did not lead to a persistent increase in inflation. These results are interesting not only for Japan, but also for other advanced economies where monetary policy is currently constrained by the ZLB.","Label":"0"},{"DOI":"10.2139/ssrn.3469267","Abstract":"At the moment of elaborating the present paper we do not have the official figures for the end of the budget of 2018. However, based on the data available now, we find that the Romanian economy did not face the pessimistic predictions circulating in the spring: double-digit inflation, leu / euro exchange rate. over 6, Robo 5%, massive recession etc. Moreover, as presented in the statistics, for the whole year, the real GDP growth rate tends to exceed the 4.2% level. Essentially, the level of gross government debt for the end of 2018 is estimated to be at 34.9% of GDP, and in the medium term (2019 - 2021) it will be below 40% of GDP, falling within the 60% ceiling. established by the Treaty of Maastricht. For the year 2019, a gross government debt level of 35.3% is estimated.","Label":"0"},{"DOI":"10.17016/feds.1999.31","Abstract":"We examine the extent of downward nominal wage rigidity using the microdata underlying the BLS employment cost index--an extensive, establishment-based dataset with detailed information on wage and benefit costs. We find stronger evidence of downward nominal wage rigidity than did previous studies using panel data on individuals. Firms appear able to circumvent part, but not all, of this rigidity by varying benefits: Total compensation displays modestly less rigidity than do wages alone. Given our estimated amount of rigidity, a simple model predicts that the disinflation over the 1980s would have raised equilibrium unemployment notably. This prediction stands in contrast to the actual behavior of unemployment over this period: The addition of a term capturing the cost of rigidity (that rises as inflation falls) has no additional explanatory power in a standard Phillips Curve equation.","Label":"0"},{"DOI":"10.2139/ssrn.2114101","Abstract":"Existing studies on interest rate forecasting either treat yields as being stationary around a fixed mean or as a random walk process. In this study we consider forecasting the term structure of interest rates with the assumption that the yield curve is driven by factors that are stationary around a slowly time-varying mean or \"shifting endpoint\". The shifting endpoints are captured using either (i) time series methods (exponential smoothing), or (ii) long-range survey forecasts of either interest rates or inflation and output growth, or (iii) exponentially smoothed realizations of these macro variables. We find that allowing for shifting endpoints in yield curve factors can provide gains in the out-of-sample predictive accuracy, relative to stationary and random walk benchmarks. These gains are statistically significant, and can involve more than 20 percent reductions in root mean square prediction error.","Label":"0"},{"DOI":"10.1057/978-1-349-95189-5_407","Abstract":"Abstract             The modelling of economic expectations is central to economics. Expectations of future economic conditions can be represented in econometric models by survey data, expectations proxies such as adaptive expectations, expert forecasts, or market expectations. The theory that expectations are rational, that is, optimal forecasts given the model, can be a useful modelling device, but evidence from behavioural economics shows that it has important limitations.","Label":"0"},{"DOI":"10.1201/9781003138914-24","Abstract":"This study aims at determining the predictions of financial distress in telecommunications companies in the Asia Pacific during the period of 2014–2017. This study employed a quantitative approach by involving telecommunications companies in the Asia Pacific as the population meeting the requirements to be samples. Determination of samples was conducted by purposive sampling technique. The data analysis method used was logistic regression analysis. The variables used were financial risk (FR), operating risk (OR), profitability (PR), lending interest rate (LR), and inflation rate (IN). The results show that (1) PR had a negative effect on financial distress, (2) the ratio of FR, OR, LR, and IN did not have a positive effect on financial distress, indicated by a positive regression coefficient, and the resulting significance value was greater than required, > 0.05.","Label":"0"},{"DOI":"10.1257/aer.97.3.607","Abstract":"The paper generalizes the Taylor principle—the proposition that central banks can stabilize the macroeconomy by raising their interest rate instrument more than one-for-one in response to higher inflation—to an environment in which reaction coefficients in the monetary policy rule change regime, evolving according to a Markov process. We derive a long-run Taylor principle which delivers unique bounded equilibria in two standard models. Policy can satisfy the Taylor principle in the long run, even while deviating from it substantially for brief periods or modestly for prolonged periods. Macroeconomic volatility can be higher in periods when the Taylor principle is not satisfied, not because of indeterminacy, but because monetary policy amplifies the impacts of fundamental shocks. Regime change alters the qualitative and quantitative predictions of a conventional new Keynesian model, yielding fresh interpretations of existing empirical work. (JEL E31, E43, E52)","Label":"0"},{"DOI":"10.1016/j.jpolmod.2012.01.012","Abstract":"In this paper we investigate the role of financial development, or more widespread access to finance, in generating economic growth in four Latin American countries between 1980 and 2007. The results, based on panel time-series data and analysis, confirm the Schumpeterian prediction which suggests that finance authorises the entrepreneur to invest in productive activities, and therefore to promote economic growth. Furthermore, given the characteristics of the sample of countries chosen, we highlight not only the importance of a more open, competitive and therefore active financial sector in channelling financial resources to entrepreneurs, but also the relevance of macroeconomic stability (in terms of low inflation rates), and all the institutional framework that it encompasses (central bank independence and fiscal responsibility laws), structural reforms which were implemented in the 1990s, as necessary pre-conditions for financial development, and consequently for sustained growth and prosperity in the region.","Label":"0"},{"DOI":"10.1002/jae.3950080305","Abstract":"This paper provides an empirical test of the long‐run implications of the production smoothing model of inventories, the dominant framework for inventory investment research in the past. Intertemporal models of a firm holding inventories of finished goods predict a long‐run relationship between inventories, shipments, factor input prices, and the real interest rate which is tested here using cointegration test procedures. These tests provide little support for the predictions of the production smoothing model. In most of the data sets used, test statistics indicate that inventories, shipments, factor input prices, the nominal interest rate, and the inflation rate maintain a long‐run equilibrium relationship but parameter estimates of cointegrating vectors are often implausible, typically rejecting hypotheses implied by structural models of the production smoothing motive for holding inventories.","Label":"0"},{"DOI":"10.1016/j.econmod.2023.106259","Abstract":"Whether fiscal policy exacerbates or counteracts fluctuations in the economy is a key policy issue, because it contributes to growth and inflation outcomes. However, existing literature provides partly contradictory findings. Therefore, we provide the first quantitative synthesis by applying meta-regression methods to a novel data set with 3536 cyclicality estimates from 154 studies. Our main findings are: on average, fiscal policy in advanced countries is countercyclical, but developing countries lean towards procyclicality. Furthermore, government spending policies exacerbate business cycle fluctuations more than tax policies. Finally, fiscal policy plans are more countercyclical than policy outcomes. Results are robust to tackling endogeneity between the business cycle and fiscal policy. While our analysis points to several stylised facts, it also highlights the importance of data and specification choices and allows for predictions concerning the cyclical behaviour of fiscal policy given best-practice assumptions on study design.","Label":"0"},{"DOI":"10.54691/bcpbm.v26i.1937","Abstract":"Pricing of assets through machine learning has been given more attention. This article attempts to study the factors affecting the stock value. In addition to the Fama French factor, this article selects the stocks in the A-share market and adds seven other factors affecting stock value to construct a stock pricing model. The sum of squares error (SSE) of the RBF neural network's prediction results was 0.4, and the relative error was 0.955. Among the 12 factors, the economic prosperity index (HJ), consumer expectations index (CEI), and an inflation index (CPI) were significantly crucial for the growth of the A-share market value. This study is conducive to exploring the factors affecting stock prices, helping investors and other stakeholders identify significant influencing factors, and making correct responses to changes in factors to obtain additional returns.","Label":"1"},{"DOI":"10.52950/es.2021.10.2.001","Abstract":"I have employed the Bayesian Structural Time Series model to assess the recent interest rate hike by the Czech Central Bank and its causal impact on the Koruna exchange rate. By forecasting exchange rate time series in the absence of the intervention we can subtract the observed values from the prediction and estimate the causal effect. The results show that the impact was little and time limited in one model specification and none in the second version. It implies that the Czech Central Bank possesses the ability to diverge significantly from the Eurozone benchmark interest rate at least in the short term. It also shows that the interest rate hike will not be able to curb global inflation forces on the domestic price level.","Label":"0"},{"DOI":"10.1093/jeea/jvy057","Abstract":"Abstract                   An agent forms estimates (or forecasts) of individual variables conditional on some observed signal. His estimates are based on fitting a subjective causal model—formalized as a directed acyclic graph, following the “Bayesian networks” literature—to objective long-run data. I show that the agent’s average estimates coincide with the variables’ true expected value (for any underlying objective distribution) if and only if the agent’s graph is perfect—that is, it directly links every pair of variables that it perceives as causes of some third variable. This result identifies neglect of direct correlation between perceived causes as the kind of causal misperception that can generate systematic prediction errors. I demonstrate the relevance of this result for economic applications: speculative trade, manipulation of a firm’s reputation, and a stylized “monetary policy” example in which the inflation-output relation obeys an expectational Phillips Curve.","Label":"0"},{"DOI":"10.5195/cbp.2000.87","Abstract":"The breakup of the Soviet Union and the former Yugoslavia raises the question of the economic viability of the new post-Communist states. It is distinctly possible that separation was economically irrational exante, for at least some of the new states.' This, however\" will be eternally debatable, while expost results can at least be studied empirically. The useful studies undertaken by Uvalic and von Selm, discussing the costs and benefits of the breakup of the former Yugoslavia and the Soviet Union respectively, rely more on theoretical argument and prediction than on analysis of postindependence outcomes. This essay attempts a more modest task: to see whether separation has facilitated the new states' efforts to handle the urgent tasks of bringing down inflation rates and creating a macroeconomic en virorunent conducive to economic growth.","Label":"0"},{"DOI":"10.1002/for.845","Abstract":"This paper is an applied study about forecasting trend output and the output gap in the Euro area. The need for trend output forecasts is justified by an analysis of the monetary strategy of the European Central Bank. Trend output serves as a direct inflation indicator and helps to determine the reference value for money. For both purposes, trend output has to be forecasted. A permanent–transitory decomposition based on cointegration restrictions gives an estimate of trend output in the Euro area. Ex‐ante point forecasts of trend output are computed and bootstrap simulation is employed to construct prediction intervals that take estimation uncertainty into consideration. The uncertainty of trend output and the output gap is quite large and raises questions about their usefulness as indicators for monetary policy. Copyright © 2002 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.2139/ssrn.3670482","Abstract":"This paper studies the dollarization of prices in retail markets of emerging economies. We develop a model of the firm’s optimal currency choice in retail markets in inflationary economies. We derive theoretical predictions regarding the optimality of dollar pricing, and test them using data from the largest e-trade platform in Latin America. Across countries, price dollarization is positively correlated with asset dollarization and inflation, and negatively correlated with exchange rate volatility. At the micro level, larger sellers are more likely to price in dollars, and more tradeable goods are more likely to be posted in dollars. We then show that prices are sticky, and hence the currency of prices determines the short-run reaction of both prices and quantities to a nominal exchange rate shock.Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at www.nber.org.","Label":"0"},{"DOI":"10.17016/feds.2006.10","Abstract":"Survey of forecasters, containing respondents' predictions of future values of growth, inflation and other key macroeconomic variables, receive a lot of attention in the financial press, from investors, and from policy makers. They are apparently widely perceived to provide useful information about agents' expectations. Nonetheless, these survey forecasts suffer from the crucial disadvantage that they are often quite stale, as they are released only infrequently, such as on a quarterly basis. In this paper, we propose methods for using asset price data to construct daily forecasts of upcoming survey releases, which we can then evaluate. Our methods allow us to estimate what professional forecasters would predict if they were asked to make a forecast each day, making it possible to measure the effects of events and news announcements on expectations. We apply these methods to forecasts for several macroeconomic variables from both the Survey of Professional Forecasters and Consensus Forecasts.","Label":"1"},{"DOI":"10.2139/ssrn.393663","Abstract":"This paper studies the empirical applications of the autocorrelation tests, the unit root tests, and the efficient estimation procedures introduced in Guo and Phillips (1999a) to daily return series for the S&P 500 Index and a set of eight individual stocks. As a further example of estimating the mean and volatility parameters, quarterly inflation rate series for several developed countries are also examined. The results illustrate that efficiency gains are realized and greater prediction power are obtained from the efficient estimation approach in estimating and forecasting both the mean and volatility, and that skewness and excess kurtosis in the data justifies the use of the new methods. In general, models of this type promise to be useful in fitting data series characterized by dynamic structures in both the mean and second moments, especially those with highly skewed and heavy-tailed features, as are commonly present in financial and macroeconomic series.","Label":"0"},{"DOI":"10.2139/ssrn.228898","Abstract":"This paper analyzes the case of Panama, one of the largest countries currently adopting the dollar as its legal tender, and evaluates some of the predictions of the theory on the costs and benefits of full dollarization. The main conclusions drawn from the case of Panama are that on one hand, dollarization does not guarantee fiscal discipline, the elimination of currency risk does not preclude default risk or the high volatility of sovereign spreads, and that dollarization may increase slightly GDP growth volatility. On the other hand, a dollarized economy delivers delivers an impressive inflation performance and may even reduce the impact of external confidence shocks, although not external real shocks. Finally, it is not clear whether the low interest rates in Panama are a consequence of the dollarization regime or the competitive internationalized banking system.","Label":"0"},{"DOI":"10.1016/0167-4870(90)90007-v","Abstract":"Both the ability to buy (household income) and the willingness to buy (attitude, expectation) determine consumer expenditure, saving and credit at the aggregate level. The willingness to buy, to save or to borrow, named consumer sentiment, is measured with a set of survey questions. These questions pertain to the evaluation and expectation of the general economic situation of the nation, household finances, inflation, unemployment, a good time to buy, and saving conditions. In this study it is shown that another subset of survey questions provides a better prediction of consumer spending, credit and saving than Katona's Index of Consumer Sentiment. Income is the most important determinant of consumer spending and saving. One of the principal component scores of the evaluation and expectation questions add to the explanation of consumer expenditure, credit, and savings, especially for durable goods and for credit.","Label":"1"},{"DOI":"10.2139/ssrn.1882854","Abstract":"Using several unique data sets on wage agreements at both industry and firm levels in France, we document stylized facts on wage stickiness and the impact of wage-setting institutions on wage rigidity. First, the average duration of wages is a little less than one year and around 10 percent of wages are modified each month by a wage agreement. Data patterns are consistent with predictions of a mixture of Calvo and Taylor models. The frequency of wage change agreements is rather staggered over the year but the frequency of effective wage changes is seasonal. The national minimum wage has a significant impact on the probability of a wage agreement and on the seasonality of wage changes. Negotiated wage increases are correlated with inflation, the national minimum wage increases and the firm profitability.","Label":"0"},{"DOI":"10.3982/ecta7451","Abstract":"We document cash management patterns for households that are at odds with the predictions of deterministic inventory models that abstract from precautionary motives. We extend the Baumol–Tobin cash inventory model to a dynamic environment that allows for the possibility of withdrawing cash at random times at a low cost. This modification introduces a precautionary motive for holding cash and naturally captures developments in withdrawal technology, such as the increasing diffusion of bank branches and ATM terminals. We characterize the solution of the model, which qualitatively reproduces several empirical patterns. We estimate the structural parameters using micro data and show that quantitatively the model captures important economic patterns. The estimates are used to quantify the expenditure and interest rate elasticity of money demand, the impact of financial innovation on money demand, the welfare cost of inflation, and the benefit of ATM ownership.","Label":"0"},{"DOI":"10.1016/j.jeconom.2003.10.019","Abstract":"Existing results on the properties and performance of forecast combinations have been derived in the context of mean squared error loss. Under this loss function empirical studies have generally found that equally-weighted combined forecasts lead to better performance than estimates of optimal forecast combination weights which in turn outperform the best individual predictions. We show that this and other results can be overturned when asymmetries are introduced in the loss function and the forecast error distribution is skewed. We characterize the optimal combination weights for the most commonly used alternatives to mean squared error loss and demonstrate how the degree of asymmetry in the loss function and skews in the underlying forecast error distribution can significantly change the optimal combination weights. We also propose estimation methods and investigate their small sample properties in simulations and in an inflation forecasting exercise.","Label":"1"},{"DOI":"10.2139/ssrn.1311113","Abstract":"In this paper I discuss various notions and aspects of integration and macroeconomic convergence, namely economic and monetary integration; real and nominal convergence. The EU has offered a great deal of information about the relation between all these types of integration and macroeconomic convergence. The EU has assumed that monetary integration is a precondition of deep economic integration and it has also assumed that the criteria to be adopted to converge to its own brand of economic and monetary union (EMU) are basically the same needed within the monetary union itself. Judging from the evidence of the first ten years of EMU, the actual relationship between real growth and inflation has turned out to be far from clear; and the paper provides a comparison between statistical evidence and the diverging predictions offered by two standard macroeconomic models.","Label":"0"},{"DOI":"10.1016/j.jimonfin.2008.06.005","Abstract":"Studies of banking competition and competitive behavior both within and across countries typically utilise only one of the few measures that are available. In trying to assess the relative competitive position of banking markets in 14 European countries, existing indicators of competition are found to give conflicting predictions across countries, within countries, and over time. This is because indicators of competition tend to measure different things and are additionally influenced by cross-country differences in cost efficiency, fee income levels, real economic growth and inflation. We attempt to separate bank pricing power from these embodied influences and derive more consistent cross-country estimates of banking sector competition. The main result is that our measure of bank pricing power suggests that banking market competition in Europe may well be stronger than implied by traditional measures and analysis.","Label":"0"},{"DOI":"10.1007/s00181-006-0098-x","Abstract":"In the empirical literature there is wide consensus that financial spreads cannot constitute a broadly based assessment on future output growth and inflation because the bivariate estimated regressions are not stable over time and lead to relatively poor out-of-sample forecasting performance (e.g. J Econ Liter 41:788–829, 2003). This conclusion arised for the USA, as well as for several European countries. In this paper we check whether the marginal predictive content of some financial spreads (the slope of the yield curve, the reverse yield gap and the credit spread) for macroeconomic forecasting in the euro area can be recovered using techniques taking into account potential parameters instability. We set up a quarterly Bayesian vector autoregression model with time-varying coefficients, comprising both target variables, as well as other monetary policy indicators, to serve as a benchmark. Then, the properties of the spreads as leading indicators are assessed by augmenting this benchmark BVAR with the spreads, one at a time. We find time variation of the coefficients to be a relevant issue in our model, especially for forecasting output growth, but financial spreads continue to have no or negligible marginal predictive content for both output growth and inflation. Overall, our results confirm that there is no ready-to-use financial spread that can replace an encompassing multivariate model for the prediction of target variables in the euro area.","Label":"0"},{"DOI":"10.2139/ssrn.1735431","Abstract":"We explore the role of strategic price-discrimination by retailers for price determination and inflation dynamics. We model two types of customers, “loyals\" who buy only one brand and do not strategically time purchases, and “shoppers\" who seek out low-priced products both across brands and across time. Shoppers always pay the lowest price available, the “best price”. Retailers in this setting optimally choose long periods of constant regular prices punctuated by frequent temporary sales. Supermarket scanner data confirm the model's predictions: the average price paid is closely approximated by a weighted average of the fixed weight average list price and the “best price\". In contrast to standard menu cost models, our model implies that sales are an essential part of the price plan and the number and frequency of sales may be an important mechanism for adjustment to shocks. We conclude that our “best price\" construct provides a tractable input for constructing price series.","Label":"0"},{"DOI":"10.1111/j.1465-7295.2009.00213.x","Abstract":"This article extends a standard Beckerian model of fertility behavior to formulate the effect of house price (HP) on fertility. The simple model predicts a negative effect of HP on the number of children for a representative household not only through the income effect but also through the compensated substitution effect. The prediction is confirmed by a cointegration analysis applied to the annual data at the aggregate level covering the period from 1971 to 2005 in Hong Kong. It is found that a 1% increase in HP is significantly related to a 0.45% decrease in total fertility rates (TFRs), which is robust in sensitivity tests with an alternative model specification and alternative measures of TFRs. This implies that high HP inflation can account for about 65% of the fertility decrease in Hong Kong in the past four decades. (JEL J13, J11, C32)","Label":"0"},{"DOI":"10.18077/chss.2016.66..006","Abstract":"This study predicted excess earnings rates through the methods by Fama and Bliss (1987) and Cochrane and Monika Piazzesi(2005) using data on forward rates of Chinese bonds, quoting the increased R2 compared to the results by Fama and Bliss (1987) when Cochrane and Monika Piazzesi(2005) forecasted excess earnings rates of bonds by creating factors to expect earnings rates. The results suggest the following; when expecting excess earnings rates of bonds by creating return forecasting factors, R2 was in the 70% range, indicating a clearer explanation power compared to a case using the method by Fama and Bliss (1987), which recorded the 10% range. This high ability to expect is deemed to be due to the characteristics of the economic system and financial markets unique in China. In addition, when conducting a regression analysis on return forecasting factors, inflation, which is a representative macroeconomic factor, and Coincident Composite Index, it has been found that return forecasting factors have a significant explanatory power, which is also statistically significant, in both real economies. The earnings rate prediction curve had a positive (+) impact on the inflation after two months and a negative (-) effect on Coincident Composite Index after eight months. This suggests that return forecasting factors can not only be used as a predictor for excess earnings rates in the bond markets, but also be used as a tool to expect future changes of some variables to the real economy.","Label":"0"},{"DOI":"10.1016/0169-2070(90)90064-i","Abstract":"This paper examines the accuracy of forecasts of the international economy made by the OECD. Our large data set, comprising over 7,000 pairs of forecasts and outcomes, includes one-, two-, and three-step ahead semi-annual forecasts of the main components of demand, output and prices for Canada, France, Germany, Italy, Japan, the U.K. and the U.S.A. over the twenty-year period 1968–1987. Various measures of accuracy are computed; also a comparison is made with competing naive and time-series predictions. The analysis includes a full range of diagnostic checks on forecast performance, including rationality tests for unbiasedness, efficiency and consistency. Although there is considerable variation in the accuracy of these forecasts, they are generally superior to the naive and time-series predictions. Error is predominantly non-systematic. However, our analysis exposes exceptions, particularly forecasts of government consumption, and in some of the forecasts of fixed and inventory investment, the foreign balance and inflation. Accuracy in these cases could be improved by a simple linear correction, or by incorporating information contained in recent, known forecast errors. At least half the OECD forecasts fail one or more of the rationality tests.","Label":"0"},{"DOI":"10.4236/tel.2021.113030","Abstract":"This paper is aimed to identify the predicted factors for the world stock market in the last six decades, and up to the first quarter of 2021 year. The historical data and analysis of trends for volumes, and prices besides the fundamentals data such as interest rates, currency exchange rates, inflation rates, trading volume, and annual returns for listed corporations, used to be the predicted factors available to forecast the financial stock markets prices and volume, for the listed companies, national stock index, and regional stock indexes. However, in the last six decades, other new major factors became more reliable keys for the prediction of future prices and volume trends, in the world stock markets besides the previous two factors. These include the options strike rates for underling shares, psychological price barriers, national, regional and international crises, irrational and noise trading, and finally the health crisis known as the COVID-19, as what happened in 2020. This paper discussed these predicted factors which now dominate in the world stock markets, and suggested stated ratios for the reliability of each presented measure, during different decades up to April of 2021, and how the reliability of theses indictors was changed from one decade to another.","Label":"0"},{"DOI":"10.1109/icdacai57211.2022.00064","Abstract":"Gold has long been a financial asset used by investors to fight inflation and escape financial crises, and Bitcoin is an emerging financial asset that is gaining prominence in the modern economy. This paper analyzes the price trends of gold and bitcoin, which builds a price prediction model and a trading model. First, to achieve a higher yield, we need to make a forecast for gold and bitcoin and then design a trading strategy based on the forecast. In this paper, we use two models to make forecasts. Using ARIMA Time Series Analysis, we need to predict past price movements with 1826 cycles. We need to find the characteristics of current and past price movements that have an impact on future price movements. In this paper, we use Boruta Random Forest Algorithm to filter out the four factors that have the most influence on the price of gold and bitcoin, respectively, from a total of 21 variables, and finally, we use the price trend prediction values and get an investment strategy. Traders can get $92,115.43 on 9/10/2021 for $1,000 on 9/11/2016 with the strategy. The five-year return reached 9111.54%, with an average annualized return of 147.10%.","Label":"1"},{"DOI":"10.1002/for.3980060105","Abstract":"Professional analysts' judgments of the political riskiness of 49 focal countries for the period 1983‐1985 were studied. Data were collected on nine predictor variables; each was significantly correlated at the 0.01 level with ratings of political riskiness. The highest correlation was with infant mortality and life expectancy; either accounted for roughly 50% of the variance in ratings. Different variables were better predictors of political risk within different geographic regions. A factor analysis suggested the presence of three underlying factors. The predictor variable with the highest loading was chosen to represent each of the three factors. These were: exchange rate differential; estimated inflation rate; and infant mortality rate. Approximately 75% of the variance in ratings could be accounted for on the basis of a linear combination of the three predictor variables. These three variables were capable of good prediction even for various subsets of countries based on geographic region or other criteria. Using all nine variables as predictors resulted in only marginal improvement. A cluster analysis revealed little difference among clusters of judges. Ratings by undergraduate students closely paralled those of professional analysts. As in previous studies of expert predictions and forecasts, claims of expertise in political risk analysis were better supported by command of factual knowledge than by differentially superior predictive ability.","Label":"1"},{"DOI":"10.5195/emaj.2014.46","Abstract":"This study explores the significance of firm-specific, country, and macroeconomic factors in explaining variation in leverage using a sample of banks from Turkish banking sector. The analysis is based on quarterly firm-level data from Turkish banking sector in 2002–2012. We aims to contribute to the empirical capital structure literature in the following ways. Our first contribution comes from assessing the importance of firm-specific factors, country-level factors and industrial factors for capital structure decisions in Turkish banking sector. Second, we employ appropriate and advanced dynamic panel data estimators, Blundell and Bond’s (1998) generalized methods of moment’s estimators (GMM System). We find that leverage is significantly and positively associated with average industry leverage, firm size and GDP growth. We find also that leverage is significantly and negatively associated with tangibility, profitability, inflation and financial risk. The regression results for leverage are both theoretically and empirically plausible for banks in Turkey. Moreover, tangibility, profitability and GDP growth are consistent with the predictions of the pecking order theory, while firm size is consistent with the predictions of the trade-off theory. Our findings suggest that the capital structures of financial and non-financial firms are ultimately determined by the same drivers.","Label":"0"},{"DOI":"10.1051/shsconf/202317001022","Abstract":"The exchange rate between the US dollar and the RMB has been changing over the past year. Through the analysis of daily changing data, the direct calculation of linear regression will lead to the overall upward trend of the data, but not the rise and fall of the exchange rate. Therefore, it is necessary to introduce a more accurate ARIMA model to predict the possible development and change of data in a short period of time and analyze what policy causes the sharp fluctuations of data in a short period of time. In the process of applying the ARIMA model, this paper analyzed the shortcomings of ordinary linear regression and therefore proposed how to select the appropriate model for different data processing. The research results of this article provide more beginners in statistics with ideas for solving problems: prediction problems that cannot be solved by simple linear regression and existing elementary models can be analyzed using certain time series models, and reasonable explanations for data changes can be given based on existing policy reasons, Including irresistible inflation and the United States' own adjustment to the Federal Reserve's interest rate hike.","Label":"0"},{"DOI":"10.26740/jim.v9n2.p342-358","Abstract":"The Bank is a financial institution that functions to accumulate and distribute funds to the public and providing other banking services. In channelling funds, banks are not protected from the internal and external risks that cause financial difficulties. This study examines the influence of RGEC factors, bank size, market value, and macroeconomic to predict financial distress using the Crisis and Default Index. RGEC factors used in this study is risk profile which is proxy by NPL and LDR, good corporate governance is proxy of the size of board directors, earnings proxied by ROA, ROE, NIM, BOPO, and capital is proxied by CAR. The variable of bank size and market value is proxied by PBV and PER. While the macroeconomic variables used are economic growth, inflation, and exchange rates. This study used 19 banks in the BUSN group as a research sample during 2015-2019. The result showed that internal factors and bank size did not significantly influence the prediction of financial distress. Market value variable proxied by PBV has a significant negative effect on the prediction of financial distress. This is important for internal bank parties to keep stock prices from falling and investors are interested in investing; PER and macroeconomic variables do not significantly affect the prediction of financial distress because good internal banking fundamentals face changes in economic conditions. There is no influence of variables with financial distress because these variables appropriate with Bank Indonesia and BUSN are implementing them correctly.","Label":"0"},{"DOI":"10.1145/3410352.3410827","Abstract":"Economic indicators are key statistics based on economy, some examples of economic indicators are inflation rate, gross domestic product (GDP), unemployment rate, consumer price indices (CPI), interest rate, exports, consumption of energy, among others. Most of the published studies are focused on contextualizing and predict a particular economic indicator without considering the current general situation on how non-linear models have been used in predicting some of the economic indicators. This article, has analyzed in the scientific production the artificial intelligence methods mostly used in the development of prediction models of economic indicators. The study was carried out by means of a systematic literature review (SLR) using the Web of Science (WOS), Scopus and Google Scholar bibliographic databases (BD) as resources. The documents and general information analyzed qualitatively are filtered between the range of years 2015 to 2019 to which an adequate set of quality and selection criteria were applied. The approach of the research questions allowed to describe the outcomes in categories where the studies by predicted economic indicator and applied artificial intelligence method have been successfully included. The outcomes that have been obtained in this article represent a starting point for researchers, academics and professionals who wish to carry out studies related to the prediction of economic indicators using some artificial intelligence (AI) methods. In conclusion, some of the artificial intelligence methods used to predict economic indicators are artificial neural networks (ANN), adaptive systems of diffuse neuro inference (ANFIS), genetic programming (GP), support vector regression (SVR), machines extreme learning and other machine learning (ML) techniques.","Label":"1"},{"DOI":"10.2139/ssrn.2747473","Abstract":"A number of recent studies in the economics literature have focused on the usefulness of factor models in the context of prediction using \"big data\". We add to this literature by analyzing whether \"big data\" are useful for modelling low frequency macroeconomic variables such as unemployment, inflation and GDP. In particular, we analyze the predictive benefits associated with the use of principal component analysis (PCA), independent component analysis (ICA), and sparse principal component analysis (SPCA). We also evaluate machine learning, variable selection and shrinkage methods, including bagging, boosting, ridge regression, least angle regression, the elastic net, and the non-negative garotte. Our approach is to carry out a forecasting \"horse-race\" using prediction models constructed using a variety of model specification approaches, factor estimation methods, and data windowing methods, in the context of the prediction of 11 macroeconomic variables relevant for monetary policy assessment. In many instances, we find that various of our benchmark models, including autoregressive (AR) models, AR models with exogenous variables, and (Bayesian) model averaging, do not dominate specifications based on factor-type dimension reduction combined with various machine learning, variable selection, and shrinkage methods (called \"combination\" models). We find that forecast combination methods are mean square forecast error (MSFE) \"best\" for only 3 of 11 variables when the forecast horizon, h=1, and for 4 variables when h=3 or 12. Additionally, non-PCA type factor estimation methods yield MSFE-best predictions for 9 of 11 variables when h=1, although PCA dominates at longer horizons. Interestingly, we also find evidence of the usefulness of combination models for approximately 1/2 of our variables, when h>1. Most importantly, we present strong new evidence of the usefulness of factor based dimension reduction, when utilizing \"big data\" for macroeconometric forecasting.","Label":"1"},{"DOI":"10.3390/su14169964","Abstract":"Macroeconomic indicators are the key to success in the development of any country and are very much important for the overall economy of any country in the world. In the past, researchers used the traditional methods of regression for estimating macroeconomic variables. However, the advent of efficient machine learning (ML) methods has led to the improvement of intelligent mechanisms for solving time series forecasting problems of various economies around the globe. This study focuses on forecasting the data of the inflation rate and the exchange rate of Pakistan from January 1989 to December 2020. In this study, we used different ML algorithms like k-nearest neighbor (KNN), polynomial regression, artificial neural networks (ANNs), and support vector machine (SVM). The data set was split into two sets: the training set consisted of data from January 1989 to December 2018 for the training of machine algorithms, and the remaining data from January 2019 to December 2020 were used as a test set for ML testing. To find the accuracy of the algorithms used in the study, we used root mean square error (RMSE) and mean absolute error (MAE). The experimental results showed that ANNs archives the least RMSE and MAE compared to all the other algorithms used in the study. While using the ML method for analyzing and forecasting inflation rates based on error prediction, the test set showed that the polynomial regression (degree 1) and ANN methods outperformed SVM and KNN. However, on the other hand, forecasting the exchange rate, SVM RBF outperformed KNN, polynomial regression, and ANNs.","Label":"1"},{"DOI":"10.2139/ssrn.1295982","Abstract":"In this paper I consider the problem of optimal linear filtering, smoothing and trend extraction for m-period differences of processes with a unit root. Such processes arise naturally in economics and finance, in the form of rates of change (price inflation, economic growth, financial returns) and finding an appropriate smoother is thus of immediate practical interest. The filter and resulting smoother are based on the methodology of Singular Spectrum Analysis (SSA) and their form and properties are examined in detail. In particular, I find explicit representations for the asymptotic decomposition of the covariance matrix and show that the first two leading eigenvalues of the decomposition account for over 90% of the variability of the process. I examine the structure of the impulse and frequency response functions finding that the optimal filter has a \"permanent\" and a \"transitory component\" with the corresponding smoother being the sum of two such components. I also find explicit representations for the extrapolation coefficients that can be used in out-of-sample prediction. The methodology of the paper is illustrated with three short empirical applications using data on U.S. inflation and real GDP growth and data on the Euro/US dollar exchange rate. Finally, the paper contains a new technical result: I derive explicit representations for the filtering weights in the context of SSA for an arbitrary covariance matrix. This result allows one to examine specific effects of smoothing in any situation and has not appeared so far, to the best of my knowledge, in the related literature.","Label":"0"},{"DOI":"10.1108/01443580610639893","Abstract":"Purpose The purpose of this paper is to derive the real implications of inflation targeting using optimizing models characterized by endogenous time preference.   Design/methodology/approach To ensure consistent consumption and savings behavior, the rate of time preference is modeled as an increasing function of real wealth.   Findings  The results are not uniform and depend on the methods for modeling money in the general equilibrium framework; money in the utility function (MIU) and cash‐in‐advance constraints (CIA). With MIU, time preference wealth effects link the monetary and real sectors by endogenizing real interest rate. Monetary growth raises steady state capital and consumption by the Tobin effect. However, if money is introduced through CIA constraints, inflation policies are sensitive to the structure of the constraint itself. If the constraint applies to consumption and capital purchases, monetary growth lowers the steady state demand for both commodities and reverses the Tobin effect. If the constraint applies only to consumption goods, the same monetary policy is superneutral. This time preference specification has important advantages. It is consistent with the literature that integrates reinforcing wealth effects into aggregative models using ad‐hoc consumption or savings functions. Allowing the rate of time preference to depend positively on real wealth implies that optimizing behavior, not ad‐hoc specification yields wealth effects that endogenize the real interest rate and generate a Tobin effect. This time preference specification provides optimizing foundations for modeling savings as a decreasing function of real wealth, which is empirically verifiable and consistent with empirical predictions of consumption as an increasing function of real wealth.    Originality/value This paper demonstrates the different effects that monetary policy maintains on steady state capital, consumption and real balance holdings in economies characterized by an endogenous rate of time preference.","Label":"0"},{"DOI":"10.18778/1508-2008.24.06","Abstract":"This study investigates the impact of macroeconomic instabilities on returns volatility spillover that is transmitted from the global to the Islamic equity market. The economic factors examined are the exchange rate, inflation rate, interest rate, and production growth. To achieve the purpose of the study, we utilize three analysis tools: a GARCH(p,q) model to derive values of volatility for all variables; an asymmetry dynamic conditional correlation (ADCC) model to produce a measure of volatility spillover as the dependent variable; and a panel data regression technique to assess the causality significance of macroeconomic factors to volatility spillover. This study is the first which expands such approaches. We observe monthly data of world and Islamic market indices, exchange rates, consumer price indices, interest rates, and industrial production indices. The data, which range from May 2002 to February 2019, are taken from the world market, and twenty-three economies, which consist of fourteen developed and nine emerging markets that have Islamic stock indices. In several sections, we provide important additional analysis for five stock markets in Central European economies, which are compared to the others. The finding suggests that the presence of volatility spillover on the Islamic markets that originates from the global market is affected by the internal instabilities of macroeconomic factors, except for industrial production instability for developed markets, including Central European markets. An implication of the study is that regulators should anticipate and prevent adverse consequences of volatility spillover by arranging their internal economic policy to control inflation rates, interest rates, and industrial production growth, as well as exchange rate flexibility. Moreover, market practitioners should include both global market volatility and macroeconomic instabilities in their prediction to create minimum risk.","Label":"0"},{"DOI":"10.4324/9780203443965-14","Abstract":"The second main stage in the development of orthodox monetarism involved the expectations-augmented Phillips curve analysis which was absorbed into monetarist analysis after the mid-to-late 1960s. Central to this phase is Friedman’s 1967 Presidential Address to the American Economic Association, subsequently published in 1968 in the American Economic Review as ‘The Role of Monetary Policy’. In this article (reprinted on pp. 164-79) Friedman denies the existence of a permanent/long-run trade-off between inflation and unemployment and introduces the natural rate of unemployment hypothesis. The essence of this hypothesis is a reaffirmation of the classical view that in the long run nominal magnitudes cannot determine real magnitudes such as employment and output. According to Friedman monetary policy cannot, other than for very limited periods, achieve some target unemployment rate and any attempt to maintain unemployment below the natural rate will produce accelerating inflation; a prediction subsequently borne out by the experience of many western economies during the 1970s (see Snowdon and Vane 1997). In the conduct of monetary policy he prescribes that the authorities pursue a ‘stable’ rate of monetary growth in line with the trend/long-run growth rate of the economy to ensure long-run price stability. Friedman argues that the natural rate of unemployment can be reduced only by appropriate supply-side microorientated policies which improve the operation of the labour market. In 1981 Robert Gordon described Friedman’s 1968 paper as probably the most influential article written in macroeconomics in the previous twenty years. More recently James Tobin (1995), one of Friedman’s most eloquent, effective and long-standing critics, has described the paper as ‘very likely the most influential article ever published in an economics journal’ (emphasis added).","Label":"0"},{"DOI":"10.1007/978-3-031-32719-3_52","Abstract":"The article discusses the theoretical foundations for the emergence of overdue loans and forecasting financial risk in Russian banks under market uncertainty. The relevance of the study is due to the fact that the growth of bad debts of commercial banks on loans is currently the most acute problem. The dynamics of the volume of overdue debt on loans from commercial banks of the Russian Federation for 2012–2021 was analyzed. In the course of the study, it was revealed that the volume of bad debts is influenced both by internal factors, such as poor management of the loan portfolio, and by external factors, such as abrupt changes in the level of inflation, the growth of the exchange rate, etc. In order to study the influence of factorial signs on the effective sign - the growth rate of overdue debts, a correlation-regression model was compiled. In addition to the effective feature Y - the growth rate of overdue debt, the model included such factorial features as: X1 - the growth rate of GDP per capita, X2 - the growth rate of the average per capita income of the population, X3 - the growth rate of foreign trade surplus, X4 - inflation index, X5 is the growth rate of capital outflow, X6 - is the growth rate of cash, X7- is the interest rate on loans, X8 - is the US dollar exchange rate, X9 - is the price of a barrel of oil URLS dollars, X10 - is the growth of wages.","Label":"0"},{"DOI":"10.18421/sar53-05","Abstract":"CPI is one of the most frequently used indicators to measure the inflation rate in a region. The government can maintain economic stability by knowing the CPI value in advance. Therefore, we need a suitable method to predict an accurate CPI value. In this research, we investigate the prediction of CPI based on the machine learning method, SVR, and compare it to the ARIMAX method. We use Indonesia CPI data from January 2015 to October 2021. We investigate the SVR method using four kernel functions: Radial Basis Function (RBF), Polynomial, Linear, and Sigmoid. We build the ARIMAX model through the auto ARIMA process. We divide the data into two parts with three scenarios to investigate the performance of the methods: training and testing. The results show that the partition of 80% training and 20% testing gives the best performance. The SVR method performs best using a linear kernel, with an RMSE value of 0,743 and a MAPE value of 0,684%. The best ARIMAX model is model (0,2,1) with an RMSE value of 1,928071 and a MAPE of 1,731598 %. From the plot of prediction results and indicators of RMSE and MAPE, the SVR predicts CPI data better than the ARIMAX method, with CPI in the previous one-month data (MA1) being the most influential variable on the next CPI value.","Label":"1"},{"DOI":"10.2139/ssrn.3846065","Abstract":"This paper is aimed to identify the predicted factors for the world stock market in the last six decades, and up to first quarter of the 2021 year. The historical data and analysis of trends for volumes, and prices besides the fundamentals data such as, interest rates, currency exchange rates, inflation rates, trading volume, and annual returns for listed corporations, used to be the predicted factors available to forecast the financial stock markets prices and volume, for the listed companies, national stock index, and regional stock indexes.However, in the last six decades other new major factors became more reliable keys for the prediction of future prices and volume trends, in the world stock markets beside the previous two factors. These includes the options strike rates for underling shares, psychological price barriers, national, regional and International crises, irrational and noise trading, and finally the health crisis known as the COVID-19, as what happened in 2020. This paper discussed these predicted factors which now dominate in the world stock markets, and suggested stated ratios for the reliability of each presented measure, during different decades up to April of 2021, and how the reliability of theses indictors were changed from one decade to another. Key words: World Stock markets, Stock markets trends, options strike rates, irrational trading, psychological price barriers, financial crisis.","Label":"0"},{"DOI":"10.33020/saintekom.v8i2.56","Abstract":"Gold is one of the investment commodities whose value continues to increase from year to year. The rise in gold prices will encourage investors to choose to invest in gold rather than the capital market. Investment in gold gives better results for the long term and with better purchasing power, so gold investment is an effective solution considering the value of money annually eroded by inflation. Such a state of economic instability is what drives many people, organizations and companies to invest in gold precious metals. Factors influencing the rise or fall of gold price according to Riefiyono (2010) are change of exchange rate (dollar exchange rate to rupiah), world political situation, domestic economic situation, and interest rate.   The method used in this case is K-Nearest Neighbor (KNN) is a method that uses In the training phase, this algorithm only retains feature vectors and sample training data classification. In the classification phase, the same features are calculated for testing data (whose classification is unknown).   The results obtained are successfully made an application for the prediction of gold prices by utilizing the method of Nearest Neighbor Retrieval. This application can help users in knowing the gold price prediction results are expensive or cheap with views in terms of economic situation, interest rates, political situation, and changes in exchange rates.","Label":"1"},{"DOI":"10.2139/ssrn.369441","Abstract":"Since the late 1970s/early 1980s, the entire U.S. economy has gone through some structural changes. Outside of the technological changes, the Federal Reserve monetary policies have probably been the main force behind these changes. These policies, known as soft-landing policies, focused on a stable growth in the economy by keeping the inflation low, with the ultimate objective of removing extreme fluctuations. To cope with these structural changes, the composite leading economic indicators have gone through a series of revisions since 1996 (CLI-96) with the objective of improving its quality information for the prediction of the near term state of the economy. In this research we look at two related questions: (1) Have these revisions in CLI-96 captured all the effects of the structural changes on the state of the economy since the early 1980s, or are there still some effects left behind and not captured? (2) Given that the latter part of question (1) is true, can this new information be measured and utilized to produce a better prediction of the near term state of the economy? Our research shows that CLI-96 did not capture all the effects of the structural changes in the economy. When the probability distribution of the CLI-96 growth rates for the expansion periods since 1983 is used, the two methodologies of the classical statistical decision theory and the Bayesian have predicted the 2001 recession correctly, but the overall reliability of their predictions has deteriorated. Overall, it can be concluded that the severity of the 2001 recession is more comparable to the economic slowdowns of 1993 and 1996 than to the recession of 1990.","Label":"0"},{"DOI":"10.2139/ssrn.1726225","Abstract":"This study attempts to quantify whether a 4 percent withdrawal rate can still be considered as safe for U.S. retirees in recent years when earnings valuations have been at historical highs and the dividend yield has been at historical lows. We find that the traditional 4 percent withdrawal rule is likely to fail for recent retirees. The maximum sustainable withdrawal rate (MWR) for retirees may continue declining even after the peak in earnings valuations in 2000. Our lowest point estimate for an MWR with a 60/40 allocation between stocks and bonds is 1.46 percent for new retirees in 2008. We also discuss confidence intervals for these predictions. The regression framework with variables to predict long-term stock returns, bond returns, and inflation (the components driving the retiree's remaining portfolio balance) produces estimates that fit the historical data quite well, and we use backtesting for a further robustness check. Nevertheless, there are important qualifications for these predictions. In particular, they depend on out-of-sample estimates as the circumstances of the past 15 years have not been witnessed before, and there is always potential for structural changes which could leave recent retirees in better shape than suggested by the model. Looking forward, this methodology can guide new retirees toward a reasonable range for their MWR so that the 4 percent rule need not be blindly followed.","Label":"0"},{"DOI":"10.1007/978-981-15-1244-5_4","Abstract":"This chapter aims to assess the impact of energy price adjustments under a macro-econometric modeling framework at the backdrop of the government’s efforts of energy price reforms in recent times. The effect of energy price changes on macroeconomic outcomes has been predicted with alternative scenarios of deregulations of domestic energy prices, particularly to the outcomes for growth, inflation, fiscal balances and external balances. The prediction has been done for the period FY2015 to FY2021 in line with the Seventh Five Year Plan period (2015–2019) and the Perspective Plan, 2021. Overall, the out of sample performance of the model seems quite good. The model initially analyzes macroeconomic data for the period 1980–2011. The sample validation and out of sample prediction imply that the model fit is good and it can be used for policy simulations through assumed shocks. The results suggest that an upward revision of energy prices will be slightly inflationary and as a result, the real gross domestic product (GDP) growth rate will fall slightly during the predicted period. However, the GDP growth and inflationary situation might improve if changes in other macroeconomic indicators take place along with energy price adjustments.","Label":"0"},{"DOI":"10.48550/arxiv.1810.09494","Abstract":"Researchers are often interested in predicting outcomes, conducting clustering analysis to detect distinct subgroups of their data, or computing causal treatment effects. Pathological data distributions that exhibit skewness and zero-inflation complicate these tasks - requiring highly flexible, data-adaptive modeling. In this paper, we present a fully nonparametric Bayesian generative model for continuous, zero-inflated outcomes that simultaneously predicts structural zeros, captures skewness, and clusters patients with similar joint data distributions. The flexibility of our approach yields predictions that capture the joint data distribution better than commonly used zero-inflated methods. Moreover, we demonstrate that our model can be coherently incorporated into a standardization procedure for computing causal effect estimates that are robust to such data pathologies. Uncertainty at all levels of this model flow through to the causal effect estimates of interest - allowing easy point estimation, interval estimation, and posterior predictive checks verifying positivity, a required causal identification assumption. Our simulation results show point estimates to have low bias and interval estimates to have close to nominal coverage under complicated data settings. Under simpler settings, these results hold while incurring lower efficiency loss than comparator methods. Lastly, we use our proposed method to analyze zero-inflated inpatient medical costs among endometrial cancer patients receiving either chemotherapy and radiation therapy in the SEER medicare database.","Label":"1"},{"DOI":"10.1016/j.ribaf.2022.101854","Abstract":"Significant surge in gold prices has attracted speculators, investors and intellectuals alike. Factors driving gold prices, the effectiveness of gold price predictions, the economic viability of gold mining, risk management using gold, and its comparisons against exchange rates and stock prices have been some of the consistent foci of researchers. Applying bibliometrics on 453 top articles published on gold between 1970 and 2021, we present a comprehensive overview of the academic discussions on one of the fast evolving research domains. Apart from identifying the publication and citation trends, we note seven intellectual clusters contributing to growth of the contemporary research identified as: dynamics of gold prices and its linkage with other asset prices, gold prices: forecasting and comparison, gold as an instrument for an inflation hedge, gold and currency market, economic policy and gold prices, role of gold in the global financial market, and expected value and volatility of gold.","Label":"0"},{"DOI":"10.1016/j.econmod.2022.105841","Abstract":"The existing literature found that state ownership generally boosts bond ratings but ignores the implications for rating quality. Using China's corporate bonds issued from 2008 to 2018, we find that bonds issued by state-owned enterprises (SOEs) have relatively poorer rating quality than their non-SOE peers, as supported by the SOE ratings' weaker predictive power for future downward rating events. Importantly, the SOE ratings' poorer prediction performance is partly because of rating inflation; only relatively overrated SOE bonds contain less relevant information in ratings but not nonoverrated SOE bonds. This asymmetry in rating quality is prominent in the case of a local controlling government or when the SOE bonds are rated in booms wherein the incentive to inflate ratings is stronger. The evidence is consistent with a government guarantee induced rating bias where expected government guarantees reduce credit rating agencies' (CRAs') reputational costs and induce CRAs to inflate SOE ratings.","Label":"0"},{"DOI":"10.1109/ecti-con49241.2020.9157907","Abstract":"International businesses usually use Forex exchange market to support their business. However, investing has a risk so they need an accuracy Forex information to make the decision. The simple moving average (SMA) has been widely used and a well-known moving average method for time series forecasting. In this empirical study, we would like to do a performance analysis of EUR/U SD Forex rates by adding simple moving averaged technique and financial factors (Dollar Index (DX), US Interest rate (federal funds rate), Inflation rate (IR) and real Gross Domestic Product (GDP)). Four Forex datasets are Forex, Forex with factors, Forex with SMA, and Forex with factors and SMA to forecast Forex rates. Research efforts on Multilayer Perceptron (MLP) and Linear Regression (LM) for forecasting EUR/USD Forex rates. It is shown by using mean square error (MSE) that by adding financial factors and simple moving average to Forex datasets, the performance has improved significantly.","Label":"1"},{"DOI":"10.48550/arxiv.1505.05314","Abstract":"When providing probabilistic forecasts for uncertain future events, it is common to strive for calibrated forecasts, that is, the predictive distribution should be compatible with the observed outcomes. Several notions of calibration are available in the case of a single forecaster alongside with diagnostic tools and statistical tests to assess calibration in practice. Often, there is more than one forecaster providing predictions, and these forecasters may use information of the others and therefore influence one another. We extend common notions of calibration, where each forecaster is analysed individually, to notions of cross-calibration where each forecaster is analysed with respect to the other forecasters in a natural way. It is shown theoretically and in simulation studies that cross-calibration is a stronger requirement on a forecaster than calibration. Analogously to calibration for individual forecasters, we provide diagnostic tools and statistical tests to assess forecasters in terms of cross-calibration. The methods are illustrated in simulation examples and applied to probabilistic forecasts for inflation rates by the Bank of England.","Label":"1"},{"DOI":"10.33301/jed-p-2018-20-02-01","Abstract":"This paper examines the impact of financial inclusion (FI) on monetary policy (MP) – a case study in Vietnam. The PCA method is used to construct a FI index- considered as a comprehensive measure of FI. To answer the main research questions, OLS and GLS models are used to analyze and to overcome the phenomenon of heteroskedasticity. Data is collected through secondary sources including World Bank and IMF reports (for the period 2004-2015). The results of empirical research indicate that there is a negative impact of FI on MP. Accordingly, FI transmits to more successful MP, making efficient financial intermediation and balances, contributing to a stable and sustainable economy. This study concludes that FI will enable monetary policy to extend its reach to the financially excluded and aid policy makers to make better predictions of movements in inflation.","Label":"1"},{"DOI":"10.1057/s41308-018-0056-6","Abstract":"Secular stagnation theory has developed substantially recently and offers substantial insights that policymakers have yet to fully internalize. This paper reviews the considerations that led me to revive the secular stagnation idea, summarizes the theory as I understand it today, and argues that events since I started advocating the secular stagnation view have tended to confirm its predictions and reject those of its critics. It addresses the various objections, both theoretical and empirical, that have been put forward to the secular stagnation idea, and argues that if secular stagnation is a central macroeconomic issue, much of the conventional wisdom regarding macroeconomic policy needs to be rethought. Contrary to current orthodoxy, monetary policies may be able to have lasting impacts on levels of output but not to determine rates of inflation. Fiscal policies may be essential for assuring full employment and financial stability. Increases in government indebtedness may contribute to financial stability.","Label":"0"},{"DOI":"10.1016/1062-9408(93)90016-x","Abstract":"The article describes a variety of accuracy measures, error diagnostics and rationality tests and applies them to the Organisation for Economic Cooperation and Development's macroeconomic forecasts for Canada and the United States. The forecasts examined are one, two and three steps ahead for a wide range of aggregate demand and output, inflation and balance-of-payments variables, 4,134 pairs of forecasts and outcomes in all. Major findings include: The OECD forecasts are better than naive no-change predictions and forecasts generated by simple autoregressive time-series models. Forecasts for the United States are more accurate than those for Canada. Most forecasting error is nonsystematic. Forecasting accuracy deteriorates from oneto two- to three-step ahead forecasts. The OECD's forecasting performance neither improves nor deteriorates over time. The tests reveal several instances where simple linear corrections could improve forecasting accuracy. Many forecasts fail bias and efficiency tests so the rational expectations hypothesis generally is not supported.","Label":"0"},{"DOI":"10.1080/09538259000000032","Abstract":"In the recent writing on the methodology of economics there has been a shortage of systematic analyses of realism and explanation and an absence of analysis of their inter-relationships. This article attempts to provide a detailed account of the structure of economic explanation built upon realist and essentialist premises. Invisible-hand explanations characteristic of Austrian economics and the question of using the quantity theory for explaining inflation are used as illustrations. From another perspective, the analysis amounts to providing a reconstructive interpretation of the deep structure of the Austrian approach to explaning economic phenomena. It is suggested that realist-essentialist explanations be analysed in terms of redescription, reduction, ontological identification, and unification: Austrian (as well as some other) explanaions can be analysed as reductive theoretical redescriptions of economic phenomena using ontological identification statements and pursuing ontological unification of apparently diverse phenomena. Among these and other things, questions related to the deductive-nomological model, prediction, the implications of subjectivism and the role of common sense are discussed.","Label":"0"},{"DOI":"10.2139/ssrn.2039670","Abstract":"In this paper we take an in-depth view of one particular type of inefficiency that may be present in the combination of forecasts: Mincer and Zarnowitz (MZ) inefficiency. Under mild assumptions we show that weighted combinations of forecasts are MZ-inefficient with probability one. We also show that convex linear combinations of forecasts will always display MZ-inefficiency when the individual forecasts are MZ-efficient. No assumptions about the availability of private or public information are required for these results. All this implies that greater reductions in Mean Squared Prediction Error are possible and that the traditional optimal weighted combination may not coincide with the optimal weighted MZ-efficient combination. We illustrate our findings with a couple of empirical applications in the context of the combination of inflation forecasts for Chile and the U.S. A simple adjustment based upon a rolling OLS strategy is shown to remove the MZ-inefficiency of the combinations quite well.","Label":"0"},{"DOI":"10.1186/s40100-016-0070-9","Abstract":"Beef is a staple food for Argentine consumers, and although the country has been a major exporter, the highest proportion of beef production is consumed in the domestic market. With rising inflation rates in the last 5 years, and given the beef prices’ strong weight on the composition of the Consumer Price Index, the Argentine government began taking measures to control it. They initially forced price agreements with members of the marketing and production chain and ended up with a total ban on exports. The results were not as expected and caused serious distortions at different levels of the beef chain. This study aimed to determine whether the impact on some economic and production variables would have been different without such intervention. A VAR model was estimated in order to compare the observed behavior with intervention measures and estimated predictions with a theoretically free market.","Label":"0"},{"DOI":"10.2139/ssrn.4349573","Abstract":"We propose two types of equal predictive ability (EPA) tests with panels to compare the predictions made by two forecasters. The first type, namely S-statistics, focuses on the overall EPA hypothesis which states that the EPA holds on average over all panel units and over time. The second, called C-statistics, focuses on the clustered EPA hypothesis where the EPA holds jointly for a fixed number of clusters of panel units. The asymptotic properties of the proposed tests are evaluated under weak and strong cross-sectional dependence. An extensive Monte Carlo simulation shows that the proposed tests have very good finite sample properties even with little information about the cross-sectional dependence in the data. The proposed framework is applied to compare the economic growth forecasts of the OECD and the IMF, and to evaluate the performance of the consumer price inflation forecasts of the IMF.","Label":"0"},{"DOI":"10.1016/j.euroecorev.2021.103982","Abstract":"Standard New Keynesian models predict that expansionary fiscal policy is inflationary. In contrast, this paper presents empirical evidence that prices do not increase in response to a positive government spending shock. Instead, the response of prices is flat or even negative. This finding is robust across a wide range of specifications of our Structural Vector Autoregression (SVAR) model and across different price indices. The puzzling response of prices is accompanied by an increase in output and private consumption, as found in most of the existing literature, as well as an increase in Total Factor Productivity. We show that the introduction of variable technology utilization can enable an otherwise standard New Keynesian model to account for our empirical findings. The model implies that the government spending multiplier is substantially lower when the economy is in a fundamental liquidity trap, as compared to normal times, in contrast to the predictions of standard New Keynesian models.","Label":"0"},{"DOI":"10.1007/978-981-16-7334-4_13","Abstract":"This research paper presents the approach of applying the simulation technique to predict the upcoming trend of Malaysia’s unemployment rate. The recent Malaysia’s unemployment rate has fluctuated at quite a high rate ever since the COVID-19 pandemic occurred. Population growth, Growth Domestic Product (GDP), inflation rate, interest rate, exchange rate, investment, government expenditure and most importantly the number of COVID-19 cases act as the independent variables in this paper. The Multiple Linear Regression (MLR) is used to determine the significance of each variable to be included in the model and also to simulate the upcoming trend of Malaysia’s unemployment rate. The result of the analysis shows that the upcoming five years trend of Malaysia’s unemployment rate will continue to increase in the future based on the average value of the simulations conducted.","Label":"0"},{"DOI":"10.1080/07350015.2021.1933991","Abstract":"We study efficient estimation for models with nonlinear heteroscedasticity. In two-step quantile regression for heteroscedastic models, motivated by several undesirable issues caused by the preliminary estimator, we propose an efficient estimator by constrainedly weighting information across quantiles. When the weights are optimally chosen under certain constraints, the new estimator can simultaneously eliminate the effect of preliminary estimator as well as achieve good estimation efficiency. When compared to the Cramér-Rao lower bound, the relative efficiency loss of the new estimator has a conservative upper bound, regardless of the model design structure. The upper bound is close to zero for practical situations. In particular, the new estimator can asymptotically achieve the optimal Cramér-Rao lower bound if the noise has either a symmetric density or the asymmetric Laplace density. Monte Carlo studies show that the proposed method has substantial efficiency gain over existing ones. In an empirical application to GDP and inflation rate modeling, the proposed method has better prediction performance than existing methods.","Label":"1"},{"DOI":"10.1016/j.jinteco.2020.103389","Abstract":"A large literature estimates the exchange rate pass-through to prices (ERPT) using reduced-form approaches, whose results are an important input for Central Banks. We show two shortcomings of these empirical measures for monetary policy analysis, which are quantitatively important and may lead to imprecise and biased inflation predictions. First, while the literature describes a single ERPT, which we will label unconditional, there are different ERPT conditional on each shock that hits the economy. Second, these crucially depend on expected monetary policy, so that empirical ERPT measures should not be taken as given in evaluating policy actions. We use a simple model of a small and open economy to understand the intuition behind these two critiques, showing that these results seem to hold under many alternative specifications. We then highlight the quantitative relevance of these distinctions using a large-scale DSGE model of a small open economy.","Label":"0"},{"DOI":"10.48550/arxiv.2003.02803","Abstract":"We propose two types of equal predictive ability (EPA) tests with panels to compare the predictions made by two forecasters. The first type, namely $S$-statistics, focuses on the overall EPA hypothesis which states that the EPA holds on average over all panel units and over time. The second, called $C$-statistics, focuses on the clustered EPA hypothesis where the EPA holds jointly for a fixed number of clusters of panel units. The asymptotic properties of the proposed tests are evaluated under weak and strong cross-sectional dependence. An extensive Monte Carlo simulation shows that the proposed tests have very good finite sample properties even with little information about the cross-sectional dependence in the data. The proposed framework is applied to compare the economic growth forecasts of the OECD and the IMF, and to evaluate the performance of the consumer price inflation forecasts of the IMF.","Label":"0"},{"DOI":"10.2139/ssrn.1341947","Abstract":"This paper analyzes the predictability of different style portfolio returns. Styles, as used in this paper and Barberis and Shleifer (2003), can be defined as groups of securities with a common characteristic, such as value (Graham and Dodd (1934)) and size (Banz (1979)). I specifically look at the determinants of style investing, such as style momentum and predictor variables such as macroeconomic variables (e.g. yield spread, inflation, industrial production, etc.), and show how learning about these variables affects the predictability of different style portfolio returns compared to linear models. A time-varying parameter model and a Kalman filter are used to take into account the effect of learning in this paper. At the end, I find that returns on style portfolios such as value and size appear to be related to the yield spread and other macroeconomic variables. This paper also finds that time-varying parameter models provide better in-sample and out-of-sample predictions then simple benchmark constant parameter models.","Label":"0"},{"DOI":"10.1016/j.jedc.2016.10.001","Abstract":"We use a model in which media of exchange are essential to examine the role of liquidity and monetary policy on production and investment decisions in which time is an important element. Specifically, we consider the effects of monetary policy on the length of production time and entry and exit decisions for firms. We show that higher rates of inflation cause households to substitute away from money balances and increase the allocation of bonds in their portfolio thereby causing a decline in the real interest rate. The decline in the real interest rate causes the period of production to increase and the productivity thresholds for entry and exit to decline. This implies that when the real interest rate declines, prospective firms are more likely to enter the market and existing firms are more likely to stay in the market. Finally, we present reduced form empirical evidence consistent with the predictions of the model.","Label":"0"},{"DOI":"10.1016/j.jedc.2013.02.007","Abstract":"We run an experiment where groups of six subjects must set prices in a non-stationary macroeconomic environment, where prices are complements. The exogenous variable, a business indicator, is common knowledge and prices are flexible, disregarding sticky prices or sticky information. In a first treatment subjects insignificantly corrected for past errors, which implies that history plays a role for determining current prices. By reporting the business indicator in a simpler form the second treatment tacitly offered a heuristic for setting prices. This option was widely taken, bringing about an excess response to the business indicator and a significant deviation from equilibrium even in the long run. In a third treatment with staggered pricing we observe that subjects look only one round into the future but not further ahead, contrary to theoretical predictions. Our findings suggest that monetary transmission may be impaired due to what we label sticky reasoning, the failure or unwillingness to iteratively delete dominated strategies.","Label":"0"},{"DOI":"10.2139/ssrn.3214322","Abstract":"This paper evaluates the effects of forward guidance and large-scale asset purchases (LSAP) when the nominal interest rate reaches the zero lower bound. I investigate the effects of the two policies in a dynamic new Keynesian model with financial frictions adapted from Gertler & Karadi (2011, 2013), with changes implemented so that the framework delivers realistic predictions for the effects of each policy on the entire yield curve. I then match the change that the model predicts would arise from a linear combination of the two shocks with the observed change in the yield curve in a high-frequency window around Federal Reserve announcements, allowing me to identify the separate contributions of each shock to the effects of the announcement. My estimates correspond closely to narrative elements of the FOMC announcements. My estimates imply that forward guidance was more important in influencing inflation, while LSAP was more important in influencing output.","Label":"0"},{"DOI":"10.2139/ssrn.2665116","Abstract":"This paper studies the impact of recessions on the longer-run level of output using data on 23 advanced economies over the past 40 years. We find that severe recessions have a sustained and sizable negative impact on the level of output. This sustained decline in output raises questions about the underlying properties of output and how we model trend output or potential around recessions. We find little support for the view that output rises faster than trend immediately following recessions to close the output gap. Indeed, we find little evidence that growth is faster following recessions than before; if anything post-trough growth is slower. Instead, we find that output gaps close importantly through downward revisions to potential output rather than through rapid post-recession growth. The revisions are made slowly (over years) – a process that leads to an initial underestimation of the effect of recessions on potential output and a corresponding under-prediction of inflation.","Label":"0"},{"DOI":"10.2139/ssrn.406704","Abstract":"In the simplest frictionless theory, an increase in real interest rates causes a symmetric decline in investment for all firms because they discount new projects at a higher cost of capital. I develop and test a specific debt-market financing channel in which differences in the maturity structure of debt result in varied responses of investment to changes in real and nominal interest rates. Firms with high levels of short-term debt suffer a decline in cash flows, relative to firms financed with long-term debt, when nominal interest rates increase. In U.S. firm-level data between 1953 and 2001, I find that the investment of firms with a high current portion of debt is more sensitive to changes in real and nominal interest rates when compared with firms that have only long-term debt. Consistent with my predictions, firms with high levels of short-term debt also display higher investment sensitivity to inflation.","Label":"0"},{"DOI":"10.1080/13504850500358819","Abstract":"Over the last three decades, the Turkish economy has experienced severe macro-shocks, among which depreciation of the Turkish lira is the most noticeable one. The Turkish lira (TL) has depreciated from 13 TL per US dollar in 1973 to more than 1.5 million TL per dollar today. It is expected that because of these shocks, some of the macro-relationships could suffer from structural instability which makes policy formulation and predictions difficult. This paper considers the demand for money in Turkey. To take account of currency substitution, the demand for money that includes the exchange rate in addition to income, interest rate and inflation rate is estimated. After incorporating the CUSUM and CUSUMSQ tests in bounds testing approach for cointegration, it is shown that in Turkey for a successful and effective monetary policy, the monetary authorities would rather concentrate on M1 because not only is it cointegrated with its determinants and it is stable, all four determinants belong to the cointegrating space.","Label":"0"},{"DOI":"10.48550/arxiv.2211.16641","Abstract":"Scanner big data has potential to construct Consumer Price Index (CPI). This work utilizes the scanner data of supermarket retail sales, which are provided by China Ant Business Alliance (CAA), to construct the Scanner-data Food Consumer Price Index (S-FCPI) in China, and the index reliability is verified by other macro indicators, especially by China's CPI. And not only that, we build multiple machine learning models based on S-FCPI to quantitatively predict the CPI growth rate in months, and qualitatively predict those directions and levels. The prediction models achieve much better performance than the traditional time series models in existing research. This work paves the way to construct and predict price indexes through using scanner big data in China. S-FCPI can not only reflect the changes of goods prices in higher frequency and wider geographic dimension than CPI, but also provide a new perspective for monitoring macroeconomic operation, predicting inflation and understanding other economic issues, which is beneficial supplement to China's CPI.","Label":"1"},{"DOI":"10.2139/ssrn.1349094","Abstract":"We propose two new procedures for comparing the mean squared prediction error (MSPE) of a benchmark model to the MSPEs of a small set of alternative models that nest the benchmark. Our procedures compare the benchmark to all the alternative models simultaneously rather than sequentially, and do not require reestimation of models as part of a bootstrap procedure. Both procedures adjust MSPE differences in accordance with Clark and West (2007); one procedure then examines the maximum t-statistic, the other computes a chi-squared statistic. Our simulations examine the proposed procedures and two existing procedures that do not adjust the MSPE differences: a chi-squared statistic, and White's (2000) reality check. In these simulations, the two statistics that adjust MSPE differences have most accurate size, and the procedure that looks at the maximum t-statistic has best power. We illustrate, our procedures by comparing forecasts of different models for U.S. inflation.","Label":"0"},{"DOI":"10.2139/ssrn.2553136","Abstract":"We generalise the stylised macroeconomic Agent-Based model introduced in our previous paper (\"Tipping points in macroeconomic agent-based models\", JEDC 50 29–61 2015), with the aim of investigating the role and efficacy of monetary policy of a \"Central Bank\", that sets the interest rate such as to steer the economy towards a prescribed inflation and unemployment level. Our major finding is that provided its policy is not too aggressive (in a sense detailed in the paper) the Central Bank is successful in achieving its goals. However, the existence of different equilibrium states of the economy, separated by phase boundaries (or \"dark corners\"), can cause the monetary policy itself to trigger instabilities and be counter-productive. In other words, the Central Bank must navigate in a narrow window: too little is not enough, too much leads to instabilities and wildly oscillating economies. This conclusion strongly contrasts with the prediction of DSGE models.","Label":"0"},{"DOI":"10.1353/jda.2011.0008","Abstract":"This paper investigates the currency regime choices of six Southeast Asian (SEA) countries, namely Indonesia, Korea, Malaysia, Philippines, Singapore and Thailand, for the period 1973-99 from the perspectives of optimum currency area (OCA), macroeconomic stabilization and currency crisis. Regime transition dynamics are insignificant among three broad categories of regimes, such as fixed, intermediate and floating regimes but significant among a variety of intermediate regimes. Economic development, financial liberalization and inflation are found to be significant to the pegged regime choice, while high degree of trade openness, capital mobility, real exchange rate volatility and fiscal performance are significant to the choice of a more flexible regime. However, the policy of financial (capital account) liberalization under a pegged (intermediate) regime was paradoxical in nature and has been proved to be inappropriate in the aftermath of crisis. Except this, the static regime choice in SEA countries is largely consistent with the predictions of international macroeconomics.","Label":"0"},{"DOI":"10.1111/j.0307-3378.2006.00232.x","Abstract":"By considering the theoretical connection between labour and product markets, the paper evaluates the economic relationship of these markets within the contractual wage rigidity New Keynesian explanation of business cycles. The empirical analysis focuses on the short‐run cyclical behaviour of real output, prices and wages for 19 industrial countries. Time‐series and cross‐sectional regressions are estimated. Cross‐sectional cyclical correlations in the labour and goods markets are also evaluated across countries. Consistent with the theoretical predictions, aggregate uncertainty is an important factor in increasing the flexibility of the nominal wage in response to aggregate demand shocks. Wage flexibility accelerates price inflation and moderates the response of real output growth to aggregate demand shocks. Wage flexibility does not appear to be an important factor in differentiating the real and inflationary effects of energy price shocks across countries. Finally, aggregate uncertainty increases the responsiveness of output and price to productivity shocks.","Label":"0"},{"DOI":"10.1016/j.eneco.2023.106738","Abstract":"Stock and oil relationship is usually time-varying and depends on the current economic conditions. In this study, we propose a new Dynamic Stochastic Mixed data sampling (DSM) copula model, that decomposes the stock-oil relationship into a short-run dynamic stochastic component and a long-run component, governed by related macro-finance variables. Inference and prediction is carried out using a novel Bayesian estimation strategy, that can efficiently estimate the latent states and delivers an estimate of the log marginal likelihood used for model comparison. We find that inflation/interest rate, uncertainty and liquidity factors are the main drivers of the long-run co-dependence. We show that the multi-step-ahead variance covariance forecasts constructed using the proposed approach are closer to the true values as compared to the benchmark model. Finally, investment portfolios, based on the proposed DSM copula model, are more accurate and produce better economic outcomes as compared to other alternatives.","Label":"0"},{"DOI":"10.54691/bcpbm.v46i.5085","Abstract":"Debt-to-GDP ratio can commendably indicate the ability of serving debt of a country and it has correlation with inflation ratio, actual ratio, deficit ratio and GDP ratio. Moreover, the debt-to-GDP ratio can be predicted with other ratios. This paper studies on these ratios and explores the impact of these ratios on the US bond and currency market and gives some credible suggestions. The paper uses Pearson analysis to study the correlation of the five ratios. Further, the degree of the correlation is presented. Linear and ridge regression are used to forecast the Debt-to-GDP ratio fluctuations and the prediction model and formula are also given. The result of the paper is significant for investors to grasp the correlation and seize better opportunity. For nation administrator, the paper gives a more accurate method to predict future ratios thus preparing ahead of schedule.","Label":"1"},{"DOI":"10.1016/j.ijforecast.2023.02.001","Abstract":"We propose two types of equal predictive ability (EPA) tests with panels to compare the predictions made by two forecasters. The first type, S -statistics, focuses on the overall EPA hypothesis, which states that the EPA holds, on average, over all panel units and over time. The second type, C -statistics, focuses on the clustered EPA hypothesis where the EPA holds jointly for a fixed number of clusters of panel units. The asymptotic properties of the proposed tests are evaluated under weak and strong cross-sectional dependence. An extensive Monte Carlo simulation shows that the proposed tests have very good finite sample properties, even with little information about the cross-sectional dependence in the data. The proposed framework is applied to compare the economic growth forecasts of the OECD and the IMF, and to evaluate the performance of the consumer price inflation forecasts of the IMF.","Label":"0"},{"DOI":"10.1057/978-1-349-95189-5_2285","Abstract":"Abstract             This article provides an overview of the uncovered interest parity assumption. It traces the history of the concept, summarizes evidence on the empirical validity of uncovered interest parity, and discusses different interpretations of the evidence and the implications for macroeconomic analysis. The uncovered interest parity assumption has been an important building block in multi-period models of open economies and, although its validity is strongly challenged by the empirical evidence, at least at short time horizons, its retention in macroeconomic models is supported on pragmatic grounds by the lack of much empirical support for existing models of the exchange risk premium.","Label":"0"},{"DOI":"10.5539/ijef.v10n12p43","Abstract":"Accurate prediction of gasoline price is important for the automobile makers to adjust designs and productions as well as marketing plans of their products. It is also necessary for government agencies to set effective inflation monitoring and environmental protection policies. To predict future levels of the gasoline price, due to difficulties of obtaining accurate estimates of influential external factors, data driven time-series forecasting models thus become more suitable given the convenience and practicability they are providing. In this paper, five popular time-series forecasting models, i.e., ARIMA-GARCH, exponential smoothing, grey system, neural network, and support vector machines models, are applied to predict gasoline prices in China. Comparing the performances of these models, it is noted that for this specific time series, a parsimonious ARIMA model performs the best in predicting the gasoline prices for a short time horizon, while for the medium length and long run the SVR and FNN models outperforms others respectively.","Label":"1"},{"DOI":"10.2139/ssrn.2816710","Abstract":"Along with monetary tools, fiscal policies have been strong instrument of the government to boost the economy, especially in recession periods, as a reason, the government always has to face budget deficit, whose effect is still controversial. Thus, this paper is aim to clarify the impacts of budget deficit on economic growth in the case of Viet Nam, and access long-run relationship among macro variables, by applying Autoregressive Distributed Lag (ARDL) to analyze quarterly data for the period from 2003 to 2015. After undertaking statistical method, it’s convinced that there is a long-run relationship among macro variables. Besides, budget deficit has no effect on economic growth, which is relevant to Ricardian paradigm. Whereas, productive expenditures has significant positive impact. However, non-productive spending and consumer price index (inflation) both reveal adverse effect. Therefore, all government’s decisions in term of spending are recommended to be taken under precautions.","Label":"0"},{"DOI":"10.1111/obes.12163","Abstract":"Quantile aggregation (or ‘Vincentization’) is a simple and intuitive way of combining probability distributions, originally proposed by S.B. Vincent in 1912. In certain cases, such as under Gaussianity, the Vincentized distribution belongs to the same family as that of the individual distributions and it can be obtained by averaging the individual parameters. This article compares the properties of quantile aggregation with those of the forecast combination schemes normally adopted in the econometric forecasting literature, based on linear or logarithmic averages of the individual densities. Analytical results and Monte Carlo experiments indicate that the properties of quantile aggregation are between those of the linear and the logarithmic pool. Larger differences among the combination schemes occur when there are biases in the individual forecasts: in that case quantile aggregation seems preferable on the whole. The practical usefulness of Vincentization is illustrated empirically in the context of linear forecasting models for Italian GDP and quantile predictions of euro area inflation.","Label":"1"},{"DOI":"10.1016/0304-4076(93)90047-9","Abstract":"This paper investigates the construction and application of point-optimal invariant (POI) tests of joint AR(1)−AR(4) disturbances against jointMA(1)−MA(4) disturbances in the linear regression model. A Monte Carlo experiment is conducted to assess and compare the small sample performances of two asymptotic tests and two POI tests. Of the asymptotic tests, the Lagrange multiplier test is found to have distinctly better small sample properties than the prediction test. We also find that the extra computation required to perform a POI test is rewarded by a clear improvement in size and power properties in comparison to the asymptotic tests. The use of a POI test is illustrated with an application to a quarterly model of price inflation in the United Kingdom during 1947–1970. The paper concludes with some discussion of the problem of testing general AR(p) disturbances against MA(q) disturbances.","Label":"0"},{"DOI":"10.1590/s0034-71401999000400001","Abstract":"This paper investigates whether political economy factors contribute to explain the exchange rate policy in Brazil from 1964 to 1997. An analytical framework presents the tradeoff between the positive effect of a depreciated exchange rate on the balance of payments and its negative effect on inflation as driving force affecting exchange rate policy. The exchange rate policy resulting from this tradeoff depends on the political environment. We test our hypotheses by modeling the exchange rate disequilibrium level as a Markov switching model with time varying transition probabilities, and the influence of political economy variables on the transition probabilities is tested. The results support partially the predictions of our analytical framework. According to our statistical results there is an election cycle: the probability of having an overvalued exchange rate is higher in the months preceding elections, while the probability of having an undervalued exchange rate is higher in the months succeeding elections.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2007.03.002","Abstract":"This paper applies a large data set, consisting of 167 monthly time series for the UK, both economic and financial, to simulate out-of-sample predictions of industrial production, inflation, 3-month Treasury Bills, and other variables. Fifteen dynamic factor models that allow forecasting based on large panels of time series are considered. The performances of these factor models are then compared to the following competing models: a simple univariate autoregressive, a vector autoregressive, a leading indicator, and a Phillips curve models. The results show that the best dynamic factor models outperform the competing models in forecasting at 6-, 12-, and 24-month horizons. Thus, the financial markets may have predictive power for the economic activity. This can be a useful tool for central banks and financial institutions, which may use the factor models to construct leading indicators of the economic conditions. In addition, researchers can see a strategic application of factor models.","Label":"0"},{"DOI":"10.15388/ekon.2001.16963","Abstract":"The aim of this article is to inform about research. which was done by use of artificial neural networks [ANN] applications for prognoses of Lithuania National Stock Exchange indexes LIT IN, LITIN-A, LITIN-VVP. Analysis for entropy shows the level of chance of tbe variations and correspondingly shows possibilities to find economic factors, which may influence Stock Exchange variations. Correlation analysis shows dependance between some Lithuania macroeconcmic indicators, foreign exchange indexes and LITIN, LITIN-A, LITIN-VVP indexes. It helps to include such indicators in to the autoregression, autoregression with the cause and cause prediction models. ANN learning is executed by weighted values of past period corresponding national indexes, by country’s macroeconomic indicators (like GNP, unemployment, inflation. interest rates and so on) and by other country’s Stock Exchange indexes (USA - Dow Jones and S&P, EU - Eurex, Russia - RTS). Comparison is made with the linear multidimensional regression method.","Label":"1"},{"DOI":"10.2139/ssrn.879821","Abstract":"Based on the significance of a Minimum Variance Portfolio (MVP) for the understanding of dollarization equilibria, a significant strand of the debate concerned with the driving forces behind this phenomenon has focused on analyzing the determinants of the relative volatility of inflation vis-à-vis real depreciation. This analysis contributes in the identification of those factors by extending the basic CAPM formulation via the introduction of credit risk that is directly linked to the shock that determines real returns for dollar denominated assets: unanticipated shifts in the real exchange rate. We show this ingredient can end up altering the perceived relative volatility of peso and dollar assets in a way that fuels financial dollarization (by increasing the relative hedging opportunities offered by the latter). We calibrate our model using Peruvian data for the period 1998-2004, and its predictions show a better fit with observed financial dollarization ratios than those of the basic CAPM model.","Label":"0"},{"DOI":"10.2139/ssrn.3034358","Abstract":"Negative interest rates are present in various marketplaces since mid-2014, following the negative interest rate policy (NIRP) adopted by the European Central Bank in order to lift the economic growth (and, therefore, the inflation). However, this policy involves difficulties for market practitioners as there is no model that enables to forecast negative interest rates in a coherent and sounding theoretical manner. Facing this lack of reliable models, the well-known Historical Approach (HA) appears to be a good resource. By tweaking the HA, we derive a data-driven and very tractable tool that allows practitioners to generate yield-curve distribution at future discrete time horizons. So, we provide a robust and easy-to-understand forecasting model, suitable for the NIRP context, allowing to appreciate its prediction power. Besides the methodology development that we present in this work, various numerical illustrations are reported in order to shed light on the benefit (and the limit) of our forecasting approach.","Label":"0"},{"DOI":"10.4172/2162-6359.1000340","Abstract":"This study sought to determine the economic factors predicting IPO share price volatility at the Nairobi Securities Exchange under the mediating role of regulatory authorities such as the Central Bank of Kenya, Capital Markets Authority, Nairobi Securities Exchange and National Treasury, and the intervening function of Investment banks, commercial banks, brokerage houses, media and politics. Through a correlational research design employing simple regression, the results are contradictory on the economic indicators and their effect on different sectors of the economy. With the exception of Equity bank which showed a positive relationship with interest rates, Foreign exchange, Nairobi Securities All Share Index and Lagged Share Price, KenGen and Safaricom showed no significant relationship with their economic predictors. A reworked model comprising inflation rate, interest rate, foreign exchange rate and money supply captured the overall market prediction with the initial three having negative significance whereas money supply had positive significance as a predictor of share price volatility.","Label":"0"},{"DOI":"10.1016/j.econlet.2016.11.007","Abstract":"This paper considers a standard New Keynesian model with heterogeneous expectations on the future level of inflation and output. A biased perception of the target pursued by the Central Bank may arise due to idiosyncrasies in information processing, leading to heterogeneous beliefs about the target. We consider an arbitrarily large number of agents’ beliefs and apply the concept of Large Type Limit. We find that an increase in the sensitivity of agents in selecting the optimal prediction strategy or in the spread of beliefs is crucial for the extent of the Central Bank to stabilize the economy. When the predictors are largely dispersed around the target, the Taylor principle is a requisite for stability since it prevents the self-fulfilling reinforcement mechanism between the realizations of the relevant macroeconomic variables and the forecasts of the agents. When the set of beliefs is somehow anchored to the target, stability can be achieved with weaker monetary policy.","Label":"0"},{"DOI":"10.54691/bcpbm.v30i.2513","Abstract":"Under the impact of the epidemic, the economy of all countries has been affected to varying degrees, and the most obvious common one is that the global inflation rate has risen, thus resulting in the phenomenon of purchasing power deviation. The focus of this paper is that the traditional Capital Asset Pricing Model (CAPM) lacks the prediction of this part of the risk, so it can not realize the original intention of THE CAPM Model, completely to wash away this part of the risk. As well as the domestic and foreign research review in recent years, the literature analysis, the conclusion is drawn, in view of the traditional CAPM in the international portfolio investment deficiency, as well as the applicability in the real financial market, this paper suggests that under the purchasing power parity offset, the use of high-order CAPM through the international portfolio investment is a more stable choice.","Label":"0"},{"DOI":"10.2139/ssrn.3326617","Abstract":"We present a Bayesian hierarchical framework for both cross-sectional and time-series return prediction. Our approach builds on a market-timing predictive system that jointly allows for time-varying coefficients driven by fundamental characteristics. With a Bayesian formulation for ensemble learning, we examine the joint predictability as well as portfolio efficiency via predictive distribution. In the empirical analysis of asset-sector allocation, our hierarchical ensemble learning portfolio achieves 500% cumulative returns in the period 1998-2017, and outperforms most workhorse benchmarks as well as the passive investing index. Our Bayesian inference for model selection identifies useful macro predictors (long-term yield, inflation, and stock market variance) and asset characteristics (dividend yield, accrual, and gross profit). Using the selected model for predicting sector evolution, an equally weighted long-short portfolio on winners over losers achieves a 46% Sharpe ratio with a significant Jensen’s alpha. Finally, we explore an underexploited connection between classical Bayesian forecasting and modern ensemble learning.","Label":"1"},{"DOI":"10.1080/15140326.2018.1526865","Abstract":"In this paper, the empirical analysis finds that the dynamics of inflation and unemployment can be described by a Phillips curve when allowing for a positive co-movement between trend-adjusted productivity and unemployment. This suggests that improvements in productivity have been achieved by laying off the least productive part of the labor force. Furthermore, the natural rate of unemployment is a function of the long-term interest rate, indicating that monetary policy is not completely neutral in the long run. This result rejects the natural rate hypothesis and, at the same time, provides empirical support for the structural slump theory in a world of imperfect knowledge. The recent theory of imperfect knowledge economics (IKE) seems to address the problem that many economic models lack: persistence in the observed data. By combining IKE and the structural slumps theory it is possible to obtain predictions that are theoretically and empirically consistent.","Label":"0"},{"DOI":"10.2139/ssrn.3297736","Abstract":"The modeling of multivariate time series in an agnostic manner, without assumptions about underlying theoretical structure is traditionally conducted using Vector Auto-Regressions. They are well suited for linear and state-independent evolution. A more general methodology of Multivariate Recurrent Neural Networks allows to capture non-linear and state-dependent dynamics. This paper takes a range of small- to large-scale Long Short-Term Memory MRNNs and pits them against VARs in an application to US data on GDP growth, inflation, commodity prices, Fed Funds rate and bank reserves. Even in a small-sample regime, MRNN outperforms VAR in forecasting: its out-of-sample predictions are about 20% more accurate. MRNN also fares better in interpretability by means of impulse response functions: for instance, a temporary shock to the Fed Funds rate variable generates system dynamics that are more plausible according to conventional economic theory.","Label":"1"},{"DOI":"10.2139/ssrn.2567014","Abstract":"We use a model in which media of exchange are essential to examine the role of liquidity and monetary policy on production and investment decisions in which time is an important element. Specifically, we consider the effects of monetary policy on the length of production time and entry and exit decisions for firms. We show that higher rates of inflation cause households to substitute away from money balances and increase the allocation of bonds in their portfolio thereby causing a decline in the real interest rate. The decline in the real interest rate causes the period of production to increase and the productivity thresholds for entry and exit to decline. This implies that when the real interest rate declines, prospective firms are more likely to enter the market and existing firms are more likely to stay in the market. Finally, we present reduced form empirical evidence consistent with the predictions of the model.","Label":"0"},{"DOI":"10.1007/s40844-017-0072-7","Abstract":"Between 2003 and 2015 the prices of apartments in Hong Kong (adjusted for inflation) were multiplied by a factor of 3.8. This is more than in the United States prior to the so-called subprime crisis of 2007. The analysis of this speculative episode confirms the mechanism and regularities already highlighted by the present authors in similar episodes that occurred previously in other countries. Based on these regularities, it is possible to predict the price trajectory over the time interval 2016–2025. It suggests that, unless appropriate relief is provided by the mainland, Hong Kong will experience a decade-long slump. This bubble took considerable proportions largely because the currency board system through which Hong Kong interest rates are modeled on US rates made it impossible to “cool the market”. In fact, it resulted in loans with negative real interest rates.","Label":"0"},{"DOI":"10.1016/0304-3932(95)01191-p","Abstract":"In the U.S., existing monetary base measures add an adjustment factor for changes in reserve requirement ratios to high powered money. Implicitly, the monetary base assumes that the economic effects of changes in reserve requirements are identical to those due to changes in high-powered money. Theory, however, does not generally support the prediction that the two policy tools will have the same economic effects. Structural VARs are estimated to compare the short-run paths of inflation and output growth under two different types of policy shocks. In doing so, this analysis gives one a measure of the costs associated with this implicit equivalence assumption. The evidence is consistent with the hypothesis that the Federal Reserve at least partially offsets reserve requirement changes with open market operations and the hypothesis that dynamic explanations of macroeconomic variables are improved by separating reserve requirement changes from other monetary policy moves.","Label":"0"},{"DOI":"10.1002/jae.1176","Abstract":"We propose two new procedures for comparing the mean squared prediction error (MSPE) of a benchmark model to the MSPEs of a small set of alternative models that nest the benchmark. Our procedures compare the benchmark to all the alternative models simultaneously rather than sequentially, and do not require re‐estimation of models as part of a bootstrap procedure. Both procedures adjust MSPE differences in accordance with Clark and West (2007); one procedure then examines the maximum t‐statistic, while the other computes a chi‐squared statistic. Our simulations examine the proposed procedures and two existing procedures that do not adjust the MSPE differences: a chi‐squared statistic and White's (2000) reality check. In these simulations, the two statistics that adjust MSPE differences have the most accurate size, and the procedure that looks at the maximum t‐statistic has the best power. We illustrate our procedures by comparing forecasts of different models for US inflation. Copyright © 2010 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.1109/icaiti.2018.8686737","Abstract":"Groceries are strategic commodities that have an important role in economic, social, and even political aspects in various countries including Indonesia. The groceries affect the livelihood of the people with the scale of the fulfilment of high needs as well as factors supporting the welfare of the community. The classical problem in the fulfilment of grocery is the fluctuation of the prices of groceries. The increase in the prices of groceries commodities becomes a major factor in inflation. To overcome these problems, one of the efforts made by the government is to stabilize the price policy of grocery so that farmers as producers get profitable results and the community as consumers can afford to buy groceries at affordable prices. To accommodate the afford it is needed a forecasting step to predict the prices of groceries. This study aims to predict the prices of national groceries using the Average Based Fuzzy Time Series method with Song - Chissom and Markov Chain approach. The data used are prices of groceries weekly period from 2015 - 2017. Data is divided into two phases: training and testing dataset with the ratio of 90: 10. Based on MAPE value and feasibility test, it can be concluded that Average Based Fuzzy Time Series with Markov Chain approach shew better than Song - Chissom approach for prediction the prices of national groceries.","Label":"1"},{"DOI":"10.2139/ssrn.1716","Abstract":"We present a general equilibrium model in which unemployed workers search for employment opportunities. We deviate from the traditional search and matching literature by allowing each worker to simultaneously sample a number of firms; exogenously given, this number is a natural proxy for labor market information available to workers. As it approaches infinity, the information nears completeness, and our setup converges to the Walrasian one, with the equilibrium converging as well. On the other hand, as the number of searches declines, a traditional search model emerges with with the standard results. Thus, our model nests the conventional search models and the Walrasian model, which enables us to move between the two paradigms by varying the number of searches. We show that for a sufficiently large number of searches there exists an equilibrium such that each firm offers the same wage which is equal to the marginal productivity of labor. At the same time the model predicts involuntary unemployment at this wage. The aggregate employment in this model is determined by demand factors and by the level of information available to workers. On the other hand, wages are determined solely by technology and the exogenously given price of capital. This feature of the model leads to empirical predictions that are consistent with stylized facts but are hard to replicate using the Walrasian setup. In particular, changes in the variability of demand shocks can reduce employment without affecting wages, whereas technological changes can affect wages without altering the level of employment. Thus, our economy generates co-movements of wages and employment that could be interpreted as reflecting wage rigidities. Another empirical prediction is a negative correlation between job turnover and unemployment. While higher turnover implies more layoffs, it also improves the prospects for the unemployed to find a job as it increases the proportion of hiring firms. In our setting the latter effect dominates the former. Using the data on 20 largest OECD countries we show that the level of unemployment is negatively correlated with the rate of job destruction as is predicted by our model. It has been argued in the literature that higher rates of inflation increase the volatility of the relative demand for goods. In our paper, greater volatility in relative demands leads to higher rates of turnover and thereby to lower rates of unemployment. Thus, we believe that our model can be extended to imply a negative co-movement of inflation and unemployment, i.e., the Phillips curve.","Label":"0"},{"DOI":"10.55643/fcaptp.2.49.2023.3991","Abstract":"The russian federation's launch of a full-scale war against independent Ukraine on February 24, 2022, has presented unprecedented challenges to the country. In addition to resistance on the battlefield, Ukraine must implement adaptive macroeconomic policies to address the situation. This combination of military and economic efforts not only prevents economic collapse but also maintains fragile macroeconomic stability during wartime. Monetary stability becomes especially important, highlighting the absolute necessity for effective implementation of monetary policy.This article aims to identify the key characteristics of Ukraine's defence economy and forecast key policy rates and exchange rates during the war.The prerequisite for forecasting was the analysis of endogenous and exogenous factors determining the current state of the Ukrainian economy: index of business expectations in Ukraine and partner countries, state of international trade and balance of payments, disparities in the labour market, reorientation of the state budget to military needs, devaluation of the national currency, high inflation, increase of financial capital price.Modelling is based on consumer price index (CPI), household inflation expectations, key policy rate of the National Bank of Ukraine, real and nominal effective exchange rates hryvnia to USA dollar, gross and net international reserves, gross and net foreign exchange market interventions, the UK CPI, the USA CPI, EU CPI, and the weighted average yield of domestic government bonds. The methodology involved the use of the VECM model (Vector Error Correlation Model) and the Bagging machine learning method, adapted to time series. Using this methodology enabled an accurate forecast of the key policy rate. In determining the optimal exchange rate, a modified formula was used that takes into account the monetary base, total bank deposits, foreign currency deposits in banks, exchange rate in the black market, and international reserves. This modification enabled the prediction of an exchange rate that closely approximates the official exchange rate.","Label":"1"},{"DOI":"10.2139/ssrn.3374813","Abstract":"Problem definition: We study the impact of inventory allocation mechanism on the ordering behavior of retailers serviced from a central distribution center. Based on the allocation scheme employed by the distribution center, retailers may have an incentive to inflate/deflate their orders to gain a more favorable allocation. Such strategic ordering may, in turn, impact the resulting allocation efficiency across markets and system profits.Academic/Practical Relevance: Distribution centers often have limited inventory (e.g., due to order aggregation or perishability), making inventory allocation necessary. However, information about demand often resides locally, resulting in allocation based on the orders received (information asymmetry).Methodology: We first develop theory through an analytical model that depicts a pooling setting where retailers are collectively responsible for both overstocking and understocking costs. We consider three allocation mechanisms that are common in the literature and relevant for practice: proportional, linear, and uniform. We then test the derived theoretical predictions through a controlled laboratory experiment. Motivated by these results, we conclude by sketching a practical – tailored – application of the uniform allocation principle.Results: While all three allocation rules are system optimal under common knowledge of local demands, only the uniform rule incentivizes retailers to place an order equal to local demand. Consistent with theory, our experimental results show that the proportional and linear rules result in larger and more frequent order inflation/deflation, with the degree of strategic ordering being largest under the linear rule. Strategic ordering not only decreases system efficiency but also a retailer's own profits.Managerial Implications: Our study highlights how the type of allocation rule employed across retailers can significantly affect stockout and wastage across markets, through its effect on retailers' ordering. Applying the uniform principle to contain inflation/deflation of local needs is the dominant choice (both theoretically and in laboratory experiments).","Label":"0"},{"DOI":"10.2139/ssrn.3926171","Abstract":"Since the outbreak of Covid-19 and the central bank and government interventions that followed, new challenges in credit modeling have emerged. Relations between credit risk and macroeconomic drivers that have been fairly stable over decades have broken down. An example is the unemployment rate which has been widely used in predicting default rates in retail loan segments. Since mid-2020 this no longer works because of government interventions like monthly payments to citizens which allows them to service their debt despite suffering income loss due to unemployment or business closures. This results in substantially lower default rates than predicted by credit models. In this article, using data published by the US Federal Reserve Bank in Q1 2021, a framework is suggested that quantifies the effect of central bank and government interventions and shows how to include intervention scenarios into credit models improving the accuracy of their short-term predictions and allowing analysts to evaluate long-term scenarios. Furthermore, potential side-effects of intervention like increased inflation are quantified.","Label":"0"},{"DOI":"10.24843/mite.2021.v20i01.p18","Abstract":"Currency is a standardized payment instrument used all around the world. Almost each country has their own currency, and it has a variable value. Asia is one of the biggest continent in the world. Most tourists whom visit Indonesia come from Asia. Thus, that makes the most currency exchanged in Indonesia are currencies from Asia. Currency exchange rate difference between one currency and another affected by several factor. One of those factor is inflation in its country. To overcome that issue, one needs a prediction system that can be used to predict the exchange rate of currencies in the future. Quantum Neural Network is used in this research to predict Indonesian Rupiah exchange rate value to other currency in Asia. Singapore, Hongkong and Japan currencies are particularly used in this research. Results obtained from this research are accuracies. Quantum Neural Network produces 99.78% accuracy on Singapore Dollar to Indonesian Rupiah exchange rate, 99.57% on Hongkong Dollar to Indonesian Rupiah, and 99.60% on Japanese Yen to Indonesian Rupiah.","Label":"1"},{"DOI":"10.1109/icoei56765.2023.10126034","Abstract":"Exploring trends and patterns in the stock market has always been extremely challenging because of multiple (macro and micro) factors. The stock market is a dynamically, and non-linearly volatile entity based on time-stamped data. Stock market forecasting not only assists investors in contributing to the economy but also businessmen in funding expansion and savers in beating inflation. This research employs the past five years' historical data of various stock indices as an input to the “machine learning and deep learning algorithms” to forecast the price of the next day. The algorithms that have played a major role in forecasting stock prices are “Gated Recurrent Unit (GRU)”, “Long Short-Term Memory (LSTM)”, and “Support Vector Regression (SVR)”. The percentage error turned out to be the least with LSTM and SVR for one-day prediction. However, the evaluation metric - MAPE for a continuous range of price forecast is least for SVR and R-squared turned out to be higher with LSTM and SVR. The evaluation metric values for GRU are neither very high nor very low.","Label":"1"},{"DOI":"10.1007/978-981-19-2980-9_13","Abstract":"Fuel costs are falling worldwide during the pandemic, but not in India. In recent years, the petrol’s price has risen dramatically in all across the states of India, and reaching in three digits. The government is also targeting it as their best revenue source. It indicates that the fuel costs causes more inflation and common people have to suffer. These increased prices have robbed Indian citizens of living a healthy life. This paper analyzes Delhi’s petrol price and forecasting by examining daily petrol prices’ forecasting performance from June 16, 2017, to December 15, 2021. Various time series, machine learning, deep learning, and ensemble learning models are used to find the best model for forecasting the results. We have analyzed the performance of the models with the help of the performance metrics such as MSE, RMSE, MAPE, and NRMSE. The outcomes of the models indicate that time series-based models are pretty compelling.","Label":"1"},{"DOI":"10.1145/3308558.3313479","Abstract":"Current reputation systems in online labor markets (e.g., Freelancer, PeoplePerHour) experience three major shortcomings: (1) reputation inflation (i.e., reputation scores are inflated to above average values) (2) reputation attribution (i.e., attribution of reputation scores to individual skills is unfeasible) and (3) reputation staticity (i.e., reputation scores are uniformly averaged over time). These shortcomings render online reputation systems uninformative, and sometimes even misleading. This work proposes a data-driven approach that deflates reputation scores by solving the problems of reputation attribution and saticity. The deflating process starts with projecting any random set of skills to a set of competency dimensions. For each competency dimension, a Hidden Markov Model estimates a contractor's current (but latent) competency-specific expertise. Aggregation of competency-specific estimates provides expertise predictions for any given set of required skills. Empirical analysis on 61,330 completed tasks from a major online labor market shows that the resulting estimates are deflated and they better predict contractor performance. These results suggest a series of implications for online (labor) markets and their users.","Label":"0"},{"DOI":"10.1145/3219104.3229253","Abstract":"In the ever-changing1 real estate market, there are certain factors that have a huge impact on the fluctuating of house prices, and there are relationships between those factors. The only way to understand the behavior of the changes would be to explore historical data of those factors that impact the housing prices most. Many research papers have studied to predict the trends of house prices, in various countries, using various statistical models, and machine learning methods. Florida housing prices not only depend on various economics indexes but also impact by other natural disasters factors such as hurricane etc. which will be considered in future research. This project will involve the study of the housing market in Florida; we will be considering various factors such as the number of sales, employment rate, interest rate, GDP, inflation rate, hurricane strikes etc. Dataset from 1985 to 2016 will use in our analysis and case study and the time series is adopted. The prediction of this model is promising.","Label":"1"},{"DOI":"10.1080/14697688.2017.1357971","Abstract":"The analysis of the financial cycle and its interaction with the macroeconomy has become a central issue for the design of macroprudential policy since the 2007–08 financial crisis. This paper proposes the construction of financial cycle measures for the US based on a large data set of macroeconomic and financial variables. More specifically, we estimate three synthetic financial cycle components that account for the majority of the variation in the data set using a dynamic factor model. We investigate whether these financial cycle components have significant predictive power for economic activity, inflation and short-term interest rates by means of Granger causality tests in a factor-augmented VAR set-up. Further, we analyze whether the synthetic financial cycle components have significant forecasting power for the prediction of economic recessions using dynamic probit models. Our main findings indicate that all financial cycle measures improve the quality of recession forecasts significantly. In particular, the factor related to financial market participants’ uncertainty and risk aversion—related to Rey’s (2013) global financial cycle—seems to serve as an appropriate early warning indicator for policymakers.","Label":"0"},{"DOI":"10.1109/eiconcit50028.2021.9431897","Abstract":"The price of chili is one of the food commodities that can affect the inflation rate. Its uncertain price and even increasing at certain times will negatively impact society and state. The price offer for chili is still highly dependent on the amount of chili produced. At the same time, the amount of chili productivity depends on the harvested area and land productivity. When the supply in the market is lacking, the price will increase far from its average price. Otherwise, when the supply is excessive, the price will fall far below the regular price. Therefore, it requires a method to estimate this chili’s price to support decision making related to price issues. Many forecasting methods have been used to predict data, such as Backpropagation Neural Networks (BPNN) and Single Moving Average (SMA), proven in some cases to provide good forecasting results. These two methods will be compared with the lowest error rate and the best method in predicting chili’s price. The results of this research will help various parties as a consideration in making decisions and planning.","Label":"1"},{"DOI":"10.18778/0208-6018.345.03","Abstract":"In this study we focus on distress events of European banks over the period of 1990–2015, using unbalanced panel of 3,691 banks. We identify 132 distress events, which include actual bankruptcies as well as bailout cases. We apply CAMEL‑like bank‑level variables and control macroeconomic variables (GDP, inflation, unemployment rate). The analysis is based on traditional logistic regression and k‑means clustering. We find, that the probability of distress is connected with macroeconomic conditions via regional grouping (clustering). Bank‑level variables that were stable predictors of distress from 1 to 4 years prior to event are equity to total assets ratio (leverage) and loans to funding (liquidity). From macroeconomic factors, the GDP growth is a reasonable variable, however with differentiated impact: for 1 year distance high distress probability is connected with low GDP growth, but for 2, 3 and 4 year distance: high distress probability is conversely connected with high GDP growth. This shows the changing role of macroeconomic environment and indicates the potential impact of favorable macroeconomic conditions on building‑up systemic problems in the banking sector.","Label":"1"},{"DOI":"10.1007/s11403-016-0174-z","Abstract":"We extend in a minimal way the stylized macroeconomic Agent-Based model introduced in our previous paper (Gualdi et al. in J Econ Dyn Control 50:29–61, 2015a), with the aim of investigating the role and efficacy of monetary policy of a ‘Central Bank’ that sets the interest rate such as to steer the economy towards a prescribed inflation and employment rate. Our major finding is that provided its policy is not too aggressive (in a sense detailed in the paper) the Central Bank is successful in achieving its goals. However, the existence of different equilibrium states of the economy, separated by phase boundaries (or “dark corners”), can cause the monetary policy itself to trigger instabilities and be counter-productive. In other words, the Central Bank must navigate in a narrow window: too little is not enough, too much leads to instabilities and wildly oscillating economies. This conclusion strongly contrasts with the prediction of DSGE models.","Label":"0"},{"DOI":"10.2118/9203-ms","Abstract":"Abstract The oil industry has seen inflation on both sides of the balance sheet well above that experienced by the general consumer, not only in increased costs, but in the difficulty of finding new reserves, and arbitrary government imposed tariffs. Figures presented will show that the high profits reported by presented will show that the high profits reported by many oil companies are misleading and still do not leave adequate funds for reserve replacement costs. Conclusions are drawn that governments must leave adequate and more funds with companies for future development.  Introduction Twenty-two and one half years ago was my first time in Texas. I came for a production school at Kilgore. At that school I learnt one very important thing - that a course in communications was not how to manipulate a field radio, but how to convey and receive messages and ideas, so that they are mutually understood. I hope this paper well help in some measure in providing some facts figures and ideas that may be useful in getting one oil industry message across to governments and the public, and for it to be understood by them. We have been very poor at this in the past. Inflation in the oil industry, which in the context of this paper refers to the exploration, drilling and completion aspects and not to the refining or marketing, in the last decade, has been spectacular. It has occurred on both sides of the balance sheet, but before going into specific figures I believe it is important to stress that in this paper I will be talking about and using approximate and average numbers. I chose to use such numbers to make the paper of more general use and to illustrate a point, and to develop an argument, rather than to cover any one area or many areas with specific figures that would be more confusing, and still only lead to the same conclusions. Figures for a specific area have been used in some areas where I believe they are generally representative or illustrate a point. Where the figures for a specific area are completely different from other areas they only serve to stress that that area is out of step with the rest of the world. It might also be important to stress that the views expressed are those of an engineer trying to develop his own oil and gas, and may not be presented in the purist form that would have been chosen by an accountant or an economist. Returning briefly to the balance sheet we have on the positive side an increase in the gross oil price from $3.50 per barrel to somewhere between $30 and $40 per barrel, depending of course on location, type of crude and a number of other variables. This has been reflected in the much publicized percentage profits increase of many companies, a most misleading profits increase of many companies, a most misleading and misunderstood figure. On the negative side of the balance sheet costs have escalated at varying rates, government takes have escalated, in many cases far beyond any reasonable business prediction, and oil and gas in meaningful quantities now have to be found in locations that are operationally much harder, and therefore much more expensive even without the influence of the normal meanings of inflation. It is important to spread the message that whilst the profits may seem high to the outsider, the extra funds generated are still far from adequate to find and develop the future petroleum needs of the world, and that these funds must be left with industry to reinvest.   DEFINITIONS AND PRINCIPLES For the purposes of this paper I have used the following definitions: Inflation as defined in the dictionary: A rise in prices and a fall in the value of money, caused by prices and a fall in the value of money, caused by an increase in the amount of money available to buy goods and services, or by their scarcity. Consumer inflation in my interpretation is the percentage increase or multiplier by which the cost percentage increase or multiplier by which the cost of day to day items have increased in current moneys (dollars) without regard to the increase in the take home pay package.","Label":"0"},{"DOI":"10.1108/jes-04-2019-0176","Abstract":"Purpose                     The purpose of this paper is to analyse the long-term nature of the interrelationship between interest rate and exchange rate.                                                           Design/methodology/approach                     By employing Mexican data, the authors estimate a non-linear autoregressive distributed lags (NARDL) model to investigate the nature of the changes and the interaction between interest rate and exchange rate in response to monetary authorities’ actions.                                                           Findings                     The results show that, contrary to simplistic predictions, the real exchange rate causes the real interest rate in an asymmetric way. The bounds testing approach of the NARDL models suggests the presence of co-integration among the variables and the exchange rate variations appear to have significant long-run effects on the interest rate. Most importantly, these effects are asymmetric and positive variations in the exchange rate have a lower impact on the interest rate. It is also interesting to report that the reverse is not true: the interest rate in the long-run exerts no statistical significant impact on the exchange rate.                                                           Practical implications                     The asymmetric long-term relationship between real exchange rate and real interest rate is evidence of why monetary authorities are reluctant to free float exchange rate. In Mexico, as in most developing countries, monetary policy strongly responds to exchange rate movements because these have relevant effects on commercial trade. Moreover, in dollarized economies these effects are stronger because of pass-through impacts to inflation, income distribution and balance-sheet equilibrium (the well-known “original sin”).                                                           Originality/value                     Under inflation targeting and flexible exchange rate regime, despite central banks pursue the control of short-term interest rate, in the long-run one could observe that it is the exchange rate that influences the interest rate, and that this reverse causality is stronger in emerging economies. This paper contributes by analysing the asymmetric relationship between the variables.","Label":"0"},{"DOI":"10.29244/ijsa.v1i1.47","Abstract":"The chili is an important commodity in Indonesia, which has a fairly large price fluctuations. Fluctuations in prices often raises the risk of loss even have contributed to inflation. Chili price data is time series data that is not independent between observations (autocorrelation) and do not spread to normal. In addition, chili price data does not have the diversity of homogeneous data. One method that can be used to predict the pattern of the data is spline regression. The data used in this study is data the average weekly price of chili in Jakarta from January, 2010 to October, 2015. The best spline model is a second order spline models with three knots. The model has a value of Mean Absolute Percentage Error (MAPE) of 9.57% and determination coefficient of 86.41%. The model obtained in this research is already well in predicting the pattern of the chili price, but it was only able to predict well for a period of one month. Prediction chili prices in Jakarta for November are in the range of Rp 35.565. Keywords: chili price, regression, spline.","Label":"0"},{"DOI":"10.2139/ssrn.1107488","Abstract":"We introduce a Nelson-Siegel type interest rate term structure model with the underlying yield factors following autoregressive processes revealing time-varying stochastic volatility. The factor volatilities capture risk inherent to the term structure and are associated with the time-varying uncertainty of the yield curve's level, slope and curvature. Estimating the model based on U.S. government bond yields applying Markov chain Monte Carlo techniques we find that the yield factors and factor volatilities follow highly persistent processes. Using the extracted factors to explain one-year-ahead bond excess returns we observe that the slope and curvature yield factors contain the same explanatory power as the return-forecasting factor recently proposed by Cochrane and Piazzesi (2005). Moreover, we identify slope and curvature risk as important additional determinants of future excess returns. Finally, we illustrate that the yield and volatility factors are closely connected to variables reflecting macroeconomic activity, inflation, monetary policy and employment growth. It is shown that the extracted yield curve components have long-term prediction power for macroeconomic fundamentals.","Label":"0"},{"DOI":"10.2139/ssrn.2747064","Abstract":"This paper revisits the relationship between interest rates and exchange rates in a small open emerging economy using wavelet-based methodologies. Based on data for Romania, our results confirm the theoretical predictions on the interest rate - exchange rate relationship during turmoil or policy changes. In the short term, the relationship is negative, confirming the sticky-price models, and over the long term, the relationship is positive, confirming the Purchasing Power Parity theory. At the beginning of the turmoil, the exchange rate movements generally take the lead over the interest rates for the first month, but the monetary authorities take the lead afterwards. Our results reveal that in a small open emerging economy with a direct inflation targeting monetary policy regime, the relationship between exchange rates and interest rate is fundamentally different from that in an advanced economy. Also, our results stress the necessity that the central bank must pay simultaneous attention to both variables in order to achieve their monetary policy targets.","Label":"0"},{"DOI":"10.15637/jlecon.37","Abstract":"This paper assesses the importance of infrastructure availability in the host developing country in increasing its attractiveness for overseas investors. I also take into account market size, economic development, macroeconomic stability, regional and income groupings, ability of the people to speak an international language and access to sea. Using annual data for a panel of 90 developing countries over the years 1980-2007, I found that consistent with the prediction of the market size hypothesis, population is found to have a significant positive effect on inward FDI. Sound macroeconomic management proxied by exchange rate and economic development have plausible significant effects on FDI inflows, whereas, high inflation signalling economic disorder deter foreign investors. Infrastructure availability measured through telephone-density positively influence overseas investors location choice. Though, it is sensitive to alternative proxy measures but robust with respect to specification of the estimating model. Language and geographic location dummies confirm that foreign firms prefer Anglophones, and are reluctant to invest in South Asia, MENA and Francophone countries. A significant time trend is also witnessed","Label":"0"},{"DOI":"10.11113/jt.v73.4321","Abstract":"House prices in Malaysian cities increased drastically in the past few years, notably in the state of Penang.  The existence of a housing bubble is speculated by major property players. This paper ascertains whether a housing bubble exists in Penang and explores the long-run and short-run determinants of Penang residential prices. Quarterly data (2000Q1 to 2012Q2) of House Price Index is the dependent variable and Gross Domestic Product, Consumer Price Index (CPI), Base Lending Rate (BLR) and Housing Supply as independent variables. Econometric model together with fully modified Ordinary Least Squares regression were used to detect the presence of housing bubble in Penang. The determinants of Penang house prices are based on Granger causality and variance decomposition analysis using the vector autoregressive (VAR) model. The results show no evidence of housing bubble in Penang housing market. CPI has both long-run and short run causality relationship with house prices while CPI and BLR explain a large part of housing price variance. Results show changes in inflation and cost of borrowing will greatly affect Penang house prices.","Label":"0"},{"DOI":"10.1016/j.econmod.2016.12.025","Abstract":"This paper revisits the relationship between interest rates and exchange rates in a small open emerging economy using wavelet-based methodologies. Based on data for Romania, our results confirm the theoretical predictions on the interest rate - exchange rate relationship during turmoil or policy changes. In the short term, the relationship is negative, confirming the sticky-price models, and over the long term, the relationship is positive, confirming the Purchasing Power Parity theory. At the beginning of the turmoil, the exchange rate movements generally take the lead over the interest rates for the first month, but the monetary authorities take the lead afterwards. Our results reveal that in a small open emerging economy with a direct inflation targeting monetary policy regime, the relationship between exchange rates and interest rate is fundamentally different from that in an advanced economy. Also, our results stress the necessity that the central bank must pay simultaneous attention to both variables in order to achieve their monetary policy targets.","Label":"0"},{"DOI":"10.35297/qjae.010027","Abstract":"This paper analyzes Brazil’s 2004–16 business cycle, which subsumes what is now regarded as the nation’s most severe macroeconomic recession in more than a century. During the steep recession, which stretched over more than two years, national production at one point fell 3.8 percent per annum while the unemployment rate rose from 4.6 to as high as 11.9 percent. This study, after delineating its methodology, examines the behavior of different Brazilian macroeconomic aggregates during the cycle. These aggregates include GDP, the money supply, interest rates, savings, industrial production of higher- and lower-order goods, and inflation. Also examined are the Brazilian government’s interventions that rearranged Brazil’s structure of production and ignited an unsustainable boom, the role of price controls in prolonging economic recovery, and the recovery per se using the theoretical lens of the Austrian-adjustment process. Finally, empirical data from the recent Brazilian cycle will be analyzed in light of the predictions of Austrian business cycle theory (ABCT). The data were found overall to support the theory.","Label":"0"},{"DOI":"10.5539/ijef.v11n9p1","Abstract":"The level of the yield curve is strongly associated with a very important macroeconomic variable for developing economies: the inflation. Therefore, it becomes relevant for economic studies the development of a time series model that can accurately predict this variable. This article proposes the estimation and prediction of the yield curve level using the GAS (Generalized Autoregressive Score) class of time-varying coefficient models. The formulation of these models facilitates a general framework for time series modelling presenting a series of advantages, including the possibility of specifying any conditional distribution deemed appropriate for the yield curve level. In addition, the complete structure of the predictive distribution is transported to the mechanism that updates the time-varying parameters, via score function. When analyzing the evaluation criteria, the measures of adherence, and both Wilcoxon and Diebold & Mariano tests, it was verified that the adjustment of the GAS model (2,2) with gamma distribution to the series containing the Brazilian Yield Curve level of January 2006 and February 2017 presented a satisfactory result.","Label":"0"},{"DOI":"10.2139/ssrn.1411144","Abstract":"In this paper we investigate the effects of EU enlargement on price convergence. The internal market is expected to boost integration and increase efficiency and welfare through a convergence of prices in product markets. Two principal drivers are crucial to explain price developments. On the one hand, higher competition exerts a downward pressure on prices because of lower mark ups. On the other hand, the catching up process of low income countries leads to a rise in the price levels and higher inflation over a transition period. Using comparative price levels for individual product categories price convergence can be established. However, the speed of convergence is rather slow, with half lives around 10 years. The enlargement has slightly stimulated the convergence process, and this impact is robust across different groups of countries. Moreover, the driving forces of convergence are explored. In line with theoretical predictions, the rise in competition exerts a downward pressure on prices, while catching up of low income countries leads to a rise in price levels.","Label":"0"},{"DOI":"10.1016/j.jmacro.2016.04.002","Abstract":"Whether the real interest rates respond in a different manner to macroeconomic news at the zero lower bound (ZLB) as compared to the case away from the ZLB is essential for assessing the effectiveness of government policies and the validity of the policy implications of New Keynesian models at the ZLB. The results from analyzing “real-side” news and price news reveal that nominal rates are less sensitive to news, while real interest rates respond to some news in the opposite direction at the zero lower bound as they would do in normal times. This suggests that, at least in the short run, policies that increase inflation (e.g., fiscal expansion) are favorable to the economy at the zero lower bound; this result is consistent with the prediction of the New Keynesian models. By using an identification strategy based on heterogeneity, I find that at the ZLB, monetary policy news is less effective in affecting short- and medium-term real rates and its effect dies off faster.","Label":"0"},{"DOI":"10.55208/aj.v3i1.63","Abstract":"This study examined Nigerian inflationary trends and drivers from 1985 through 2021(37years). The study explored how Money Supply (MS), Dollar Exchange Rate (DEXCHR), Government Expenditure (GEXP), and National Debt (NDT) affect Nigeria's Inflation Rate (INFLR). The Autoregressive distributed lag model showed mixed integration in aggregate secondary data from a CBN Statistical Bulletin. The model's multicollinearity and heteroskedasticity tests showed that it is homoskedastic and fit for prediction. MS only passed the statistical significance test long-term. This implies that MS is a strong determinant of INFLR in the long run (P-value= 0.0226) but not in the short run (P-value= 0.5056); DEXCHR exerted a positive insignificant effect on INFLR on the short and long run, evident with p-values of 0.3842 and 0.3981 respectively; LogGEXP exerted a negative significant effect on INFLR on the short and long run, evident with p-values of 0.0362 and 0.0289 respectively; and LogNDT exerted a positive Hence, inflationary trends do not significantly affect INFLR in Nigeria. The report advised the central bank to stop printing cheap currency to reduce money supply.","Label":"0"},{"DOI":"10.1109/icaccs57279.2023.10112863","Abstract":"Digital currencies like dollars, euros, and yen are analogous to cryptocurrencies. One can purchase and sell bitcoins using exchanges. For several months in 2017, the market capitalization of cryptocurrencies increased dramatically, which significantly increased their appeal. As a result, interest in virtual currencies has increased. Unlike traditional paper money, which may be created as needed by the market, the supply of cryptocurrency is finite. This prevents currency depreciation and printing inflation from occurring. The remaining 21 million cryptocurrencies are expected to take a long time to mine, and related infrastructure will be required to handle such large computations, possibly with a low return in the future, given the limited supply of cryptocurrencies and the fact that 80% of them had already been mined by mid-July 2018. Utilizing machine learning, this programme assists with cryptocurrency price forecasting. To quantitatively to tell beforehand bitcoin prices with greater precisely. The proposed system uses the LSTM algorithm, a machine learning algorithm, as demonstrated by experimental results, to predict cryptocurrency prices with a high level of accuracy.","Label":"1"},{"DOI":"10.1109/icrito51393.2021.9596527","Abstract":"The price of food and food related items are dynamic. A measure change in the price affects the buying behaviour of the consumer and monetary policies by the Government. The Consumer Food Price Index (CFPI) reflects the variations in food prices during a certain period. In India, the CFPI is released monthly by the Central Statistical Organization. It also reflects the inflation and helps the Government to take corrective measures in time. In this paper we have applied the machine learning approach in forecasting the consumer food price index in India. In specific, this work has focused on the applicability of Artificial Neural Network (ANN) models with back propagation learning in predicting the future values of CFPI. The monthly data for rural, urban and combined from the period 2013 to 2021 have been used to train and validate the models. The Mean Absolute Percentage Error (MAPE) values have been used to validate the accuracy of the models. The experimental results show that a simple ANN model with back propagation algorithm is highly capable in forecasting the future values of CFPI.","Label":"1"},{"DOI":"10.17016/ifdp.1988.334","Abstract":"This paper considers how exchange controls, black markets, and forward-looking expectations condition the impact of exchange rate devaluations in developing countries. A model incorporating these features is developed to analyze the response of key external balance indicators to anticipated devaluations. The model is driven by the movements of black market exchange rates in perfect foresight equilibrium, which in turn force changes in export under-invoicing and official trade statistics. The predicted movements in all measurable variables, both before and after devaluation, closely mirror those historically associated with devaluation episodes. The analysis is then extended to the case of 'devaluation cycles' to examine the paths of the black market rate and official trade statistics in the face of persistent inflation which over-values the real exchange rate and motivates periodic devaluations. Statistical analysis of a multi-devaluation data set strongly supports some of the most important predictions of the model: black market exchange rates typically depreciate in response to official devaluation, and all else equal, increases in the black market rate reduce official measures of dollar value exports.","Label":"0"},{"DOI":"10.23917/jep.v8i2.1041","Abstract":"There are a wide variety of monetary models of exchange rate determination, all of which are outgrowth and extension of the basic flexible-price version pioneered by Frenkel (1978) and Bilson (1978). The research aims to know and prove by empiri-cal means the flexible price monetary model is relevant and advantageous to explain the fluctuation of exchange rate rupiah. The methodology involves testing first two assumption of the monetary model, namely, the price arbitrage (unified goods market) and the existence of a stable money demand function. Having these assumption held, the estimation of fluctuation in exchange rate in 1997-2005 was estimated using the flexible price monetary model developed for this purpose. Estimation of fluctuation in exchange rate suggest that the actual behavior of exchange rate in the period 1997 – 2005 is highly consistent with prediction of the flexible price monetary model. Fluctuation in exchange rate of Indonesia was largely explained by such variables as domestic money demand, domestic income and expected inflation, consistent with hypothesis of the flexible price monetary model.","Label":"0"},{"DOI":"10.1109/com-it-con54601.2022.9850653","Abstract":"India's government spends 1.5 percent of its annual GDP on public healthcare, which is significantly less than that of other countries. Global public health spending, on the other hand, has almost doubled in line with inflation in the last two decades, reaching US ${\\$}8.5$ trillion in 2019, or 9.8% of global GDP. Multinational multi-private sectors provide around 60% of comprehensive medical treatments and 70% of out-patient care, which charge patients astronomically high fees. Because of the rising expense of quality healthcare, increased life expectancy, and the epidemiological shift toward non-communicable diseases, health insurance is becoming an essential commodity for everyone. Insurance data has increased dramatically in the last decade, and carriers now have access to it. The health insurance system explores predictive modeling to boost its business operations and services. Computer algorithms and Machine Learning (ML) is used to study and analyze the past insurance data and predict new output values based on trends in customer behavior, insurance policies, and data-driven business decisions, and support in formulating new schemes. Additionally, ML has found enormous and potential applications in the insurance industry. Thus, this paper develops a real-time insurance cost price prediction system named ML Health Insurance Prediction System (MLHIPS) using ML algorithms which will aid the insurance companies in the market for easy and rapid determination of values of premiums and thereby curb down health expenditure. The proposed model incorporates and demonstrates different models of regression such as Ridge Regression, Lasso Regression, Simple Linear Regression, Multiple Linear Regression and Polynomial Regression to anticipate insurance costs and assess model outcomes. In the proposed model, the Polynomial Regression model has achieved better results with an RMSE value of 5100.53 and R -squared value of 0.80 compared to all the other models.","Label":"1"},{"DOI":"10.1080/10168737.2021.1999298","Abstract":"This paper analyzes the sources of business cycle fluctuations in Kazakhstan and the relevance of various frictions in the economy using a medium-scale DSGE model with imperfect exchange rate pass-through. We estimate the model via Bayesian methods and present estimates of structural parameters of the model and highlight the role of various shocks in explaining the actual dynamics of observed variables. In the absence of quality and deseasonalized data, we show that the DSGE model with time-varying markups possesses a reasonable level of accuracy as the one-sided Kalman filter predictions match the dynamics of the observable variables. Posterior estimates of the model show that the long-run growth rate of output is 4.5% per annum and the exchange rate pass-through to domestic prices is between 21% and 35% within a quarter. We also find that risk premium shocks have played an important role in determining the inflation rate, the interest rate and the real exchange rate in the economy since 2015.","Label":"0"},{"DOI":"10.1080/13547860.2020.1862391","Abstract":"We specify a mixed-frequency Nelson–Siegel term structure (MF-NS) model with fiscal policy information to investigate the influence of fiscal policy on interest rate term structure. This paper finds the following results: First, fiscal policy information can significantly improve both the in-sample fitting and out-of-sample predictions of the Chinese yield curve. More importantly, compared with short-term bonds, the fiscal variable has a greater contribution to long-term bonds. Second, the response of the level factor of the yield curve to monetary impulse is positive, while the response to fiscal surprise is negative. Furthermore, we suggest that monetary policy shows an inflation expectation effect for the level factor. However, fiscal policy shocks on the level factor via the wealth effect. Finally, fiscal policy account for the larger forecast variance of yield curve than monetary policy does in the short forecast horizon. Meanwhile, this paper further shows that fiscal policy has a greater contribution to forecast variance of long-term yield than short-term yield.","Label":"0"},{"DOI":"10.1109/wisscon56857.2023.10133865","Abstract":"In Today's competitive environment, every Industry wants to grow fast to become a leader in their business. There is a need for the regular growth of business in the form of expansion. For Expansion, they required more capital. There are primarily 3 ways to raise Capital. These ways are an Initial Public Offering (IPO), Angel investors, and Business loans. Generally, when a company grows beyond a certain size, it is difficult for individual investors to continue to run the operations within their own capacity of capital. Companies need constant capital. An IPO method for raising capital often raises a company's profile and enhances its credibility with suppliers, Creators, and customers. Raising capital is the primary motivation for an IPO, however, it can also provide an opportunity for a partial sell-down by founders/early-stage investors. After IPO, the shares of a company are available in the form of stocks in an open platform. Including stocks in a public investment portfolio can prove to be beneficial. By investing in stocks of various companies, individuals can generate savings and shield their money against inflation and taxes. However, in order to optimize returns on investment, it is important to have the ability to predict stock prices. All the surveyed techniques are based on the concepts of Machine Learning. These techniques are compared by highlighting their strengths and weaknesses. In the survey of existing works, it is found that combining LSTM with another model can be the most effective technique for stock price prediction. The future scope of improvements in the surveyed research is also suggested in the paper. Researchers in this field can take advantage of these suggested improvements for further research in the field to enhance the performance of techniques used for stock price prediction.","Label":"1"},{"DOI":"10.1007/978-3-319-31822-6","Abstract":"This book explores widely used seasonal adjustment methods and recent developments in real time trend-cycle estimation. It discusses in detail the properties and limitations of X12ARIMA, TRAMO-SEATS and STAMP - the main seasonal adjustment methods used by statistical agencies.  Several real-world cases illustrate each method and real data examples can be followed throughout the text. The trend-cycle estimation is presented using nonparametric techniques based on moving averages, linear filters and reproducing kernel Hilbert spaces, taking recent advances into account. The book provides a systematical treatment of results that to date have been scattered throughout the literature. Seasonal adjustment and real time trend-cycle prediction play an essential part at all levels of activity in modern economies. They are used by governments to counteract cyclical recessions, by central banks to control inflation, by decision makers for better modeling and planning and by hospitals, manufacturers, builders, transportation, and consumers in general to decide on appropriate action. This book appeals to practitioners in government institutions, finance and business, macroeconomists, and other professionals who use economic data as well as academic researchers in time series analysis, seasonal adjustment methods, filtering and signal extraction. It is also useful for graduate and final-year undergraduate courses in econometrics and time series with a good understanding of linear regression and matrix algebra, as well as ARIMA modelling.","Label":"0"},{"DOI":"10.29207/resti.v4i1.1266","Abstract":"Jakarta Islamic Index (JII) is an organization engaged in the economy with the aim to pay attention to stock movements every day. With the JII, people who do not understand about shares and their movements, will be easy to know and understand the movement of shares that occur at certain times. The problem in this research is that many investors are unable to predict the rise and fall of stock prices. The prediction process can be done with a backpropagation algorithm. The algorithm is a concept of computer science which is widely used in the case of analysis, prediction and pattern determination. The process starts from the analysis of the variables used namely interest rates, exchange rates, inflation rates and stock prices that occurred in the previous period. The variables used are continued in the formation of network patterns and continued in the process of training and testing in order to produce the best network patterns so that they are used as a process of identifying JII stock price movements. The results obtained in the form of the value of stock price movements with an error rate based on the MSE value of 11.85% so that this study provides information in the form of knowledge for making a decision. The purpose of the research is used as input for investors in identifying share prices. In the end, the benefits felt from the results of this study, investors can make an initial estimate before investing in JII.","Label":"1"},{"DOI":"10.1016/j.ijforecast.2009.12.015","Abstract":"Loss functions play a central role in the theory and practice of forecasting. If the loss function is quadratic, the mean of the predictive distribution is the unique optimal point predictor. If the loss is symmetric piecewise linear, any median is an optimal point forecast. Quantiles arise as optimal point forecasts under a general class of economically relevant loss functions, which nests the asymmetric piecewise linear loss, and which we refer to as generalized piecewise linear (GPL). The level of the quantile depends on a generic asymmetry parameter which reflects the possibly distinct costs of underprediction and overprediction. Conversely, a loss function for which quantiles are optimal point forecasts is necessarily GPL. We review characterizations of this type in the work of Thomson, Saerens and Komunjer, and relate to proper scoring rules, incentive-compatible compensation schemes and quantile regression. In the empirical part of the paper, the relevance of decision theoretic guidance in the transition from a predictive distribution to a point forecast is illustrated using the Bank of England’s density forecasts of United Kingdom inflation rates, and probabilistic predictions of wind energy resources in the Pacific Northwest.","Label":"1"},{"DOI":"10.1111/jtsa.12511","Abstract":"This article introduces a new class of functional‐coefficient predictive regression models, where the regressors consist of auto‐regressors and latent factor regressors, and the coefficients vary with certain index variable. The unobservable factor regressors are estimated through imposing an approximate factor model on high dimensional exogenous variables and subsequently implementing the classical principal component analysis. With the estimated factor regressors, a local linear smoothing method is used to estimate the coefficient functions (with appropriate rotation) and obtain a one‐step ahead nonlinear forecast of the response variable, and then a wild bootstrap procedure is introduced to construct the prediction interval. Under regularity conditions, the asymptotic properties of the proposed methods are derived, showing that the local linear estimator and the nonlinear forecast using the estimated factor regressors are asymptotically equivalent to those using the true latent factor regressors. The developed model and methodology are further generalized to the factor‐augmented vector predictive regression with functional coefficients. Finally, some extensive simulation studies and an empirical application to forecast the UK inflation are given to examine the finite‐sample performance of the proposed model and methodology.","Label":"0"},{"DOI":"10.2139/ssrn.1631797","Abstract":"The saving rate of China is high from many perspectives - historical experience, international standards and the predictions of economic models. Furthermore, the average saving rate has been rising over time, with much of the increase taking place in the 2000s, so that the aggregate marginal propensity to save exceeds 50%. What really sets China apart from the rest of the world is that the rising aggregate saving has reflected high savings rates in all three sectors - corporate, household and government. Moreover, adjusting for inflation alters interpretations of the time path of the propensity to save in the three sectors. Our evidence casts doubt on the proposition that distortions and subsidies account for China's rising corporate profits and high saving rate. Instead, we argue that tough corporate restructuring (including pension and home ownership reforms), a marked Lewis-model transformation process (where the average wage exceeds the marginal product of labour in the subsistence sector) and rapid aging process have all played more important roles. While such structural factors suggest that the Chinese saving rate will peak in the medium term, policies for job creation and a stronger social safety net would assist the transition to more balanced domestic demand.","Label":"0"},{"DOI":"10.5897/jeif2014.0572","Abstract":"The research presented in this study, investigates chiefly the causal relationship between oil prices and key macroeconomic variables in Nigeria in a multivariate framework using times series data from 1980 to 2010. To examine whether there is prediction between oil prices and macroeconomic indicators (inflation, interest rate, exchange rate and real gross domestic product) as well as the impact of oil prices on the applied macroeconomic indicators, this research adopted the Granger causality and the ordinary least squares respectively. After ensuring data stationarity, the results suggest that in the short run, changes in the gross domestic product (GDP) is not influenced by oil price volatility, nor do we find evidence of influence on key macroeconomic variables. Again the findings indicate that there is a positive but insignificant relationship between oil price and the Nigerian Gross domestic product. Overall oil prices have no significant impact on real GDP and exchange rate in Nigeria. The result suggests that Nigeria has a special case of the Dutch Disease, where a country’s seeming good forutne proves ultimately detrimental to its economy. Key words: Oil and Gas, Gross Domestic Product, causality, macroeconomic indicators.","Label":"0"},{"DOI":"10.2139/ssrn.4298837","Abstract":"The report has tried to predict the share price of Colgate Palmolive on the basis of historical data. The report consists of the detailed analysis of the past data and its credibility in order to predict the future price changes in the share price of the Colgate Palmolive. Colgate Palmolive is the American worldwide company that deals with the production and distribution of household, healthcare and various personal care products. The company is regarded as trusted and recognize brand and been continually serving hundreds of millions of customers across 220 countries.In the process of analysing the data, daily data has been used as a base. During the process, the report has tried to identify the link by analysing correlation coefficient between the share price movements in a day to the share price changed in next day of the company. This has been calculated by using multiple linear regression model. In the process of establishing the link, the report has attempted on checking the Variance Inflation Factor (VIF), residual analysis, analysis of Variance (ANOVA) and also the adjusted R2.","Label":"0"},{"DOI":"10.2139/ssrn.1364811","Abstract":"This paper analyzes the predictability of different style portfolio returns (a.k.a. Fama-French factors) considering time-varying sensitivities of these returns to different macroeconomic variables and own momentums. Styles, as used in this paper, can be defined as groups of securities with a common characteristic, such as value (Graham and Dodd (1934)) and size (Banz (1979)), and have been popularized by Fama and French papers. This paper specifically looks at determinants of style investing, such as style momentum and predictor variables such as macroeconomic variables (e.g. yield spread, inflation, industrial production, etc.), and show how 'learning' about these variables affects the predictability of different style portfolio returns compared to models where there is no learning (e.g. linear models). A time-varying parameter model and a Kalman filter are used to take into account the effect of learning in this paper. At the end, it is found that returns on style portfolios such as value and size appear to be related, with time-varying sensitivities, to yield spread and other macroeconomic variables. This paper also finds that time-varying parameter models provide better in-sample and out-of-sample predictions then simple benchmark constant parameter models.","Label":"0"},{"DOI":"10.1109/hnicem.2014.7016218","Abstract":"This paper presents a new method in forecasting Philippine Peso to US Dollar exchange rate. Compared to the conventional way, in which the Philippine Dealing System (PDS), as monitored by the Central Bank, determines the rate by analysing demand and supply, the use of artificial neural network, having consumer price index, inflation rate, lending interest rate and purchasing power of the peso as the inputs is presented in this paper. Though foreign exchange rates vary on a daily basis, the output of this paper is prediction of the average foreign exchange rate every month. Artificial Neural Network serves as a powerful tool in forecasting Philippine Peso to US Dollar exchange rate not requiring expert knowledge in banking and finance thus letting the public gain access to a helpful beacon which is the foreign exchange rate. However, the accuracy of the forecast using artificial neural network is highly dependent on the volume of the training data, in this paper, an alternative algorithm that will increase the accuracy of the conventional artificial neural network with limited volume of training data is presented and analyze.","Label":"1"},{"DOI":"10.1002/jae.582","Abstract":"In this paper we propose a Bayesian econometric procedure for the evaluation and comparison of DSGE models. Unlike in many previous econometric approaches we explicitly take into account the possibility that the DSGE models are misspecified and introduce a reference model to complete the model space. Three loss functions are proposed to assess the discrepancy between DSGE model predictions and an overall posterior distribution of population characteristics that the researcher is trying to match. The evaluation procedure is applied to the comparison of a standard cash‐in‐advance (CIA) and a portfolio adjustment cost (PAC) model. We find that the CIA model has higher posterior probability than the PAC model and achieves a better in‐sample time series fit. Both models overpredict the magnitude of the negative correlation between output growth and inflation. However, unlike the PAC model, the CIA model is not able to generate a positive real effect of money growth shocks on aggregate output. Overall, the impulse response dynamics of the PAC model resemble the posterior mean impulse response functions more closely than the responses of the CIA model. Copyright © 2000 John Wiley & Sons, Ltd.","Label":"0"},{"DOI":"10.5296/ber.v11i2.18672","Abstract":"Jordan, similar to other nations around the globe, has been severely affected by the COVID-19 pandemic cut across Jordanian service, banking, insurance, and industrial sectors. The spread of the virus and attempts to control it have generated both social and economic turbulence, turmoil, disorder, uncertainty, and uneasiness in the country. The government of Jordan acted promptly in March 2020 by ordering a national lockdown to mitigate the impact of COVID-19 on these economic sectors. The COVID-19 has had both direct and indirect negative effects on these sectors, which are projected to vary from the short to the long term. It is possible to measure the short-term effects as seen in this conceptual work. Some of the short-term effects anticipated include economic recession, high unemployment rate, high inflation, etc. In conclusion, these sectors will continue to encounter challenges because of the ongoing economic slowdown in Jordan due to lockdown and other social measures put in place by the government. Currently, there is yet to be a tentative and complete statistical prediction of the negative economic effects and cost of COVID-19 in Jordan, particularly on its sectors of the economy.","Label":"0"},{"DOI":"10.29244/ijsa.v4i2.600","Abstract":"The fluctuations of curly red chili price affect the inflation rate in Indonesia. So that, the basic characteristics of price movement and correctly prediction for curly red chili price become concern in various studies. Empirical Mode Decomposition (EMD) method helps to examine behavioral characteristics of curly red chili prices in Indonesia easily. Ensemble EMD (EEMD) and modified EEMD are the decomposition method of time series which is development of EMD method. The decomposed data with EMD methods can also used for price forecast. The forecasting with ARIMA and trend polynomial performed to assess the effect of decomposition with EMD methods for forecast stability of curly red chili price in Indonesia under various conditions. The results show the most influence factor for price fluctuation of curly red chili in Indonesia is season and growing season. In this case, the ability of a decomposition method to produce the actual components that describe the pattern of data signals affect the accuracy of the predicted value obtained using the model. The predicted value using the decomposed data by modified EEMD always better than EEMD on the overall condition.","Label":"0"},{"DOI":"10.48550/arxiv.2007.10160","Abstract":"In the data-rich environment, using many economic predictors to forecast a few key variables has become a new trend in econometrics. The commonly used approach is factor augment (FA) approach. In this paper, we pursue another direction, variable selection (VS) approach, to handle high-dimensional predictors. VS is an active topic in statistics and computer science. However, it does not receive as much attention as FA in economics. This paper introduces several cutting-edge VS methods to economic forecasting, which includes: (1) classical greedy procedures; (2) l1 regularization; (3) gradient descent with sparsification and (4) meta-heuristic algorithms. Comprehensive simulation studies are conducted to compare their variable selection accuracy and prediction performance under different scenarios. Among the reviewed methods, a meta-heuristic algorithm called sequential Monte Carlo algorithm performs the best. Surprisingly the classical forward selection is comparable to it and better than other more sophisticated algorithms. In addition, we apply these VS methods on economic forecasting and compare with the popular FA approach. It turns out for employment rate and CPI inflation, some VS methods can achieve considerable improvement over FA, and the selected predictors can be well explained by economic theories.","Label":"1"},{"DOI":"10.2139/ssrn.3303817","Abstract":"Summarizing Hendry's forty years of work on taming uncertainty is \"clear and distinct\": Test, test, test. Sure - but test what? Test the maintained assumptions of the disturbances. Test the parameter restrictions of a given model. Test the explanatory power of a model against a rival model. In brief, test everything that is not clear and distinct. We implement Hendry's view to forecast FOMC forecasts. Specifically, monetary policy is forward looking and, in its pursuit of transparency, it communicates its economic projections to the public at large. As a result, there is interest in whether these projections are credible. We argue that central to that credibility is the public's ability to replicate FOMC's projections using publicly available data only. In other words, is it possible to anticipate, reliably and independently, what the FOMC will anticipate for the federal funds rate? To address this question, we assemble FOMC projections from 1992 to 2017; examine their statistical properties; postulate models to predict FOMC projections; estimate the parameters of these models; and generate out-of-sample predictions for inflation, unemployment, and the federal funds rate for 2018. As the reader will soon realize, there is a lot more testing to be done.","Label":"0"},{"DOI":"10.2139/ssrn.3202810","Abstract":"It has been recently documented that survey-based point predictions outperform even the most successful forecasting models. However, corresponding variance forecasts are frequently diagnosed as being heavily distorted. Forecasters who report inconspicuously low ex-ante variances often produce squared forecast errors that are much larger on average. In this paper, we document the novel stylized fact that this variance misalignment is related to the rounding behavior of survey participants. Discarding responses which are strongly rounded provides an easily implementable correction that i) can be carried out in real time, i.e. before outcomes are observed, and ii) delivers a significantly improved match between ex-ante and ex-post forecast variances. According to our estimates, uncertainty about inflation, output growth and unemployment in the U.S. and the Euro area is higher after correcting for the rounding effect. The increase in the share of non-rounded responses in recent years also helps to understand the trajectory of survey-based average uncertainty during the years after the financial and sovereign debt crisis. Our findings are in line with assertions from the previous literature regarding the connection between survey respondents' rounding behavior and their uncertainty about future macroeconomic outcomes.","Label":"0"},{"DOI":"10.1177/056943451405900209","Abstract":"Lowering taxes and raising government spending are both forms of expansionary fiscal policy. Often students mistakenly believe that their relative impact on GDP is equivalent, i.e. a dollar increase in government expenditure increases GDP by the same amount as a dollar decrease in taxes. This paper describes a classroom exercise that demonstrates a) how both fiscal stimuli create greater aggregate output and b) which fiscal stimulus spending is more effective. In this exercise, six students come to the front of class and act as business owners, the instructor acts as the government with a stimulus plan, and the remaining students are workers/consumers. Going through a sequence of financial decisions of how much to save and spend, students learn how the initial fiscal shock sets off a chain reaction, leading to successive rounds of changes in spending and income. This simple framework can then be used to evaluate the effect of relaxing standard assumptions, and to demonstrate the impact of automatic stabilizers such as taxes and transfer payments. Finally, this exercise can be used to facilitate a discussion on how the theoretical predictions differ from the actual real-world results due to credit liquidity restrictions, unemployment benefits, inflation, and governmental inefficiency.","Label":"0"},{"DOI":"10.3923/tasr.2014.61.78","Abstract":"The purpose of this study is to provide a useful model for predicting the stock prices of companies listed in the Tehran Stock Exchange (TSE) during the Global Financial Crisis (GFC). Linear and exponential regression method and Artificial Neural Networks (ANNs) were used for this purpose. Then a comparison was done between the methods to determine the most effective of them for predicting the stock prices in the TSE. In this study, the stock prices were modelled by using the variables of the growth rate of industrial products, companies’ net assets, inflation, oil prices, earning per share and price ratio of dividends. The study uses a body of data from 250 companies in the years, 2008-2011. The results showed that the correlation coefficients for the linear and exponential regressions are equal to 30.5 and 35.1%, respectively and for ANNs, they are 86.041%. This shows the tangible superiority of ANNs for predicting stock prices compared to classical methods. This means that investors must use scientific methods to forecast stock prices instead of using traditional methods, especially during the GFC.","Label":"1"},{"DOI":"10.3390/jrfm14050198","Abstract":"Gold is often used by investors as a hedge against inflation or adverse economic times. Consequently, it is important for investors to have accurate forecasts of gold prices. This paper uses several machine learning tree-based classifiers (bagging, stochastic gradient boosting, random forests) to predict the price direction of gold and silver exchange traded funds. Decision tree bagging, stochastic gradient boosting, and random forests predictions of gold and silver price direction are much more accurate than those obtained from logit models. For a 20-day forecast horizon, tree bagging, stochastic gradient boosting, and random forests produce accuracy rates of between 85% and 90% while logit models produce accuracy rates of between 55% and 60%. Stochastic gradient boosting accuracy is a few percentage points less than that of random forests for forecast horizons over 10 days. For those looking to forecast the direction of gold and silver prices, tree bagging and random forests offer an attractive combination of accuracy and ease of estimation. For each of gold and silver, a portfolio based on the random forests price direction forecasts outperformed a buy and hold portfolio.","Label":"1"},{"DOI":"10.2139/ssrn.1145416","Abstract":"This paper examines how the estimation results for a standard New Keynesian model with constant gain least squares learning is sensitive to the stance taken on agents beliefs at the beginning of the sample. The New Keynesian model is estimated under rational expectations and under learning with three different frameworks for how expectations are set at the beginning of the sample. The results show that initial beliefs can have an impact on the predictions of an estimated model; in fact previous literature has exposed this sensitivity to explain the changing volatilities of output and inflation in the post-war United States. The results indicate statistical evidence for adaptive learning, however the rational expectations framework performs at least as well as the learning frameworks, if not better, in in-sample and out-of-sample forecast error criteria. Moreover, learning is not found to better explain time varying macroeconomic volatility any better than rational expectations. Finally, impulse response functions from the estimated models show that the dynamics following a structural shock can depend crucially on how expectations are initialized and what information agents are assumed to have.","Label":"0"},{"DOI":"10.1007/978-981-16-4513-6_56","Abstract":"The paper mainly aims to predict the household incomeHousehold income due to the fuel priceFuel pricefluctuationFluctuation in Malaysia as resulted from the subsidy removal. Other macroeconomic variables namely household incomeHousehold income, household expenditure, household size, inflation rate and gross domestic product (GDP) also added to increase the efficiency of the model. The data is simulated based on the historical data ranges from 2006 to 2016. The Granger causality test is used to examine the causal relationship between variables. The results revealed that there is a causal relationship between the selected variables. Then, the household incomeHousehold income is predicted using the Vector Autoregressive (VAR) model. The predictionPrediction takes place for the next ten periods. The findings showed that the predicted income is decreasing as the predicted fuel priceFuel price decreases. This indicate that the future income will be enough as the predicted fuel price decreases. However, if the inverse trend of predicted fuel priceFuel price occurs, the future income will not be enough to compensate the increase in the fuel price. Thus, this model could be beneficial in helping individual to plan their spending of income.","Label":"0"},{"DOI":"10.1080/0144619042000202799","Abstract":"Clients need to be informed in advance of their likely future financial commitments and cost implications as the design evolves. This requires the estimation of building cost based on historic cost data that is updated by a forecasted Tender Price Index (TPI), with the reliability of the estimates depending significantly on accurate projections being obtained of the TPI for the forthcoming quarters. In practice, the prediction of construction tender price index movement entails a judgemental projection of future market conditions, including inflation. Statistical techniques such as Regression Analysis (RA) and Time Series (TS) modelling provide a powerful means of improving predictive accuracy when used individually. An integrated RA‐TS model is developed and its predictive power compared with the individual RA or TS models. The accuracy of the RA‐TS model is shown to outperform the individual RA and TS models in both one and two‐period forecasts, with the integrated RA‐TS model accurately predicting (95% confidence level) one‐quarter forecasts for all the 34 holdout periods involved, with only one period not meeting the confidence limit for two‐quarter forecasts.","Label":"0"},{"DOI":"10.1016/j.ijforecast.2007.01.004","Abstract":"This paper documents the presence of systematic bias in the real GDP and inflation forecasts of private sector forecasters in the G7 economies in the years 1990–2005. The data come from the monthly Consensus Economics forecasting service, and bias is measured and tested for significance using parametric fixed effect panel regressions and nonparametric tests on accuracy ranks. We examine patterns across countries and forecasters to establish whether the bias reflects the inefficient use of information, or whether it reflects a rational response to financial, reputational and other incentives operating for forecasters. In several G7 countries – Japan, Italy, Germany and France – there is evidence of a change in the trend growth rate. In these circumstances, standard tests for rationality are inappropriate, and a bias towards optimism in the consensus forecast is inevitable as rational forecasters learn about the new trend. In all countries there is evidence that individual forecasters converge on the consensus forecast too slowly. However, the persistent optimism of some forecasters, and the persistent pessimism of others, is not consistent with the predictions of models of “rational bias” that have become popular in the finance and economics literature.","Label":"0"},{"DOI":"10.1007/s10614-013-9366-y","Abstract":"A noteworthy characteristic of empirical studies on the economic uncertainty index is that very few published papers depend on normative analysis. Therefore, normative analysis cannot be used to refute the precision of the economic uncertainty index; the lack of precision is simply the outcome of a misspecification of a commonly used model and a complex data collection process. To overcome this shortcoming, this paper uses the optimal form of the economic uncertainty index and determines its empirical validity based on a sample of 7 countries, including 3 developed and 4 developing countries. Using a grid search optimization procedure, the findings provide some policy implications; the optimal economic uncertainty index can characterize the uncertainty level of macroeconomic conditions and serve as a guiding policy tool for improving uncertainty levels in macroeconomic conditions. The estimated response function of the optimal economic uncertainty index suggests that the exchange rate, inflation, interest rate and output are useful indicators for central banks’ decision-making and that the optimal index supports the prediction of economic uncertainty.","Label":"0"},{"DOI":"10.2139/ssrn.2308922","Abstract":"In this paper we introduce Quasi Likelihood Ratio tests for one sided multivariate hypotheses to evaluate the null that a parsimonious model performs equally well as a small number of models which nest the benchmark. We show that the limiting distributions of the test statistics are non-standard. For critical values we consider two approaches: (i) bootstrapping and (ii) simulations assuming normality of the mean square prediction error (MSPE) difference. The size and the power performance of the tests are compared via Monte Carlo experiments with existing equal and superior predictive ability tests for multiple model comparison. We find that our proposed tests are well sized for one step ahead as well as for multi-step ahead forecasts when critical values are bootstrapped. The experiments on the power reveal that the superior predictive ability test performs last while the ranking between the quasi likelihood-ratio test and the other equal predictive ability tests depends on the simulation settings. Last, we apply our test to draw conclusions about the predictive ability of a Phillips type curve for the U.S. core inflation.","Label":"0"},{"DOI":"10.2139/ssrn.3522499","Abstract":"Although survey-based point predictions have been found to outperform successful forecasting models, corresponding variance forecasts are frequently diagnosed as heavily distorted. Forecasters who report inconspicuously low ex-ante variances often produce squared forecast errors that are much larger on average. In this paper, we document the novel stylized fact that this variance misalignment is related to the rounding behavior of survey participants. Rounding may reflect the fact that some survey participants employ a rather judgmental approach to forecasting as opposed to using a formal model. We use the distinct numerical accuracies of panelists’ reported probabilities as a means to propose several alternative and easily implementable corrections that i) can be carried out in real time, i.e., before outcomes are observed, and ii) deliver a significantly improved match between ex-ante and ex-post forecast uncertainty. According to our estimates, uncertainty about inflation, output growth and unemployment in the U.S. and the Euro area is higher after correcting for the rounding effect. The increase in the share of non-rounded responses in recent years also helps to understand the trajectory of survey-based average uncertainty during the years since the financial and sovereign debt crisis.","Label":"0"},{"DOI":"10.1007/s11146-019-09697-w","Abstract":"In mortgage debt contracts, real property serves as collateral and the terms of mortgage financing are largely conditional on the certification of collateral value by appraisers. However, overstatement of collateral value is common in the appraisal industry, causing troubles in the mortgage market as observed in the recent crisis. In this paper, we examine whether competition in the appraisal industry affects appraisal bias. We model appraiser behavior given a loan officer’s preference for favorable appraisals (i.e. appraisal values at least as high as the transaction prices). As appraisers cater to loan officers to increase their probability of winning future business, our model predicts more inflated appraisals in more competitive markets. We confirm this prediction using a sample of purchase mortgages originated between 2003-2006 by a large subprime mortgage lender. Our results show that a one standard deviation increase in appraiser competition, measured at the MSA/year level, is associated with a 1.6–3.7 percentage point increase in the share of at-price appraisals. Furthermore, the effect is stronger in areas experiencing high house price growth.","Label":"0"},{"DOI":"10.5539/ijef.v7n11p190","Abstract":"This paper aims at improving the prediction accuracy through using combining forecasts approaches. In forecast combination, the crucial issue is the selection of the weights to be assigned to each model. In addition to traditional methods, we propose, also, two sophisticated approaches. These suggested methods are modified Bayesian Moving Average (BMA) and Extended Time-varying coefficient (ETVC). The first technique is based on merging the traditional BMA with other frequentist combination schemes to avoid the subjective prior inside the traditional Bayesian technique. The suggested ETVC approach provides consistent time-varying parameters even if there are some measurement errors, omitted variables bias and if the true functional form is unknown. Concerning the included models, we consider both linear and nonlinear models in order to calculate the forecasts of quarterly Egyptian CPI inflation. We find that our proposed scheme ETVC is superior to the best model and all other static combination schemes including the time-varying scheme based on the random walk coefficients updated (TVR) approach. Additionally, the suggested modified Bayesian approach improves the traditional BMA and overcomes the problem of depending on the arbitrary choice for the initial priors.","Label":"0"},{"DOI":"10.2991/978-94-6463-030-5_135","Abstract":"The Consumer Price Index (CPI) is an important indicator to measure the level of inflation in our country. It reflects the impact of commodity price changes on the daily lives of residents. It is an important basis for governments at all levels to carry out fiscal policies and the central bank to formulate monetary policies. CPI data reflecting economic phenomena have obvious seasonal time series characteristics. By extracting a total of 59 months from January 2017 to November 2021 in our country, a seasonal differential autoregressive moving average model (SARIMA) is established for empirical analysis and prediction. The results show that SARIMA (0, 1, 0) (0, 1, 1)12 has a high degree of fitting and can better reflect the future trend of my country’s CPI. Based on this, using this model to predict the trend of my country’s CPI in 2022, it is found that my country’s CPI will remain stable at about 102% in 2022, which provides a certain reference for the decision-making of the government, enterprises and other market entities.","Label":"0"},{"DOI":"10.3982/qe1703","Abstract":"Although survey‐based point predictions have been found to outperform successful forecasting models, corresponding variance forecasts are frequently diagnosed as heavily distorted. Professional forecasters who report inconspicuously low ex ante variances often produce squared forecast errors that are much larger on average. In this paper, we document the novel stylized fact that this variance misalignment is related to the rounding behavior of survey participants. Rounding may reflect the fact that some survey participants employ a rather judgmental approach to forecasting as opposed to using a formal model. We use the distinct numerical accuracies of panelists' reported probabilities as a way to propose several alternative and easily implementable corrections that (i) can be carried out in real time, that is, before outcomes are observed, and (ii) deliver a significantly improved match between ex ante and ex post forecast uncertainty. According to our estimates, uncertainty about inflation, output growth and unemployment in the U.S. and the Euro area is higher after correcting for the rounding effect. The increase in the share of nonrounded responses in recent years also helps to understand the trajectory of survey‐based average uncertainty during the years since the financial and sovereign debt crisis.","Label":"0"},{"DOI":"10.1080/07350015.2021.1953508","Abstract":"Noncausal, or anticipative, heavy-tailed processes generate trajectories featuring locally explosive episodes akin to speculative bubbles in financial time series data. For a two-sided infinite α-stable moving average (MA), conditional moments up to integer order four are shown to exist provided is anticipative enough, despite the process featuring infinite marginal variance. Formulas of these moments at any forecast horizon under any admissible parameterization are provided. Under the assumption of errors with regularly varying tails, closed-form formulas of the predictive distribution during explosive bubble episodes are obtained and expressions of the ex ante crash odds at any horizon are available. It is found that the noncausal autoregression of order 1 (AR(1)) with AR coefficient ρ and tail exponent α generates bubbles whose survival distributions are geometric with parameter . This property extends to bubbles with arbitrarily shaped collapse after the peak, provided the inflation phase is noncausal AR(1)-like. It appears that mixed causal–noncausal processes generate explosive episodes with dynamics à la Blanchard and Watson which could reconcile rational bubbles with tail exponents greater than 1.","Label":"0"},{"DOI":"10.35774/econa2017.03.082","Abstract":"Introduction. Most economic agents use forecasts of macro environment. Predictions are the primary basis of the budgets development and approval. Methodology and forecasting accuracy influence actual realization of object, through the stimulation of economic agents.  Purpose. The article aims to identify patterns in macroeconomic forecasts which are completed by domestic and foreign experts.  Method (methodology). To carry out the analysis, we have not used the individual forecasts of institutions. It has been completed the database of historical change of predictions of the same indicator. Accordingly, the macro index of Ukraine of certain year was predicted by experts from 5 to 10 times at different time intervals. The fluidity of experts’ mood was analysed along with external conjuncture effects and internal prejudices of specialists. Forecasts, which have been made on a medium term for 2-4 years, are disconnected by experts from the current situation and mostly reflect internal models and mood. Therefore, despite the year of the object realization, short-term and medium-term forecasts have features that need to be highlighted.  Results. The analytical and graphical analysis of the expert forecasts flow of macroeconomic indices has been carried out. The trends in the economic conditions (periods of growth, crisis) and the internal attitudes of foresights performers have been distinguished. Own medium-term forecast has been formed. The ineffectiveness of expert forecasting of inflation processes in Ukraine for previous periods has been shown.  Application of results. Performers of economic reproduction forecasts can effectively take into account the marked trends and correct their own calculation methodology. The collected data can be the basis for further statistical and econometric analysis, determination of the main factors in expert forecasting, construction of intelligent systems with recurrent correction of prognostic error.","Label":"0"},{"DOI":"10.29167/a1i1p151-160","Abstract":"Due to complex and sophisticated nature of financial markets, many features including psychological, political and economic can influence the routine behaviour and considered by characteristic nonlinearities. There have been many efforts about the stock market prediction by using technical analysis methods. Concerning the application area of entropy into economics which could be referred as econophysics; there are two approaches that could be investigated within. These two could be named as ontological and metaphorical. As the Second Law of Thermodynamics has a critical role in the concept of ontological approach, the economy is considered as processes of physics and biology that are brought by energy while the metaphorical approach is more concerned with the application of finance and equilibrium theory on the info design of entropy. This research takes the metaphorical approach to the investigation of Oil & Gas Producers industry sector of the London Stock Exchange’s FTSE-100 index. First, we observed the necessity to analyse each stock with the Bernoulli Theorem to compute an index for the desirability of each to express the complexity of the investment decisions. Then, an analysis is conducted for the sector with the computation. During the computation phase, macroeconomic figures are introduced to the Bernoulli Theorem, as inflation. In addition to this, other stock movements in the sector are introduced for precise prediction as well as the parameter of the trading volume of each stock. With the suggested approach, the desirability index is formed as an unconventional theoretical approach within econophysics for expression of the complex nature of investment environment.","Label":"0"},{"DOI":"10.1515/em-2021-0007","Abstract":"Abstract  Objectives Modeling and forecasting possible trajectories of COVID-19 infections and deaths using statistical methods is one of the most important topics in present time. However, statistical models use different assumptions and methods and thus yield different results. One issue in monitoring disease progression over time is how to handle excess zeros counts. In this research, we assess the statistical empirical performance of these models in terms of their fit and forecast accuracy of COVID-19 deaths.   Methods Two types of models are suggested in the literature to study count time series data. The first type of models is based on Poisson and negative binomial conditional probability distributions to account for data over dispersion and using auto regression to account for dependence of the responses. The second type of models is based on zero-inflated mixed auto regression and also uses exponential family conditional distributions. We study the goodness of fit and forecast accuracy of these count time series models based on autoregressive conditional count distributions with and without zero inflation.   Results We illustrate these methods using a recently published online COVID-19 data for Tunisia, which reports daily death counts from March 2020 to February 2021. We perform an empirical analysis and we compare the fit and the forecast performance of these models for death counts in presence of an intervention policy. Our statistical findings show that models that account for zero inflation produce better fit and have more accurate forecast of the pandemic deaths.   Conclusions This paper shows that infectious disease data with excess zero counts are better modelled with zero-inflated models. These models yield more accurate predictions of deaths related to the pandemic than the generalized count data models. In addition, our statistical results find that the lift of travel restrictions has a significant impact on the surge of COVID-19 deaths. One plausible explanation of the outperformance of zero-inflated models is that the zero values are related to an intervention policy and therefore they are structural.","Label":"0"},{"DOI":"10.22214/ijraset.2022.44231","Abstract":"Abstract: Commodity costs and the prediction of the remarkable adjustments is a tough mission in oil, and gold-generating nations along with UAE, USA in addition to borrowing nations along with India. It is beneficial for each character to music the costs earlier than the unanticipated ascents and descents as we're going to encompass many elements which can also additionally replicate the adjustments in costs along with the conflicts among the nations, new standards or rules being introduced, authorities adjustments, ideology adjustments, and the conflict among nations (eg. Russia Ukraine War which led to a 30 percentage increment in crude oil costs), etc. Predicting those costs is amongst one of the maximum complicated classes to investigate due to the fact fluctuations withinside the charge of those commodities are particularly irregular, nonlinear, and range dynamically with excessive uncertainty. This innovation is proposed as a hybrid version for herbal fueloline, crude oil, and gold charge prediction on a unmarried platform that makes use of complicated statistical, predictive analytics, and superior deep studying algorithms. We validate the end result and examine those empirical outcomes with different studies withinside the literature. The proposed innovation could have better accuracy that is extra strong and reliable. We have many regions to goal withinside the industry, in which inventory marketplace corporations are one of the maximum essential clients, and on the alternative hand, the folks that need to music the records and who're interested by extracting the results in order that it addresses, train the humans which allows in knocking down the inflation charge, authorities corporations that may are expecting the adjustments similarly earlier than can paintings on vital steps to govern those adjustments.","Label":"1"},{"DOI":"10.1101/2022.02.22.481550","Abstract":"ABSTRACT    Generalised Additive Models (GAMs) are increasingly popular for describing smooth nonlinear relationships between predictors and response variables. GAMs are particularly relevant in ecology for representing hierarchical functions for discrete responses that encompass complex features including zero-inflation, bounding and uneven sampling. However, GAMs are less useful for producing forecasts as their smooth functions provide unstable predictions outside the range of training data.    We introduce Dynamic Generalised Additive Models (DGAMs), where the GAM linear predictor is jointly estimated with unobserved dynamic components to model time series that evolve as a function of nonlinear predictor associations and latent temporal processes. These models are particularly useful for multivariate series, as they can estimate hierarchical smooths while learning complex temporal associations via dimension-reduced latent factor processes. We implement our models in the mvgam R package, which uses the mgcv and rjags packages to construct smoothing splines and estimate unobserved parameters in a probabilistic framework.     Using simulations, we illustrate how our models outperform competing formulations in realistic ecological forecasting tasks while identifying important smooth predictor functions. We use a real-world case study to highlight some of mvgam’s key features, which include functions for: calculating correlations among series’ latent trends, performing model selection using rolling window forecasts, online data augmentation via a recursive particle filter, and visualising probabilistic uncertainties for smooths and predictions.    Dynamic GAMs (DGAM) offer a solution to the challenge of forecasting discrete time series while estimating ecologically relevant nonlinear predictor associations. Our Bayesian latent factor approach will be particularly useful for exploring competing dynamic ecological models that encompass hierarchical smoothing structures while providing forecasts with robust uncertainties, tasks that are becoming increasingly important in applied ecology.","Label":"0"},{"DOI":"10.1109/icaccs57279.2023.10113035","Abstract":"In recent years, machine learning algorithms have gained popularity in the field of economic forecasting. This study aims to predict the Indian Gross Domestic Product (GDP) using advanced machine learning algorithms. To achieve this, we collected data from various sources, including time series analysis and inflation rate. We analyzed the data using linear regression and polynomial regression techniques to determine which method produced the most accurate results. Our results showed that the polynomial regression model outperformed the linear regression model in terms of accuracy. The polynomial regression model was better able to capture the non-linear relationships between the independent variables and the dependent variable (GDP). Specifically, our findings showed that the polynomial regression model was able to predict the Indian GDP with an accuracy of 91%, compared to 87% for the linear regression model. This study highlights the importance of using advanced machine learning algorithms in economic forecasting. We found that the use of high-quality data sets and advanced techniques such as polynomial regression can significantly improve the accuracy of economic forecasts. Our findings have several implications for policymakers and businesses. Accurate predictions of economic indicators such as GDP can help businesses make informed decisions about investment and growth strategies, while policymakers can use these predictions to develop effective economic policies. Overall, our study provides valuable insights into the use of machine learning algorithms in predicting Indian GDP. Our findings demonstrate the effectiveness of polynomial regression in capturing non-linear relationships and improving the accuracy of economic forecasts. This study can be used as a reference for future research in this area and emphasizes the need for high-quality data sets and advanced machine-learning techniques in economic forecasting.","Label":"1"},{"DOI":"10.48550/arxiv.2107.09055","Abstract":"The stock market has been a popular topic of interest in the recent past. The growth in the inflation rate has compelled people to invest in the stock and commodity markets and other areas rather than saving. Further, the ability of Deep Learning models to make predictions on the time series data has been proven time and again. Technical analysis on the stock market with the help of technical indicators has been the most common practice among traders and investors. One more aspect is the sentiment analysis - the emotion of the investors that shows the willingness to invest. A variety of techniques have been used by people around the globe involving basic Machine Learning and Neural Networks. Ranging from the basic linear regression to the advanced neural networks people have experimented with all possible techniques to predict the stock market. It's evident from recent events how news and headlines affect the stock markets and cryptocurrencies. This paper proposes an ensemble of state-of-the-art methods for predicting stock prices. Firstly sentiment analysis of the news and the headlines for the company Apple Inc, listed on the NASDAQ is performed using a version of BERT, which is a pre-trained transformer model by Google for Natural Language Processing (NLP). Afterward, a Generative Adversarial Network (GAN) predicts the stock price for Apple Inc using the technical indicators, stock indexes of various countries, some commodities, and historical prices along with the sentiment scores. Comparison is done with baseline models like - Long Short Term Memory (LSTM), Gated Recurrent Units (GRU), vanilla GAN, and Auto-Regressive Integrated Moving Average (ARIMA) model.","Label":"1"},{"DOI":"10.1007/978-3-662-46578-3_92","Abstract":"Economic is important issue in a country since it is conducted by many sectors. Knowing stability of economic condition can be looked at by predicting the economic indicator. Unfortunately, the prediction that had been done to each of economic indicator did not concern about interconnection of them while predicting it. Because of that, learning about dependability of economic indicator still need further research about it. In other side, economic as knowledge that complex and chaos need differential dynamic to face the problem inside. Based on those reasons, this research not only observed about interconnection between indicators economic while predicting, but also needed differential dynamic which had been optimized by genetic algorithm. System got 20% until 80% for the accuracy system. The reason of why accuracy 80% was gotten because of using the same characteristics of economic indicators, ex. when system observed GDP and GNI together. Using similar data trend influenced the fitness function in GA able to optimized differential dynamic while doing prediction of economic indicators. Whereas, the decrease accuracy around 20% until 40% was came by using different characteristic of economic indicator. It can be found when learning dependable of GDP and Inflation while predict times series for GDP. Based on this research, it can be concluded that GA is able in optimizing learning the dependability of economic indicator’s Indonesia. Moreover, it can be said that using the same characteristic indicator economic give better result for GA to learning the dependability of economic indicator than not. It can be said indirectly that government should concern about value of indicators economic that have the same characteristics when monitoring economic condition.","Label":"1"},{"DOI":"10.1016/j.ijforecast.2016.02.012","Abstract":"A number of recent studies in the economics literature have focused on the usefulness of factor models in the context of prediction using “big data” (see Bai and Ng, 2008; Dufour and Stevanovic, 2010; Forni, Hallin, Lippi, & Reichlin, 2000; Forni et al., 2005; Kim and Swanson, 2014a; Stock and Watson, 2002b, 2006, 2012, and the references cited therein). We add to this literature by analyzing whether “big data” are useful for modelling low frequency macroeconomic variables, such as unemployment, inflation and GDP. In particular, we analyze the predictive benefits associated with the use of principal component analysis (PCA), independent component analysis (ICA), and sparse principal component analysis (SPCA). We also evaluate machine learning, variable selection and shrinkage methods, including bagging, boosting, ridge regression, least angle regression, the elastic net, and the non-negative garotte. Our approach is to carry out a forecasting “horse-race” using prediction models that are constructed based on a variety of model specification approaches, factor estimation methods, and data windowing methods, in the context of predicting 11 macroeconomic variables that are relevant to monetary policy assessment. In many instances, we find that various of our benchmark models, including autoregressive (AR) models, AR models with exogenous variables, and (Bayesian) model averaging, do not dominate specifications based on factor-type dimension reduction combined with various machine learning, variable selection, and shrinkage methods (called “combination” models). We find that forecast combination methods are mean square forecast error (MSFE) “best” for only three variables out of 11 for a forecast horizon of h = 1 , and for four variables when h = 3 or 12 . In addition, non-PCA type factor estimation methods yield MSFE-best predictions for nine variables out of 11 for h = 1 , although PCA dominates at longer horizons. Interestingly, we also find evidence of the usefulness of combination models for approximately half of our variables when h > 1 . Most importantly, we present strong new evidence of the usefulness of factor-based dimension reduction when utilizing “big data” for macroeconometric forecasting.","Label":"1"},{"DOI":"10.1109/icst56971.2022.10136262","Abstract":"The capital market will make it uncertain to collect investments in the future because it is constantly shifting. This ambiguity shows that there are risks that investors must accept. Investors typically aim to maximize their expected return considering the risk taken. In order to minimize investment risk, it is critical to measure the movement of the stock market. Indonesia Stock Exchange (IDX) indicator values are a reflection of the state of the stock market. The focus of this research is to forecast the IDX using macroeconomic factors that reflect the current state of the economy. Interest rates, inflation rates, money supply, and exchange rates are the macroeconomic variables. Bank Indonesia provided secondary data for this study. ARIMA, LSTM, and ANN are the approaches used in this study. This approach is thought to be useful for handling issues, representing complex patterns of each macroeconomic variable, and predicting values with lowest error. Based on the research results, the Root Mean Square Error (RMSE) for the ARIMA (0.087), LSTM (0.0298), and ANN (0.0466). The best time to predict is 2 months before. The RMSE value proves that macroeconomic variables are good indicators to predict the IDX movement.","Label":"1"},{"DOI":"10.47260/jafb/1343","Abstract":"Abstract Understanding the effects of people's interactions on social media on economic fluctuations is essential for analyzing economic dynamics and making predictions. ‘Time-varying’ and ‘time-scale dependent’ volatilities between tweets sent from Turkey containing the terms \"economic crisis\", \"inflation\", \"unemployment\", \"economic recession\", \"#dolar\" (also their lagged series), and TL/USD FX rate was examined with dynamic conditional correlation (DCC) GARCH model. 7.402.035 Tweet data were used for the study, and their count was averaged between the dates 01.10.2020 and 11.03.2022, and a time series of 15, 30 and 60 minutes was obtained. These series of tweets were compared with the USD/TL FX rate data for the same periods. The results show that examining -delayed relationships of up to 10 lags- 6th and 10th lag of 60 min frequency Twitter data have high level of conditional correlations with TL/USD FX rate. However, except for these series 12 of that is not dynamic but a CC process and for 105 series are statistically not significant to explain CC and DCC relationship. JEL classification numbers: G12, G17, G41. Keywords: Twitter narratives, DCC-GARCH, USD/TL FX rate, narrative economics.","Label":"1"},{"DOI":"10.1057/s11369-019-00158-z","Abstract":"Discussions of Modern Monetary Theory elicit surprisingly strong passions. Many of the critiques of MMT by conventional macroeconomists are valid, yet there is a resistance to giving MMT the credit it deserves. MMT puts a comprehensive framework for describing the quantity and price of money at its center, while conventional macro has framed fiscal policy choices through a narrow prism of loanable funds, which suggests higher budget deficits will compete with private borrowers leading to higher rates and lower investment. That prediction has not been born out precisely because broader drivers of money demand and supply have undergone major shifts reflecting demographics and the evolution of credit availability. For me, the most problematic aspect of MMT is the political economy prescription that fiscal authorities be responsible for maintaining low and stable inflation. In an era of dysfunctional and polarized politics, the value of an independent central bank is likely to be greater than ever. Getting the relationship between deficits and interest rates wrong has dented the credibility of conventional macroeconomics and it would be wise to put a broader framework for money at the center of discussions around policy tradeoffs.","Label":"0"},{"DOI":"10.19044/esj.2018.v14n22p173","Abstract":"United Kingdom, as the world’s fifth largest economy, maintains good cooperation relation with China in the area of economy and trade. As the world’s fourth largest foreign exchange trading currency, the exchange rate fluctuation of the sterling pound has an important economic impact on the world’s foreign exchange market and it also has a significant impact on the trade with China. There are many factors that influence the exchange rate. By using time series approach, this paper analyzes the impact of two main variables, Libor and Shibor, and five common economy variables, inflation rate, interest rate, balance of trade, GDP and money supply, on the change of the sterling pound exchange rate. The results of the empirical analysis show that five common factors have significant relation with exchange rate. For the two main variables, Libor has a strong correlation with the sterling pound exchange rate, but Shibor has no such relation. Meanwhile, this paper focuses on analyzing the possibility of arbitrage according to the empirical results. It was found that the model for the impact on exchange rate in this paper cannot predict future exchange rate. As a result, short-term arbitrage prediction cannot be made.","Label":"0"},{"DOI":"10.3923/jas.2012.645.652","Abstract":"This study analyzed the forecasting performances of various multivariate models in predicting 1-8-quarters-ahead of the growth rate of GDP, the consumer price index inflation rate and the three months Treasury bill rate for South Africa over an out-of-sample period of 2000:Q1-2011:Q2, using an in-sample period of 1960:Q1-1999:Q4. The study compared the forecasting performances of the classical and the Minnesota-type Bayesian vector autoregressive (VAR) models with those of linear (fixed-parameter) and nonlinear (time-varying parameter) VARs involving a stochastic search algorithm for variable selection, estimated using Markov Chain Monte Carlo methods. In general, the study finds that variable selection, whether imposed on a time-varying VAR or a fixed parameter VAR, and non-linearity in VARs, play an important part in improving predictions when compared to the linear fixed coefficients classical VAR. However, the results does not indicate marked gains in forecasting power across the different Bayesian models, as well as, over the classical VAR model, possibly because the problem of over parameterization in the classical VAR is not that acute in our three-variable system. Hence, future research would aim to look at VAR models that include over 10 variables.","Label":"0"},{"DOI":"10.2139/ssrn.3897551","Abstract":"In 1919, John Maynard Keynes wrote his famous tract The Economic Consequences of the Peace. In that work, he anticipated the collapse of the first era of globalization that began in the midnineteenth century. He admonished the short-sighted assumption that these years of relative peace and prosperity for many was a permanent norm, interrupted only briefly by the Great War. The diplomatic failures, lapses in leadership, and promotion of narrow interests and vision outlined by Keynes underpinned his prediction of a backslash of economic nationalism, trade protectionism, and recession. The paper revisits the turning points in the evolution of the global economic system since 1919 by focusing primarily on the evolution of the international monetary system and policy cooperation/coordination. We identify three disruptions and examine how each prompted a change in the underlying ideology about how the international monetary system should organize: World War I, Bretton Woods, 1970s Great Inflation and Managed Floating. Each turning point was characterized by different forms and institutions of cooperation, how rules (either explicit or implicit) were designed and implemented, and the crucial importance of the historical context. Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at www.nber.org.","Label":"0"},{"DOI":"10.2139/ssrn.2898082","Abstract":"The focus of this study was to establish key factors responsible for the performance of non-African foreign Commercial banks in Uganda, in the light of Global Advantage Theory. The analysis was supplemented by structure–conduct performance (SCP) and efficiency hypothesizes (ES). The study analysed the performance of licensed non-African foreign commercial banks on average, over the period 2000-2011, using Linear multiple regression analysis. The study findings showed that, management efficiency, capital adequacy and reputation/goodwill are key factors affecting the performance of non-African foreign commercial banks in Uganda. On the contrary, credit risk has a negative impact on performance of non-African foreign commercial banks in Uganda. On a positive note, diversification, investment in securities and correct prediction of inflation are factors that drive the enhanced performance of non-African foreign commercial banks in Uganda. The emerging policy implication is that commercial banks’ managements should focus on improving: management efficiency; bank reputation/goodwill; credit risk management; capital adequacy levels; diversification and investment. In addition, monetary policy regulations and instruments should not enforce high liquidity and capital adequacy levels. There is also need for regulations on non-interest income activities to harmonize the impact of diversification on all commercial banks’ performance and avoid the exploitation of commercial banks’ customers.","Label":"0"},{"DOI":"10.1016/j.jeconom.2015.12.004","Abstract":"This paper provides early assessments of current U.S. Nominal GDP growth, which has been considered as a potential new monetary policy target. The nowcasts are computed using the exact amount of information that policy makers have available at the time predictions are made. However, real time information arrives at different frequencies and asynchronously, which poses the challenge of mixed frequencies, missing data, and ragged edges. This paper proposes a multivariate state space model that not only takes into account asynchronous information inflow it also allows for potential parameter instability (DYMIBREAK). We use small scale confirmatory factor analysis in which the candidate variables are selected based on their ability to forecast nominal GDP. The model is fully estimated in one step using a nonlinear Kalman filter, which is applied to obtain simultaneously both optimal inferences on the dynamic factor and parameters. Differently from principal component analysis, the proposed factor model captures the comovement rather than the variance underlying the variables. We compare the predictive ability of the model with other univariate and multivariate specifications. The results indicate that the proposed model containing information on real economic activity, inflation, interest rates, and Divisia monetary aggregates produces the most accurate real time nowcasts of nominal GDP growth.","Label":"0"},{"DOI":"10.2139/ssrn.3949463","Abstract":"We introduce a class of interpretable tree-based models (P-Trees) for analyzing panel data, with iterative and global (instead of recursive and local) splitting criteria to avoid overfitting and improve model performance. We apply P-Tree to generate a stochastic discount factor model and test assets for cross-sectional asset pricing. Unlike other tree algorithms, P-Trees accommodate imbalanced panels of asset returns and grow under the no-arbitrage condition. P-Trees also graphically capture nonlinearity and interaction effects and accommodate regime-switching and interactions between macroeconomic states and firm characteristics. For example, P-Tree identifies inflation as the most important macro predictor with regime-switching in U.S. equity data. Based on multiple pricing, prediction, and investment metrics, we find that (boosted or time-series) P-Trees outperform standard factor models and PCA latent factor models. An equally-weighted portfolio for five factors generated by P-Trees delivers an excess alpha of 1.09% against the Fama-French 3-factor benchmark, producing an annualized Sharpe ratio of 1.98 out-of-sample. Data-driven cutpoints in P-Trees reveal that long-run reversal, volume volatility, and industry-adjusted market equity drive cross-sectional return variations, consistent with variable importance analysis using random forests.","Label":"1"},{"DOI":"10.1057/s41260-023-00309-0","Abstract":"We provide strong evidence of flight-to-safety phenomenon from real estate market, with REITs as the proxy, to bond market during elevated real estate market volatility. We use three robust factors; the equity market risk premium, the momentum, and the real estate market volatility to capture the cross-sectional expected excess returns. We consider a comprehensive list of returns on REITs and maturity-sorted treasuries from January 2000 to December 2021 to predict excess returns in the three-factor linear model. We find that the expected returns on real estate market and treasury market exhibit inverse relationship in market risk premium and real estate market volatility loading factors. The momentum factor is strongly significant for the short-maturity treasuries and for the mortgage REITs in general, and for the home financing mortgage REITs in particular. The results are robust when we include macroeconomic variables and the time factor in the analysis. This observation clearly depicts interest sensitivity of these instruments. Our study has critical relevance, from the diversification perspective, in the current US macro-environment of rising inflation and interest rates.","Label":"0"},{"DOI":"10.12962/j23546026.y2020i1.7864","Abstract":"Every company is vulnerable to bankruptcy, including banking industry. Bankruptcy of a bank will have an effect on other industries, because it as intermediation institution. If the intermediation process is stalled, the payment system will stall and disturb economic activities. Therefore research about indicator to predict the bankruptcy is important. Risk management must be implemented to detect and manage risk arising from bank operations. Banks can manage bankruptcy risk from the efficiency side. This study focus on the effect financial ratio (Return on Assets and Equity to Total Assets), size bank, and macroeconomic to bankruptcy predictions. Most of the bank's revenue from credit, it is on the asset side in the balanced sheet. If the bank has small assets then potentially have financial distress. The paper aims to conceptually and based on theoretical review studies. There are signaling and efficiency theory as basic theories related with these concept. By classifying the result of previous research, found some propositions: Return on Asset, Equity to Total Asset, Size Bank, Inflation and Gross Domestic Product are able to predict bank bankruptcy. The research believes that the proposition of this study result can be tested empirically mainly in banking industry","Label":"0"},{"DOI":"10.2139/ssrn.3815223","Abstract":"Interest rate data are an important element of macroeconomic forecasting. Projections of future interest rates are not only an important product themselves, but also typically matter for forecasting other macroeconomic and financial variables. A popular class of forecasting models is linear vector autoregressions (VARs) that include shorter- and longer-term interest rates. However, in a number of economies, at least shorter-term interest rates have now been stuck for years at or near their effective lower bound (ELB), with longer-term rates drifting toward the constraint as well. In such an environment, linear forecasting models that ignore the ELB constraint on nominal interest rates appear inept. To handle the ELB on interest rates, we model observed rates as censored observations of a latent shadow-rate process in an otherwise standard VAR setup. The shadow rates are assumed to be equal to observed rates when above the ELB. Point and density forecasts for interest rates (short term and long term) constructed from a shadow-rate VAR for the US since 2009 are superior to predictions from a standard VAR that ignores the ELB. For other indicators of financial conditions and measures of economic activity and inflation, the accuracy of forecasts from our shadow-rate specification is on par with a standard VAR that ignores the ELB.","Label":"0"},{"DOI":"10.3390/su10103750","Abstract":"The accelerated development of information and communication technology (ICT) over the past two decades has encouraged an increasing number of researchers to examine and measure the impact of this technology on economic growth. Our study aims to identify and evaluate the effect of using ICT infrastructure on economic growth in European Union (EU) countries for a period of 18 years (2000–2017). Using panel-data estimation techniques, we investigate empirically how various indicators of ICT infrastructure affect economic growth, proxied in our study by GDP per capita. Within the estimates, we have included some macroeconomic control variables. Our results indicate a positive and strongly effect of using ICT infrastructure on economic growth in the EU member states, but the magnitude of the effect differs depending on the type of technology examined. Regarding the impact of macroeconomic factors, our estimates indicate that inflation rate, unemployment rate, the degree of trade openness, government expenditures, and foreign direct investments would significantly affect GDP per capita at EU level. The findings are broadly similar to the theoretical predictions, but also to the findings of some relevant empirical studies. Our research reveals that ICT infrastructure, along with other macroeconomic factors, is an important driver of economic growth in EU countries.","Label":"0"},{"DOI":"10.2139/ssrn.2350681","Abstract":"This paper aims to test the accuracy of three well-known equity valuation models for the period 1990 to 2006. This was done to a sample of German listed firms which diverge from the US market in accounting standards, market maturity and corporate governance culture (bank-based in contrast to the market-based US regime) as well as different market movements and trends which influence main input factors and estimations (e.g. market risk premium, inflation rate and GDP growth rate). To the best of our knowledge this is the first paper to address this issue for a sample of listed firms from the largest bank-based European economy.Using different accuracy measures such as absolute prediction error (average, median and central tendency) as well as multiple regression analysis the results show that dividend discount and abnormal earnings models ten to provide better accuracy than the free cash flow approach. Additionally, we find evidence of the importance in German accounting standards in the less accurate performance of the abnormal earnings model compared to previous studies due to the conservative accounting and the influence of hidden reserves. Finally, we did not find any significant valuation differences regarding the alternative values used for growth and discount rates.","Label":"0"},{"DOI":"10.2139/ssrn.3842733","Abstract":"We show that the specific factors model can be used to derive a rigorous link between movements in stock prices and productivity, wages, employment, output, and welfare. We also prove that the commonly used measure of the effective rate of protection equals the dual measure of revenue TFP, providing a theoretical foundation for why many studies have found that trade liberalization significantly increases firm-level productivity. Our method enables us to trace a tariff announcement's effect on TFP through its impact on macro variables (e.g., exchange rates) and through its effect on the relative prices of imports. We apply this framework to understanding the implications of the U.S.-China trade war. Our results show that the trade-war announcements caused large declines in U.S. stock prices, expected TFP, and expected inflation largely by moving macro variables, but also by causing declines in the returns of firms trading with China. We find that markets expect the trade war to lower U.S. welfare by 7.8 percentage points, which is much larger than the predictions of static models but in line with those of dynamic models.Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at www.nber.org.","Label":"0"},{"DOI":"10.2139/ssrn.3515958","Abstract":"Surveys of Professional Forecasters produce precise and timely point forecasts for key macroeconomic variables. However, the accompanying density forecasts are not as widely utilized, and there is no consensus about their quality. This is partly because such surveys are often conducted for “fixed events”. For example, in each quarter panelists are asked to forecast output growth and inflation for the current calendar year and the next, implying that the forecast horizon changes with each survey round. The fixed-event nature limits the usefulness of survey density predictions for policymakers and market participants, who often wish to characterize uncertainty a fixed number of periods ahead (“fixed-horizon”). Is it possible to obtain fixed-horizon density forecasts using the available fixed-event ones? We propose a density combination approach that weights fixed-event density forecasts according to a uniformity of the probability integral transform criterion, aiming at obtaining a correctly calibrated fixed-horizon density forecast. Using data from the US Survey of Professional Forecasters, we show that our combination method produces competitive density forecasts relative to widely used alternatives based on historical forecast errors or Bayesian VARs. Thus, our proposed fixed-horizon predictive densities are a new and useful tool for researchers and policy makers.","Label":"0"},{"DOI":"10.2139/ssrn.3507117","Abstract":"Surveys of professional forecasters produce precise and timely point forecasts for key macroeconomic variables. However, the accompanying density forecasts are not as widely utilized, and there is no consensus about their quality. This is partly because such surveys are often conducted for “fixed events”. For example, in each quarter panelists are asked to forecast output growth and inflation for the current calendar year and the next, implying that the forecast horizon changes with each survey round. The fixed-event nature limits the usefulness of survey density predictions for policymakers and market participants, who often wish to characterize uncertainty a fixed number of periods ahead (“fixed-horizon”). Is it possible to obtain fixed-horizon density forecasts using the available fixed-event ones? We propose a density combination approach that weights fixed-event density forecasts according to uniformity of the probability integral transform criterion, aiming at obtaining a correctly calibrated fixed horizon density forecast. Using data from the US Survey of Professional Forecasters, we show that our combination method produces competitive density forecasts relative to widely used alternatives based on historical forecast errors or Bayesian VARs. Thus, our proposed fixed-horizon predictive densities are a new and useful tool for researchers and policy makers.","Label":"0"},{"DOI":"10.20525/ijrbs.v8i6.515","Abstract":"This study had the purpose to investigate the impact of 38 scheduled major United States (US) macroeconomic news on WTI crude oil intraday volatility for the period 2012-2018. It was the aim to provide a news ranking that indicates upcoming high volatility episodes at a specific point in time. The West Texas Intermediate (WTI) light crude oil represents a benchmark since it has a signal effect on market players. High crude oil price volatility is a measure of risk and known to increase inflation, to affect producers, consumers, and investors and to destabilize economic growth. In this research approach one-minute high-frequency bid close prices provided the basis for a 1h window rolling standard deviation. Data modeling was performed using simple and multiple robust ordinary least squares (OLS) regression performed with programming language Python. The model successfully identified 21 significant news announcements in both, the simple and multiple regression models, however, simple OLS-regression appears to be more sensitive. It also provided a ranking of US news impacting WTI volatility risk. The results support the prediction of approaching high price volatility and thus, display an opportunity for market participants and decision-makers to minimize risk.","Label":"0"},{"DOI":"10.1109/cec.1999.782584","Abstract":"Financial investment decision making is extremely difficult due to the complexity of the domain. Many factors could influence the change of share prices. FGP (Financial Genetic Programming) is a genetic programming based forecasting system, which is designed to help users evaluate the impact of factors and explore their interactions in relation to future prices. Users channel into FGP factors which they believe are relevant to the prediction. Examples of such factors may include fundamental factors such as \"price-earning ratio\", \"inflation rate\" and/or technical factors such as \"5-days moving average\", \"63-days trading range breakout\", etc. FGP uses the power of genetic generated decision trees through technical rules with self-adjusted thresholds. In earlier papers, we have reported how FGP used well-known technical analysis rules to make investment decisions (E.P.K. Tsang et al., 1998; J. Li and E.P.K. Tsang, 1999). The paper tests the versatility of FGP by testing it on shorter term investment decisions. To evaluate FGP more thoroughly, we also compare it with C4.5, a well known machine learning classifier system. We used six and a half years' daily closing price of the Dow Jones Industrial Average (DJIA) index for training and over three and half years' data for testing, and obtained favourable results for FGP.","Label":"1"},{"DOI":"10.1007/978-1-4757-4062-2_9","Abstract":"This paper develops and tests a model which suggests that coordination of wage bargaining and transparency of central bank procedures are two alternative mechanisms that can increase the speed with which expectations adjust to changes in central bank policy. I consider this for an economy where actions of individual wage earners depend on ‘higher order beliefs’ — expectations of what the ‘average’ wage setter believes about the economy. In this context, when central banks change policies they face a problem not only of convincing each individual member of the public that a change has occurred; they also need to ensure that the policy change becomes common knowledge. Decisions by central banks to publish their economic forecasts or records of deliberations and efforts by wage bargainers to coordinate their activities and pool private information can both increase the speed with which higher order beliefs adjust to a policy change. I test these propositions by considering output-inflation tradeoffs in the 1990s for 21 OECD economies. The theoretical predictions of this paper and supporting empirical results suggest that in a euro zone that lacks centralized wage bargaining institutions there may be significant benefits from central bank transparency.","Label":"0"},{"DOI":"10.1057/9781137435354_8","Abstract":"With more than a hint of fatalistic resignation, Brazilians have long observed that theirs is the country of the future … and always will be. Geographically immense, with an economy and a population almost twice as large as any other in Latin America, Brazil is also endowed with enviable natural resources. But time and again throughout the country’s tumultuous history, one or the other economic or political crisis has undermined the predictions of hopeful optimists and provided rich fodder for cynics. As former president Fernando Henrique Cardoso explained about his country, “this special kind of failure that results when tantalizing potential falls tragically short of expectations. That is the kind of failure that Brazil has always specialized in.”1 The country profile has been marked by endless boom-and-bust cycles of rampant inflation, anemic economic growth, a huge external debt burden, income inequality, systemic corruption, notoriously unreliable legal enforcement, low labor productivity, and abysmal physical infrastructure. As one of the country’s leading economists explained in early 2014, even taking into account the relatively strong economic performance of 2008 to 2010, “the government has failed to undertake many fundamental reforms in the past decade.”","Label":"0"},{"DOI":"10.1016/j.elerap.2015.01.001","Abstract":"Increased internet penetration makes it possible for user generated content (UGC) to reflect people’s insights and expectations on economic activities. As representative and easily accessible UGC data that reflect public opinions on economic issues, Google search data have been used to forecast macroeconomic indicators in existing literatures. However, very little empirical research has directly used Google search data to improve the forecast accuracy. This paper proposes an integrated framework, which constructs keywords base and extracts search data accordingly, and then incorporates the search data into a mixed data sampling (MIDAS) model. Five groups of search data are extracted based on the constructed keywords and are then used in MIDAS model to forecast Chinese consumer price index (CPI) from 2004 to 2012. The empirical results indicate that the search data are strongly correlated with CPI, which is officially released by the Statistic Bureau of China; the MIDAS model including the search data outperforms the benchmark models, with the average reduction of root mean square error (RMSE) being 32.9%. This research provides a rigorous and generalizable framework for macroeconomic trend prediction using Google search data, and would have great potential in supporting business decisions by eliciting relevant information from UGC data in the Internet.","Label":"1"},{"DOI":"10.36713/epra9755","Abstract":"The Russia-Ukraine war has had a direct influence on India’s foreign policy and security. Delhi is in a precarious position since it has allies on both sides of the war. India cannot continue to see Central Europe through Russia’s eyes and must make a strategic decision. Russia’s GDP growth is expected to be 0.7 percent in 2022, down 1.9 percent from last month’s prediction, and 1.4 percent in 2023, according to Focus Economics panellists. Economists are projected to become even more conservative in the future. The goal is being undermined by an increase in spontaneous risk as well as developing political and economic disparities. Ukraine’s government is said to have spent $270 million on military bond sales. In the foreseeable future, the war will have a substantial economic impact. Because of the severity of the circumstances and the unpredictability of the war, assessing the recession may take some time. Russia maintains that Ukraine was created by the Bolsheviks following the Battle of Brest-Litovsk in 1917. Russia is frequently the world’s greatest wheat exporter, while Ukraine is the world’s second-largest grain exporter. The researcher analyses the impact of war on the global and Indian economies. KEYWORDS: Russian-Ukraine war, Inflation, Trade balance, Sanctions.","Label":"0"},{"DOI":"10.30798/makuiibf.805079","Abstract":"Share of government expenditures in the GDPs are increasing virtually everywhere. Available data for developed countries indicate that the beginnings of this upward trend date back to the mid-19th century. Interestingly, economic growth rates did not increase significantly over time despite the increases in government expenditures. Low income countries today spend more than the double of what today’s developed economies were spending on average in 1900. However, this is not helping them to converge to richer economies. Why are government expenditures increasing then? This question might have global pertinence but due to the variety of country-specific factors, it can be best studied on a single country level. In this article, the country of focal interest is Turkey. Five important variables that might affect government expenditures from different angles are evaluated regarding their contributions to the out-of-sample predictions of government expenditures using random forest methodology. Military expenditures are estimated as primarily important for determining the government expenditures in Turkey in the last fifty years, while tax collections happened to be the second most important factor affecting the ups and downs of government expenditures around a time-varying average line. Per capita income, urbanization and inflation also affect government expenditures in various ways.","Label":"1"},{"DOI":"10.2139/ssrn.1331984","Abstract":"Purpose – This paper analyzes forecasting problems from the perspective of information extraction. We study circumstances under which the forecast of an economic variable from one domain (country, industry, market segment) should rely on information regarding the same type of variable from another domain even if the two variables are not causally linked. Thus, Granger causality linking variables from different domains may be the rule and should be exploited for forecasting. Design/methodology/approach – The article applies information economics, in particular the study of rational information extraction in order to shed light on the debate on causality and forecasting. Findings – It is shown that the rational generalization of information across domains can lead to effects that are hard to square with economic intuition but are nevertheless worth being taken into consideration for forecasting. Information from one domain is shown to affect another domain if there is at least one common factor affecting both domains which is not (or not yet) observed when a forecast has to be made. The analysis suggests the theoretical possibility that the direction of such effects across domains can be counter-intuitive. In time-series econometrics such effects will show up in estimated coefficients with the “wrong” sign. Practical implications – This study helps forecasters by indicating a wider set of variables relevant for prediction. The analysis offers a theoretical basis for using lagged values from the type of variable to be forecast but from another domain. E.g., when forecasting the bond risk spread in one country we suggest introducing in the time-series model the lagged value of the risk spread from another country. Two empirical examples illustrate this principle for specifying models for prediction. While we limit the application to risk spreads and inflation rates the approach suggested here is widely applicable. Originality/value – The present study builds on a probability theoretical analysis to inform the specification of time-series forecasting models.","Label":"0"},{"DOI":"10.2139/ssrn.2998272","Abstract":"In the field of economics, recent advances in the areas of machine learning, shrinkage, and variable selection have been spectacularly successful. In one key area of study, advances in both modelling and estimation have enabled empirical practitioners to show the usefulness of latent factors designed to efficiently extract common information from interesting new datasets. At the center of this big data success are di¤usion and mixed frequency indices, which have proven useful time and time again in forecasting contexts. This paper lends further support to recent claims of the usefulness of these sorts of indices, albeit with a twist. We show that the usefulness of said indices is pronounced during low GDP growth periods, while simple autoregressive models are adequate during high growth periods. This finding stems from the introduction of very simple hybrid models that employ dynamic recursive (rolling) thresholding in order to switch between benchmark linear models and more complex index driven models, depending on GDP growth conditions. In the context of predicting both quarterly real GDP growth and CPI inflation, these hybrid models are found to be superior, for all forecast horizons. When comparing the hybrid models against a host of alternatives, mean square forecast error gains reach as high as 35%, during the Great Recession, and remain significant throughout our entire prediction period. Additionally, the very best short-term GDP forecasting models contain variants of the Aruoba, Diebold and Scotti (2009) business conditions index, although these models are most useful when di¤usion indices are also incorporated. Thus, mixing mixed frequency and di¤usion indices matters. Finally, across all experiments, we find strong new evidence of the usefulness of survey predictions, including those from the Survey and Professional Forecasters, and those from the Livingston Survey.","Label":"1"},{"DOI":"10.1007/s00181-022-02289-3","Abstract":"In this paper, we analyze the forecasting performance associated with using machine learning, shrinkage, and variable selection methods during a historical period that contains the Great Recession of 2008. We find that these methods are most useful during “low” GDP growth periods, while simple autoregressive models are adequate during “high growth” periods. This finding stems from the introduction of very simple “hybrid” models that employ dynamic recursive (rolling) thresholding in order to switch between benchmark linear models and more complex index-driven models, depending on GDP growth conditions. In the context of predicting both quarterly real GDP growth and CPI inflation, these hybrid models are found to be superior, for all forecast horizons. When comparing the hybrid models against a host of alternatives, mean square forecast error gains reach as high as 35%, during the Great Recession, and remain significant throughout our entire prediction period. Additionally, the very best short-term GDP forecasting models contain variants of the Aruoba et al. (2009) business conditions index, although these models are most useful when diffusion indices are also incorporated. Thus, mixing mixed frequency and diffusion indices matters. Finally, across all experiments, we find strong new evidence of the usefulness of survey predictions, including those from the Survey of Professional Forecasters, and those from the Livingston Survey. While we leave the examination of alternative datasets, such as those including other recessionary periods, episodes of war, and epidemics to future research, we hypothesize that the findings in this paper point to the potential usefulness of machine learning, shrinkage, and variable selection methods during recessions, as well as to the usefulness of the hybrid models that we introduce.","Label":"1"},{"DOI":"10.1108/fs-06-2017-0017","Abstract":"Purpose                     This paper aims to analyze forecasting problems from the perspective of information extraction. Circumstances are studied under which the forecast of an economic variable from one domain (country, industry, market segment) should rely on information regarding the same type of variable from another domain even if the two variables are not causally linked. It is shown that Granger causality linking variables from different domains is the rule and should be exploited for forecasting.                                                           Design/methodology/approach                     This paper applies information economics, in particular the study of rational information extraction, to shed light on the debate on causality and forecasting.                                                           Findings                     It is shown that the rational generalization of information across domains can lead to effects that are hard to square with economic intuition but worth considering for forecasting. Information from one domain is shown to affect that from another domain if there is at least one common factor affecting both domains, which is not (or not yet) observed when a forecast has to be made. The analysis suggests the theoretical possibility that the direction of such effects across domains can be counter-intuitive. In time-series econometrics, such effects will show up in estimated coefficients with the “wrong” sign.                                                           Practical implications                     This study helps forecasters by indicating a wider set of variables relevant for prediction. The analysis offers a theoretical basis for using lagged values from the type of variable to be forecast but from another domain. For example, when forecasting the bond risk spread in one country, introducing in the time-series model the lagged value of the risk spread from another country is suggested. Two empirical examples illustrate this principle for specifying models for prediction. The application to risk spreads and inflation rates illustrates the principles of the approach suggested here which is widely applicable.                                                           Originality/value                     The present study builds on a probability theoretic analysis to inform the specification of time-series forecasting models.","Label":"0"},{"DOI":"10.1109/icic47613.2019.8985785","Abstract":"Capital markets are complex and dynamic, so they have risks and uncertainties. The main activity in the capital market is investment. There are several instruments for investing, namely gold, land, savings, deposits, bonds and stocks. Investors need a variety of information to help determine the right momentum to invest, one of which is the stock price in the future. By making predictions, investors can minimize the risk of loss in investing. The purpose of this study is to compare the Multilayer Perceptron and Long Short-Term Memory algorithm in predicting Indonesian Composite Stock Price Index in the future based on macroeconomic factors. This study uses Dow Jones Industrial Average, Shanghai Stock Exchange, world gold prices, world oil prices, USD to IDR exchange rate, inflation, BI Rate, and money supply as macroeconomic factors to predict the price of the Indonesian Composite Stock Price Index. The time series used for the research data is monthly, from January 1991 to December 2018. Based on the results of the evaluations that have been conducted, this study found that modeling using the Multilayer Perceptron algorithm has a better performance than Long Short-Term Memory. Evaluation using Root Mean Squared Error and R-squared each produces a value 86.86% and 3.19% for Multilayer Perceptron; 74.24% and 3.94% for Long Short- Term Memory.","Label":"1"},{"DOI":"10.2139/ssrn.3447189","Abstract":"Can the fiscal theory of the price level account for the exit from the zero lower bound (ZLB) regime of the U.S.? If so, why has the Japanese economy been trapped in the ZLB for more than two decades? This study examines the extent to which the fiscal theory can account for the exit in a recurrent regime-switching context. Monetary policy in a ZLB regime is inherently passive as it is forced to maintain the interest rate at zero. Therefore, an active fiscal policy lowering the real-value of government bonds held by the public can generate higher expected inflation, helping the exit. At the heart of this theory is the uniqueness of a non-Ricardian stable equilibrium at which agents' beliefs are coordinated. Contrary to the fixed regime prediction, the economy switching between the ZLB and a Ricardian regime with an active monetary/passive fiscal policy mix is shown to be robustly subject to indeterminacy, making the coordination of agents' beliefs hard because both monetary and fiscal policies are overall strongly passive. We then highlight that a lower discount factor and higher productivity growth are the key factors for the fiscal theory to be consistent with the exit of the ZLB in a regime-switching setting. In particular, the productivity differential is shown to be critical in explaining the different equilibrium paths experienced by the U.S. and Japan.","Label":"0"},{"DOI":"10.1080/03796205.1989.12128959","Abstract":"This paper attempts to measure the value of unrecorded economic activity in South Africa. The value of unrecorded activity is inferred from the quantity of notes in circulation. It is observed that the ratio of notes in circulation to official measures of gross domestic product and expenditure has increased significantly in recent years. This development has coincided with greater freedoms for black South Africans to migrate to the urban areas of South Africa and to engage in economic activity there. Differences between the actual demand for notes and predictions of such demands, derived from models of the demand for notes, as estimated by regression analysis for the period 1950 to 1980, are used to infer the volume of unrecorded activity. Annual data is applied. The models used to estimate the demand for notes are a mixture of uni-variate time series models, combined with bank debits, interest rates and inflation as other independent variables. The time series models provide very good fits. The addition of the other independent variables add little explanatory power. Consideration is also given to the reference of possible changes in the demand for notes by the banking system. Both on theoretical and empirical grounds it is shown that much of the increase in the demand for notes unrecorded outside rather than inside the banking system.","Label":"0"},{"DOI":"10.1016/j.jeconom.2005.07.026","Abstract":"This paper outlines testing procedures for assessing the relative out-of-sample predictive accuracy of multiple conditional distribution models. The tests that are discussed are based on either the comparison of entire conditional distributions or the comparison of predictive confidence intervals. We also briefly survey existing related methods in the area of predictive density evaluation, including methods based on the probability integral transform and the Kullback–Leibler Information Criterion. The procedures proposed in this paper are similar in many ways to [Andrews’, 1997. A conditional Kolmogorov test. Econometrica 65, 1097–1128.] conditional Kolmogorov test and to [White's, 2000. A reality check for data snooping. Econometrica 68, 1097–1126.] reality check. In particular, a predictive density test is outlined that involves comparing square (approximation) errors associated with models i,i=1,…,n, by constructing weighted averages over U of E((Fi(u|Zt,θi†)-F0(u|Zt,θ0))2), where F0(·|·) and Fi(·|·) are true and model-i distributions, u∈U, and U is a possibly unbounded set on the real line. A conditional confidence interval version of this test is also outlined, and appropriate bootstrap procedures for obtaining critical values when predictions used in the formation of the test statistics are obtained via rolling and recursive estimation schemes are developed. An empirical illustration comparing alternative predictive models for U.S. inflation is given for the predictive confidence interval test.","Label":"0"},{"Abstract":"Inflation is a major determinant for allocation decisions and its forecast is a fundamental aim of governments and central banks. However, forecasting inflation is not a trivial task, as its prediction relies on low frequency, highly fluctuating data with unclear explanatory variables. While classical models show some possibility of predicting inflation, reliably beating the random walk benchmark remains difficult. Recently, (deep) neural networks have shown impressive results in a multitude of applications, increasingly setting the new state-of-the-art. This paper investigates the potential of the transformer deep neural network architecture to forecast different inflation rates. The results are compared to a study on classical time series and machine learning models. We show that our adapted transformer, on average, outperforms the baseline in 6 out of 16 experiments, showing best scores in two out of four investigated inflation rates. Our results demonstrate that a transformer based neural network can outperform classical regression and machine learning models in certain inflation rates and forecasting horizons.","Label":"1"},{"Abstract":"This paper proposes a parsimoniously time varying parameter vector autoregressive model (with exogenous variables, VARX) and studies the properties of the Lasso and adaptive Lasso as estimators of this model. The parameters of the model are assumed to follow parsimonious random walks, where parsimony stems from the assumption that increments to the parameters have a non-zero probability of being exactly equal to zero. By varying the degree of parsimony our model can accommodate constant parameters, an unknown number of structural breaks, or parameters with a high degree of variation.   We characterize the finite sample properties of the Lasso by deriving upper bounds on the estimation and prediction errors that are valid with high probability; and asymptotically we show that these bounds tend to zero with probability tending to one if the number of non zero increments grows slower than $\\sqrt{T}$.   By simulation experiments we investigate the properties of the Lasso and the adaptive Lasso in settings where the parameters are stable, experience structural breaks, or follow a parsimonious random walk. We use our model to investigate the monetary policy response to inflation and business cycle fluctuations in the US by estimating a parsimoniously time varying parameter Taylor rule. We document substantial changes in the policy response of the Fed in the 1980s and since 2008.","Label":"1"},{"DOI":"10.2139/ssrn.3031796","Abstract":"We introduce machine learning in the context of central banking and policy analyses. Our aim is to give an overview broad enough to allow the reader to place machine learning within the wider range of statistical modelling and computational analyses, and provide an idea of its scope and limitations. We review the underlying technical sources and the nascent literature applying machine learning to economic and policy problems. We present popular modelling approaches, such as artificial neural networks, tree-based models, support vector machines, recommender systems and different clustering techniques. Important concepts like the bias-variance trade-off, optimal model complexity, regularisation and cross-validation are discussed to enrich the econometrics toolbox in their own right. We present three case studies relevant to central bank policy, financial regulation and economic modelling more widely. First, we model the detection of alerts on the balance sheets of financial institutions in the context of banking supervision. Second, we perform a projection exercise for UK CPI inflation on a medium-term horizon of two years. Here, we introduce a simple training-testing framework for time series analyses. Third, we investigate the funding patterns of technology start-ups with the aim to detect potentially disruptive innovators in financial technology. Machine learning models generally outperform traditional modelling approaches in prediction tasks, while open research questions remain with regard to their causal inference properties.","Label":"1"},{"DOI":"10.22198/rys.2000.19.a753","Abstract":"During the period 1982-1998, the Mexican society, economy, and political system were affected by a series of events which generated uncertainty. This uncertainty is evidenced by frequent devaluations, crises in the stock exchange, high levels of inflation, the implementation of adjustment policies, two political assassinations, a radical trade liberalization, the emergence of guerrilla movements, the privatization of state enterprises, and changes that help the entry of foreign investment, to mention but some of the factors in this situation. In a recent period (1995-1998), after the turmoil in 1995, the economy has become more stable. The GNP?s growth rate in 1996 was 4.5%, in 1997 5%, and in 1998 4.5%.According to solvent organizations? predictions, the Mexican economy will be on a stable course for the next two or three years, at least until the presidential sucession in 2000. In light of its experience, and despite the seriousness of uncertainty and the political tensions, the country has kept a stability that would have been difficult to maintain in a different context. There are elements in the society, in the economy and in the political system (among which is notable the continuance of corporatism) which have allowed the country to confront this uncertainty and to set up compensations which have had positive effects as measured by the solving of many problems.","Label":"0"},{"DOI":"10.2139/ssrn.1105728","Abstract":"This paper explores the transmission of credit conditions into the real economy. Specifically, I examine the forecasting power of the term structure of credit spreads for future GDP growth. I find that the whole term structure of credit spreads has predictive power, while the term structure of Treasury yields has none. Using a parsimonious macro-finance term structure model that captures the joint dynamics of GDP, inflation, Treasury yields and credit spreads, I decompose the spreads and identify the drivers of this transmission effect. I show that there is a pure credit component orthogonal to macroeconomic information that accounts for a large part of the forecasting power of credit spreads. The macro factors themselves also contribute to the predictive power, especially for long maturity spreads. Additional factors affecting Treasury yields and credit spreads are irrelevant for predicting future economic activity. The credit factor is highly correlated with the index of tighter loan standards, thus lending support to the existence of a transmission channel from borrowing conditions to the economy. Using data from 2006-2008, I capture the ongoing crisis, during which credit conditions have heavily tightened and I show that the model provides reasonably accurate out-of-sample predictions for this period. As of year-end 2008, the model predicts a contraction of -2% in real GDP growth for 2009, which is lower than comparable survey forecasts.","Label":"0"},{"DOI":"10.2139/ssrn.812088","Abstract":"Our objectives in this paper are twofold. First, we introduce block bootstrap techniques that are (first order) valid in recursive estimation frameworks. Thereafter, we present two examples where predictive accuracy tests are made operational using our new bootstrap procedures. In one application, we outline a consistent test for out-of-sample nonlinear Granger causality, and in the other we outline a test for selecting amongst multiple alternative forecasting models, all of which are possibly misspecified. More specifically, our examples extend the White (2000) reality check to the case of non-vanishing parameter estimation error, and extend the integrated conditional moment tests of Bierens (1982, 1990) and Bierens and Ploberger (1997) to the case of out-of-sample prediction. In both examples, appropriate re-centering of the bootstrap score is required in order to ensure that the tests have asymptotically correct size, and the need for such re-centering is shown to arise quite naturally when testing hypotheses of predictive accuracy. In a Monte Carlo investigation, we compare the finite sample properties of our block bootstrap procedures with the parametric bootstrap due to Kilian (1999); all within the context of various encompassing and predictive accuracy tests. An empirical illustration is also discussed, in which it is found that unemployment appears to have nonlinear marginal predictive content for inflation.","Label":"0"},{"DOI":"10.1017/cbo9781139342674.017","Abstract":"Chapter Preview. This chapter deals with the analysis of measurements over time, called time series analysis. Examples of time series include inflation and unemployment indices, stock prices, currency cross rates, monthly sales, the quarterly number of claims made to an insurance company, outstanding liabilities of a company over time, internet traffic, temperature and rainfall, and the number of mortgage defaults. Time series analysis aims to explain and model the relationship between values of the time series at different points of time. Models include ARIMA, structural, and stochastic volatility models and their extensions. The first two classes of models explain the level and expected future level of a time series. The last class seeks to model the change over time in variability or volatility of a time series. Time series analysis is critical to prediction and forecasting. This chapter explains and summarizes modern time series modeling as used in insurance, actuarial studies, and related areas such as finance. Modeling is illustrated with examples, analyzed with the R statistical package. Exploring Time Series Data 17.1.1 Time Series Data A time series is a sequence of measurements y1, y2, …, yn made at consecutive, usually regular, points in time. Four time series are plotted in Figure 17.1 and explained in detail later. Each time series is “continuous,” meaning each yt can attain any value in some interval of the line.","Label":"0"},{"DOI":"10.15740/has/irjaes/11.2/299-310","Abstract":"Forecasting is a function in management to assist decision making. It is also described as the process of estimation in unknown future situations. In a more general term it is commonly known as prediction which refers to estimation of time series or longitudinal type data. The main object of this paper is to compare the traditional time series model with machine learning algorithms. To predict the gold prices based on economic factors such as inflation, exchange rate, crude price, bank rate, repo rate, reverse repo rate, gold reserve ration, Bombay stock exchange and National stock exchange. Two lagged variables are taken for each variable in the analysis. The ARIMAX model is developed to forecast Indian gold prices using daily data for the period 2016 to 2020 obtained from World Gold Council. We fitted the ARIMAX (4,1,1) model to our data which exhibited the least AIC values. In the mean while, decision tree, random forest, lasso regression, ridge regression, XGB and ensemble models were also examined to forecast the gold prices based on host of explanatory variables. The forecasting performance of the models were evaluated using mean absolute error, mean absolute percentage error and root mean squared errors. Ensemble model out performs than that of the other models for predicting the gold prices based on set of explanatory variables.","Label":"1"},{"DOI":"10.1016/j.jpolmod.2003.09.001","Abstract":"This paper develops a Vector Error Correction (VEC) model and uses the recently developed technique of ‘generalized’ impulse response analysis to test the empirical relationships in the Colombian economy between coffee revenues and a set of macro variables. We find that coffee price (revenue) shocks have exerted an important influence on money growth, inflation, and real exchange rates, and the direction of these effects are in line with some of the predictions of traditional Dutch Disease type models. The major difference between our results and the results of Dutch Disease type models arise in the effects of coffee booms on real output. We find that in the time horizon of 5 years after the boom, real output has increased in response to the effects of the coffee boom. The finding that coffee booms can result in positive long-run output effects is an important finding since it contradicts the traditional conclusion of Dutch Disease type models which envision an adverse long-run effect on output. We also find that the long-run effect of coffee booms is to reduce both current account and government deficits. These results illustrate strikingly that the term “Dutch Disease” is an unfortunately pejorative term that obscures the fact that coffee booms need not be viewed as a “disease” but as an extraordinary opportunity to strengthen internal and external balances.","Label":"0"},{"DOI":"10.17016/feds.2023.029","Abstract":"We construct a Financial Stress Index (FSI) for a small open economy, which aims to provide clear and timely signals of financial market strains. This can be used in developing appropriate responses to address these adverse events. To do so, we use the principal component framework and apply it to Australian monthly data on interest rates, spreads, exchange rates, house price growth and inflation expectations. Decomposing the index into foreign and domestic components, we find that the foreign factors can explain more than half (57.4%) of our Australian Financial Stress Index (AFSI). To determine the information content of our index, we run a series of Granger causality tests on several economic and financial observables. We also estimate whether including the AFSI can improve the prediction of the different economic and financial outcomes relative to a specification that uses only its own previous data. We find that including the AFSI improves the forecasts for future retail sales growth and bank credit growth. Finally, we show that financial stress can have non-linear effects on bank credit growth. In particular, an increase in financial stress affects credit growth more adversely if AFSI is high. This result further highlights the importance of an accurate and timely measure of financial stress in an economy for researchers and policy makers.","Label":"0"},{"DOI":"10.33480/jitk.v7i2.2880","Abstract":"Predicting a currency Exchange rate and performing analysis is an action to try to determine the price valuation of a currency or other financial instrument traded on an exchange platform. Bitcoin is a consensus network that enables new payment systems and fully digital money. Bitcoin is the first decentralized peer to peer payment network that is fully controlled by its users without any central authority or intermediary. From the user's point of view, Bitcoin is like cash in the internet world. Bitcoin can also be viewed as the most prominent triple bookkeeping system in existence today. The change in Bitcoin's behavior against the US dollar is influenced by many factors. Basic or economic factors that may be affected include inflation rates and money supply. In this study, data was collected by obtaining all data through the API provided by binance.com and labeled with the specified attribute. The modeling is done by using the rapidminer application. The process begins by taking training data that has been provided previously. The next stage is the data testing process, all operators that have been previously determined are connected and tested using the Linear Regression operator. The purpose of testing this data is to predict stock prices from the testing data that has been made by the Split Data operator, which is 19% of the total data that has been prepared.","Label":"1"},{"DOI":"10.1093/oso/9780198866176.003.0009","Abstract":"Wages and wage bargaining institutions are foundational components of comparative capitalism research. Supply-side comparative capitalism research has often assumed that wage moderation—facilitated through highly coordinated wage-setting institutions—produces beneficial growth outcomes. This supposition stems from the logic that restrained unit labor cost growth causes firms to increase employment and output. However, through its demand-side perspective, new growth model literature questions the virtues of wage moderation, because the restraint of wages can be detrimental to growth via its suppression of domestic consumption. This chapter empirically tests under what conditions will wage moderation produce economic growth. Using a first-difference, distributive lag panel analysis of eighteen OECD countries from 1970 to 2015, its findings largely resonate with predictions within the growth model literature. In the presence of wage restraint, countries with larger export shares and highly coordinated wage-setting institutions realize higher growth and lower unemployment than countries with smaller export shares and uncoordinated wage-setting institutions. In contrast, wage inflation produces better growth outcomes for countries with uncoordinated wage-setting, relative to those with highly coordinated wage-setting institutions. These results suggest that wage restraint is not a winning strategy for all growth models. Rather, wage moderation is associated with better growth (and unemployment) outcomes only for countries with export-led growth strategies.","Label":"0"},{"DOI":"10.2139/ssrn.1031737","Abstract":"This paper examines the empirical significance of learning, a type of adaptive, boundedly rational expectations, in the U.S. economy within the framework of the New Keynesian model. Two popular specifications of the model are estimated: the standard three equation model that does not include capital, and an extended model that allows for endogenous capital accumulation. Estimation results for learning models can be sensitive to the choice for the initial conditions for agents expectations, so four different methods for choosing initial conditions are examined, including jointly estimating the initial conditions with the other parameters of the model. Maximum likelihood results show that learning under all methods for initial conditions lead to very similar predictions as rational expectations, and do not significantly improve the fit the model. The evolution of forecast errors show that the learning models do not out perform the rational expectations model during the run-up of inflation in the 1970s and the subsequent decline in the 1980s, a period of U.S. history which others have suggested learning may play a role. Despite the failure of learning models to better explain the data, analysis of the paths of expectations and structural shocks during the sample show that allowing for learning in the models can lead to different explanations for the data.","Label":"0"},{"DOI":"10.2139/ssrn.3014058","Abstract":"The wisdom of crowds—combining information from a collection of individual judgments—offers a useful technique to quantify an unknown variable. Averaging point estimates has proven to be effective in reducing error in the consensus estimate. However, in many managerial problems, the decision maker requires an assessment of the full distribution of uncertainty rather than just a single number. In practice, some managers have used dispersion in point estimates as a cue to uncertainty in the variable of interest, but a characterization of the exact relationship between the two has not yet been established. Using a stylized Bayesian model of overlapping information spread across a collection of judges, I show that the variance of the variable of interest can be estimated with a multiple of the variance of the individual judgments, and establish an analytical expression for the consensus predictive distribution. I then present a procedure that can be used to learn about this variance inflation factor using past judgments and realizations, and derive the resulting distribution for the new variable of interest. This aggregation method is easy to implement in practice to estimate a predictive distribution from a collection of individual judgments. Application of the procedure to forecasts available through the Survey of Professional Forecasters suggests that the resulting predictions are well-calibrated and outperform natural existing alternatives.","Label":"0"},{"DOI":"10.2139/ssrn.1910167","Abstract":"Academic research on consumption and portfolio choices over an individual’s life cycle has been flourishing for almost four decades. Since the seminal work of Merton (1969) and Samuelson (1969), economists’ models have supplied many asset allocations that would achieve optimal intertemporal consumption. Additional considerations on one’s labor decisions or unforeseen rare events have substantiated these models’ predictions and encouraged their implementation by industry practitioners. However, applications of even fairly complex models have quickly exposed the limitations and shortcomings of simplistic assumptions. For example, most models restrict the investment opportunity set to stocks and a riskless asset. Bonds, derivatives and housing are seldom included while other categories are dismissed altogether. Although some model specifications could easily allow for more financial alternatives, it is sometimes data availability (or lack thereof) that determines what variables are included. In this respect, Treasury Inflation-Protected Securities (TIPS) are challenging. The U.S. Government’s first issue was in 1997, long after TIPS were introduced in the U.K., Canada, Israel, Turkey and New Zealand. Naturally, data that span over only 15 years are of little use for the study of an individual’s optimal lifetime behavior: oftentimes, the planning horizon is set at age 90 or 100, with retirement starting at 65. Ultimately, the too recent history of TIPS returns has deterred fund managers from offering them as long-term/retirement assets and, in turn, has curbed their market reach. This project develops a rigorous methodology to estimate the real term structure of TIPS between 1970 and 1997. The resulting series is then merged with the actual data to produce a continuous series of real interest rates from 1970 until now. A summary description of our techniques and preliminary results is attached. The goodness of the newly obtained rates is tested by computing historical correlations with: Moody’s Seasoned AAA Corporate Bond Yield, the 30-Year Conventional Mortgage Rate, the OFHEO’s House Pricing Index, the Dow Jones Industrial Average Index and the S&P500 Index. We perform the exercise for all maturities (5, 10, 20 and 30 years). The outcome of this analysis is twofold. First, it provides practitioners with a reliable tool to better measure the risk-return tradeoff of portfolio strategies with TIPS. Second, it helps establishing guidelines that policy makers can use to choose qualified default investment alternatives (QDIA). Both dimensions offer fertile ground to financial experts who have long cheered TIPS as valuable retirement vehicles.","Label":"0"},{"DOI":"10.25115/eea.v40i1.5229","Abstract":"This study aims to see the anchoring effect on portfolio return volatility in the case of KSE-30. Business anomalies such as overreaction and under-reaction are affected by a variety of psychological causes. The use of anchors or baseline values known as the anchoring effect causes market under-reaction and overreaction. This research used nearness to 52-week high and nearness to historical high as proxies for under and over-reaction, respectively, to analyze the psychological causes for under and over-reaction. On the KSE-30, the findings revealed that proximity to the 52-week peak positively predicts future returns, whereas proximity to the historical high negatively predicts future returns. KSE-30 was used for rigorous testing. Similarly, the three macroeconomic variables used as control variables are the exchange rate, inflation rate, and interest rate to provide a more robust model of strong prediction capacity. The findings revealed that proximity to the 52-week maximum and proximity to the historical high and other macroeconomic factors had a forecast capacity of around 62 percent. Similarly, focused on volatility clusters, the GARCH (1, 1) model was used to measure the association between potential and past returns. The results show that there is a first order autoregressive function in the GARCH (1, 1) model. The findings also show that their predictive capacity decreases when the study's individual variables are moved from every day to annual Periods.","Label":"1"},{"DOI":"10.1002/for.2738","Abstract":"Apart from the percentage change in the price of crude oil, there is a growing tradition of using various nonlinear transformations of the price of crude oil to forecast real gross domestic product growth rates, equity returns, inflation and other macroeconomic variables. This study attempts to quantify the additional potential predictive power afforded by crude oil price volatility relative to widely used crude oil price‐based variables for more than 300 US macroeconomic time series at the monthly and the quarterly sampling frequency. We observe that regressions employing crude oil price realized volatility and crude oil price realized semivolatilities tend to afford a more consistent pattern of out‐of‐sample prediction gains relative to competitors using well‐known crude oil price measures and the autoregressive benchmark at the quarterly and monthly sampling frequency. While it is somewhat harder to find evidence of finite‐sample predictive gains relative to the benchmark, the evidence is stronger with respect to population‐level predictability 1 quarter (1 month) ahead for the model with crude oil price realized semivolatilities across the considered data and models. Furthermore, point (density) forecasts employing crude oil price realized volatility tend to be more accurate than corresponding forecasts produced under the crude oil price‐based predictive regressions in a horse race.","Label":"0"},{"DOI":"10.2139/ssrn.1899044","Abstract":"Many studies conclude that the main reason Americans pay more for health care is that its providers charge higher prices. There is little agreement on why prices are higher. I argue that higher prices are caused by a type of insurance contract unique to America. “Service benefit” contracts originated by Blue Cross/Blue Shield plans paid no monetary “indemnity” to the people insured. Rather payments went directly to providers. Initially participating providers accepted the plan benefit as payment in full, and, so long as this remained true, these contracts provided no special incentive for providers to raise their prices. This changed around 1950, when independent insurance companies began to market a new type of policy called “major medical”. These policies were imitated by the Blues and, in so doing, they introduced “coinsurance” and “deductibles” provisions into the service benefit plans. In these new service benefit hybrids, providers were free to charge patients more than the plan benefit to be paid directly by the patient. An unintended consequence of this development was the release of an inflationary spiral. A model, based on the theory of two-sided matching, provides quantitative predictions of the increase in provider prices caused by insurance. The model can quantitatively account for the inflationary spiral observed from 1949 to 1959. If service benefit insurance is the major cause of the rise in provider prices, then a reform proposed here could reverse the spiral.","Label":"0"},{"DOI":"10.1007/978-1-349-11423-8_8","Abstract":"This paper discusses economic liberalisation with reference to Chilean experience with trade and financial liberalisation. There are several reasons why the Chilean case is of interest. First, the Chilean economy pursued two distinctly different development strategies. From the 1930s to the early 1970s the economy followed inward-looking strategies and from late 1973 onwards, outward-looking strategies with stabilisation. Secondly, the process of liberalisation after 1973 was considered to be a ‘pure monetarist strategy’ as the economy was following free market oriented policies under the guidance of the military government and Chicago-trained economists. Thirdly, given that trade and financial liberalisation in Chile followed the sequence suggested by economic theory, namely trade liberalisation followed by financial reforms, it is of interest to see whether the results were consistent with the predictions of the theory. Finally, the performance of the Chilean economy both during and after the liberalisation period contained some dramatic changes. The inflation rate reached 500 per cent during 1973 but fell to 10 per cent by 1981. After the liberalisation process changes in interest rates, real exchange rates and the demand for credit remained of great concern. Real GDP growth experienced dramatic changes: for many years it averaged 8 per cent but there were decreases of over 12 per cent in two separate years.","Label":"0"},{"DOI":"10.54691/bcpbm.v38i.3753","Abstract":"The price of households had increased greatly as the demands in the market increased. Real estate had become the most popular method to resist inflation. Thus, more experts and scholars are working on the research in this area, including but not limited to find the future trends of housing prices and the possible bubble of housing prices. This paper will use the basic data regression model in Excel, powered by Microsoft, to find the factors that lead to the appreciation or depreciation of real estate, and three different methods of dealing with the data will be applied which are standardization, interception, and normal normalization. As a result of complex processes, normalization is the best way to deal with the data that was chosen from Kaggle. In the meantime, a linear correlation was done for checking the independency of each variable, and turned out to be successful. According to the analysis, an inverse relationship between the variables house age and distance nearest to the store was found, and the lower the house age is, the higher the price is, higher the house age is, lower the price is. The main aim of this paper is to investigate the relationship of the factors and their impact of them on the price of the house, was achieved and solved mathematically, and therefore, this research paper has found its goals. These results shed light on guiding further exploration of house price estimation.","Label":"0"},{"DOI":"10.1109/isssc50941.2020.9358909","Abstract":"Inflation is not a friend particularly when one tries to avoid wasting money for a few major outlays, such as buying a house or financing a comfortable retirement. In the world of finance, stock commerce is one of the essential activities for the growth and prosperity of the nation by giving a good chance to the commerce and the individuals to invest capital. Earlier, buying and selling of stocks were solely based on human conscience with luck or guessing and without understanding the background details of the stock. It was more kind of betting or gambling. The main aim of this proposed work is to make people understand the importance of investing in the share market for the opulence of a nation. Moreover, this proposed method reduces the risk of losing money in the stock market by hybridizing 2 of the most popular stock market prediction techniques i.e., Auto-Regressive Integrated Moving Average (ARIMA) and Long Short Term Memory (LSTM) with conditional weights determined using the logistic regression using Artificial Intelligence. This aids the decision making process like which stocks to buy/sell at what price at that particular instance. However, no proposed work was found directly indicating the approach that combines these monetary technical indicators with more than one machine learning algorithm. Yet, efficient results were observed as compared to some other proposed approaches as we merged more than one method to predict the same stock price.","Label":"1"},{"DOI":"10.2139/ssrn.2603262","Abstract":"Spanish Abstract: Las series de tiempo tienen una gran importancia para efectuar pronósticos sobre cualquier variable, ya que se puede tomar como variable explicativa su propio pasado y no requiere el conocimiento del dato presente de otras variables explicativas, que en muchas ocasiones no se encuentra. Como punto de partida, se realiza un estudio a la teoría de los modelos univariados de series de tiempo, en segundo lugar, se plantea un protocolo sobre los pasos a seguir para realizar un seguimiento, periodo a periodo, de la variable de tiempo y, finalmente, se expone un ejemplo con los pasos sugeridos en el protocolo para proyectar la inflación con base en la serie del IPC (Índice de precios al consumidor). English Abstract: The time series are very important to make predictions about any variable, due to its own past can be taken as explanatory variable, and it does not require knowledge of this data for other explanatory variables that often can be found. As a starting point, it is made a study of the theory of univariate time series models, secondly, it is proposed a protocol about the steps to follow in order to track period variable period of time, and finally exposed an example of the steps suggested in the protocol for forecasting inflation based on the series of CPI (consumer price index).","Label":"0"},{"DOI":"10.2139/ssrn.4284034","Abstract":"This study explores AOPEC countries' views on the Petrodollar after the second shock of globalization; since February 2022, with the start of the war in Ukraine, the world order has witnessed an economic war alongside conventional war. Along with predictions about how well the US will do at making a Russian oil price cap. Our results indicate that Russia and China are attempting to undermine U.S. control over the global monetary system for political reasons; US efforts to impose the Russian oil price cap is a source of systematic risk to them; Russia's and China's governments employ a wide range of strategies to stop that; On the other hand, the currency diversification policy that oil-exporting countries follow in order to preserve their oil revenues has become a necessity to avoid or reduce the risks of imported inflation and additional fluctuations in the value of the US Dollar. This study has contributed to the literature related to energy markets. The study investigates the change of mechanisms and currency for oil pricing according to oil-exporting countries' attitudes based on giving up the petrodollar after the second shock of globalization. Today, political factors have become a catalyst for the rapid abandonment of oil pricing in US dollars, with the trend towards market pricing away from the forces of demand and supply. In addition to the economic factors that have emerged during the last three decades.","Label":"0"},{"DOI":"10.52620/jeis.v1i1.2","Abstract":"Banking sector has close relationship with economic growth. At the end of 2015 condition of global economic has influence from China slowdown, fall down crude oil price, and rasie interest rate by the fed. These had bad impact for developing counties like Indonesia. In the fact financials crisis in Asia at 1998, sub prime mortage crisis in USA at 2008, and goverment debt crisis in Greece at 2011 made many bank in Indonesia collapse. From past crisis banking sector must have more attention to avoid sistemic crisis. This study aim to make prediction banking crisis models from three group of variable. There are internal bank, macroeconomic, and global economic. This research use Crisis and Default index to measure and identificate probably crisis in indivual bank. All of bank were listed in Indonesian Stock Exchange at 2009 until 2014 has taken as sample. This research chose logit model as a probability crisis models and use logistic regression to testing hypothesis. The result from internal factor with non performing loans, labor cost ratio, and loan to deposits ratio was positive relationship with probability banking crisis. Futhermore net interest margin and interest income to total aset was negative influence for banking crisis. Then from macroeconomic and global economic these are domestic inflation and USA real interest rate was positive influence for banking crisis. After that M2 to reserved ratio, USA growth, and oil price was negative impact to make banking crisis in Indonesia","Label":"0"},{"DOI":"10.1145/3345035.3345062","Abstract":"In this paper, we estimated affecting and important variables of fiscal and monetary policy on economic growth with comparing 3 models (BMA), (DMA) and (DMS) base on accuracy review of estimate model (MSFA), (MAFA). We have understood (BMA) model is an optimal model due to lower prediction error indicators that have shown in table [1]. So we identified the most important and affecting variables on economic growth with considering 62 indicators base on empirical data for determining affecting variables on economic growth, that with using BMA model. By doing the calculations and investigating the effect of 62 factors that have been effective in empirical studies on economic growth, it has been determined that the effect of 11 variables will be meaningful and these variables have always retained their effect, and in the presence of other variables, they have retained their effect. These variables are determined according to the posterior probability (i.e., the highest importance in explaining the economic growth and in other words the most likely to be present in the model). Capital Investment(K), Employment(L), Liquidity(M), Interest Rate(R), Inflation Rate(P), Government Expenditure(G), Balance of Payments (BP), Taxes(T), Oil Revenues (Troil), Gini Coefficient (Gni) and Saving Rate (S) are the affecting and important variables of fiscal and monetary policy on economic growth.","Label":"0"},{"DOI":"10.2139/ssrn.2520403","Abstract":"This paper studies vector autoregressive models with parsimoniously time-varying parameters. The parameters are assumed to follow parsimonious random walks, where parsimony stems from the assumption that increments to the parameters have a non-zero probability of being exactly equal to zero. We estimate the sparse and high-dimensional vector of changes to the parameters with the Lasso and the adaptive Lasso. The parsimonious random walk allows the parameters to be modelled non parametrically, so that our model can accommodate constant parameters, an unknown number of structural breaks, or parameters varying randomly. We characterize the finite sample properties of the Lasso by deriving upper bounds on the estimation and prediction errors that are valid with high probability, and provide asymptotic conditions under which these bounds tend to zero with probability tending to one. We also provide conditions under which the adaptive Lasso is able to achieve perfectmodel selection. We investigate by simulations the properties of the Lasso and the adaptive Lasso in settings where the parameters are stable, experience structural breaks, or follow a parsimonious random walk. We use our model to investigate the monetary policy response to inflation and business cycle fluctuations in the US by estimating a parsimoniously time varying parameter Taylor rule. We document substantial changes in the policy response of the Fed in the 1970s and 1980s, and since 2007, but also document the stability of this response in the rest of the sample.","Label":"1"},{"DOI":"10.1166/asl.2015.6091","Abstract":"This empirical study explores, investigates and analyzes the dynamic relationship between general macroeconomic variables in the Philippines and the overall movement of the Philippine Stock Exchange Index (PSEi). The monthly data of four macroeconomic variables, namely, Consumer Price Index (CPI), overall inflation rate, Industrial Production (IP) (as a proxy for GDP), Trade Balance, and PSEi price over the period 1998–2013 have been used for this study. This study investigates the time series as analysis of economic variables and stock market movement by using The Augmented Dickey Fuller (ADF) for the test of stationary of the variables, and LaGrange-Multiplier Test of ARCH Test and Exponential Generalized Autoregressive Conditional Heteroskedasticity (EGARCH) for the tests of heteroscedasticity in the data. The Granger Test for Causality has been applied to investigate the long-run dynamic interaction between stock market index and the aforementioned macroeconomic variables. The empirical results provide information that the Philippine macroeconomic variables have no substantial effect on the movement of stock prices. The macroeconomic variables used have no significant effects on the volatility of the PSEi and are not considered as substantial contributors for the prediction of the stock market’s future movements. The implication of this study for policymakers and portfolio/fund managers is to consider other variables or economic aspects that may significantly affect the movement of the stock market, thus investors can use such variables in predicting their investment returns.","Label":"0"},{"DOI":"10.1017/cbo9780511510762.004","Abstract":"LABORATORY EXPERIMENTS IN MACROECONOMIC ENVIRONMENTS Experiments such as the ones undertaken in Arifovic and Sargent's paper are rare. The conventional wisdom has been that controlled laboratory environments are infeasible for macroeconomic questions because we are attempting to understand how a very large number of individual households and firms interact to produce the prices and quantities we observe in the data. While this conventional wisdom is, of course, true at some level, there is more to the story. There are good reasons to take experimental macroeconomics very seriously. Mainly, we need to obtain laboratory confirmation of predictions from simple models before we can hope to correctly infer what forces are at work in large, industrialized economies. We economists often write down simple models in an effort to get some core economic intuition concerning topics of interest. The literature begun by Kydland and Prescott (1977) and continued by Barro and Gordon (1983), Rogoff (1985), Walsh (1995), and many others is one outstanding example. In these simple models, we presume to know how human beings would act when confronted with the environments we construct. Laboratory experiments can help us to understand whether such presumptions are warranted. In fact, the current paper calls those presumptions into question. The literature begun by Kydland and Prescott (1977) has been perhaps the most influential for central bankers during the last 25 years. It provides the leading explanation of why there is so much inflation among the industrialized countries of the world today.","Label":"0"},{"DOI":"10.33834/bkr.v2i2.80","Abstract":"The way in which financial markets are framed depends on who is doing the framing, although there are reflexive interdependencies between these framings. The underlying argument of the paper is that the way in which financial markets are framed in theory should reflect the different framings in the economy, and that this may benefit from input from other disciplines. Mainstream economics frames financial markets as archetypical competitive markets, focusing on prices as the key information on which to base analysis. This follows from traditional positivist methodology where computability is the key to theory appraisal. Central banks draw on this analysis for their own framing, but modify it significantly in the face of the requirement to take decisions under palpable uncertainty; some understanding is perceived to be necessary for prediction. Increasingly their role is seen as manipulating expectations in order to achieve inflation targets. Participants in financial markets in turn employ quantitative models for forming their expectations; in conditions of market turbulence the limits to these models become evident, and indeed material to prices themselves. Further, for these participants, markets are a social phenomenon. Finally the households whose experience of financial markets enables or constrains spending frame financial markets in yet another way. Understanding of these various framings would benefit from recourse to other disciplines, notably psychology, sociology and rhetoric. But methodological approach is critical for how these inputs can enhance theorising, as exemplified by the difference between the old and new behavioural economics.","Label":"0"},{"DOI":"10.2139/ssrn.3183653","Abstract":"In this paper we try to understand the economic explanation of the difference in predictability afforded by the old and the new-generation return-predicting factors. To do so, first we show that the Cieslak-Povala (2010) approach can be expressed in terms of a conditional prediction of where the level and the slope of the yield curve should be, given long-term inflation. We then explore whether this interpretation is valid, or whether, as Cochrane (2015) argues, the Cieslak-Povala factor simply owes its effectiveness to its acting as a de-trender. We answer this question by decomposing excess returns into low- and high-frequency components; by showing that the old and new return-predicting factors capture very different periodicities of the return power spectrum; and by showing that a high speed of mean-reversion is required for the high-frequency part of the spectrum. We conclude that creating strongly mean-reverting cycles is key to predicting excess returns effectively, and explore to what extent the Cieslak-Povala approach may be 'special' in this respect. We give a financial interpretation to the low- and high-frequency sources of excess returns, and, based on the understanding this decomposition affords, we show how to build almost by inspection a whole class of extremely parsimonious, robust and financially-motivated return-predicting factors which forecast in- and out-of-sample returns as well or better than factors built using many more variables.","Label":"0"},{"DOI":"10.1108/01443581211245874","Abstract":"Purpose This study is motivated by the view that Democrats are concerned with reducing unemployment in the short‐run, while Republicans are concerned with keeping inflation low to promote economic stability and growth. The purpose of this paper is to ask whether the Federal Reserve forecasts of nonfarm payroll employment are accurate and free of systematic bias during the 1977‐2000 Democratic and Republican administrations.   Design/methodology/approach The authors employ comparable forecasts from a univariate autoregressive integrated moving‐average (ARIMA) model to assess forecast accuracy. An ARIMA model efficiently utilizes past information and thus yields desirable forecasts commonly used as benchmarks.   Findings Federal Reserve forecasts during the Democratic Administrations, while failing to outperform the ARIMA forecasts, display systematic under‐prediction. Such evidence is consistent with a discretionary approach to monetary policy when the bias is in the direction of full employment. During the Republican Administrations, the Federal Reserve forecasts, while superior to the ARIMA forecasts, are free of systematic bias. This, we argue, is consistent with a monetary policy that approximated the Taylor rule.   Research limitations/implications The distinct behavior over the two administrations is unique to the nonfarm payroll employment forecasts and cannot be substantiated for the Federal Reserve forecasts of other macroeconomic variables.   Originality/value This study provides new insights into the monetary policies pursued during the 1977‐2000 Democratic and Republican administrations. The findings are useful and informative for the design and implementation of monetary policy.","Label":"0"},{"DOI":"10.1109/icit.2008.4608584","Abstract":"System marginal price is the unified price of reflecting the short-term supply and demand relation of electric commodity in the electricity market. Confirming the system marginal price is the lever and core content of electricity market. At present, how to predict the system marginal price efficiently is one of the focus problems in the research of electricity market application. In the electricity market, system marginal price is not a parameter that varies according to normal rules. It not only has relations to load curve, available generation capacity, bidding mode, system and unit of the generation companies, but also is in reference to price of commodities, inflation and so on. As we can not use mathematic mode to express the diversity and randomicity of factors which reflects electricity price, it is difficult to predict electricity price accurately. In recent years, as the chaotic theory develops, especially speaking, applying chaotic theory to load forecasting offers a new tool to study the stochastic evolution of electricity price. Furthermore, people reveal the regularity that the evolution of both electricity price time series and load time series indicates the chaotic nature, which hiding in these time series themselves. It offers foundation for predicting electricity price by using phase space reconstruction. This paper analyzes the basic character of the system marginal price time series in greater depth. Then, according to the theory of phase space reconstruction, it makes use of the time series of electricity price data, adopts adding weight one-rank local region method, does not consider the stochastic factor related to electricity price, directly analyzes historical data of the electricity price that contains all factors, and carries on forestation based on acquired objective regularity. We carryon the prediction on the historical data from California electricity market, analyze and draw a detailed comparison with existing forecasting methods such as BP algorithm and LS-VSM algorithm, which shows that mean absolute percentage error reduce 22.6% and 12.8% respectively. Therefore, this method can acquire a better forecasting result.","Label":"1"},{"DOI":"10.26555/jiteki.v7i2.20997","Abstract":"This study focuses on predicting the apartment price index in Indonesia using property survey data from Bank Indonesia. In the era of the Covid-19 pandemic, accurately predicting the sale and purchase price of apartments is essential to minimize the impact of losses, thus making apartment prices attractive to predict. The machine learning approach used to predict the apartment price index are the Random Forest method, the Multiple Regression method, and the Backpropagation method. This study aims to determine which method is more effective in predicting small amounts of data accuracy. The data used is apartment price index data from 2012 to 2019 in the JABODEBEK area. The research will produce prediction accuracy that will determine the effectiveness of the application of the method. The Random Forest method with parameters n_estimators=100 and max_features=”log2” produces an R2 accuracy of 0.977. The Multiple Regression method with a correlation between the selling price and rental price variables is 0.746, and the rental inflation variable is 0.042 produces an R2 accuracy of 0.559. The Backpropagation method with a 1000-4000-1 hidden scheme and 20000 iterations produces an R2 accuracy of 0.996. Therefore, the Backpropagation method is more suitable in this study compared to the other two methods. The Backpropagation method is suitable because it gets almost perfect accuracy, so this method will minimize losses in investing in buying and selling apartments in the Covid-19 pandemic era.","Label":"1"},{"DOI":"10.1177/139156141001100206","Abstract":"This article examines the impact of the developments in the financial sector on economic growth in India in the post-reform period. The model of Mankiw et al. (1992) was extended to establish a relationship between financial development and economic growth. The model was then estimated using quarterly data for the period 1993 to 2005 for India, using the techniques of cointegration and vector error correction method. Cointegration results show that capital–output ratio and rate of growth of human capital have positive effects on real rate of growth of GDP, irrespective of the indicator of stock market development. An increase in the market capitalization dampens economic growth, whereas turnover has no significant effect, and an increase in the money market rate of interest has a positive effect on economic growth. Real wealth, debt burden, real effective exchange rate and the rate of growth of labour have negative effects. Vector error correction method shows that the ECM term relating to market capitalization and inflation help adjust short-run dynamics of economic growth when we use market capitalization as the indicator of the stock market development. The findings lend no support to the theoretical prediction that the stock market development would play an important role in enhancing economic growth in India. On the contrary, reform measures on the market rate of interest that were introduced in the Indian banking system appear to have promoted economic growth significantly.","Label":"0"},{"DOI":"10.1017/cbo9780511492020.008","Abstract":"Spain's inclusion in 1999 among the first wave of countries participating in the eurozone defied the predictions of many observers who just a few years earlier would have deemed such an outcome improbable. A late entrant into the European Community (EC), the country had been plagued by higher than average inflation and by levels of unemployment that well exceeded those of the rest of the European Union (EU). Its system of labor market regulation, a legacy of a dirigiste past, was seen to be overly protectionist and rigid (particularly concerning layoffs) and hence, a major obstacle to successful labor market adjustment. Its system of social provision, on the other hand, was still under construction when the move toward monetary union was initiated and fell short of other EU states on many dimensions. Given this labor regime, many feared that the adoption of a currency reflecting conditions in the rest of Europe would cause a sharp loss of competitiveness, with dire consequences for employment. That, in turn, might force a radical deregulation of the labor market, ending any prospect of achieving a truly “European” social model in Spain. This chapter traces Spain's path to EMU and its implications for the country's evolving systems of social protection and industrial relations. After reviewing the basic characteristics of the Spanish social system, it examines why the Spanish government decided to pursue participation in the first wave of EMU at the end of 1998.","Label":"0"},{"DOI":"10.1007/bf02304514","Abstract":"The negative relationship between output and producers' expectations and the positive relationship between output and consumers' expectations, as hypothesized by Brunner and Meltzer, is very sensitive to the choice of the model. These Brunner-Meltzer predictions would not be supported by the results derived from a Fisherian model with or without a Phillips curve specification, such as the models presented in this paper.Within the context of the Fisherian model, an increase in the degree of adjustment by one or both sectors will lead to greater price stability. For policy purposes, this result suggests that the increase in available information or significant reduction in the costs of acquiring information may yield greater price stability. A welfare gain may also be achieved if the parameters are interdependent such that information conveyed to one sector effectively leaks to the other. In the latter case, the policy approach may be to try to influence the exogeneous expectations parameters and the lag adjustment between them.Recent studies have proposed that the labor market—or the market for new entrants and transitory workers—is the arena in which all firms participate. Hence, most of the information regarding price movements could be efficiently gathered in this market. If this is an accurate presumption, thenB* would, to some extent, be a function then of the labor market adjustment parameterA*. Further amendments to the model presented in this paper would, however, be necessary to incorporate this alternative.","Label":"0"},{"DOI":"10.1007/bf02304060","Abstract":"ConclusionsThis study used the cumulative prediction error methodology to determine if the equity returns of major U.S. banks were affected by the 1974 SDR change. This change by the IMF was viewed as an opportunity to study the adjustment process in international regulation as well as to focus on the policy's net impact. The results strongly support the contention that banks were adversely affected by the change from a dollar-based SDR to a mixed-currency SDR due to the expected increase in lending by the IMF and due to the expectation of inflation and increased exchange volatility.The results also show an expected regulatory pattern of reaction. The primary effect was on the announcement date which had reaction of −0.042 with a test statistic of −14.68. There was a negative drift from day −34 (the announcement day) to day 0 (the implementation day) with the primary decline between days −10 to 0. The implementation date had a smaller, but significant, negative return. These results support those of Davidson [1984] regarding reaction to regulatory change.A key implication of this research is the importance for international monetary agencies to exercise care in implementing policy changes. International repercussions on a country's banking system could occur as a result of a policy change. Evidence from this study indicates that one particular change, namely the recomposition of the SDR, adversely affected the stock values of U.S. banks.","Label":"0"},{"DOI":"10.2139/ssrn.2447654","Abstract":"We construct a price, dividend, and earnings series for the Industrials sector, the Utilities sector, and the Railroads sector from the beginning of the 1870s until the beginning of the year 2013 from primary sources. To infer about mispricings in the sector markets over more than a century, we investigate the forecasting power of the Cyclically Adjusted Price-Earnings (CAPE) ratio for these sectors. With regard to the CAPE ratio, which has originally been devised and employed by Campbell and Shiller (1988, 1998, 2001) as well as Shiller (2005), we define a methodological improvement to this ratio to not only be robust to inflationary changes, but also to changes in corporate payout policy. We then update the original evidence from Campbell and Shiller (1998, 2001) of the return predictability of the CAPE ratio for the overall stock market and furthermore extend this evidence to the three aforementioned sectors individually. Whereas this part of our analysis focuses on each sector of the US economy in isolation, we subsequently construct an indicator from the CAPE ratio that enables us to perform valuation comparisons across sectors. In addition to establishing the prediction of subsequent return differences based on differences in the CAPE-based valuation indicator, we also suggest a hypothetical, historical, and simple value investment strategy that rotates between the three sectors based on the valuation signals derived from the CAPE-based indicator, generating slightly more than 1:09% annualized, inflation-adjusted excess total return over the market benchmark during a period of nearly 110 years.","Label":"0"},{"DOI":"10.2139/ssrn.3001629","Abstract":"The asset pricing behavior around Rate Decision of The Central Bank is both an important and interesting Economic phenomenon. Predicting the direction and level of asset prices are important activities in the real world practice for investors. In this paper, I applied the Linear, Non-linear and Time Series methods to estimate the short term price change of several financial markets after the rate decision of FOMC in U.S. Fed by examine the data from 1990 to 2013. Our finding is that part of the asset pricing behavior is predictable conditional on the information set of rate decision. The unexpected part of hiking and cutting of benchmark overnight interest rate have significant influence on some asset classes. In the linear estimation parts, I found that the 1 basis point unexpected cut of the Fed Fund rate by the Fed Reserve in U.S. will drive 11 ticks rise of gold prices with significant level of 0.01. In the non-linear estimation parts, if the Fed Reserve cut its interest rate unexpectedly by 125 basis points, the probability that the Japanese Yen rises will be about 0.91, gold price rises will be about 0.80, the HangSeng Index rises will be 1.00, and the TSE rises will be about 0.98. My results are consistent with the hypothesis of rational behavior of economic agents in financial market and the related theory such as UIP(Uncovered Interest Rate Parity), Gold price as a prediction of inflation and international transmission of monetary policy through equity market.","Label":"0"},{"DOI":"10.1016/j.eswa.2023.120180","Abstract":"Despite the turmoil in the global financial sector over the years, Asian banking stood still with many positive characteristics - stable, balanced competition, good governance, and profitable – becoming a fertile ground for performance studies. This paper departs from previous banking performance studies in Asia by proposing a novel stochastic Multi-Criteria Decision-Making (MCDM) based on sign decomposition, offering a novel perspective in five analytical fronts. First, criteria decorrelation and filtering from country and time impacts as an initial data treatment. Second, endogenous computation of bank criteria importance for the alternatives comprised by each bank and year under analysis, in a “one-stop-shop” approach. Third, derivation of partial performance scores for each criterion under each alternative, besides traditional overall performance scores for each alternative. Fourth, mapping the exogenous/endogenous relationships among bank filtered criteria from country and year impacts using transfer entropy. Fifth, prediction of the overall performance drivers in terms of country-related contextual variables using neural networks. Our findings indicate that bank liquidity, bank capitalization, net income as well as the ability to generate profit for the shareholders are significantly related to bank performance. In addition, we find that accounting standards have a significant impact on bank performance. Although inflation is found to be positively related to bank performance, the results show that bank performance is helpful to promote people’s economic standard and life expectancy. Our study provides important implications to macroeconomic management to balance the development of macroeconomic development and bank performance.","Label":"1"},{"DOI":"10.5750/jpm.v16i1.1863","Abstract":"This paper aims at determining the various economic and non-economic factors that can influence the voting behaviour in the forthcoming United States Presidential Election using Lasso regression, a Machine learning algorithm. Even though contemporary discussions on the subject of the United States Presidential Election suggest that the level of unemployment in the economy will be a significant factor in determining the result of the election, in our study, it has been found that the rate of unemployment will not be the only significant factor in forecasting the election. However, various other economic factors such as the inflation rate, rate of economic growth, and exchange rates will not have a significant influence on the election result. The June Gallup Rating, is not the only significant factor for determining the result of the forthcoming presidential election. In addition to the June Gallup Rating, various other non-economic factors such as the performance of the contesting political parties in the midterm elections, Campaign spending by the contesting parties and scandals of the Incumbent President will also play a significant role in determining the result of the forthcoming United States Presidential Election. The paper explores the influence of all the aforementioned economic and non-economic factors on the voting behaviour of the voters in the forthcoming United States Presidential Election.   The proposed Lasso Regression model forecasts that the vote share for the incumbent Republican Party to be 41.63% in the 2020 US presidential election. This means that the incumbent party is most likely to lose the upcoming election.","Label":"1"},{"DOI":"10.5750/jpm.v6i2.503","Abstract":"This paper investigates the factors responsible for predicting 2012 U.S. Presidential election. Though contemporary discussions on Presidential election mention that unemployment rate will be a deciding factor in this election, it is found that unemployment rate is not significant for predicting the forthcoming Presidential election. Except GDP growth rate, various other economic factors like interest rate, inflation, public debt, change in oil and gold prices, budget deficit/surplus and exchange rate are also not significant for predicting the U.S. Presidential election outcome. Lewis-Beck and Rice (1982) proposed Gallup rating, obtained in June of the election year, as a significant indicator for forecasting the Presidential election. However, the present study finds that even though there exists a relationship between June Gallup rating and incumbent vote share in the Presidential election, the Gallup rating cannot be used as the sole indicator of the Presidential elections. Various other non-economic factors like scandals linked to the incumbent President and the performance of the two parties in the midterm elections are found to be significant. We study the influence of the above economic and non-economic variables on voting behavior in U.S. Presidential elections and develop a suitable regression model for predicting the 2012 U.S. Presidential election. The emergence of new non-economic factors reflects the changing dynamics of U.S. Presidential election outcomes. The proposed model forecasts that the Democrat candidate Mr. Barack Obama is likely to get a vote percentage between 51.818 % - 54.239 %, with 95% confidence interval.","Label":"0"},{"DOI":"10.1108/sajbs-10-2015-0070","Abstract":"Purpose                     The purpose of this paper is to investigate the macroeconomic determinants of foreign direct investment (FDI) for the top five South Asian economies, namely, Bangladesh, India, Pakistan, Sri Lanka, and Nepal, and to examine whether these factors are the same for each.                                                           Design/methodology/approach                     This study employs fully modified ordinary least squares and two-stage least squares estimation methods.                                                           Findings                     This study shows that South Asian economies have a number of FDI determinants in common. For example, market size and human capital are the two most common factors attracting FDI in each country (except for Nepal, which revealed a negative correlation between FDI and market size). Other factors, such as infrastructure, domestic investment, lending rates, exchange rates, inflation, financial stability/crisis, and stock turnover entered into regression with both positive and negative signs, thereby indicating that the underlying theories on FDI do not provide a clear prediction of the direction of the effect of a particular variable on FDI.                                                           Research limitations/implications                     This paper studied the effects of demand-side factors on FDI. A comparative study of the supply-side factors may add further knowledge.                                                           Practical implications                     This paper provides evidence to show that the determinants of FDI are indeed country-specific. Thus, to design a suitable FDI policy, it would not be wise to solely rely on other economies’ FDI experiences.                                                           Originality/value                     This paper provides updated evidence on factors that are essential to promoting or deterring FDI in South Asian economies.","Label":"0"},{"DOI":"10.47611/jsrhs.v11i3.3630","Abstract":"Rising immigration has led to a larger proportion of foreign players in each league. This paper aims to explore the relationship between rising immigration and average transfer fees. This paper also studies the impact of the Bosman Ruling in 1996 on the football transfer market. The variables are studied pre and post the ruling. In order to build the economic model, data of all teams from the English Premier League for the past 28 years is collected. The variables for which data are collected include the Relative Average Transfer Price (inclusive of inflation), Relative Broadcast Revenues earnt per club, and the league coefficient of the English Premier League. A multivariable linear regression is performed on these data with the Relative Average Transfer Price as the response variable and other variables as explanatory variables.Further, dummy variables are created for each team and each year to account for unaccounted changes. After analyzing the regression, the model is found to be relatively strong in its prediction power with an adjusted R Squared of 0.642 and a standard error of the regression of 21.528. The model’s results suggest that broadcast revenues and immigration numbers have the greatest impact on transfer fees, while the league coefficient is not as important as the general public’s view of it. However, it is seen that before the ruling it was the league coefficient that had a major impact on transfer fees. After the ruling in 1996, broadcast revenues and number of immigrants took precedence.","Label":"0"},{"DOI":"10.37391/ijeer.100215","Abstract":"People who want to buy a new home tend to save more on their budgets and market strategies. The current system includes real estate calculations without the necessary forecasts for future market trends and inflation. The housing market is one of the most competitive in terms of pricing and the same has varied greatly in terms of many factors. Asset pricing is an important factor in decision- making for both buyers and investors in supporting budget allocation, acquisition strategies and deciding on the best plans as a result, it is one of the most important areas in which machine learning ideas can be used to maximize and accurately anticipate prices. As a result, in this paper, we present the different significant factors that we employ to accurately anticipate property values. To reduce residual errors, we can utilize regression models with a range of characteristics. Some engineering aspects are required when employing features in the regression model for improved prediction. To improve model fit, a set of multi-regression elements or a polynomial regression (with a set of varying strengths in the elements) is frequently utilized. In these models, it is expected to be significantly affected by the slope of the spine used to reduce it. Therefore, it directs the best use of regression models over other strategies to maximize the effect. This paper's goal is to predict free hold prices for free hold consumers based on their budgets and goals. Prospective prices can be forecast by evaluating past market trends and price levels, as well as future developments.","Label":"1"},{"DOI":"10.1002/jae.2906","Abstract":"In many forecast evaluation applications, standard tests as well as tests allowing for time‐variation in relative forecast ability build on heteroskedasticity‐and‐autocorrelation consistent (HAC) covariance estimators. Yet, the finite‐sample performance of these asymptotics is often poor. “Fixed‐ b$$ b $$” asymptotics, used to account for long‐run variance estimation, improve finite‐sample performance under homoskedasticity, but lose asymptotic pivotality under time‐varying volatility. Moreover, loss of pivotality due to time‐varying volatility is found in the standard HAC framework in certain cases as well. We prove a wild bootstrap implementation to restore asymptotically pivotal inference for the above and new CUSUM‐ and Cramér‐von Mises‐based tests in a fairly general setup, allowing for estimation uncertainty from either a rolling window or a recursive approach when fixed‐ b$$ b $$ asymptotics are adopted to achieve good finite‐sample performance. We then investigate the (time‐varying) performance of professional forecasters relative to naive no‐change and model‐based predictions in real‐time. We exploit the Survey of Professional Forecasters (SPF) database and analyze nowcasts and forecasts at different horizons for output and inflation. We find that not accounting for time‐varying volatility seriously affects outcomes of tests for equal forecast ability: wild bootstrap inference typically yields convincing evidence for advantages of the SPF, while tests using non‐robust critical values provide remarkably less. Moreover, we find significant evidence for time‐variation of relative forecast ability, the advantages of the SPF weakening considerably after the “Great Moderation.”","Label":"0"},{"DOI":"10.20525/ijrbs.v11i1.1561","Abstract":"Beginning in the mid-1970s, financial distress in local governments became big news when New York City nearly collapsed due to the energy crisis and high inflation. When local governments experience financial distress, the responsibility to provide services to the community both now and in the future cannot be fulfilled. Local governments can only maintain services to the community if they are able to avoid financial distress. If the financial distress condition is maintained, there will be a stagnation in the level of community welfare which will have an impact on regional economic growth because it is not supported by adequate public services. Some local governments like Pennsylvania, have implemented a measure to indicate financial distress as stipulated in the 1987 Financially Distressed City Act (UU 47). However, the local government in Indonesia does not yet have an absolute measure for this financial distress condition. For this reason, financial distress in this study will use a relative measure indicated by the probability value measured using a defined approach. The results of the study provide an overview of how the relevant values in local government financial statements are able to predict financial distress in local governments. The findings show that the variables intergovernmental revenue (IGR), financial independence (FIND), employee expenditure (EMPEX), capital expenditure (CAPEX), and operating position (OPPOS) have a significant effect and can be used as an alternative predictor of financial distress with more comprehensive suitability with the financial characteristics of local government in East Java Province.","Label":"0"},{"DOI":"10.30585/jrems.v3i2.579","Abstract":"Imposing sanctions can have several malicious effects on a developed or developing economy and Iran is not an exception to this matter. The main purpose of this paper is to determine whether imposing oil sanctions have a significant impact on oil, gas and petroleum companies’ capital structure or not. Furthermore, a comparison between oil industry and cement industry and a prediction of oil companies’ capital structure trend are conducted. The most innovative aspect of our study is to evaluate the influence of sanctions on a firm-specific variable rather than macroeconomic level. To address this problem, we investigate oil and cement companies listed in Tehran Stock Exchange from 2006 to 2018. The leverage ratio indicating capital structure, sanction dummy variable and ROA, tangibility of assets, capital market return, economic growth and inflation rate are dependent variable, independent variable and control variables, respectively. The data are obtained from companies’ financial statements and we use OLS regression to estimate our equations. The results indicate that the 2012 oil sanctions against Iran affect the oil companies’ leverage ratio negatively and the future trend reveals that the share of equity in capital structure will increase. Moreover, we inspect no significant relationship between oil sanctions and cement companies’ capital structure. Therefore, government policymakers should plan strategies to lift or limit the oil sanctions and oil corporate managers should find some reasonable routes for balancing their companies’ capital structure to exploit debt financing benefits.","Label":"0"},{"DOI":"10.1080/23322039.2021.1999058","Abstract":"Most studies for the monetary policy effect on stock markets have concentrated on using the primary index to proxy the stock market. The present paper, avoiding “aggregation bias”, seeks to unbundle the effect of monetary policy on the stock market in two ways. First, the non-linear model is used. Second, sector-level monetary policy variable association and strength is known. Nonlinear Auto-Regressive Distributed Lag method (NARDL) has been used to separate the effect of monetary policy implications. The positive and negative separation of monetary policy variables shows meaningful information relating to each sector. Furthermore, the NARDL model provides the Error Correction equation for future prediction of the sector performance. The Error Correction Term (ECT) is significant for all the sectors, besides Information Technology. While ECT is highest for the Power sector, the lowest is reported for the Metal sector. Inflation increase has substantially more effect on sectors then its decrease. For short-run, real exchange rate positive (REER_POS (−2)), with a lag of 2 months, is effective for all the sectors. The health care sector stands out in its sensitivity to monetary policy variables. The asymmetric response of the Sector equity markets to monetary policy variables throws new insight for the policymakers, business managers, and fund managers. The nonlinearity can be helpful for business managers to relate revenue and valuation to monetary policy. Likewise, the portfolio fund managers can prepare for the expected changes in the economy to reallocate and rebalance their portfolios.","Label":"0"},{"DOI":"10.1002/nha.20017","Abstract":"The purpose of this study was to explore opportunity costs of postsecondary education in the U.S. in the past three decades (1975‐2005), as a measure to support investment decisions at national levels and as experienced by individuals deciding on pursuing further education. Based on human capital theory and inspired by a set of studies aiming at investment decisions in education, official data from the U.S. Census (i.e., CPS), along with parameters for high education achievement, were fed into a forecasting model developed for this purpose. The model included parameters for degree completion rate, time for completion, expectation of working years, retirement age, inflation and interest rates for time value of money adjustments focusing on marginal annual income flows. Seven research hypotheses were tested under this ex post facto design employing elements of both descriptive and causal‐comparative research methods. The primary finding is that the postsecondary education opportunity costs for both males and females have been increasing in the analyzed period, along with a significant correlation with enrollment rates. When considering opportunity costs of bachelor's degrees across gender, the trend is somewhat steady. However, in the case of advanced degrees, there appears to be an increase in the absolute gap based on gender in the second half of the analyzed period. Beyond descriptive statistics, trends, and prediction models of opportunity costs for bachelor's or advanced degrees, findings on college premiums and gender differences are discussed in light of the National HRD framework.","Label":"0"},{"DOI":"10.54691/bcpbm.v23i.1332","Abstract":"In order to explore the influencing factors of stock excess return and provide a particular reference for predicting the development of stocks in the country, I comprehensively refer to relevant economic theories and academic research and use the 2018 and 2019 CSI 300 index data provided by the wind to establish an econometric model. Moreover, carry out inspection and evaluation. I choose the logarithm (R) of the stock excess return as the explained variable, and the risk coefficient, market capitalization, book-to-market value ratio, turnover rate, etc., as the explanatory variables for regression analysis. According to the support of economic theory and the observation of the scatter plot trend, I removed the two explanatory variables of price-earnings ratio and net profit. In order to reduce the influence of outliers on model parameter estimation, I use the SPSS case diagnosis function to remove outliers. I performed a least-squares estimation of the initial model and performed t-tests and F-tests for the parameters and the overall equation for the remaining data. The variance inflation factor shows that the model has a multicollinearity problem, which I remedy by removing the year*ln_ME term. The model did not pass White's heteroskedasticity test. I used Eviews to perform White's heteroscedasticity correction on the model to correct the model standard error and reduce the degree of heteroskedasticity. After remediation, I used the RESET test on the model again, and although the F value increased slightly, it was still in the receptive field, so the model remediation did not make the model setting severe problems. The Jacques Bella test is shown that the model residuals do not completely obey the normal distribution, but due to the relatively large sample size, the model residuals can be approximated by a normal distribution according to the central limit theorem. In addition, I also obtain numerical prediction results through point prediction, and the scatter plot shows a high degree of interval overlap. Finally, I summarize the form presented by the final model and return to the practical significance, which proposes a reference standard for evaluating excess return from the market environment and company size, and further affirm the economic significance of excess return as a diversified evaluation of stock quality.","Label":"0"},{"DOI":"10.2118/11315-pa","Abstract":"Summary Forecasts of prices-including oil, natural gas, equipment and drilling costs, and money-affect thee valuation of all projects. The adoption of detailed forecasting procedures in the 1970's was intended to improve project evaluations in the pre-OPEC years. The practice of changing price forecasts every few months as the result of continuing price instability is costly and defeats the advantages of the forecasting process in improving project evaluation. Past price forecasts of oil, inflation, drilling, and cost of capital have been collected from public and private sources. The accuracy of forecasts since 1976are compared with actual prices. The causes of the errors are identified, and the implications for forecasting in the 1980's assessed. The costs associated with the time of professional staffs involved in changing or redoing valuations are also estimated.   Introduction The ingredient necessary for sound project evaluation prior to the OPEC cartel was accurate assessment of reserves and drilling and completion costs. This comparatively simple approach was successful because of stability of prices oil, natural gas, drilling costs, completion costs, and the price of money. Price stability was lost in the 1970's when general economic inflation combined with OPEC activities made paces more unstable and therefore more important in project evaluation. The result was the development of detailed forecasting models that attempted to provide reasonable estimates of future prices. Accurate estimates of future prices areas important, if not more important, today than reservoir analysis in producing sound evaluation of projects. The original intent of the forecasting effort wasthe development of various price profiles. The price predictions, it was hoped, would reflect long-run, secular changes. The price forecasts were not expected to coincide exactly with the prices that would eventually result, nor should it ever be expected. The gap between predicted and actual price forecasts should be as small as possible, but this is not always feasible. Oil price forecasts in the 1970's were made more difficult, for instance, because of the new and old oil categories in the U.S. that were used in addition to OPEC categories. Other examples include the early failures in estimating completion and drilling prices. Tying drilling and completion prices only to general inflation ignores the supply/demand conditions in the oil patch, which differ significantly from the general economy. Linking oil prices to general prices becomes even worse when one realizes that inflation forecasts are typically less accurate than most reserve estimates. Forecasts were initially developed at the corporate level and remained constant for the entire year. The stability in the forecasts was essential for comparison of alternative projects. It also minimized the effort of the engineers performing the evaluations, allowing them to concentrate on the engineering variables that they could control. In the late 1970's the situation changed dramatically. The oil crisis during 1979–80, along with phased decontrol of U.S. oil, produced changes in prices that shattered the forecasts in place at that time. Forecasts have changed consistently within most companies since then, first, by increasing significantly to reflect recent changes in prices and incorporating faster growth rates, and second, by dropping by as much as 100% to capture the depression-like conditions in the oil patch. The shift from extreme optimism to the current depression state occurred with a lot of changes in between. Price forecasts changed monthly-more often in some cases. The consequences of price changes designed to be representative of current price conditions have minimized, in some cases, the benefits of the more detailed forecasting effort. First, the principle that forecasts used in project evaluation are long-run, secular values that will by necessity contain errors has been rejected. Second, changing prices constantly has generated a feeling that good engineering analysis is not very important to project evaluation. \"Pricesdominate engineering variables\" has become a prevalent opinion; therefore, many engineers have said: \"Why should we worry about doing a good engineering job?\" Third, and perhaps most important, the constant revision of prices has imposed a significant cost on the companies. These costs are indirect and difficult to measure, but are nevertheless a major drain on company resources. The fundamental issue is whether the benefits of changing secular forecasts to match short-run price conditions exceed the costs of constantly rerunning evaluations already approved and the opportunities lost because of the time spent on revising existing projects. Discussion of these points identifies the strengths of current forecasting procedures that must be retained in the 1980's. The current deficiencies or weaknesses of the application of price forecasting to project evaluation must be acknowledged and corrected if the industry is to avoid the situation in which it currently finds itself. JPT P. 817^","Label":"0"},{"DOI":"10.1108/ijhma-04-2014-0010","Abstract":"Purpose – This paper aims to investigate Lithuanian house price changes. Its twin motivations are the importance of information on future house price movements to sector stakeholders and the limited number of related Lithuanian property market studies.   Design/methodology/approach – The study employs ARIMA modelling approach. It assesses whether past is a good predictor of the future. It then examines issues relating to an application of this univariate time-series modelling technique in a forecasting context.   Findings – As the results of the study suggest, ARIMA is a useful technique to assess broad market price changes. Government and central bank can use ARIMA modelling approach to forecast national house price inflation. Developers can employ this methodology to drive successful house-building programme. Investor can incorporate forecasts from ARIMA models into investment strategy for timing purposes.   Research limitations/implications – Certainly, there are number of limitations attached to this particular modelling approach. Firm predictions about house price movements are also a challenge, as well as more research needs to be done in establishing a dynamic interrelationship between macro variables and the Lithuanian housing market.   Originality/value – Although the research focused on Lithuania, the findings extend to global housing market. ARIMA house price modelling provides insights for a spectrum of stakeholders. The use of this modelling approach can be employed to improve monetary policy oversight, facilitate planning for infrastructure or social housing as a countercyclical policy and mitigate risk for investors. What is more, a greater appreciation of Lithuania housing market can act as a bellwether for real estate markets in other trade-exposed small country economies.","Label":"0"},{"DOI":"10.1007/s00181-021-02039-x","Abstract":"Our study uses the grey relational analysis (GRA) and artificial neural network (ANN) models for the prediction of consumer exchange-traded funds (ETFs). We apply eight variables, including the put/call ratio, the EUR/USD exchange rate, the volatility index, the Commodity Research Bureau Index (CRB), the short-term trading index, the New York Stock Exchange Composite Index, inflation, and the interest rate. The GRA model results showed that the NYSE, CRB, EUR/USD, and PCR were the four main variables influencing consumer ETFs. The GRA test results of all the ANN models' data showed that the back propagation neural network (BPN) was the best predictive model. Based on the classification of different percentages of training data, the results of GRA revealed that the radial basis function neural network and the time-delay recurrent neural network exhibited consistent results, compared to BPN and the recurrent neural network. The results also pointed out that different percentages of training data were suitable for predicting consumer ETFs' performance based on high and low grey relationship grade variables. Evidence has shown that the ETFs in Brazil and China are more predictable than those in other countries. All ANN models' results indicated that the use of 10% testing data could predict consumer ETFs better, particularly the ETFs of the United States (US) and those excluding the United States (EX-US). The Diebold–Mariano (DM) test results suggest that the best predictability model for consumer ETFs is BPN, which is significantly superior to other models.","Label":"1"},{"DOI":"10.1080/01603477.2016.1145061","Abstract":"The paper proposes a post Keynesian framework to explain Tobin’s q behavior in the long run. The theoretical basis is informed by the Cambridge corporate model originally proposed by Kaldor (1966), which is reinterpreted here as a theory for q. The core of the “Kaldorian q theory” is a negative long-run relation between q and growth rates, a negative relation between q and propensities to consume, and the fact that q can be different from 1 in the long-run equilibrium. We generalize this model through a medium-scale stock-flow consistent (SFC) model, which introduces important post Keynesian aspects missing in the Kaldorian model, such as endogenous money, a financial system, and inflation. We extend the model to include a more realistic treatment of firms’ financial structure decisions and allow the interdependence between these decisions and dividend policy. Numerical simulations confirm that the original Kaldorian relations between q and growth rates and propensities to consume hold, but unlike the original model, in our model, q is not independent of how firms finance their investment. We also confirm the possibility of q being different from 1 in the long run. Finally, we contrast this “post Keynesian q theory” with the Miller–Modigliani dividend irrelevance proposition and the neoclassical investment and financial theory. It is shown that its validity depends crucially on the value taken by q: for q values different from 1 the proposition will not hold and dividend policy will be relevant for equity valuation. Therefore, post Keynesian q theory stands against the main predictions of mainstream finance and constitutes an alternative for developing a macroeconomic theory for equity markets.","Label":"0"},{"DOI":"10.1108/ijhma-01-2023-0015","Abstract":"Purpose Housing market research involves observing the relationships between housing value and its indicators. However, recent literature indicates that the disruption of the COVID-19 pandemic could have an impact on the forecasting properties of some of the housing indicators. This paper aims to observe the relationships between the home value index and three potential indicators to verify their forecasting properties pre- and post-COVID-19 and provide general recommendations for time series research post-pandemic.   Design/methodology/approach This study features three vector autoregression (VAR) models constructed using the home value index of the USA, together with three indicators that are of interest according to recent literature: the national unemployment rate, private residential construction spending (PRCS) and the housing consumer price index (HCPI).   Findings Unemployment, one of the prevalent indicators for housing values, was compromised as a result of the COVID-19 pandemic, and a new indicator for housing value in the USA, PRCS, whose relationship with housing value is robust even during the COVID-19 pandemic and HCPI is a more significant indicator for housing value than the prevalently cited All-Item consumer price index (CPI).   Originality/value The study adds residential construction spending into the pool of housing indicators, proves that the finding of region-specific study indicating the unbounding of housing prices from unemployment is applicable to the aggregate housing market in the USA, and improves upon such widely accepted belief that overall inflation is a key indicator for housing prices and proves that the CPI for housing is a vastly more significant indicator.","Label":"0"},{"DOI":"10.1108/s0277-2833(2011)000022b007","Abstract":"Purpose – East European ex-communist countries have now experienced nearly two decades of turbulent economic conditions and challenges resulting from the market transition. Since the early 1990s, there has been considerable decline in unionization throughout the region. This study uses information on union membership provided by four waves of the World Values Survey (WVS) to explain trends in unionization in East European ex-communist countries from 1990 to 2006. Methodology/approach – We use random-effects and fixed-effects models to test predictions for three sets of explanations for cross-national and historical variation in unionization: industrialization, globalization, and institutions. Findings – We find a degree of support for all three explanations of union decline. Overall, our analyses reveal the strongest support for industrialization and business cycle explanations. Inflation, unemployment, and urban population growth are all significant factors in shaping patterns of unionization in ex-communist East Europe. Our analyses show that aspects of economic and financial globalization have had significant, negative effects on unionization in the region. Manufacturing imports and foreign direct investment inflows appear to have undermined the position of domestic labor and contributed to declines in union membership. Originality/value of the chapter – Successor and newly independent unions face the twin challenges of gaining public confidence as representatives of workers' interests, and withstanding increasing market pressures and conditions unfavorable for unionization. We provide evidence that without strong institutions to serve as buffers to external economic conditions, unionization levels in East European ex-communist countries are more open to market forces.","Label":"0"},{"DOI":"10.4324/9781003225539","Abstract":"The Role of Crises in Shaping Financial Systems: From the Global Financial Crisis to COVID-19 underscores the role of crises as turning points for the financial sector and its interactions with the real economy. It sheds new light on the financial industry through the lens of three recent crises – the global financial crisis, the sovereign debt crisis, and the COVID-19 pandemic. The book provides in-depth insight into the financial systems in European Economic Area countries, accentuating the role of crises in shaping the condition and development of the financial arena. The authors pay special attention to the differences between “old” and “new” Europe, i.e. countries that joined the EU in 2004 or later. It explores the implications of recent turbulences for financial institutions, financial markets, and public finance, and their relationship with the economy. The book examines low or negative interest rates, non-standard monetary policy, fiscal stimulus, dense safety nets, regulatory inflation, weak profitability of the financial sector, and the sovereign-bank nexus. Post-crisis developments are assessed, comprehensively and empirically, from both macro- and microeconomic perspectives to help readers understand the nature of policy measures and their socio-economic implications. The authors outline their predictions for the future of financial systems, focusing on the structural changes and legacy of the COVID-19 crisis and global financial interlinkages. The book adopts both theoretical and practical approaches to explore the key issues and, as such, will appeal to academics and students of financial economics and international finance, as well as policymakers and financial regulators.","Label":"0"},{"DOI":"10.31108/7.2022.15","Abstract":"Ukraine has felt the impact of strong force, which has affected the level of happiness in the country. The circumstances were military actions which was provoked by the aggression of the Russian Federation. A whole generation of people knew about the war only from historical sources and had no previous experience of survival. During the war, basic physiological needs became a priority for the civilian population of Ukraine: security, water, food, heat, sleep, medicine. All other needs of a higher order have ceased, or become to be inconsiderable. The war did not make people happy, but it changed their behavior, which was due to the need to make important current and future decisions. Current decisions focused on survival, while long-term decisions focused on choosing one of the alternative life options, taking into account its expected quality and subjective prediction of personal happiness and happiness of their children. All this has led to a number of transformations in the socio-economic sphere, such as: falling incomes and rising household expenditures; change in the structure of consumption; shortage of certain foods and medicines; the impact of inflation; intensification of migration processes; demographic disparities and family separation; reduction of human resources; reduction of life expectancy and deterioration of health of Ukrainians; limited transport and logistics within the country; termination of a significant part of enterprises and small businesses; heavy load on social infrastructure facilities; increasing the number of individuals and families in difficult life circumstances, etc. According to the Phoenix Effect, life is expected to recover very quickly after the war. Ukrainians, having gone through numerous trials, will become much more resilient and happier in the future. Key words: Ukraine, russia, war, happiness, sconomy, Society, future","Label":"0"},{"DOI":"10.1007/s11146-020-09788-z","Abstract":"Housing is central to the broader economy, as highlighted by the Great Recession of 2007–2009, yet few reliable long-run series exist for sale and rental prices of housing. Using hedonic methods, frequency conversion techniques, and a detailed dataset of over one million sale and rental listings from newspapers and online, we construct new indices of sale and rental prices from 1945 for Dublin, Ireland as a whole and for six sub-markets within the city. Sale prices rose by an average of 8.4% per year between 1945 and 2018, compared to an increase in general consumer prices of 5%. Market rents are estimated to have increase by 6.3% per year, well above prior estimates (4.4%), a finding with implications for accurately measuring living costs and living standards in Ireland since World War II. There is some evidence of rents converging across markets within the city but sale prices have diverged over the same period. Adjusting for inflation, there have been four major housing market cycles since 1945, with peaks in the late 1940s, the early 1970s, the early 1980s and the mid-2000s. The presence of both sale and rental information allows the calculation of the ratio of sale to rental prices for housing, the housing price ratio, a fundamental barometer of housing market health. We identify three phases in the gross yield on Irish housing since 1945, with downward shifts in the yield in the early 1970s and mid-1990s. An error-correction econometric analysis confirms the predictions of economic theory, that credit conditions in the credit market and user cost drive changes in the yield over time.","Label":"0"},{"DOI":"10.1016/j.rie.2016.03.002","Abstract":"We consider tests of equal population forecasting ability when mean squared prediction error is the metric for forecasting ability, the two competing models are nested, and the iterated method is used to obtain multistep forecasts. We use Monte Carlo simulations to explore the size and power of the MSPE-adjusted test of Clark and West (2006, 2007) (CW) and the Diebold–Mariano–West (DMW) test. The empirical size of the CW test is almost always tolerable: across a set of 252 simulation results that span 5 DGPs, 9 horizons, and various sample sizes, the median size of nominal 10% tests is 8.8%. The comparable figure for the DMW test, which is generally undersized, is 2.2%. An exception for DMW occurs for long horizon forecasts and processes that quickly revert to the mean, in which case CW and DMW perform comparably. We argue that this is to be expected, because at long horizons the two competing models are both forecasting the process to have reverted to its mean. An exception for CW occurs with a nonlinear DGP, in which CW is usually oversized. CW has greater power and greater size adjusted power than does DMW in virtually all DGPs, horizons and sample sizes. For both CW and DMW, power tends to fall with the horizon, reflecting the fact that forecasts from the two competing models both converge towards the mean as the horizon grows. Consistent with these results, in an empirical exercise comparing models for inflation, CW yields many more rejections of equal forecasting ability than does DMW, with most of the rejections occurring at short horizons.","Label":"0"},{"DOI":"10.1201/9781351241892-89","Abstract":"This research is to find the relationship between USD/IDR Exchange Rate volatility and four macroeconomic factors (Interest Rates, Borrowing, Treasury Bill and Money Supply). The data are taken form Indonesian Reserve Bank period July 2005 until October 2015. The first testing are stationary testing with Augmented Dickey-Fuller (ADF) to test a stationarity nature of data. Furthermore, An initialisation equation is testing with Johansen testing to test his cointegrating properties. Stationary at level stage and Cointegration are absolute requirement for a equation could be formed with VECM method. From this model it can find correlation between Exchange Rate and Trasury Bill. That VECM equation can be used to do simulation that shown an impact of the macroeconomic on Exchange Rate at economic shock condition using the Impulse Response test. This chapter discusses the relationship between USD/IDR Exchange Rate volatility and four macroeconomic factors. The factors are interest rates, borrowing, treasury bill and money supply. The model of Exchange Rate prediction are divided into two parts: (1) Technical Analysis: an analysis based on historical data such as time series analysis or regression analysis; and (2) Fundamental Analysis: an analysis that connected between variable. Researchers, R. Ramasamy and S. K. Abar stated that the volatility of Exchange Rate is influenced by nine domestic macroeconomic: Interest Rate, Inflation, Balance of Payment, Employment Rate, Corruption Index, Gross Domestic Product, Deficit/ Surplus Rate, Tax Rate and Borrowing Rate. Exchange Rate it is self when associated with the risk factors above, would affect the Credit Risk, Liquidity Risk, Operational Risk, Country Risk and Behavior Risk. Stationary at level stage and Cointegration are absolute requirement for an equation could be formed with Vector Error Correction Model method.","Label":"0"},{"DOI":"10.1007/bf00583668","Abstract":"Summary and conclusionsWe have developed a simple macroeconometric model of Bangladesh economy in order to evaluate the Five Year Development Plan. Although the model contains only five behavioral equations and two identities because of restrictions imposed by the availability of data, the sample period ex-post predictions are nearly as good as those of large scale econometric models of the US economy (OBE and WHARTON-EFU models). The consistency of the Five Year Plan was tested by comparing the plan target for major economic aggregates with projections of the same aggregates based on econometric model. Four scenarios were developed for projections. They are:Rapid restoration of business confidence with imports unrestricted,Rapid restoration of business confidence with imports restricted,Gradual restoration of business confidence with imports unrestricted,Gradual restoration of business confidence with imports unrestricted.The final year (77/78) values of model projections for real GNP, real private investment and nominal taxes are generally in line with the plan targets, while the model projections of other aggregates varied widely depending upon the assumptions. In general, the plan targets are reasonably consistent with the model projections except for price level and nominal import targets. As for the import targets, it is clear that the Bangladesh government intended to restrict the growth of imports by the use of qualitative and quantitative control measures. What is surprising to us is that the inflationary effects of import restriction is so pronounced that a more cautious import policy and a more aggressive export policy seem to be a desirable alternative. It does not seem to be a right time to introduce import-substitution policy after such devastating exogenous shocks as the civil war and subsequent floods, which reduced the productive capacity and busines confidence tremendously.Another flaw in the Five Year Plan is revealed by the examination of dynamic paths of model projections. The charts 7–10 reveal that, towards the end of the planning period, the rate of growth of real GNP slows down considerably while the rate of inflation somewhat accelerates. The rate of inflation during the middle of the planning period is projected to be considerably lower than those at the begninning and end of the period. While it should be expected that after the recovery to a normal state of economy from the postwar uncertainty and instability, the rate of growth of real GNP will slow down, 2.9 percent growth in the final year is not enough to increase the per capita real GNP since the population growth rate of the final year of plan is expected (but not assured) to be 2.8 percent. Thus a more rapid capital accumulation program towards the end of the planning period seems to be called for.","Label":"0"},{"DOI":"10.47689/tsue2022-pp340-347","Abstract":"In the framework of the research, the main substance is provision of the fact that inflation is, undoubtedly, one of basic macroeconomic categories, which requires the use of rational and effective mechanisms to achieve quality economic growth along with increase in public wealth. Presented some views of economists on origin and specifics of inflation. The main purpose of this paper is to comprehend investigation of inflation as well as to determine what kind of factors influence on its current significant growth along with provision of analysis of trends of inflation for certain period.","Label":"0"},{"DOI":"10.2139/ssrn.1402909","Abstract":"Our objective has been to experiment with diverse economic indicators in order to help equip Ukrainian policymakers with a relatively simple tool, which could deliver warning signals about a possibility of upcoming economic problems and thereby assist the Government in designing policy instruments which would help prevent or soften a slowdown or recession. The project has undertaken the following tasks: • Based on an analysis of the pattern of growth of the Ukrainian economy since the end of the post-Soviet recession (the year 2000) we have formulated the hypotheses concerning the factors preceding/affecting the upturns and downturns (with a focus on the latter) of the country’s growth; • We have studied international \"best practice\" in early warning indicators in order to design a similar system for Ukraine; • We have selected the relevant indicators, consistent with our hypotheses and used a probit model in order to experiment with these indicators; • The final set of indicators used in the model included the following lagged independent variables: changes in the value of export, changes in real exchange rate of the hryvnya, producers' price index adjusted for domestic price inflation index and the IMF’s metal price index, bank credit interest rate, changes in the industrial output of the European Union; our dependent variable (which was used as a proxy for the overall economic growth) was changes in real industrial output; • The model was used to formulate a warning forecast for the Ukrainian economy for the second half of 2008 based on the data for the January 2000 - June 2008 period; all predictions for the second half of 2008 have delivered warning about a downturn of the Ukrainian economy; • We ran a few additional experiments with the model, and • We have recommended several further steps of analysis toward a full implementation and institutionalization of such a model in the near future.","Label":"0"},{"DOI":"10.33920/vne-04-2206-05","Abstract":"The article examines the theoretical foundations for the emergence of overdue debts on loans and forecasting financial risk in Russian banks in modern conditions. The relevance of the study is that the growth of bad debts of commercial banks on loans is currently one of the most acute problems. The collected material made it possible to analyze the dynamics of the volume of overdue debt on loans in commercial banks of the Russian Federation for the period 2013–2021. In the course of the study, it was revealed that many factors influence the volume of bad debts. In order to study the influence of factorial signs on the effective sign — the amount of overdue debt, an attempt was made to use such models as: correlation-regression, AI and VaR. A hypothesis has been put forward and proved that with the help of models: correlation-regression, AI and VaR, it is possible to obtain a forecast of the volume of overdue loans in the portfolio of commercial banks of the Russian Federation. The correlation-regression model, in addition to the resultant sign Y — the growth rate of overdue debt, included such factorial signs as: X1 — the growth rate of GDP per capita; X2 — the growth rate of the average per capita income of the population; X3 — the growth rate of foreign trade surplus; X4 — inflation index; X5 — growth rate of capital outflow; X6 — growth rate of cash; X7 — interest rate on loans; X8 — US dollar exchange rate; X9 — price of a barrel of oil URLS dollars; X10 — wage growth. The study showed that the use of various forecasting tools provides different amounts of arrears, for example, for 2022: the correlation-regression model — 7159.9 billion rubles, the neural network — 4466.251 billion rubles, and the VaR model 5426 .56 billion rubles overdue loans.","Label":"1"},{"DOI":"10.2139/ssrn.463226","Abstract":"Tort liability has undergone an enormous expansion in the past 40 years. So too has the effective hourly rate obtained by plaintiff lawyers which has increased well over 1000% in that time frame (adjusted for inflation). That the enormous increases in effective hourly rates parallel the enormous expansion in tort liability raises a number of issues. In this article, I examine one of them: whether the market for contingent fee-financing of tort litigation is price competitive. To do so, I examine certain indicia of a noncompetitive market including the fact of uniform pricing, the absence of economic justification for uniform pricing such as reductions in agency costs or transactional costs, inelasticity of the price in light of highly variable production costs and the absence of price advertising. I then examine factors which inhibit the emergence of a price competitive market including asymmetrical knowledge, the utility of uniform pricing in misleading consumers as to risk, and the signaling function of uniform pricing. I then examine the reasons for the persistence of uniform pricing in the face of the predictions of economists applying standard economic theory that some lawyers would undercut standard pricing thereby generating competitive behavior that would more closely align pricing with risk and the variable cost of producing the service. I attribute the persistence of uniform pricing to market failures and analyze the reasons for such failures. Finally, I examine the actions of the bar designed to prevent a competitive market from emerging. These actions include the maintenance of barriers to entry into the tort claiming market, prohibitions against the outright purchase of tort claims and adoption of rules of ethics effectively prohibiting price competition including prohibitions against providing financial assistance to clients and brokerage of lawyers' services for profit.","Label":"0"},{"DOI":"10.2139/ssrn.2656426","Abstract":"Since the 2008 great recession, it has been a very interesting time for macroeconomics. There has been a movement to revamp how economics is taught, challenging the ability of models and mathematical equations to map agents’ behaviour and the economy. This debate has inspired my interest on the applicability of economic theories. It is argued that oversimplification and generalization of assumptions make models too abstract and impractical, yet, at various points in time, models have been relatively successful in mapping out general movements in economies. As logical beings, we are constantly seeking coherence in daily occurrences and given all its drawbacks, economic models might still currently be the best solution to understanding reality. A core model of macroeconomics is the IS-PC-MR model (3EM), and having just spent a good portion of time learning the closed economy 3EM, I thought it was apt to examine if this model accurately reflects reality and its ability to analyse shocks of such magnitude. The paper will firstly set up the 3EM, following that, it will apply the model onto the UK closed economy over 2008. This is done by analysing the Bank of England (BoE) inflation report, drawing out relevant information specific to the UK domestic economy and applying it to the model. This paper uses those reports as they are a reliable source of information and they provide the necessary data for the analysis. I will be picking up key phrases from the BoE report overview in every period and use it to explain the intuition behind the movements of the curves in the analysis and map out developments in the economy. After that, I will compare and review the proximity between the model’s prediction and what actually happened, followed by drawing conclusions about the applicability of models.","Label":"0"},{"DOI":"10.2139/ssrn.563867","Abstract":"Analyzing scanner price data that cover 27 product categories over an eight-year period from a large Mid-western supermarket chain, we uncover a surprising regularity in the data - small price increases occur more frequently than small price decreases. We find that this asymmetry holds for price changes of up to about 10 cents, on average. The asymmetry disappears for larger price changes. We document this finding for the entire data set, as well as for individual product categories. Further, we find that the asymmetry holds even after excluding from the data the observations pertaining to inflationary periods, and after allowing for various lengths of lagged price adjustment. The findings are insensitive also to the measure of price level used to measure inflation (the PPI or the CPI). To explain these findings, we extend the implications of the literature on rational inattention to individual price dynamics. Specifically, we argue that p rocessing and reacting to price change information is a costly activity. An important implication of rational inattention is that consumers may rationally choose to ignore - and thus not to respond to - small price changes, creating a \"range of inattention\" along the demand curve. This range of consumer inattention, we argue, gives the retailers incentive for asymmetric price adjustment \"in the small.\" These incentives, however, disappear for large price changes, because large price changes are processed by consumers and therefore trigger their response. Thus, no asymmetry is observed \"in the large.\" An additional implication of rational inattention is that the extent of the asymmetry found \"in the small\" might vary over the business cycle: it might diminish during recessions and strengthen during expansions. We find that the data are indeed consistent with these predictions. An added contribution of the paper is that our theory may offer a possible explanation for the presence of small price changes, which has been a long-standing puzzle in the literature.","Label":"1"},{"DOI":"10.18288/1994-5124-2019-4-48-75","Abstract":"This section conducts an estimate of the impulse response function of key macroeconomic variables to monetary policy shocks in Russia. The estimates are carried out through a dynamic factor model (DFM) of the Russian economy with structural identification of shocks by imposing various sets of sign restrictions on the behavior of endogenous variables. We restricted first the monetary aggregate M2 only (a decrease in response to an increase of the Key rate), and then—simultaneously—M2, real effective exchange rate (an increase), and GDP (a decrease). We estimated the DFM using a large dataset of 58 macroeconomic and financial variables. The estimation results suggest that there is no decreasing response of consumer prices to an exogenous tightening of the interest rate policy of the Central Bank of Russia. This empirical evidence is supported implicitly by DFM-based predictions that under the imposition of such a decreasing response as an identifying restriction to the model, a positive interest rate shock is not transmitted through the interest rate channel of monetary policy to expected increases of the interest rates on commercial loans and private deposits. However, existing empirical evidence refutes this model-based result. Therefore, this study supports the view according to which a tightening of monetary policy in Russia is inefficient in terms of restraining inflation. In addition, monetary policy shocks negatively affect investments, retail sales, export and import, real wages, and employment. Different economic activities react differently to monetary policy shocks: export-oriented activities are not sensitive to these shocks, whereas domestic pro-cyclical activities (e.g. construction) can be substantially depressed in response to unexpected increases of interest rates. Finally, the expectations of economic agents are also significantly affected by shocks in the interest rate policy of the Bank of Russia.","Label":"0"},{"DOI":"10.2139/ssrn.2569290","Abstract":"We present a five-year revision of an empirical study started in 2007. Seven years ago, we found two three distinct periods characterized by sustainable linear trends in the difference between the headline consumer price index (CPI) and the core CPI in the USA. Then we revealed similar behavior in the differences between the CPI and indices of various consumer expenditure categories. We estimated the duration of these trends which varies in a wide range from 5 years to more than 20 years. The transition periods to new trends span shorter intervals of 2 to 5 years. The transition is characterized by a higher level of volatility in the studied CPI differences. In April 2009, we introduced a simple quantitative model representing the evolution of motor fuel price (a subcategory of the consumer price index of transportation) relative to the core CPI as a linear function of time. Under our framework, all price deviations from this linear trend are transient and the price must return to the sustainable trend. The model predicted that oil price would fall to $30-$60 per barrel in 2016, which is very close to the current price. The behavior of actual oil and motor fuel price since 2010 has shown that this prediction is accurate in both amplitude and trajectory shape – a good support for the credibility of our empirical mode. We conclude that the concept of price decomposition into a short-term (oscillating) and long-term (linear trend) components deserves a deeper theoretical consideration of the driving forces behind linear time trends and can be used as a workhorse for a wide spectrum of commodity investors. According to the model, the price of crude oil will be falling to the level of $30 per barrel during the next 6 years and motor fuel will follow up the oil price. Moreover, the periodicity of the related normalized difference indicates that this low-price level may extend into the second half of the 2020s. The secular fall in energy prices may induce a lengthy period of very low inflation.","Label":"0"},{"DOI":"10.18825/irem.67309","Abstract":"Artificial Neural Networks (ANN) is an analysis method that mimics the operating principle of the human brain. The problem-solving skills and the high rate of success in solving complex problems of ANN, relative to the other traditional methods has made it a preference as well in the fields of finance and economics. I used Feed-forward back-propagation ANN (BPN-ANN) similar to related studies to forecast the indices, and employed trial-and-error method for the parameters like number of layers and neurons at layers to reach the optimal ANN structure. Extant literature has used important macroeconomic variables like inflation, interest rates and money supply to shape the future expected value of the dependent variables of the index. This study is followed a new and unique perspective from established literature to make use of the advantages of ANN to forecast on Turkish stock market index. Further, the study used the daily data between 29th July and 15th November of 2015 for BIST 100, including codified economic calendar events and major parities, dollar index and indices as variables. Due to the expected technical superiority of the system as a result of the nature of the variables to be used, a higher forecast performance is expected, even with the occurrence of events outside the scope, like important political developments. The expected results of this study, other than being an immense contribution to literature will be developed into an important tool that can be utilized by investors. Among several models, 18-20-1 structured MLP has best explanatory level with 0.893 R2 and 0.207 MSE values. This was followed the 18-16-1 structured MLP which had the minimum MSE as 0.025 and 0.88 R2. These are models 1 and 2 respectively. It is also observed that ECE (Economic Calendar Events) and ‘Other’ variables have notable effects that explain on the fluctuation of the index. Similarly, the two variables have shown their significant in other models as well. Prediction of opening is more successful than closing. ECE has greater success forecasting open prices.","Label":"1"},{"DOI":"10.20525/ijfbs.v9i3.704","Abstract":"Abstract For risk and capital measurement, banks and other financial institutions need to meet forthcoming regulatory requirements. However, it is a serious issue to think that meeting regulatory requirements is the sole or even the most important reason for establishing a scientific, sound risk management system. To direct capital to activities with the best risk/reward ratios, managers need reliable risk measures. To stay within the limits imposed by readily available liquidity, by creditors, customers, and regulators, they need estimates of the size of potential losses. They need mechanisms to monitor positions and create incentives for prudent risk-taking by divisions and individuals. Risk measurement deals with the quantification of risk exposures, whereas risk management refers to the overall process by which managers satisfy these needs and follows to define a business strategy, to detect the risks to which are visible, quantifying those risks, and to control and understand the nature of the risks it faces. This research focuses on the economic vulnerability faced by banks in the financial sector in terms of the crises issues perspective of economic distress. Here, the methodology followed is based on the CAMELS framework variables. CAMELS is an abbreviation for: capital adequacy (C), asset (A), management (M), earnings (E), liquidity (L) and sensitivity to market risk (S). Based on these terminologies, a couple of variables should be selected, such as capital asset ratio, non-performing loan, cost income ratio, industry production index, non-interest income, reserve of gold, inflation, stock turnover ratio, real interest rate as component series and return on equity (RoE) as reference series to identify the turning points of economic vulnerability in the banking sector in Bangladesh. Thus, by forecasting the directional changes it could make policymakers aware of changes in the financial markets and banking economy and allow them to undertake preventive steps for remedial purposes. The constructed MPI should have a remarkable lead time of about not less than 6 months on average in case of prediction against the leading for reference Series.By mending the financial efficacy of investment banks. Bangladesh also should improve their corresponding banking system to implement these suggestions.","Label":"0"},{"DOI":"10.2202/1534-6005.1466","Abstract":"In recent decades there has been a worldwide shift toward market-oriented economic policies, sometimes termed 'neoliberalism’. In the policy arena this trend has been most apparent in the widespread move toward privatization and deregulation. And in the academic world there has been increased respect shown to free market ideologies, even to policy views that would once have been regarded as impractical. Surprisingly, monetary policy is one area that has been relatively unaffected by the neoliberal revolution. Not only have governments retained a monopoly on fiat money, but even some free market ideologues have been skeptical of proposals for laissez-faire monetary regimes. This paper will show that market forces can greatly improve the effectiveness of monetary policy. I will argue that the Federal Open Market Committee (FOMC) should do no more than set the goals of monetary policy. Sumner (1989, 1995) and Dowd (1994) argued that the creative use of prediction markets for goal variables might allow central banks to more accurately target variables such as inflation. I will briefly review the literature on policy futures markets, examine Bernanke and Woodford’s (1997) critique of policies that “target the forecast”, and then suggest some improvements in previous reform proposals. More importantly, I show that policy future markets can address some of the key weaknesses of orthodox macroeconomic theory and policy, particularly the lack of consensus over structural models. Under this sort of policy regime, open market operations would reflect the views of not merely 12 individuals, but rather the consensus opinion of all those who choose to engage in open market operations. Even an issue as basic as the optimal monetary instrument would no longer be determined by the monetary authority, instead, each individual participant in the policymaking process would choose their own policy indicator. I will also show that a universal FOMC can improve the effectiveness of monetary policy even if the average level of decision-making skills on the expanded FOMC is inferior to the average skill level of the current 12 members.","Label":"0"},{"DOI":"10.2118/161831-ms","Abstract":"Abstract Since the early days of the petroleum industry, prediction of oil prices has been a real challenge. The puzzling question we need to answer when evaluating project's NCF is: how much is the price of a barrel during the life-span of the project? Accordingly, oil price modeling became a vital tool to predict both short- term and long-term prices. Unfortunately, there are many uncertainties associated with the available models and none of them can predict oil prices with acceptable accuracy. Only limited controlling parameters are captured by these models. These parameters are basic and derived from simple assumptions of supply and demand dependency. Nowadays, the need for a reliable oil price model became more critical as a change of oil price is experiencing dramatic fluctuations that affect economic decision parameters a great deal. This paper presents an oil-price model to project the price behavior in the next 20 years. Different scenarios were examined out of which \"Economic-Scenario\" was found to be the best suitable predictor. This model takes into account multiple effects of fourteen parameters that are believed to have the highest impacts on oil price. These factors have been further classified into key categories such as supply, demand, reserve and externalities (political/environmental/social) which is regionally based. Other parameters such as population growth and technology are embedded within these key factors. According to this model, oil price has been found to have strong reliance on the US Dollar and inflation, which has been incorporate into the model to ensure a more reliable outcome. Market behavior modeling is a continuous process which is planned to be integrated into the proposed model in the near future once consistent data become available. The major obstacle in modeling market behavior is the lack of futuristic behavior that is primarily dependent on accurate historical data. This data should reflect the performance of short-term effects such as lifestyle, human behavior, politics, conflicts, wars, natural disasters, environmental issues and other economies’ behaviors. The ultimate goal of this modeling effort is to assist in economic and risk analysis evaluation of petroleum projects.","Label":"0"},{"DOI":"10.1353/jda.2018.0005","Abstract":"This paper explored the determinants of banking sector development in Southern African Development Community (SADC) countries using the dynamic generalised methods of moments (GMM) estimation technique with panel balanced data ranging from 1994 to 2014. The major advantage of the GMM approach is its ability to capture the dynamic characteristic of banking sector development data and address the endogeneity problem. The impact of banking sector on economic growth has been investigated by several researchers and their findings show consensus with regard to the direction of causality between the two variables. What is still unclear or not yet agreeable is what determines banking sector development. Although few studies attempted to address that question, they overlooked the SADC region, a grouping of countries which over the last two decades relied on savings mobilization and allocative efficiency ability of the banking sector to influence economic growth. The current study contributes to literature because no similar study has been done on SADC countries to the best of the author’s knowledge. Few similar studies as shown by literature have used a single country as a unit of analysis, which is not very useful to SADC for regional banking sector policy formulation. Apart from not having focused on SADC countries, previous studies on banking sector development determinants ignored the dynamic aspect of banking sector development data and the endogeneity problem. This paper addressed all the shortcomings. The findings of this study are: (1) The lag of banking sector development and GDP positively and significantly influenced banking sector development in line with theoretical predictions. Trade openness negatively and significantly impacted on banking sector development whilst inflation had a marginal positive impact on banking sector development in SADC countries. Government consumption and unemployment had a negative but insignificant effect on banking sector development. These results are supported by literature. The implication of the study is that SADC countries should implement economic growth enhancement policies in order to increase the development of their banking sectors. They are also urged to reduce government final consumption expenditure, trade openness and unemployment levels in order to enhance banking sector development.","Label":"0"},{"DOI":"10.1007/s10269-011-2017-9","Abstract":"BackgroundThe only rationale for using biosimilar drugs is for cost saving. The market development for biosimilar drugs will therefore depend on the degree to which cost saving measures are required by nations, medical insurers and individuals, and the absolute savings that could be gained by switching from original drugs. This paper is designed to discover the degree to which financial constraints will drive future health spending, and to discover if legal or safety issues could impact on any trend.MethodsA structured literature search was performed for papers and documents up to 13 March, 2011. Where multiple sources of data were available on a topic, data from papers and reports by multinational or national bodies were used in preference to data from regions or individual hospitals.ResultsAlmost all health systems face current significant cost pressures. The twin driver of increasing cancer prevalence, as populations’ age and cancer medicine costs rising faster than inflation, places oncology as the most significant single cost problem. For some countries, this is predicted to make medicine unaffordable within a decade. Most developed countries have planned to embrace biosimilar use as a cost-control measure. Biosimilar introduction into the EU has already forced prices down, both the price of biosimilar drugs and competitive price reductions in originator drugs. Compound annual growth rates of use have been predicted at 65.8% per year.ConclusionsMost developed countries have planned to embrace biosimilar use as a major cost-control measure. Only legal blocks and safety concerns are likely to act against this trend. For centralized healthcare systems, and those with a strong tradition of generic medicine use, biosimilar use will clearly rise with predictions of more than 80% of prescriptions of some biologic drugs within one year of market entry in the USA. Delaying the implementation of such programs, however, risks a real crisis in healthcare delivery for many countries and hospitals which few can now afford.","Label":"0"},{"DOI":"10.24843/jlk.2019.v07.i04.p12","Abstract":"Currency exchange rates, or often referred to as the exchange rate, are the price of one unit of a foreign currency in a domestic currency or can also be called the price of a domestic currency against a foreign currency. The value of a country's currency is strongly influenced by the flow of capital between countries. The high exchange rate of other countries' currencies against a country will result in the deterioration of the economic situation of a country. The weakening of the currency exchange rate will cause Indonesia's foreign debt to increase and the balance sheets of companies and banks will decline. The phenomenon of volatile rupiah exchange rate fluctuations often occurs in Indonesia which will cause economic conditions, especially trade will be disrupted because trade is valued in US dollars (USD). Therefore, serious handling is needed in the face of erratic exchange rate fluctuations because it will affect the economic performance of a country so that a decision can be made after knowing the exchange rate of the next period. In helping to make decisions, the authors make a forecasting model of the rupiah exchange rate against USD using the radial basis function of the neural network. In this research used factors that influence the fluctuation of the rupiah exchange rate against IDR, namely the value of exports, imports, GDP, BI interest rates, inflation rates, and the money supply. In this research optimization of learning rate and hidden neuron parameters was done to get the lowest error value or error rate. The results of the research using the radial basis of neural network functions produce accuracy values ranging from 89 - 95% in the training process while the testing process ranges from 67 - 98% and with an error rate of 4 - 11% in the training process while 2 - 32% for testing process.  Key Words : Exchange rates, forecasting, RBF, training, testing, accuracy","Label":"1"},{"DOI":"10.2139/ssrn.2193265","Abstract":"Five years ago, we found three distinct periods characterized by sustainable quasi-linear trends in the difference between the headline consumer price index (CPI) and the core CPI in the USA. Then we revealed similar behavior in the differences between the CPI and indices of various consumer expenditure categories. We estimated the duration of these trends which varies in a wide range from 8 years to more than 20 years. The transition periods to new trends span shorter intervals of 2 to 5 years. The transition is characterized by a higher level of volatility in the studied CPI differences. In this study, we revisit the revealed trends and transition periods using additional CPI estimates between 2008 and 2012. It is found that our major predictions are right: the headline CPI intersected the core CPI in 2011 and both variables have been evolving in sync since then. The difference between the core CPI and the index of energy has been suffering a transition period since 2008 with extremely high fluctuations. The index of food has been growing relative to the core CPI and did not reach its turning point. The difference between the core CPI and the index of housing passed through its transition period in 2008. When normalized to the CPI, the differences associated with energy and housing demonstrates clear periodicity. The observed trends and periodicity allow predicting the evolution of energy, food, and housing at a horizon of twenty five and more years. The consumer price index of energy may fall in 2013 by ten to twenty per cent from the 2012 level. The periodicity of the related normalized difference implies that this fall may extend into the second half of the 2020s. The housing index will be also falling relative to the core CPI, partly due to its energy related components. It is not excluded that the food price index will be rising another five to ten years. The secular fall in energy and housing prices may induce a lengthy period of very low inflation.","Label":"0"},{"DOI":"10.17261/pressacademia.2023.1702","Abstract":"Purpose- This paper employs the public debt equation of motion, which covers variables that represent a country's competitiveness, such as past public debt, GDP, external balance, real exchange rate, real interest, and inflation, to estimate the public debt of Southern EU countries (Greece, Ireland, Italy, Portugal, and Spain). The paper is designed to test whether the public debt equation of motion (see Croce and Ramon, 2003; IMF, 2013; Chirwa and Odhiambo, 2018), which is characterized by significant variables representing competitiveness in macroeconomics, can statistically account for the public debt of Southern EU countries after the monetary union period including the EU public debt crisis. Consequently, based on the findings, it will be determined whether the competitiveness problems of Southern EU countries are important in the EU public debt crisis. Methodology- The analysis is performed with the nonlinear autoregressive network with exogenous inputs (NARX) with quarterly data for the period from 2005Q1 to 2021Q4. In NARX, which is a dynamic non-parametric neural network used in time series analysis, the prediction performance of the model is more robust than other neural network models, as the gradient descent approaches the local minimum perfectly (see Lin et al., 1996; Gao and Er, 2005; Diaconescu, 2008). However, it is important to define the parameters correctly in NARX to obtain effective results. In the study, parameters are defined according to the minimum Mean Squared Error values. The feedback Levenberg-Marquardt (LM) algorithm, which produces fast and effective results, is used as the training algorithm. The performance of the training algorithm for robustness is compared with testing and validation. Findings- The analysis results reveal that public debt in Southern EU countries is statistically explained by the public debt equation of motion with a confidence ratio of over 95%. Conclusion- This result implies that the public debt problem in Southern EU countries is associated with their competitiveness (see also Hall and Soskice, 2001; Dallago and Guglielmetti, 2011; Hall, 2012; Lane, 2012; Gros, 2012; Iversen et al., 2016; De Ville and Vermeiven, 2016; Frieden and Walter, 2017). In addition, the analysis goes beyond parametric analyzes that relate economic growth or a few variables with public debt and reveals the importance of inclusive variables and non-parametric analyzes in the estimation of public debt. Keywords: EU public debt crises, Southern EU countries, NARX, competitiveness problems JEL Codes: C45, F35, F45, N14, N24 Purpose- This paper employs the public debt equation of motion, which covers variables that represent a country's competitiveness, such as past public debt, GDP, external balance, real exchange rate, real interest, and inflation, to estimate the public debt of Southern EU countries (Greece, Ireland, Italy, Portugal, and Spain). The paper is designed to test whether the public debt equation of motion (see Croce and Ramon, 2003; IMF, 2013; Chirwa and Odhiambo, 2018), which is characterized by significant variables representing competitiveness in macroeconomics, can statistically account for the public debt of Southern EU countries after the monetary union period including the EU public debt crisis. Consequently, based on the findings, it will be determined whether the competitiveness problems of Southern EU countries are important in the EU public debt crisis. Methodology- The analysis is performed with the nonlinear autoregressive network with exogenous inputs (NARX) with quarterly data for the period from 2005Q1 to 2021Q4. In NARX, which is a dynamic non-parametric neural network used in time series analysis, the prediction performance of the model is more robust than other neural network models, as the gradient descent approaches the local minimum perfectly (see Lin et al., 1996; Gao and Er, 2005; Diaconescu, 2008). However, it is important to define the parameters correctly in NARX to obtain effective results. In the study, parameters are defined according to the minimum Mean Squared Error values. The feedback Levenberg-Marquardt (LM) algorithm, which produces fast and effective results, is used as the training algorithm. The performance of the training algorithm for robustness is compared with testing and validation. Findings- The analysis results reveal that public debt in Southern EU countries is statistically explained by the public debt equation of motion with a confidence ratio of over 95%. Conclusion- This result implies that the public debt problem in Southern EU countries is associated with their competitiveness (see also Hall and Soskice, 2001; Dallago and Guglielmetti, 2011; Hall, 2012; Lane, 2012; Gros, 2012; Iversen et al., 2016; De Ville and Vermeiven, 2016; Frieden and Walter, 2017). In addition, the analysis goes beyond parametric analyzes that relate economic growth or a few variables with public debt and reveals the importance of inclusive variables and non-parametric analyzes in the estimation of public debt. Keywords: EU public debt crises, Southern EU countries, NARX, competitiveness problems JEL Codes: C45, F35, F45, N14, N24","Label":"1"},{"DOI":"10.1007/s13132-023-01270-4","Abstract":"One of the most important issues in recent years has been the issue of population aging and its effects on the economy. It is clear that aging leads to increased healthcare costs, decreased productivity, saving, investment, risk taking, etc.; finally, the economic growth will slow. On the other hand, it is necessary to address the issues of sustainable development, namely inequality, life expectancy, and green life for enhancing the quality of life. The application of artificial intelligence approaches such as machine learning (ML), artificial neural network (ANN), and deep learning (DL) can create condition that make the life easier for humans and make things easier. The aim of article is to pay attention to the importance of population aging and sustainable development goals in G20 countries and the potential application of artificial intelligence to increase the quality of life. Centralized programs can be considered to reduce the negative consequences of population aging and lack of attention to sustainable development goals. As a case study and in order to show the benefits of artificial intelligence, we have tried to predict the population changes in England. The main contribution of this article is that we have integrated the issue of sustainable development and aging problem in G20 countries in terms of theoretical and analytical study as a complementary method. We have tried to fill the gap between social science subjects such as aging and SDGs in G20 countries using AI-based potential applications. We used artificial neural network (ANN) and genetic algorithm (GA) as prediction methods. Some economic indicators such as GDP, inflation rate, and import are used as input variables. GA is used as feature selection and finding the most important variables. The results show that the rate of fertility is decreasing and the rate of aging is increasing. So, AI-based production and approaches can be impactful in achieving SDGs and improving elderly life. We can conclude that by investing and identifying potential threats, the effects of reduced economic growth and productivity can be prevented or reduced.","Label":"1"},{"DOI":"10.1201/9781003138037-10","Abstract":"The welfare of farmers has been the agenda for elections in world’s largest democracy since 1947. Political parties made fortunes by exploiting the fragile economic status of farmers and making promises of farmer dare in every election, just to repeat them in next election, but with nothing changing for farmers. Urban workers earn eight times more than agricultural worker in India. Technology can bring prosperity to Indian farmers and reduce poverty. Blockchain is a distributed ledger of transactions and digital events shared among the participating parties. Blockchain technology and financial technology (fintech) can provide cost effective accessibility of finance, insurance, smart contracts, e-payments, weather updates, land registrations, supply chain, and future trading solutions. An enhanced income for farmers offers a multiplier effect by boosting the demand for products, services, and investment. Better supply chains will reduce supply shocks and control inflation. This chapter reviews the synergy of existing information and communication technology (ICT) infrastructure in India, stable and technologically well informed central government, predominantly young demographic profiles and an emerging start-up culture for transition to Agriculture 5.0 by developing blockchain and fintech solutions for the agriculture sector. Blockchain is relatively unexplored technology in India. Blockchain is hard to implement due to complexity and lacks regulatory clarity. Political will and vision can make blockchain and economic prosperity a reality for Indian farmers. A care model is proposed to enhance the adoption of technology in India for Agriculture 5.0. This chapter discusses the need for Agriculture 5.0 in India, scope for artificial intelligence, mobile applications, drones, blockchain in agriculture, and drip irrigation. The use of artificial intelligence provides opportunities to take informed decision on crop yields, pest management, crop disease prediction, weather forecast, soil health and ground level indicators. Sanctity of contracts, rigid labour laws, complex land record administration, and lack of political will are challenges for blockchain adoption in India. Technology adoption in India is facing problems due to lack of capital among small and marginal farmers. Smart phone penetration in rural areas provides an opportunity to connect farmers with technology through mobile applications. Drones provide an opportunity to collect real time data using sensors for soil conditions, crop growth, dry regions, pest and crop diseases, and spraying. Existing digital infrastructure will support blockchain enabled services for farmers in India.","Label":"0"},{"DOI":"10.58627/dpuiibf.1286984","Abstract":"Veri setindeki gözlemlerde eksiklik olması durumu olarak ifade edilen eksik veri panel verilerde de sıklıkla ortaya çıkabilmektedir. Bu durum ise geniş bir veri seti ile çalışma avantajına sahip panel veri modelleriyle çalışma avantajını kısıtlamaktadır. Panel verilerde eksik gözlemlerin olması durumunda ise dengesiz panel veri söz konusu olmaktadır. Çalışmanın amacı, eksik veriye sahip dengesiz panel veri ile atama algoritmaları ile dengeli hale getirilmiş panel veri sonuçlarını karşılaştırmaktır. Bu amaçla uygulama bölümünde 1991-2019 döneminde eksik veriye sahip 15 Akdeniz ülkesinde işsizlik oranı ile ekonomik büyümesi arasındaki ilişki incelenmek istenmiştir. Öncelikle model dengesiz panel veri analizi ile tahmin edilmiş, daha sonra çeşitli atama yöntemleri kullanılarak dengeli panel veri modeli tahmin edilmiştir. Çalışmanın sonunda, dengesiz panel veri ve atama yoluyla oluşturulan dengeli panel veri ile elde edilen sonuçlar karşılaştırılmış, AIC ve BIC kriteri bakımından en küçük değeri veren dengesiz panel veri modeli tahminleri yorumlanmıştır. Buna göre, işsizlik oranını etkileyen faktörler olarak ekonomik büyüme ve nüfus yoğunluğu belirlenmiştir. Kamu harcamalarının GSYİH’ya oranı ve enflasyon oranının işsizlik oranı üzerinde anlamlı bir etkisi bulunamamıştır. Missing data expressed as a deficiency in the observations in the data set can also often occur in the panel data frequently. This restricts the advantage of working with panel data models that have the advantage of working with a large dataset. In case of missing observations in the panel data, the unbalanced panel data is in question. The purpose of the paper is to compare results of unbalanced panel data with missing data and panel data balanced with assignment algorithms. For this purpose, in the application section, the relationship between unemployment rate and economic growth in 15 Mediterranean countries with missing data in the period of 1991-2019 is aimed to be examined. First, the model was estimated with unbalanced panel data analysis, then the balanced panel data model was estimated using various assignment methods. At the end of the study, the results obtained with the balanced panel data generated through unbalanced panel data and imputation were compared, and the unbalanced panel data model predictions giving the smallest value in terms of AIC and BIC criteria were interpreted. Accordingly, economic growth and population density were determined as the factors affecting the unemployment rate. The ratio of public expenditures to GDP and the inflation rate did not have a significant effect on the unemployment rate.","Label":"0"},{"DOI":"10.2307/3866565","Abstract":"Following the oil price rises of late 1973, several organizations predicted massive accumulations of international reserves in the major oil exporting countries during the remainder of the decade. The predictions have not been realized. Most commentators failed to anticipate the speed with which highly ambitious development strategies could be formulated and implemented in the major oil exporting countries. The growth of government expenditure in these countries over the period 1972-78 was, by any standards, spectacular; in both absolute and percentage terms, it was more rapid than the growth in their revenues. The overall fiscal position of the 12 major oil exporting countries moved from a surplus of almost $40 billion in 1974 to a deficit of approximately $15 billion in 1978. Movements in these countries' international reserve holdings have been closely correlated with overall fiscal developments. After examining these developments, the paper shows that the conventional presentation of fiscal and monetary accounts is inappropriate for examining the impact of fiscal policy on the domestic economies of oil exporting countries. An alternative presentation is provided that focuses on the domestic budget deficit and its implications for domestic liquidity creation. Application of the alternative framework to six major oil exporting countries for the period 1972-78 provides strong support for the propositions that the domestic budget deficit is the primary determinant of movements in domestic liquidity and inflation and that fiscal policy must be the primary instrument of demand management. Sharp reductions in the rate of growth of the domestic budget deficit have been closely associated with the restoration of domestic financial stability; earlier attempts to control inflationary pressures through subsidies and price controls, while highly expansionary fiscal policies were pursued at the same time, were not successful. The paper concludes with a discussion of some issues surrounding the formulation and implementation of appropriate fiscal policies in oil exporting countries. Notwithstanding data deficiencies and rapid structural change, for five oil exporting countries there appears to be a stable relationship between the demand for real liquid balances and real non-oil gross domestic product. This relationship, in conjunction with information concerning the private sector's balance of payments and domestic bank credit developments, provides an indication of the magnitude of the domestic budget deficit that is consistent with price and real output targets. The primary constraint on the implementation of appropriate fiscal and monetary policies is an inadequate adaptation of economic management infrastructures to the transformation of oil exporting economies.","Label":"0"},{"DOI":"10.2139/ssrn.2024176","Abstract":"Commercial real estate (CRE) has undergone enormous changes over the past two decades, even apart from the financial crisis. At the end of 2010, commercial mortgage balances totaled over $2 trillion. That was about twice as many at the end of 2000. At its peak in 2008, the ratio of balances to the size of the U.S. economy was one and a half times as large as it was in 2000. Historically, more than half of commercial mortgages were held by commercial banks and other depositories. Life insurers historically were the other major holders. Over the past dozen years, however, “nontraditional investors” have held increasingly important shares of total commercial mortgages. Thus, the relative size of the commercial mortgage market has fluctuated considerably and the percentages of total commercial mortgages that different groups of investors held have also shifted considerably over time. In addition, (inflation-adjusted) CRE prices dipped by more than 20 percent in the early 1990s, before rising about 50 percent during the 2000s and then dropping by about 50 percent since 2007. Since 2007, various indicators signaled that commercial mortgage underwriting, after apparently being lax, had tightened rapidly and severely. We combined information from several indicators of commercial mortgage underwriting to construct a single underwriting index (UW) for 1990-2011. We used information about commercial mortgage underwriting from banks and from government-employed bank examiners. We also used information about the commercial mortgages that were acquired by life insurance companies. These data series each directly measured an important aspect of underwriting. To construct UW, we then combined those data series with an indirect indicator of underwriting, the net flow of commercial mortgages acquired by “nontraditional” investors. We also explain why some well-known indicators were unlikely to accurately reflect underwriting during 1990-2011. We then used the UW in a vector auto-regression to estimate how CRE prices and commercial mortgages responded to changes in underwriting, and, in turn, how prices and mortgages affected underwriting itself. We found that underwriting had important, independent effects on the CRE market. The estimates suggested that both price and non-price components of underwriting affected commercial real estate. We also found that underwriting itself responded to developments in commercial real estate. In particular, we found that underwriting loosened when (the growth rates of) CRE prices were predicted to rise. One implication is that underwriting amplified movements in CRE markets: Predictions of faster price growth loosened underwriting, which raised CRE lending and prices, which in turn loosened underwriting further.","Label":"0"},{"DOI":"10.2307/3867215","Abstract":"This paper describes the construction and use of a small macroeconomic model, MINIMOD, of the United States and its major industrial trading partners. The goal is to have a readily understandable and transparent model of manageable size that is suitable for policy analysis. Consequently, an eclectic theoretical model has been specified for each of the two economies, with equations for aggregate demand and supply of goods and capital accumulation, and with consistent treatment of government and private sector flows of funds. The model was specified such that it has desirable long-run properties, including the neutrality of money and the property that government debt cannot grow without limit relative to output. Values for the parameters of the model were obtained, with a few exceptions, from the properties of a larger, multicountry model; the paper describes the methodology of reducing a larger model to its core interactions using partial simulation techniques. The model is simulated to gauge the effects of changes in monetary and fiscal policies under two alternative assumptions concerning expectations of future rates of inflation, of long-term bond rates, and of the exchange rate: (i) expectations adapt to past movements in the variables, or (ii) expectations are consistent with the model's own predictions. The simulations imply that an increase in the money supply is likely to depreciate the exchange rate and to stimulate output in the home country, as prices are slow to adjust; in the long run, however, real magnitudes will be unaffected. Government spending increases also have a temporary stimulatory effect on output in the home country, but, for unchanged money supplies, tend to appreciate the exchange rate. These conclusions are common to many macroeconomic models. However, MINIMOD also makes it possible to see how sensitive the results are to assumptions concerning expectations. It is shown that the paths of major macroeconomic variables may be quite different in the two cases mentioned above. In particular, in response to a money supply change, the exchange rate is likely to overshoot its equilibrium value under consistent expectations, though not under adaptive expectations, and output effects are likely to be smaller under consistent expectations. Government expenditure changes seem to have more similar effects in the model under the two expectations assumptions, though the changes induced in the exchange rate and in long-term bond rates are larger with model-consistent expectations. It is also shown that in this case, credible, preannounced policy changes may have substantial effects before they are actually implemented: a future fiscal contraction may in fact have a stimulatory effect on output when it is announced, because of a decline in long-term interest rates and a depreciation of the currency.","Label":"0"},{"DOI":"10.2118/1009-0016-jpt","Abstract":"Guest editorial \"Our supplies of...oil and natural gas are being rapidly depleted, and many of the great fields are already exhausted.\" Not a warning from last year, when oil prices set a record of USD 147/bbl, but the words of pioneering conservationist Gifford Pinchot in 1910. Fears of \"peak oil\" are nothing new. The economist William Jevons forecast in 1865 that falling coal resources threatened the British Empire. Predictions of imminent decline came from petroleum geologists in 1885, 1919, and 1956; from US President Jimmy Carter in 1977; and from the US government in 1980. A prominent \"peak oiler,\" Colin Campbell, claimed in 1989 that oil output had peaked; another, Kenneth Deffeyes, put the peak date, rather precisely, at 16 December 2005. The high prices of 2008 seemed to give credibility to the idea that we had reached the physical limits of production. But now that prices have fallen, peak oil advocates raise a new alarm—that decline will be hastened by a lack of investment. The opening years of the 21st century have been marked by milestones in the world of oil: the war in Iraq, the Shell reserves downgrade, hurricane Katrina, and the breaking of the once unthinkable USD 100/bbl barrier. Many have seized on these events as evidence that we are crossing the threshold of peak oil. Behind us, a century-and-a-half of abundant, cheap oil that fuelled industrial civilization and brought unprecedented prosperity to a fortunate global minority. Ahead of us, permanent declines in oil production, scarce and unaffordable energy, wars over dwindling resources, disastrous climate change, perhaps the collapse of modern society. But these ideas are based on misconceptions, flawed reasoning, and excessive pessimism. The world has abundant oil and gas for decades to come, geopolitical conflicts can be avoided by adroit policies, and we can learn to use hydrocarbons without unacceptable environmental damage.   Cheap Oil and Underinvestment Recent high prices certainly seem to give some credibility to the idea that we are approaching some fundamental limit of oil resources. But we should remember how we arrived at this situation, because the culprit is not constraints on oil in the ground: it is the long 1986–98 period of cheap oil and underinvestment. Low prices decimated the oil industry, while the rise of energy-hungry new powers in Asia, combined with robust demand in the developed world and geopolitical upsets in major producers, stealthily ate up spare production capacity. As oil prices rose, investment increased, but much was consumed by cost inflation, while the most promising areas were mostly off-limits for political reasons. Supply growth was therefore disappointing. The inevitable result, perhaps amplified by speculation and market nervousness, was a sharp rise in the oil price.","Label":"0"},{"DOI":"10.2139/ssrn.1442226","Abstract":"Heterogeneity is important for the modeling of economic agents. Economic agents differ in their beliefs, access to information, preferences, and endowments. Despite these differences and despite strong and persuasive arguments put forward for including heterogeneity in finance and macroeconomics, the representative agent paradigm is still the leading structural approach in empirical finance and macroeconomics. One major barrier for incorporating heterogeneity is the lack of tangible data on the beliefs of individual agents. In our research program, we partially overcome this barrier by using the stated predictions of financial and macroeconomic forecasters as proxies for the beliefs of agents. See for example Anderson, Ghysels and Juergens (2005) where we use the disagreement of financial forecasters to proxy for the amount of belief heterogeneity. Uncertainty is crucial for the understanding of financial and macroeconomic issues. Most empirical research in finance and macroeconomics incorporates risk in a central way but fails to distinguish risk from uncertainty. Following Knight (1921), Keynes (1937), and recent papers on robustness and ambiguity, we distinguish uncertainty from risk by calling an event risky if its outcome is unknown but the distribution of its outcomes is known, and an event uncertain if its outcome is unknown and the distribution of its outcomes is also unknown. The few papers that have studied uncertainty and its impact on asset pricing have been mostly theoretical. One major barrier for incorporating uncertainty is the lack of tangible data on uncertainty. In our research program, we suggest empirically tractable methods of measuring uncertainty. See for example Anderson, Ghysels and Juergens (2009) where we use the disagreement of macroeconomic forecasters as a proxy for uncertainty. We propose to study a new structural model of forecasters which simultaneously incorporates heterogeneity and uncertainty. A significant limitation of the existing literature is the lack of a structural model describing the behavior of forecasters that is integrated with a fully specified model of asset prices and the macroeconomy. Previous studies typically have adopted a reduced form approach for modeling the behavior of forecasters. However, forecasters are optimizing agents and we propose a method for modeling their behavior that leads to improved measures of heterogeneity and uncertainty. Unlike previous studies (including our own earlier work) we propose to simultaneously disentangle risk, uncertainty, disagreement and heterogeneous beliefs. We intend to study asset pricing and the determination of macroeconomic variables in economies featuring uncertainty and heterogeneous agents. We will examine the effects of risk, uncertainty, disagreement, and heterogeneous beliefs on the market excess return, the cross-section of returns, the determination of output and inflation, and the link between consumption and asset prices. Our results should benefit practitioners and policy makers by increasing their understanding of the dynamics of uncertainty and beliefs. It should allow practitioners to give clients better advice on asset allocations that avoid catastrophic losses. It should allow government policy makers to respond quicker to a changing economy to mitigate the severity of recessions.","Label":"0"},{"DOI":"10.2139/ssrn.280097","Abstract":"There has been surprisingly little empirical work explaining why countries choose different bundles of taxes. Early research by Musgrave and Hinrichs focused on the amorphous distinction between direct and indirect taxes. More recent research has examined the use of trade taxes and inflation, with little appreciation for the fact that countries are choosing a complete revenue mix. We examine the determinants of tax composition in 100 countries using data averaged over the periods 1975-80, 1981-85, and 1986-92. The dependent variables are tax revenues from the different sources as fractions of total revenue (or of GDP), including personal income taxes, corporate taxes, social security & payroll taxes, domestic goods & services taxes, trade taxes and tax rates, property taxes, and nontax revenues from seigniorage and public enterprises. All tax sources have increasing marginal political costs attached to their use. Consequently, as the scale or size of total revenues increases, reliance on all revenue sources can be expected to increase, though some tax bases may be used more heavily than others. We find strong evidence supporting this scale effect. Our empirical analysis also provides strong support for the prediction that countries tend to rely more heavily on tax sources for which the base is relatively large, and there is evidence that the use of taxes that depend on widespread literacy increases as educational attainment rises. While an explanation of the tax mix that relies on economic variables measuring scale, tax bases, and administration and enforcement costs works reasonably well even in a diverse sample of countries, we find that tax composition also varies with the nature of the political regime. Socialist countries tend to make more use of corporate, sales, and excise tax sources than other regimes, perhaps due to the greater ease with which the activity of businesses can be monitored, a stronger ideological interest in taxing business, or a reduced need to use taxation of individuals to accomplish social goals. We also find that more repressive governments rely less on personal income taxation, possibly because this tax source requires a higher degree of voluntary compliance than other forms of taxation. At a general level, the results as a whole they add to the set of stylized facts that may serve as a basis for further theoretical work that can unify the experience of different countries around the world. The ability to model the tax mix of a diverse sample of countries raises interesting questions about the possibilities for tax reform. To the extent that international differences in the mix of taxes are predictable, proposals for reform that do not take the underlying forces into account are likely to be unsuccessful, or may be very costly if they do succeed in altering the existing equilibrium.","Label":"0"},{"DOI":"10.33140/jerr.02.02.01","Abstract":"Background: The Consumer Price Index (CPI) is the main indicator for determining the prices level of a certain economy. The above-mentioned rate refers to the average prices on an indicated period and it is calculated mainly on goods consumed basis by selected families through weighting criteria and therefore, identifying the inflation damages on waged workers as well as their life standards thus, providing precise information on their earnings improvement or compensating their previous or equivalent buying empowerment. The application of rates is based on statistics models whereby; the temporary series is identified as observation of different periods that relevant variable values stand to foresee the future hypothesis confirmation. Objective: To Estimate the Consumer Price Index in Mozambique using Time Series Models. Methods: The following study based on monthly CPI data of Mozambique dating January 2011 to July 2020 out of 115 observed analyses. The data was processed through free open codes Gretl and 4.02-R Version Statistic Packages. The data hereby used was provided by the Mozambican National Statistics Institute (INE). The study applied the Box and Jenkins approach claiming that each temporary series value is based on its previous values due to the temporarily correlation between the series values that generally exist. The method consists of adjusting the Auto-regressive integrated Moving Average Method (ARIMA) to a data group under four interactive stages cycles Results: From 103 observations taken into account, the highest registered index was 158,25 corresponding to December 2016. On the other hand, it is notable that 101,62 is the smallest rate corresponding to January 2011period. The 114,68 medium rate breaks apart the price series in half resulting 50% of rates below such price and consequently, the remaining 50% above the same price. The similar parameter indicates all distribution format ends. Positive numbers indicate the widest end on the right while the negative numbers indicate the widest end on the left. Consequently, the positive asymmetry (1, 5217) indicates that the distribution has a wide end on the right. For kurtosis, the series is platykurtic since its result is less than 3 (2,6904 <3). Conclusion: The CPI in Mozambique showed an increasing trend in the period analyzed, between January 2011 and July 2020, with a sharp rise in 2016 returning to the original level and the normal growth trend of the series. In the estimation stage, it was possible to adequately select (02) two ARIMA models (p,d,q) that presented good fit to the data, and among them, the model selected as the most appropriate for predictions according to performance measures, was ARIMA (0.1.0) with constant, because it presented lower values of absolute mean percentage error (AMPS) and mean quadratic error (REQM). According to the selected model, the previsions for the period from August 2020 to July 2021 indicate a slight growth in consumer price index.","Label":"0"},{"DOI":"10.2118/90184-ms","Abstract":"Abstract The US economy and use of oil and gas energy grew rapidly together for many decades. This seemingly symbiotic relationship ended when nominal oil prices jumped eight-fold (1973–81), triggering the worst US recession since World War II. Subsequent recessions have followed every significant, if generally short-term, oil price hike. Economic growth has happened when oil prices were either relatively low or stable. The oil price jump of the '70s also correlates with a nine-fold increase in natural gas price, a four-fold increase in coal price, a three-fold increase in cost of electricity, and a significant drop in energy demand. These events provide bases for better understanding of the relationship between energy use and economic growth. Although the conventional measure of \"economic growth\" is percentage change in GDP, other criteria - inflation, interest rates, unemployment, relative strength of currency, imports and exports, corporate profitability, etc. - are also important and are reviewed since the \"economy\" is complex and multidimensional. Sudden energy price changes provide measures of elasticity (effect of price on supply and demand) essential for better understanding and predictions of energy use and economic growth. Knowledge of elasticity is vital for forecasting, planning and policy development. Inevitable constraints imposed by changing environmental and political considerations impact both future US energy use and economic activity not unlike actual physical shortages. Possible means for alleviating adverse impacts, and for transitioning from oil and gas to other energy sources must be explored. Importantly, the potentially significant impacts of both anticipated and unforeseen technological breakthroughs must be evaluated and incorporated into any meaningful view of the future.  Introduction: A History of US Oil and Gas Colonel Edwin L. Drake discovered oil in the US in 1859. Five years later, production was 6000 BOPD, and oil's value for illumination spurred growth to 83,000 BOPD by 1882, at an annual rate of 15%. Subsequently, Appalachian Basin growth faltered; by 1918 it accounted for only 8% of US total of 1 million BOPD, as large new fields were found in California, Texas, and Oklahoma. Between 1900 and 1920, oil and gas consumption in the US grew at 11% and 9% respectively, as use of automobiles with internal combustion engines proliferated1. Table 1 illustrates subsequent consumption as MBOPD and MMCFPD and as quadrillion BTU's (or quads), and also oil and gas energy as a percent of total US energy use2,3. (One quad is 172 million bbls or nearly 500 MBOPD, and also equates to 0.9 TCF or about 2.5 BCFPD). Significant changes either in energy use or the economy are illustrated. The period 1920–29 is the post WW I boom, 1929–40 is the Great Depression, 1940–45 is WW II, 1945 to 1970 covers the post WW II boom, 1970–83 is the period of oil price increase and uncertainty triggered by the Arab Oil Embargo and the Iran-Iraq War, and 1983 to 2003 is the post price shock period beginning at the low point in US energy consumption in 1983.","Label":"0"},{"DOI":"10.1016/b978-0-12-802303-7.00002-4","Abstract":"Risk refers to the chance that some unfavorable outcome will occur contrary to our expectations. Accounting statements and financial ratios measure risk in the context of risk of default and the capacity of the firm to meet its obligations at a certain period of time. The total return on any investment is the sum of the dividend and the capital gain. Historical rates of returns help investors to choose among alternative investment assets. The required return is the sum of real risk-free rate plus expected inflation and risk premium. The excess return required from an investment in a risky asset over that required from a risk-free investment is called risk premium. The variability of returns is known as risk. Risk can be classified into systematic and unsystematic risk. Systematic risks have market-wide effects and affect a large number of assets. Unsystematic risks are those that affect a small number of assets. A portfolio is a group of assets formed as a result of diversification. The variance or standard deviation of expected returns is one of the best-known measures of risk. Portfolio risk can be measured through portfolio variance and standard deviation. Covariance and correlation coefficient are two measures which analyze how the returns on a pair of stocks vary together. Beta is the amount of systematic risk present in a particular risky asset in relation to that in an average risky asset. Beta coefficient is the measure of sensitivity of a share price to movement in the market price.There are a number of risk return models. Mean–variance optimization is a quantitative tool for allocation of assets based on the trade-off between risk and return. Capital asset pricing model (CAPM) is the most important risk return model widely used in the industry. Efficient frontier represents the set of portfolios which has the maximum return for any given level of risk or minimum risk for every level of return. Modern portfolio theory represents a theory of finance which attempts to maximize portfolio’s expected return for a given portfolio risk or equivalently minimize the risk for a given level of expected return. Capital market theory suggests that investors diversify their cash flows between a riskless security and the risky portfolio M. Portfolio M is the market portfolio which contains all risky assets in the market place and have the highest level of expected return per unit of risk for any available portfolio of risky assets.CAPM is the cornerstone of modern financial economics. This model gives the prediction of the relationship between the risk of an asset and its expected return. CAPM expresses the expected return for an investment as the sum of the risk-free rate and expected risk premium. Arbitrage pricing theory considers several factors that capture market-wide risks. Multifactor models classify the risk factors into macroeconomic and microeconomic factors. Investors use credit ratings to assess credit risk and compare different issuers and debt issues.","Label":"0"},{"DOI":"10.30525/2256-0742/2017-3-4-216-223","Abstract":"The purpose of the research is to identify the influence of Ukraine’s economic development on the international agencies' credit rating of its banking system. The instability and ambiguous geopolitical position of Ukraine are complicating any predictions for its economic developments. In the meanwhile, massive restructuring of all sectors of the economy became the necessary minimum for the reformation of the country and the achievement of the international standards. It is interesting to see how exactly these international standards, as represented by the evaluation of the rating agencies, appraise Ukraine, and particularly its banking sector. The methodology involves the analysis of the three major Ukrainian banks – PrivatBank, Oschadbank, and Ukreximbank using Fitch’s credit quality assessment systematic as an example. The comparative analysis was performed using Tier 1 capital ratio and loan-to-deposit ratio of these banks, year-to-year quarterly GDP growth, consumer price index (CPI) year-to-year change, UAH/USD exchange rate, 2-year and 5-year government bond yield, as well as 2-year and 5-year credit default swap (CDS). Results show that the most influential credit rating drivers for Ukrainian banks are: exchange rate; funding and liquidity; capital position and asset quality; sovereign risk. The research showed that the 2-year and 5-year government bond yield in USD and 2-year and 5-year CDS were influenced by similar trends. The yield on short-dated Ukrainian governmental bonds has shown a parallel increase with the corresponding CDS that indicated the market’s evaluation of the stressed condition of the country’s government and economy. Additionally, conventional yield structures displayed inversed nature with 2-year governmental bond yield in USD trading at significantly higher yields than 5-year government bond yield in USD during times of economic distress. Although longer maturity instruments should usually trade at a higher rate, such a development could have reflected the public markets’ scepticism to the Ukrainian government’s short-term solvency. The closer look at the Tier 1 capital ratio, which is considered to be a key indicator of the financial health of the banks, revealed analogy between it and three major Ukrainian banks rating development, indicating the Tier 1 capital ratio as a strong influencing factor. Loan-to-deposit ratio as an indicator of bank liquidity moved in parallel with decreasing credit ratings. The strong decrease in the UAH/USD exchange rate mirrored a strong increase in inflation and overall worsening state of the Ukrainian economy also being reflected in the major banks’ ratings. Practical implications. The correlation of these factors is relevant for bank managers and investors who can use financial market indicators to forecast and plan their own ability to conduct business. Likewise, academic researchers can further build on this study to add to the literature on country-specific reviews of sovereign debt crises and their impact on national banking systems. Value/originality. This research demonstrates that a worsening of financial indicators of the health of Ukraine’s financial system as measured by government bond yields and the trading of credit default swaps, as well as the country’s economic downturn, go along with a decline of local banks’ credit ratings.","Label":"0"},{"DOI":"10.1007/bf00123887","Abstract":"Concluding remarksWhile the final version of the 1986 Tax Reform Act retained budget funding of the IRS, the Senate proposal to finance spending from audit revenues represented a seriously debated alternative that continues to receive attention as a method for increasing enforcement. At one level, the ultimate failure of the proposal is puzzling. Given Congress's unwillingness to raise tax rates to cover spending, the budget deficits of the 1980s must be financed from some other source — inflation, borrowing or increased enforcement. Turning the IRS into a bounty-hunting agency would seem to be a straightforward way of producing extra revenue.This popular view reveals a basic confusion about the behavior of bounty-hunting agents. It implicitly assumes that a bounty-hunting agency would behave as a general revenue-maximizing Leviathan and automatically increase enforcement above the status quo budgetary level in pursuit of additional revenue. But bounty hunters want to maximize net audit revenues — not net general revenues. As I have emphasized, too thorough a hunt will reduce the bounty.The possibility of taxpayer adjustment implies a Laffer-like relationship between audit revenue and enforcement. Conceivably, enforcement activity could be raised to the point where taxpayers choose to report all of their income. Then audits would raise no revenue. Increased revenue and increased output in the form of enforcement do not necessarily go hand-in-hand. Allowing pure bounty hunters to spend all audit revenues could lead to either increased or decreased enforcement.Conceptually, Congress could obtain the enforcement outcome it desired by determining the representative individual's taxable base (Y), calculating the taxpayer response to changes in enforcement (dx*/dL), choosing the ‘correct’ model of the agency head's behavior and finally specifying in the financial proposal the appropriate fraction, m, of audit revenues that agents may spend.One potential problem with this procedure is its presumption that information is costlessly available to Congress. If Congress does not know how taxpayers respond to changes in enforcement, for instance, then it might miscalculate the appropriate revenue fraction. Indeed, my tentative prediction that the Senate's revenue multiple would have lowered enforcement suggests the difficulties in specifying the ‘correct’ multiple.But this problem would not appear to be insurmountable. In a static environment, where the taxpayer adjustment function does not change over time, Congress could discover the ‘correct’ revenue multiple through a trial and error process. Then, at a later date, Congress could amend the financing structure accordingly.A more serious problem confronts Congress once we acknowledge that the economic environment may change. Consider the possibility that taxpayer income changes within and across legislative periods. A revenue fraction that was appropriate initially would not necessarily be appropriate several years, or even months later. This helps explain why the Senate proposal ultimately failed even though it seemed ideally suited for the revenue ‘crisis’ of the 1980s.The failure of the 1986 proposal also suggests why legislators choose to budget finance the operation of most bureaus rather than place them on a type of performance payment schedule. Once government specifies a payment formula, it loses control of the bureau's output over the contract period. In contrast, the appropriation process allows government to use the budget as a tool to induce in-period and across-period adjustments in the output of a bureau when conditions outside legislators' control change unexpectedly.","Label":"0"},{"DOI":"10.1093/acrefore/9780190625979.013.171","Abstract":"High-Dimensional Dynamic Factor Models have their origin in macroeconomics, precisely in empirical research on Business Cycles. The central idea, going back to the work of Burns and Mitchell in the years 1940, is that the fluctuations of all the macro and sectoral variables in the economy are driven by a “reference cycle,” that is, a one-dimensional latent cause of variation. After a fairly long process of generalization and formalization, the literature settled at the beginning of the year 2000 on a model in which (1) both n the number of variables in the dataset and T, the number of observations for each variable, may be large, and (2) all the variables in the dataset depend dynamically on a fixed independent of n, a number of “common factors,” plus variable-specific, usually called “idiosyncratic,” components. The structure of the model can be exemplified as follows: xit=αiut+βiut−1+ξit,i=1,…,n,t=1,…,T,(*) where the observable variables xit are driven by the white noise ut, which is common to all the variables, the common factor, and by the idiosyncratic component ξit. The common factor ut is orthogonal to the idiosyncratic components ξit, the idiosyncratic components are mutually orthogonal (or weakly correlated). Lastly, the variations of the common factor ut affect the variable xit dynamically, that is through the lag polynomial αi+βiL. Asymptotic results for High-Dimensional Factor Models, particularly consistency of estimators of the common factors, are obtained for both n and T tending to infinity. Model (∗), generalized to allow for more than one common factor and a rich dynamic loading of the factors, has been studied in a fairly vast literature, with many applications based on macroeconomic datasets: (a) forecasting of inflation, industrial production, and unemployment; (b) structural macroeconomic analysis; and (c) construction of indicators of the Business Cycle. This literature can be broadly classified as belonging to the time- or the frequency-domain approach. The works based on the second are the subject of the present chapter. We start with a brief description of early work on Dynamic Factor Models. Formal definitions and the main Representation Theorem follow. The latter determines the number of common factors in the model by means of the spectral density matrix of the vector (x1tx2t⋯xnt). Dynamic principal components, based on the spectral density of the x’s, are then used to construct estimators of the common factors. These results, obtained in early 2000, are compared to the literature based on the time-domain approach, in which the covariance matrix of the x’s and its (static) principal components are used instead of the spectral density and dynamic principal components. Dynamic principal components produce two-sided estimators, which are good within the sample but unfit for forecasting. The estimators based on the time-domain approach are simple and one-sided. However, they require the restriction of finite dimension for the space spanned by the factors. Recent papers have constructed one-sided estimators based on the frequency-domain method for the unrestricted model. These results exploit results on stochastic processes of dimension n that are driven by a q-dimensional white noise, with q<n, that is, singular vector stochastic processes. The main features of this literature are described with some detail. Lastly, we report and comment the results of an empirical paper, the last in a long list, comparing predictions obtained with time- and frequency-domain methods. The paper uses a large monthly U.S. dataset including the Great Moderation and the Great Recession.","Label":"0"},{"DOI":"10.1287/mnsc.2013.1812","Abstract":"Francesca Gino, Erin L. Krupka, Roberto A. Weber Does the option for regulatory oversight change behavior? Although monitoring and regulation can be used to combat socially costly unethical conduct, their intended targets can often avoid regulation or hide their behavior. This surrenders at least part of the effectiveness of regulatory policies to firms' and individuals' decisions to voluntarily submit to regulation. The authors study individuals' decisions to avoid monitoring or regulation and thus enhance their ability to engage in unethical conduct. They conduct a laboratory experiment in which participants engage in a competitive task and can decide between having the opportunity to misreport their performance and having their performance verified by an external monitor. To study the effect of social factors on the willingness to be subject to monitoring, the authors vary whether participants make this decision simultaneously with others or sequentially, as well as whether the decision is private or public. The insight for management: The opportunity to avoid being submitted to regulation produces more unethical conduct than situations in which regulation is either exogenously imposed or entirely absent.    Elena Obukhova, George Lan Do job seekers benefit from contacts? Although it is intuitively plausible that a job seeker benefits by using contacts in her job search, researchers have been plagued by theoretical disagreements and inconclusive empirical evidence. Single-firm studies consistently find that job seekers applying through referrals achieve better labor-market outcomes than job seekers applying without referrals, but the evidence from job-seeker studies is mixed. To solve this puzzle, the authors clarify the distinction between having social capital and using contacts as a search method. They examine the school-to-work transition of 291 university graduates who engaged in 3,112 contemporaneous job searches in their study. The insight for management: Although a job seeker's social capital may not affect whether or not she uses contacts to search for a job, using contacts as a job-search method does improve her job-search outcomes.    Anandasivam Gopal, Manu Goyal, Serguei Netessine, Matthew Reindorp How does a new product launch affect plan productivity? Product launch—an event when a new product debuts for production in a plant—is an important phase in product development. But launches disrupt manufacturing operations, resulting in productivity losses. Using data from North American automotive plants from years 1999–2007, the authors estimate that a product launch entails an average productivity loss of 12%–15% at the plant level, which translates to a monetary loss of $42–$53 million per launch in lost productivity. The authors identify several ways to mitigate the decrease in productivity. They suggest that product (or mix) flexibility in the body shop is critical for reducing the productivity loss. Also, a plant's past experiences with product launches as well as with manufacturing similar products (specifically, on the same platform as the launch product) temper the productivity losses even further. Nevertheless, there are subtle differences in the accrued learning with these two types of experiences: Whereas the positive impact of platform experience persists over time, the learning accrued with launching other products in the same plant decays more quickly. The insight for management: Launching products at a flexible plant with appropriate platform experience could recover approximately $31 million per launch in lost productivity.    Linda V. Green, Sergei Savin, Nicos Savva How many nurses should be scheduled on a given day? The problem of determining nurse staffing levels in a hospital environment is a complex task because of variable patient census levels and uncertain service capacity caused by nurse absenteeism. The authors combine an empirical investigation of the factors affecting nurse absenteeism rates with an analytical treatment of nurse staffing decisions. Using data from the emergency department of a large urban hospital, they find that absenteeism rates are consistent with nurses exhibiting an aversion to higher levels of anticipated workload. The authors provide characterizations of the optimal staffing levels in both situations and show that the failure to incorporate absenteeism as an endogenous effect results in understaffing. The insight for management: Understaffing creates absenteeism and worsens service levels; the optimal staffing levels should consider the reaction of staff who may not report to work when anticipated workloads are high.    Felipe A. Csaszar, J. P. Eggers How does the method of decision making affect outcomes? The authors study four information aggregation structures commonly used by organizations to evaluate opportunities: individual decision making, delegation to experts, majority voting, and averaging of opinions. They investigate how the performance of each of these structures is contingent upon the breadth of knowledge within the firm and changes in the environment. They explore when delegation is preferable to other structures, such as voting and averaging. They show that that delegation is the most effective structure when there is diversity of expertise, when accurate delegation is possible, and when there is a good fit between the firm's knowledge and the knowledge required by the environment. Otherwise, depending on the knowledge breadth of the firm, voting or averaging may be the most effective structure. Finally, they use their model to shed light on which structures are more robust to radical environmental change and when crowd-based decision making may outperform delegation. The insight for management: How a decision should be made depends on critical attributes of the organization and problem type.    Haitao Li, Tao Li, Cindy Yu Is the Federal Reserve pro-growth or anti-inflation? The authors study the time-varying nature of U.S. monetary policies They find that the Fed is proactive in controlling inflation in one regime and accommodative for growth in another. Moreover, proactive monetary policies are associated with more stable inflation and output gap and therefore could have contributed to the Great Moderation. The authors also highlight the importance of switching regimes for term structure modeling. Without the regimes, inflation and output can explain less than 50% of the variations of bond yields. With the regimes, the two variables can explain more than 80% of the variations of bond yields. The insight for management: The Fed can be either pro-growth or anti-inflation; in order to understand Fed behavior, it is critical to account for regime changes.    Nan Jia, Jing Shi, Yongxiang Wang How do trading partners coinsure to improve performance? Using novel transaction-level data on Chinese business groups, the authors provide direct evidence of the coinsurance theory of business groups by investigating when different types of internal resources are transferred within a business group. The authors find that in Chinese business groups, a credit crunch experienced by the controlling shareholding firm (the “controller”) of a publicly listed firm increases the loan-based related party transactions (RPTs) including loan guarantees and intercorporate loans provided by the listed firm to the controller. In turn, when the listed firm's performance dips, the controller and its supporting firms provide more support to the listed firm in the form of non-loan-based RPTs. The insight for management: Business groups support each other in order to ensure the successful continuation of the group.    Monic Sun, Feng Zhu How is ad content affected by contract terms? When incentivized by ad revenue, content providers are more likely to tailor their content to attract “eyeballs,” and as a result, popular content may be excessively supplied. The authors empirically test this prediction by taking advantage of the launch of an ad-revenue-sharing program initiated by a major Chinese portal site in September 2007. Participating bloggers allowed the site to run ads on their blogs and received 50% of the revenue generated by these ads. After analyzing 4.4 million blog posts, the authors find that, relative to nonparticipants, popular content increased by approximately 13% on participants' blogs after the program took effect. Approximately 50% of this increase can be attributed to topics shifting toward three domains: the stock market, salacious content, and celebrities. Meanwhile, relative to nonparticipants, participants' content quality increased after the program took effect. The authors also find that the program effects are more pronounced for participants with moderately popular blogs and seem to persist after participants enroll in the program. The insight for management: The content and quality of ads depend directly on the contract terms of the content provider; revenue incentives increase the intensity of ads for the most popular items and improve ad quality.    Izak Duenyas, Bin Hu, Damian R. Beil How do auction purchases affect supply contracts? The authors study an optimal procurement mechanism for a newsvendor-like problem where the buyer's (newsvendor's) purchase price of the supplies is not fixed but is determined through interaction with candidate suppliers. The buyer has some idea of supplier costs but does not know their costs exactly. Recent literature has shown how the buyer can implement the optimal procurement mechanism by announcing a revenue function (specifying a payment for each quantity the buyer may purchase), then auctioning off the supply contract with the specified revenue function. The authors show that a simple modified version of the standard open-descending auction for a fixed quantity is also an optimal mechanism for obtaining supplies. What distinguishes the proposed auction mechanism is its simplicity and familiarity for the suppliers—open-descending auctions are very easy to run and ubiquitous in practice, whereas auctioning supply contracts with a specified revenue function is much less observed and more difficult to explain to suppliers. The insight for management: Simple and common auction methods can achieve optimal supply contracts.    Jian Yang, Yinggang Zhou How can credit risk be assessed across networks of credit institutions? Using credit default swap data, the authors propose a novel empirical framework to identify the structure of credit risk networks across international major financial institutions around the recent global credit crisis. Specifically, they identify three groups of players, including prime senders, exchange centers, and prime receivers of credit risk information. Leverage ratios and, particularly, the short-term debt ratio appear to be significant determinants of the roles of financial institutions in credit risk transfer, whereas corporate governance indexes, size, liquidity, and asset write-downs are not significant. The insight for management: New research carries important implications for a new regulatory standard on capital subcharge and liquidity coverage ratio.    Chrysanthos Dellarocas, Zsolt Katona, William Rand To link or not to link? A defining property of the World Wide Web is a content site's ability to place virtually costless hyperlinks to third-party content as a substitute for or complement to its own content. Costless hyperlinking has enabled new types of players, usually referred to as content aggregators, to successfully enter content ecosystems, attracting traffic and revenue by hosting links to the content of others. This, in turn, has sparked a debate between content creators and aggregators regarding the legitimacy and costs/benefits of uninhibited free linking. The authors model the complex interplay between content and links in settings where sites compete for traffic. The authors attempt to distill how hyperlinking affects the (a) incentives of content nodes to produce high-quality content versus to link to third-party content, (b) profits of the various stakeholders, (c) average quality of content that becomes available to consumers, and (d) impact of content aggregators. The insight for management: The link economy has both benefits and drawbacks for content creators and consumers.    Martin G. Kocher, Julius Pahlke, Stefan T. Trautmann Does haste make waste? The authors study the effects of time pressure on risky decisions for pure gain opportunities, pure loss opportunities, and mixed opportunities involving both gains and losses. They find that time pressure has no effect on risk attitudes for gains but increases risk aversion for losses. For mixed opportunities, subjects become simultaneously more loss averse and more gain seeking under time pressure, depending on the framing of the opportunities. The results suggest the importance of aspiration levels, and thus the overall probability to break even, under time pressure. The insight for management: Time pressure creates risk aversion for decisions surrounding losses.    Tao Li How is stock variability affected by differences among investors? Heterogeneity in beliefs and time preferences among investors make stock volatility stochastic, even though the volatility of the underlying dividend is constant. The Black–Scholes implied volatility surface, which depends on wealth distribution, investors' beliefs, and time preferences, exhibits observed patterns that are widely documented in various options markets. The author tests a model against weekly S&P 500 index options from January 1996 to April 2006. The model shows comparable performance to the stochastic volatility and jump model and outperforms the traders' rules and two no-arbitrage models (stochastic volatility, and stochastic volatility and stochastic interest rate) in terms of out-of-sample pricing errors. The insight for management: New modeling approaches capture the effect of shareholder differences on the volatility of stock option prices.","Label":"0"},{"DOI":"10.2118/22022-pa","Abstract":"Summary EOR projects, notably CO2 floods, are the next generation of recovery methods in the more mature west Texas waterfloods. Installing and operating a CO2 flood can be extremely expensive. In this paper, we discuss methods used to make several active CO2 floods more profitable by reducing operating costs and deferring investments.   Introduction Our goal in studying several active west Texas CO2 floods was to determine the optimum near-term cash flow, overall project economics (rate of return, present woth, etc.), and oil recoveries. We developed various CO2 flood designs with a reservoir simulator by altering specific operating parameters, including the half-cycle slug size, gas/water ratio (GWR), injection schemes, and total CO2 slug sizes. The resulting injection and production rates were then entered into an economic simulator to determine the most economical set of operating conditions. We also assessed the impact of various economic conditions - oil prices, CO2 prices, gas processing fees, and operating costs - on the optimization process. This was done to ensure that the optimum set of operating conditions did not change drastically should the economic environment change. This study shows how optimizing operations can significantly improve the economics of existing CO2 floods. An additional benefit of the study was insight gained on plant sizing and adjusting injection schemes to minimize or defer investments while maximizing the economics of new projects.   Background During the late 1970's and early 1980's, Amoco Production Co. committed significant manpower to evaluate the feasibility of full-scale CO2 flooding in west Texas. Before the feasibility work, Amoco undertook numerous CO2 pilots in various fields.1 Because of high crude prices, optimistic price forecasts (Fig. 1), and successful pilot recoveries, the future of CO2 flooding looked promising. The approach taken at the time was first to history match waterflood performance with an in-house black-oil simulator.2 The resulting reservoir description then was transferred to a streamline generating model and finally to a miscible streamtube model. The CO2 prediction was done at a single GWR with the CO2 injection slug size changed to find an optimum based on present worth. The reservoir simulation provided oil, gas, and CO2 production rates and CO2 injection rates for input into an economic model. Because of the man-hours and computer time involved in simulating the CO2 process, only a few GWR's were tried, with slug size as the main variable. In these early CO2-flood designs, CO2 reinjection was planned and a plant design was needed to remove H2S and hydrocarbons and to handle the peak predicted total gas production. Because of the single GWR being used, the gas rate was expected to increase to some peak and then decline, leaving excess plant capacity. This type of injection scheme impaired the economics because a large plant investment was needed at the beginning of the project. Unless there was an offset property feasible for CO2 flooding, the excess plant capacity went unused once the peak was past. The costs of plants and other investments were relatively high compared with today's environment because of high oil prices and high inflation rates. Most projects were still economical, however, because oil price forecasts were optimistic and tax relief from the Windfall Profits Tax was granted for EOR projects. One shortcoming of this early approach was the optimistic nature of the miscible streamtube model. Although this model adequately handled loss of miscibility, it was unable to regain it should the pressure rise above the miscible pressure. The model also was too efficient in areal sweep: the displacement was piston-like through the streamtube and all streamtubes were eventually swept for nearly 100% areal sweep efficiency. Injectivity losses also were handled inadequately in the streamtube model. Water hysteresis was accounted for, but solvent relative permeability effects3,4 were not. The miscible streamtube model also had limited ability to make changes in the pattern configuration and injection schemes. If such changes were to be made, the streamline generator had to be run again for entry into the miscible streamtube model. This was both time-consuming and costly. As a result of these model shortcomings, many economic sensitivities were run with various rate and reserve scenarios to become comfortable with the final CO2-flood design.","Label":"0"},{"DOI":"10.1017/s1365100504030202","Abstract":"The Encyclopedia Americana, 2002 edition, concludes its entry on Milton Friedman as follows: “His major work, A Monetary History of the United States, 1867–1960, was published in 1963.” That might be seen as an indirect compliment to Anna J. Schwartz, who coauthored the Monetary History with Friedman but is not mentioned in the encyclopedia entry. Similarly, the Nobel Committee neglected to mention Schwartz when, in awarding Friedman his Prize in 1976, it described A Monetary History as “[h]is major work [and] … one of Friedman's most profound and also most distinguished achievements.” Fortunately, the economics profession as a whole has not been so negligent, and the phrase “Friedman and Schwartz” has become second nature to economists when discussing the importance of monetary policy. Beside her collaborations with Friedman, Anna Schwartz is perhaps best known for her longevity, which is on an epoch-shattering scale. Her career as an economic researcher began a quarter-century before the publication of A Monetary History, and has continued in the 40 years since. Schwartz's first journal article was published in May 1940, the month Winston Churchill became Prime Minister of the United Kingdom and over 18 months before the United States entered World War II. She has worked at the National Bureau of Economic Research in New York City continuously since 1941. Monetary economics has been a constant interest for her, and she is the only person to have had items published in the inaugural issues of both the Journal of Money, Credit, and Banking (February 1969) and the Journal of Monetary Economics (January 1975).The JME piece was a book review, and so does not appear in the bibliography below. Schwartz's numerous book reviews make rewarding reading and include a prediction in Kyklos in 1968 of an era when economists would use Internet connections to download macroeconomic databases. The JME moved into its fiftieth volume in 2003, and Schwartz became one of only two authors (the other being Thomas Sargent) to have published in both volumes 1 and 50 of the journal. With the NBER branching out in the 1970's into a national network of researchers, Schwartz has been for a quarter century an unmistakable fixture at the NBER monetary economics program's regular meetings at Cambridge, Massachusetts. At the time of the interview, her contributions to the NBER's various working paper series spanned from NBER Technical Paper No. 4, 1947, to NBER Working Paper No. 9321, November 2002. The latter paper covered the issue of equity price behavior, the same subject of her 1940 publication, implying that Schwartz had entered a remarkable seventh decade of research in that area. Much of Schwartz's early research was on UK economic growth and fluctuations in the nineteenth century, and was reflected in a two-volume study essentially completed in the early 1940's but not published until 1953 [Gayer et al. (1953)]. Robert Lucas, who read the volume as a graduate student in history, describes it as “an amazingly ambitious and exciting mix of history and theory.” Schwartz's collaboration with Milton Friedman on the relationship between the quantity of money and other variables began in 1948. Their early findings on the importance of money were reported by Friedman in a 1952 American Economic Review paper, but, by and large, he had problems promoting their work in the 1950's. Friedman's solo work in the fifties on flexible exchange rates, the consumption function, and the limits of stabilization policy would cement his reputation and be cited in his eventual Nobel award, but the monetary policy studies initially made a much more limited impact. All of Friedman's remaining 1950's writings on money were in “in-house” University of Chicago publications or in congressional testimony.A short excerpt from a Journal of Political Economy paper by Friedman on money did appear in the 1959 proceedings issue of the American Economic Review. Two books by Friedman in the early 1960's previewed some findings from the monetary history project with Schwartz. The first of these, A Program for Monetary Stability, is now recognized as a classic, but its muted reception is evidenced by the fact that economists have never been able to agree on which year it was published. The second book, Capitalism and Freedom (1962), was intended for a wide audience, but was virtually driven underground when all major U.S. newspapers declined to review it. In 1969, a Federal Reserve Bank of New York official, Richard Davis, gave this perspective on reactions to early monetarist work of the 1950's and early 1960's: “[E]conomists regarded this group—when they regarded it at all—as a mildly amusing, not quite respectable collection of eccentrics…. The fact is that the view held by Friedman and others on the predominant importance of money was just not given serious attention by most economists.” The turning point was in 1963, when Friedman and Schwartz's 15 years of research finally saw print in their Monetary History and the article “Money and Business Cycles.” The Monetary History is justly celebrated, and has remained in print for 40 years.Furthermore, of the 93 books listed by Princeton University Press in its Economics and Finance Catalogue 2003, the Monetary History is the only pre-1994 publication included. The “Cycles” paper, as Davis acknowledged, provided “[b]y far the largest mass of evidence” on the cyclical relation between money and output. In addition, the paper's “tentative sketch” of the monetary transmission mechanism became a cornerstone of the monetarist literature, and an inspiration to many monetary economists, including the late Rudiger Dornbusch, as they endeavored to escape the “single interest rate channel” view of the transmission mechanism. Schwartz began the 1970's with another collaboration with Friedman, Monetary Statistics, and went on in 1973 to join a number of economists, including fellow monetarists Karl Brunner and Allan Meltzer, in forming the Shadow Open Market Committee (SOMC). The SOMC commented regularly on U.S. economic policy and, in particular, offered monetary policy recommendations to address the severe inflation problem of the 1970's. Schwartz remains on the SOMC 30 years later, the only founding member to serve since the SOMC's inception. Friedman and Schwartz's final major collaboration, Monetary Trends in the United States and the United Kingdom, was published in 1982. Among monetary economists, the response to Monetary Trends was mild compared to the reception for the Monetary History. Work by Friedman and Schwartz and other monetarists had already changed macroeconomic thinking substantially, and most academic work was now concerned with rigorous modeling of short-run dynamics, rather than the empirical evidence on long-run relations that concerned Friedman and Schwartz in their Trends study. Schwartz's own work over the past 20 years has been prolific, and has often been in collaboration with Michael Bordo, with whom she has written some 25 articles. While her areas of research have included banking regulation and the role of international financial institutions, Bordo's and her mutual interest in monetary economics and economic history has repeatedly been evident in their work. Among the issues that their studies, sometimes with further collaborators, have addressed are the role of monetary targets in Canada and the United Kingdom in the face of money demand instability, whether monetary policy rules could have avoided the Great Contraction, the historical record of alternative monetary policy regimes, and the history of economic thought, including the development of monetarism.","Label":"0"}]
